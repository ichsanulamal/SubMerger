

# 1 Introduction - 01 Managing risks.en.srt

- Hi, I'm Mike Chapple, and I'd like to welcome you to our SSCP Risk Identification, Monitoring, and Analysis course. The system security certified practitioner certification is a popular entry-level certification for information security professionals. Earning the SSCP certification requires passing an exam, covering seven different domains of information security. This course covers one of those domains, risk identification, monitoring, and analysis. This domain accounts for 15% of the questions on the exam. And this course is part of an eight-core series designed to prepare you for the SSCP exam. In this course, we'll be focusing on understanding the risk management process, performing security assessment activities, operating and maintaining monitoring systems, and analyzing monitoring results. The information you learn in this course will help you pass the SSCP exam and also provide a critical foundation for your career in information security. In addition to the information I cover in this course, I encourage you to visit my website at certmike.com and join my free SSCP Study Group. I'll send you exam tips, practice test questions, and reminders to help keep you on track with your test preparation. All right, let's get rolling. 

# 1 Introduction - 02 What you need to know.en.srt

- [Instructor] I've designed this series of SSCP courses with the beginner in mind. While you'll probably find it a little easier to complete this course and the SSCP certification if you have a technology background, that's not a requirement for taking the test, although you will need some experience to earn your certification. If you're looking to get started in cybersecurity, this course series will provide you with all the information you need. If you're a technology professional with some security work experience under your belt, this course series will help you fill in any gaps in your knowledge and build a solid foundation as you prepare to take the SSCP exam. 

# 1 Introduction - 03 Study resources.en.srt

- [Mike] The courses on this site contain all of the information that you'll need to pass the SSCP exam. I've worked with thousands of students over the years and helped them successfully pass this test. Along the way, I found that different people learn in different ways. And the best way to prepare for the exam is to use a diverse set of resources. In addition to these courses, there are three other study resources that I recommend to help you prepare for the exam. I've selected each of them with you in mind to help you learn the SSCP material, prepare for the test, and pass the exam on your first try. First, I recommend that you get a copy of the official SSCP study guide published by John Wiley and Sons. This book covers the same material that I discuss in this course and serves as an excellent reference as you prepare for the exam. I highly recommend having a copy by your side as you study. Second, David Seidl and I wrote the official SSCP practice tests book that contains hundreds of practice test questions, covering each of the SSCP domains as well as two full length practice tests to help you assess your knowledge. It's available in both Kindle ebook and paperback forums. Finally, I also recommend that you visit my website at certmike.com and sign up for my free SSCP study group. I'll send you emails to help keep you on track for the exam along with free practice tests, study tips, and other resources to help you get ready. If you visit certmike.com now and click the SSCP link, you'll be able to sign up for the free study group and I'll send you an email with links to resources that will help you pass the exam. 

# 2 Risk Management - 04 Risk assessment.en.srt

- [Instructor] Risks abound in the world of cyber security. From hackers and malware to lost devices and missing security patches, there's a lot on the plate of cybersecurity professionals. Now, of course, addressing each one of these risks takes both time and money. Therefore, cybersecurity professionals need to prioritize these risks in order to spend these precious resources where they will have the greatest security effect. That's where risk assessment comes into play. Risk assessment is the process of identifying and triaging the risks facing an organization based upon the likelihood of their occurrence and their expected impact on the organization. First, we need a common language. In everyday life, people often use the terms threat, risk, and vulnerability interchangeably, but these are actually three very different concepts. A threat is some external force that jeopardizes the security of your information and systems. Threats might be naturally occurring, such as hurricanes and wildfires, or man-made such as hacking and terrorism. You can't normally control what threats are out there. They exist independent of your organization. Now, there is one related term that you should know for the exam. A threat vector is the method that an attacker uses to get to your target. This might be a hacker toolkit, social engineering, or physical intrusion. Vulnerabilities are weaknesses in your security controls that a threat might exploit to undermine the confidentiality, integrity, or availability of your information or systems. Vulnerabilities might include missing patches, promiscuous firewall rules, or other security misconfigurations. You do have control over the vulnerabilities that exist in your environment and as security professionals, we spend much of our time hunting down and remediating vulnerabilities. Risks occur when your environment contains both a vulnerability and a corresponding threat that might exploit that vulnerability. For example, if you haven't updated your antivirus signatures recently and hackers release a new virus on the internet, you face a risk. You're vulnerable because you're missing a security control and there is a threat, the new virus. There is no risk if either the threat or the vulnerability factor is missing. For example, if you live in an area far from the coast, it doesn't matter if your building is vulnerable to hurricanes because there isn't any threat of a hurricane in your region. Similarly, if you store your backup tapes in a fireproof box, there isn't any risk from a building fire because your storage container isn't vulnerable to fire. And once you've identified the risks facing your organization, you probably still have a somewhat overwhelming list. The next stage in the process of risk assessment ranks those risks by two factors, their likelihood and their impact. The likelihood of a risk is the probability that it will actually occur. For example, there is a risk of earthquake in both and Wisconsin. However, when you look at the data, you find that the probability of an earthquake occurring is far higher in California, where almost 5,000 significant earthquakes occurred over the last 25 years. During that same time, Wisconsin didn't experience a single major earthquake. Therefore, risk managers in California might have to be hypervigilant about the risk of earthquakes while those in Wisconsin can probably ignore that risk. The impact of a risk is the amount of damage that will occur if the risk materializes. For example, an earthquake might cause devastating damage to a data center while a rainstorm might not cause any damage at all. When we perform risk assessments, we have two different categories of technique that we can use to assess the likelihood and impact of a risk: qualitative techniques and quantitative techniques. Qualitative techniques use subjective judgment to assess risks, typically categorizing them as low, medium, or high on both the likelihood and impact scales. Quantitative techniques use objective numeric ratings to assess likelihood and impact. Here's an example of a qualitative risk assessment chart. When considering a specific risk, the assessor first rates the likelihood as low, medium, or high, and then does the same for the impact. The chart then categorizes the overall risk. For example, a high probability, high impact risk would be categorized as a high risk overall, while a medium probability, low impact risk would have an overall rating of low. I'll cover the second risk assessment technique, quantitative risk, in the next video. 

# 2 Risk Management - 05 Quantitative risk assessment.en.srt

- [Instructor] When we're able to gather quantitative data about our assets and risks, we can use that information to make data-informed decisions about risk. The process of using numeric data to assist in risk decisions is known as quantitative risk management. Security professionals performing a quantitative risk assessment do so for a single risk asset pairing at a time. For example, they might conduct an assessment based upon the risk of flooding to a data center. As they conduct the assessment, they must first determine the values for several variables. The first of these is the asset value, or AV. This is quite simply the estimated value in dollars of that asset. Risk assessors determining an asset's value have several options available to them. The original cost technique simply looks at the invoices from an asset purchase and uses those purchase prices to determine the asset value. This is the easiest technique to perform because it simply requires looking at those invoices. However, it's often criticized because the cost to actually replace an asset may be significant higher or lower if asset prices have changed since the purchase. The depreciated cost technique is an accounting favorite. This approach begins with the original cost of the asset and then reduces its value over time as the asset ages. The depreciation technique uses an estimate of the asset's useful life and then gradually decreases the asset value until it reaches zero at the end of its projected life span. Replacement cost technique is the most popular among risk managers because it produces results that most closely approximate the actual costs that an organization will incur. It goes out and looks at current supplier prices to determine the cost of replacing an asset in the current market and then uses that cost as the asset's value. We might use this technique to value our data center at $20 million because that's the amount of money that would be required to rebuild it after a disaster. The second variable that we must consider is the exposure factor, or EF. The exposure factor is based upon the specific risk considered in the risk assessment, and it estimates the percentage of an asset that will be damaged if that risk materializes. For example, if we expect a flood might damage 50% of our data center, we'd set the exposure factor for a flood to 50%. The next variable is the single-loss expectancy, or SLE. This is the actual damage that we expect to occur if a risk materializes one time. We compute the SLE by multiplying the asset value by the exposure factor. So if we have a data center valued at $20 million and we expect that a flood would cause 50% damage to the facility, we compute our SLE by multiplying these two numbers together, finding that a single flood would cause $10 million in damage. That's the impact of the risk. Now, the SLE only gives us an idea of impact. As you know, risk assessment must also consider the likelihood of a risk. That's where the annualized rate of occurrence, or ARO, comes into play. The ARO is the number of times each year that we expect a risk to occur. Now, in the case of a flood, we might consult FEMA flood maps to determine that there's a 1% annual risk of flood in the vicinity of our data center. That's the same as saying that we expect 0.01 floods to occur each year. So our ARO is 0.01. Now, our risk analysis needs to incorporate both of these likelihood and impact values. We do this by computing the annualized loss expectancy, or ALE. The ALE is the amount of money we expect to lose each year from that risk asset pairing. And it's a good measure of overall risk. We compute the ALE by multiplying the single loss expectancy and the annualized rate of occurrence together. In the case of that flood risk to our data center, the SLE was $10 million and the ARO was 0.01. Multiplying these together, we get an annualized loss expectancy of $100,000. We expect to lose $100,000 each year from the risk of flooding to our data center. Now, it's important to remember that that cost won't occur every year. In reality, we'll have $10 million of damage each time a flood occurs. But we only expect that to happen once every 100 years. So that averages out to $100,000 per year. Now that's how you perform a quantitative risk analysis. You should definitely memorize these formulas and be prepared to compute them on the exam. Quantitative techniques also help us assess our ability to restore IT services and components quickly in the event of a failure. We do this by looking at several time values. The values we use depend upon whether an asset is repairable or nonrepairable. That is, whether we can fix it or whether it needs to be replaced. For nonrepairable assets, those that we cannot fix, our most important metric is the mean time to failure. That's the amount of time that we expect will pass before an asset fails. When using mean values, it's important to remember the meaning of average. Half of the assets of that type will fail before the MTTF, and half will last longer than the MTTF. Mean values are useful for planning purposes, but they shouldn't be completely depended upon. If our asset is repairable, we look at two different values. The first is the mean time between failures, or MTBF. Now, that's quite similar to the MTTF. It's simply the average amount of time that passes between failures of a repairable asset. The second value that we track for repairable assets is the mean time to repair, or MTTR. This is the amount of time that an asset will be out of service for repair each time that it fails. When we look at the MTTR and MTBF values together, we can get a good idea of the expected downtime for an IT component. 

# 2 Risk Management - 06 Risk management.en.srt

- [Instructor] Once you complete a risk assessment for your organization, you're left with a prioritized list of risks that require your attention. Risk management or risk treatment is the process of systematically analyzing potential responses to each risk and implementing strategies to control those risks appropriately. No matter what risk you're managing, you have four basic options for addressing the situation: You can perform risk avoidance, risk transference, risk mitigation, or risk acceptance. And when you avoid a risk, you change your organization's business practices so that you're no longer in a position where that risk can affect your business. In the last video, we performed a risk assessment of the risk that flooding posed to an organization's data center. If we chose to pursue a risk avoidance strategy for that risk, we might relocate our data center to a facility where there is no risk of flooding. Transferring a risk attempts to shift the impact of a risk from your organization to another organization. The most common example of risk transference is an insurance policy. Many organizations are now considering the purchase of cybersecurity insurance policies to protect against the financial damage caused by hackers and identity theft. It's important to remember, however, that you can't always transfer a risk completely. For example, you can purchase insurance to cover the financial damage caused by a security breach, but no insurance policy can repair your business's reputation in the eyes of your customers. In our flood risk example, we might choose to transfer the financial risk of our data center flooding from our organization to an insurance company by purchasing flood insurance. Risk mitigation takes actions designed to reduce the likelihood and/or the impact of a risk. If we wanted to mitigate the risk of our data center flooding, we might engage a flood control specialist to install systems designed to divert water away from our facility. In almost every risk assessment, managers find themselves confronted with a very long list of risks and inadequate resources to avoid, transfer or mitigate all of them. For business reasons, they must accept some of those risks. Now, risk acceptance should only take place as part of a thoughtful analysis that determines the cost of performing another risk management action outweighs the benefit of controlling that risk. In our flooding scenario, we might conclude that all of the other risk management options are too costly and decide to continue operations in our current facility as is, and deal with the aftermath of a flood if it occurs. Now, one important note. Accepting a risk is not the same thing as ignoring a risk. Ignoring a risk is when management sticks its head in the sand and chooses not to do anything about a risk without going through a formal risk acceptance process. When risks are ignored, it's a risk management failure. Every organization must choose the appropriate mix of these risk management strategies for their own technical and business environment. The combination of risks that affect an organization are known as its risk profile, and the organization adopts risk management strategies to address the risks in that profile. The initial level of risk that existed in an organization before any controls are put in place is the organization's inherent risk. Then controls are applied to reduce that risk. But of course not every risk can be completely eliminated. The risk that remains after the inherent risk is reduced by controls is known as the residual risk. And controls themselves may introduce some new risk. For example, if you install a firewall as a risk management control, that may reduce your risks substantially, but it also adds a new risk that the firewall itself may fail. That new risk that results from adding controls is known as the control risk. Now, the reality is that the organization will need to accept some ongoing risk in order to continue operations. Business leaders must decide how much risk they choose to accept. This is a process known as determining the organization's risk tolerance or risk appetite. The goal of risk management is to make sure that the combination of the residual risk and the control risk is below the organization's risk tolerance. 

# 2 Risk Management - 07 Ongoing risk management.en.srt

- [Presenter] Implementing security controls is only the beginning of the risk management journey. Security professionals must perform a variety of ongoing activities to ensure that risks remain properly managed. These include monitoring and assessing controls, measuring control effectiveness, reporting and continuous improvement. Risk control assessments represent a point in time analysis of the risks facing an organization and the ability of controls to manage those risks properly. These assessments may be completed as self-assessments by an internal security team, or as external assessments by a consultant or auditor. The risk environment changes on a regular basis. An organization should routinely review those risk assessments and perform periodic control assessments designed to test the correct functioning and effectiveness of their security controls. For example, most organizations use a firewall to block unwanted network traffic. A control assessment of the firewall might use network scanning tools to verify that it is not allowing any unwanted traffic through the perimeter. Organizations should also conduct routine measurement of the effectiveness of their security controls and use this information to inform management reporting. These routine activities should include both technical control reviews and operational control reviews. For example, an organization might track the number of compromised end-user accounts as a means to evaluate the effectiveness of anti-phishing controls. They might also track the number of vulnerabilities detected in public-facing systems as a way to evaluate the effectiveness of operating system and application patching. Organizations seeking to assess the security knowledge and skills of software developers might use the number of critical findings from initial scans of new web applications. And finally, organizations might use the number of data breaches requiring notification of individuals as a measure of the overall effectiveness of their security program. All of these measures provide valuable information to management as they seek to refine their cybersecurity strategies and programs. All security programs should embrace a spirit of continuous improvement that seeks to enhance controls and improve the overall state of information security in the organization over time. The results of control effectiveness measures, risk assessments and expert knowledge should feed this improvement process. 

# 2 Risk Management - 08 Risk management frameworks.en.srt

- [Instructor] Risk management is a complex topic, and fortunately, organizations don't need to design their own risk management processes from the ground up. Risk management frameworks provide proven, time-tested techniques for performing enterprise risk management. One of the most widely used risk management frameworks was developed by the National Institute of Standards and Technology, a US federal government agency. The NIST process is mandatory for many government computer systems, but private organizations have also widely adopted this approach because they find it helpful. The framework is found in NIST special publication 800-37. This document runs over 60 pages and includes great detail on the framework that's good reading for anyone involved in risk management. The publication is available for free on NIST's website. For our purposes, an overview of the six steps in the process will be more than enough to prepare for the exam. This diagram shows the six steps involved in managing risk according to NIST. Before beginning the process, the organization should gather information in two different categories. The first set of information involves the technology architecture, and it includes reference models, technical details, business process information, and information system boundaries. The second input to the process is organization specific information, including the laws, regulations, and policies that apply, the strategy of the organization, its priorities, resource availability, and supply chain information. Now after gathering all this information, the organization enters step one of the risk management framework. In this step, it categorizes the information system being assessed as well as the information stored, processed, and transmitted by that system. This is normally done by performing an impact assessment. In step two, the organization selects the security controls that should be used to manage risks to the information system. This is based upon the systems categorization from step one. Now the organization will likely begin with a standard baseline of controls and then add or subtract specific controls to tailor the specification to the system's needs. After selecting the controls, the organization moves to step three, where it implements the selected controls. And then in step four, the organization performs a control assessment to determine whether the controls were correctly implemented, operate correctly, and meet security requirements. After this assessment is complete, the organization enter step five where it authorizes operation of the information system. In the federal government authorization is a very formal process where a senior government official must accept any remaining risks. Once a system is authorized and running, we move to step six of the assessment where the organization monitors the security controls on an ongoing basis to ensure their continued effectiveness and respond to any environmental changes. If this monitoring detects significant issues, the cycle may begin again at step one. While the NIST risk management framework is very popular, it's not the only approach to risk management. The International Organization for Standardization also offers a risk management framework in a document called ISO 31000. This is a similar process, but it divides the steps differently. The activities in the ISO 31000 process are risk identification, risk analysis, risk evaluation, risk treatment, establishing the context, monitoring and review, and communication and consultation. Your organization may choose to adopt the NIST risk management framework or the ISO 31000 process directly, or to develop your own process based on these concepts. 

# 2 Risk Management - 09 Risk visibility and reporting.en.srt

- [Instructor] Cybersecurity teams have a wide variety of risk identification, assessment, and management tools at their disposal. You've already learned about many of them in this course. Risk visibility and reporting techniques ensure that the results of these risk management processes are clearly documented and tracked over time. The core tool that most organizations use for maintaining ongoing visibility into risks is a risk register. The risk register is a centralized document that tracks information about the nature and status of each risk facing the organization. Risk registers may be used on an organization-wide basis or they may be used to track the risks associated with a single project or subject domain. In some cases, risk registers may be referred to as risk logs. Now, risk registers vary from organization to organization, but they typically contain the following types of information: a description of each risk, a categorization scheme used to group the risks into similar segments, the results of a risk assessment including the probability and impact of the risk, and a risk rating calculated by multiplying the probability and impact scores. The risk register may also include actions taken to manage a risk, including specific risk mitigation steps that are either completed or in progress. Here's an example of a risk register that I helped develop with a group called EDUCAUSE. It's a tool used to help higher education IT organizations manage high-level technology risks facing their institutions. It includes quite a few risk statements covering many different domains of technology and the different types of risks that the organization may face. For example, this risk here in number 17 says that information technology communications and networks might not be protected from complete or intermittent failure. It goes on to explain some possible causes of that risk and the impact that it might have on the organization. Then it provides institutions with the ability to rate that risk based on its likelihood and impact. So for example, if I think this is a likely risk, I might assign it a value of three for high. And if it would have a moderate impact on the organization, I might give it a value of two. Then we have a risk score computed by multiplying the likelihood and impact together and we see that three times two is six. That's just one example of a risk register, one of the many IT risks facing an organization. Every organization should develop its own register, maybe based on some of these common templates, but identifying the specific risks facing their organization. When developing that risk register, the organization has many sources of information available to help populate the register with risks. These include the results of formal risk assessments conducted by the organization, audit findings identified by internal and external auditors, risks identified by members of the IT or planning team, and threat intelligence contributed by third parties. Threat intelligence is playing an increasingly important role in many organizations' efforts to maintain visibility into the risks that they face. By sharing threat intelligence, organizations may pool their knowledge to help combat external threats either by purchasing a threat intelligence service from a vendor or by joining a threat intelligence sharing consortium. Threat intelligence sharing efforts provide an anonymized way for organizations to communicate with each other about the nature and characteristics of attacks that they may experience. Threat intelligence information may be used to monitor risk trends in a general way, or it may be used operationally to create, for example, a black list of IP addresses known to be the source of attacks. Today's cybersecurity environment is complex with many different risks facing the organization. The use of risk registers, threat intelligence, and similar solutions helps organizations maintain visibility into these risks as they seek to manage them. Now, the risk register is a lengthy document that often provides too much detail for business leaders. When communicating risk management concepts to senior leaders, risk professionals often use a risk matrix or heat maps such as the one shown here. This approach quickly summarizes risks and allows senior leaders to quickly focus on the most significant risks facing the organization. 

# 3 Threat Modeling - 10 Threat intelligence.en.srt

- [Instructor] Threat intelligence is a critical component of any organization's cybersecurity program, allowing the organization to stay current on emerging cybersecurity threats. Broadly defined, threat intelligence consists of the set of activities that an organization undertakes to educate itself about changes in the cybersecurity threat landscape and integrate information about changing threats into its cybersecurity operations. There is a ton of information available online about cybersecurity threats. In fact, you could probably make a full-time job out of reading about cybersecurity. Most of us don't have time to read all day, but every security professional should take the time to remain current on our field, gathering information from freely available public sources is known as open-source intelligence. Some of the more common sources of open-source intelligence include security websites, vulnerability databases, the general news media, social media, information published on the dark web, public and private information sharing centers, file and code repositories, and security research organizations. Some techniques are fairly straightforward and can be used by adversaries as well as corporate security teams. For example, an adversary can develop a list of targets for social engineering attacks by conducting email harvesting, where they searched the web for valid email addresses from the targets domain, and then use those addresses to send out phishing attacks. Coming through all of this open source intelligence can be very time-consuming and many organizations simply don't have the time to invest in reading through this data and mining it for critical intelligence nuggets. An entire threat intelligence industry has sprung up to support these companies with closed-source and proprietary threat intelligence products that use predictive analytics. These products range from information briefs that summarize critical security issues to IP reputation services that provide real-time information about IP addresses engaged in cybersecurity threat activities. Organizations may send these feeds directly to firewalls, intrusion prevention systems and other security tools, and use them to block access from suspect IP addresses in real-time. Some security organizations even publish real-time threat maps on their websites that allow you to visualize the attacks that they're detecting. Now, these are more marketing gimmick than useful security tool, but they sure are fun to watch. With all of these different information sources available to you, you should take the time to evaluate how well each one fits into your security program. You can use three important criteria to evaluate a threat intelligence source. The first is timeliness. How soon after a new threat arises or evolves? Will the threat intelligence source reflect this new information? The second is accuracy. Is the information reported by the threat intelligence source correct? And finally, threat intelligence sources should be reliable. This means that they should consistently deliver a timely and accurate intelligence in a way that meets your business needs. 

# 3 Threat Modeling - 11 Managing threat indicators.en.srt

- Threat information management tools simplify the processing of threat information. One of the most important elements of threat data are threat indicators. These are pieces of information that make it possible to describe or identify a threat. For example, threat indicators might include IP addresses, malicious file signatures, communications patterns, or other identifiers that analysts can use to identify a threat actor. Threat information is only useful if we're able to share it among collaborators. We'll talk more about threat information sharing techniques in the next video, but for now, let's focus on mechanisms. If I detect a threat on my network, and I want to tell other like-minded security folks about that threat, how do I do so? And how can I do it in an automated fashion? If we don't all speak the same language, that information sharing becomes difficult. Fortunately, we have several frameworks at our disposal to help with this task. The Cyber Observable eXpression or CybOX framework, provides a standardized schema for categorizing security observations. CybOX helps us understand what properties we can use to describe intrusion attempts, malicious software, and other observable security events when we're trying to explain them to other people. The Structured Threat Information eXpression or STIX, is a standardized language used to communicate security information between systems and organizations. STIX takes the properties of the CybOX framework and gives us a language that we can use to describe those properties in a structured manner. And the Trusted Automated eXchange of Indicator Information or TAXII, is a set of services that actually share a security information between systems and organizations. TAXII provides a technical framework for exchanging messages that are written in the STIX language. STIX, TAXII and CybOX work together and they're part of a community driven effort facilitated by the US Department of Homeland Security. You can see here on the DHS website a visual description of how these three standards fit together. CybOX provides the schema that we can use to classify different threats. CybOX is used to define the information elements that we can then represent using the language of STIX. We can then exchange STIX formatted threat information using TAXII. OpenIOC is another framework for describing and sharing security threat information that was originally developed by FireEye's Mandiant security team. Here's an example of the OpenIOC framework being used to describe a security threat. We can see here that this indicator is describing a file called Evil.exe that's malicious code used as a financial threat. If we scroll down to the definition, we can see that the indicator here is a service named MS latent time services, where the DLL file contains evil.exe, or there is a file named bad.exe that is between 4,096 and 10,240 bytes in length. Hopefully you can see here how this information could be very useful as threat intelligence. As we're trying to make this information useful, the best way to do that, is to make sure that the security tools we use are able to both generate and consume threat indicators in the same format. By automating the exchange of threat information between devices, we simplify the work of security analysts and improve the effectiveness of our own security work. 

# 3 Threat Modeling - 12 Intelligence sharing.en.srt

- [Instructor] You just learned about some of the technology used to share threat intelligence information between systems in your organization. These included TAXII, STIX, and CyBox. These technologies really shine when you're able to use them to share information with your peers in other groups within your organization and at other organizations. Take a moment to think about the different business functions that would benefit from threat intelligence information within your own organization. You may have a variety of supported functions where threat intelligence sharing would add value, such as incident response teams who are tasked with actively responding to security incidents. Vulnerability management teams who must identify potential weaknesses that could lead to future incidents. Risk management teams who must understand the big picture of cybersecurity risk. Security engineering teams who must design controls to combat emerging threats. And detection and monitoring teams, such as the security operations center, who are responsible for actively monitoring the security environment for threat indicators. Technology frameworks for threat intelligence allow the automated sharing of information between the tools and systems used by each of these functions. Information becomes even more powerful when shared in a collaborative manner across different organizations. To facilitate this work, information sharing and analysis centers, or ISACs, bring together cybersecurity teams from competing organizations to help share industry-specific security information in a confidential manner. The goal of the ISACs is to gather and disseminate threat intelligence without jeopardizing anonymity. It's a safe way for competitors to cooperate. Here's a listing of the various ISACs that exist. As you look through it, you'll see that there are many crossing very different industries. There's an automotive ISAC, an aviation, communications ISAC. There's one for the defense sector, even ones as specific as covering natural gas and elections. Almost every industry has at least one ISAC that covers its operations. ISACs are usually non-profit organizations and as such are quite cost-effective. If you're active in cybersecurity, you should seek out the ISAC for your industry and join their information sharing efforts. 

# 3 Threat Modeling - 13 Identifying threats.en.srt

- [Instructor] Organizations face many different kinds of threat. And it's often difficult to keep track of all these threats and identify those that pose the greatest risk. Security professionals use threat modeling techniques to identify and prioritize threats, and assist in the implementation of security controls. When identifying potential threats to an organization, security professionals should use a structured approach. Don't just sit down and start thinking of all of the things that could go wrong. It's too easy to leave things out with this type of haphazard approach to threat identification. Instead, conduct a structured walkthrough of the potential threats to information and systems. Let's look at three ways that an organization can use a structured approach to threat identification. First, an organization can use an asset focused approach. In this approach, analysts use the organization's asset inventory as the basis for their analysis and walkthrough, asset by asset, identifying the potential threats to that asset. For example, when they get to the organization's web presence, they might identify the severing of a single fiber optic cable as a threat to the continued availability of the website. Second, an organization can use a threat focused approach. Using this method, the organization thinks of all of the possible threats out there, and then thinks through how those threats might affect different organizational information systems. For example, they might list the threat of a hacker and then think through all the ways that a hacker might try to gain access to their network. Threats to an organization may include a wide spectrum of groups ranging from known adversaries, to contractors, trusted partners, and even rogue employees. This approach seeks to understand the capability of our adversary. Finally, an organization can use a service focused approach. This is most commonly used by service providers who offer services over the internet to other organizations. For example, an organization that exposes an API to the public might think through all the interfaces offered by that API and the threats that could affect each interface. The identification of all the threats facing an organization is the first step in the threat modeling process. 

# 3 Threat Modeling - 14 Automating threat intelligence.en.srt

- [Instructor] Threat intelligence is one of the areas where automation can provide tremendous benefits. Let's take a look at a few examples. One of the most useful security automations that an organization can easily adopt is the automated blacklisting of IP addresses reported by threat intelligence services as the source of malicious activity. These threat intelligence services often include a direct feed of IP addresses that's updated in real time as malicious activity is detected across their client's networks. These threat feeds are designed for direct integration with firewalls, intrusion prevention systems, routers, and other devices with the capability of automatically blocking traffic. Technologists are often worried about deploying any tool that automatically blocks traffic, and this is a legitimate operational concern. For this reason, organizations considering this automation should first deploy the threat intelligence feed in alert only mode to identify traffic that would be blocked by the rule for further investigation by cybersecurity analysts. After the team becomes confident in the accuracy of the service, they may then move to an automated blocking strategy. If you receive threat feeds from a variety of sources, you can also use automation to combine the information received from those feeds into a single stream of intelligence. Incident response is another one of the rapidly emerging areas of automation as security teams seek to bring the power of automation to what is often the most human-centric task in cybersecurity, investigating anomalous activity. While SIEM automation and other security tools may trigger an incident investigation, the work of the incident responder from that point forward is often a very manual process that involves the application of tribal knowledge, personal experience and instinct. While incident response will likely always involve a significant component of human intervention, some organizations are experiencing success with automating portions of their incident response programs. One of the best starting points for incident response automation involves providing automated incident response data enrichment to human analysts, saving them the tedious time of investigating routine details of an incident. For example, when an intrusion detection system identifies a potential attack, a security automation workflow can trigger a series of activities. These might include performing reconnaissance on the source address of the attack, including IP address ownership and geolocation information. It might also include supplementing the initial incident report with other log information for the targeted system based upon a SIEM query. We also might trigger a vulnerability scan of the targeted system that's designed to assist in determining whether the attack had a high likelihood of success. All of these actions can take place immediately upon detection of the incident and be appended to the incident in the tracking system for review by a cybersecurity analyst. Teams seeking to implement incident response data enrichment will benefit from observing the routine activities of first responders and identifying any information gathering requirements that are possible candidates for automation. Security orchestration, automation, and response, or SOAR, platforms automate the routine work of cybersecurity by enhancing our existing SIEM technology to facilitate these automated responses. Machine learning and artificial intelligence open up a whole new world of automation possibilities. For example, if cybersecurity analysts detect a new strain of malware, they can use automated malware signature creation tools to scan executable files for unique characteristics that might be used in a signature definition file. 

# 3 Threat Modeling - 15 Threat hunting.en.srt

- [Instructor] The cyber security threat landscape has shifted significantly over the past few years. Those of us who have been around the security field, for a while, remember the days when we saw our primary role as building solid defenses that would prevent cyber intrusions from happening in the first place. Today, we'd consider it naive to believe that we could prevent every possible type of attack from occurring. We know that today's threat landscape includes sophisticated attackers who have the resources and time available to bypass many of the security controls that we put in place to defend our organizations. Our base assumption has necessarily changed. Instead of thinking that we can defend against every possible attack, we now take a view known as the assumption of compromise. If we accept it, as a given, that attackers may have already established a foothold on our networks, we now have the responsibility to search out and eliminate those compromises. That's where threat hunting comes into play. Threat hunting is an organized, systematic approach to seeking out indicators of compromise on our networks. Threat hunters use a combination of time tested security techniques and new predictive analytics technology to track down signs of suspicious activity and conduct thorough investigations. Google Trends shows us how interest in threat hunting grew rapidly. We didn't really see a lot of searches for the term threat hunting before 2016, but then Google searches took off quickly as organizations adopted this new approach. When we begin a threat hunting endeavor, we need to shift our mindset from a defense-focused way of thinking to an offense-focused approach. We need to think like the attackers who target our systems. When we conduct threat hunting, the first thing that we need to do is establish a hypothesis. That's simply saying to ourselves, here's a way that an attacker might get into our organization. We might establish our hypothesis based upon profiling of threat actors and their activities, based on threat feeds, or even on vulnerability advisories or bulletins. In some cases, we might conduct intelligence fusion that brings many of these diverse sources together. Once we've established our hypothesis, we think of the indicators of compromise that might be associated with that hypothesis. These indicators could be anything unusual. For example, they might include unusual binary files stored on a system, including those with known malicious content, unknown content, or unexpected modifications, or an indicator might be an unexpected process running on a system, or the unusual consumption of resources by a system process. Or we might find the presence of unexpected accounts, within systems and applications, or unusual permissions assigned to those accounts. We might find deviations in network traffic patterns, unexplained log entries, or configuration changes made to systems, applications, and devices that don't correspond with our change tracking process. Searching for these indicators is the core work of threat hunting. We can improve our detection capabilities by integrating our own threat intelligence efforts with third party threat intelligence products and data collected by our SIM. It's also helpful if we can bundle critical assets in our analysis tools to help us quickly highlight indicators that appear on our most important systems. Once we discover indicators that appear to show a compromise, we can then move into our standard incident response process. We look for signs of how the attacker might have maneuvered through our network, and we begin the process of containment, eradication, and recovery. 

# 4 Understanding Vulnerability Types - 16 Vulnerability impacts.en.srt

- [Lecturer] Vulnerabilities in our infrastructure, systems and applications expose our organizations to the risk of a security breach. Before we explore vulnerabilities in detail, let's spend some time reviewing the goals of cybersecurity and the types of risks that can occur in an organization. When we think of the goals of information security, we often use a model known as the CIA triad shown here. The CIA triad highlights the three most important functions that information security performs in an enterprise, confidentiality, integrity and availability. Confidentiality ensures that only authorized individuals have access to information and resources. This is what most people think of when they think about cyber security, keeping secrets away from prying eyes and confidentiality is in fact, how security professionals spend the majority of their time. Malicious individuals seeking to undermine confidentiality are said to engage in disclosure, making sensitive information available to individuals or the general public without the owner's consent. When this type of data loss occurs, we refer to the situation as a data breach. We also use the term data exfiltration, to describe the act of removing sensitive data from an organization's systems and networks. Security professionals are also responsible for protecting the integrity of an organization's information. This means that there aren't any unauthorized changes to that information. These unauthorized changes may come in the form of a hacker seeking to intentionally alter information or a service disruption accidentally affecting data stored in the system. In either case, it's the information security professional's responsibility to prevent these lapses in integrity. The final goal of information security is availability. Ensuring that authorized individuals are able to gain access to information when they need it. If users can't access important business records or systems, that lack of availability may have a profound impact, on the business. Malicious individuals seeking to undermine availability, engage in attacks, known as denial of service attacks. These attacks try to either overwhelm a system or cause it to crash, therefore denying legitimate users, the access that they need. The impacts of a security incident may be wide ranging depending upon the nature of the incident and the type of organization affected. We can categorize the potential impact of a security incident using the same categories that businesses generally use to describe any type of risk. Financial risk is, as the name implies, the risk of monetary damage to the organization. This might include the costs of restoring damaged equipment and data, conducting an incident response investigation or notifying individuals that their data was stolen and that they are now vulnerable to identity theft. Reputational risk occurs when the negative publicity surrounding a security breach causes the loss of goodwill among customers, employees, suppliers, and other stakeholders. It's often difficult to quantify reputational damage. As these stakeholders may not come out and directly say that they will reduce or eliminate their volume of business with the organization, as the result of a security breach. But the reality is that the breach may still have an impact on their future decisions about doing business with your organization. Strategic risk is the risk that an organization will become less effective in meeting its major goals and objectives, as the result of a breach. Suppose that you experienced a security incident, where one employee loses a laptop that contains new product development plans. This incident may pose strategic risk to the organization, in two different ways. First, the organization doesn't have another copy of those plans, they may be unable to bring the new product to market or may suffer significant product development delays. Second, if competitors gain hold of those plans, they may be able to bring competing products, to market more quickly, or even beat the organization to market, gaining first mover advantage. Operational risk is the risk to the organization's ability to carry out its day to day functions. Operational risks may slow down business processes, delay delivery of customer orders, or require the implementation of time-consuming manual workarounds to normally automated practices. Compliance risk occurs when a security breach causes an organization to run a foul of legal or regulatory requirements. For example, the health insurance portability and accountability act, HIPAA, requires that healthcare providers and other covered entities protect the confidentiality, integrity and availability of protected health information. If a hospital loses patient medical records, they run a foul of HIPAA requirements and are subject to sanctions and fines, from the US Department of Health and Human Services. That's an example of the compliance risk. As you conduct vulnerability analysis, you should keep all of these different types of risk in mind and use them to assess the potential impact, that an attacker exploiting a vulnerability, might have on your organization. 

# 4 Understanding Vulnerability Types - 17 Supply chain vulnerabilities.en.srt

- [Instructor] Every IT organization depends upon hardware, software and services provided by outside vendors. Whether that comes in the form of server operating systems, database platforms, applications, managed services, or other technologies, administrators must understand how security issues arising in the supply chain can impact their organizations. One of the most important vendor-related issues that security professionals must monitor are the end-of-life announcements made by vendors about products used within the organization. Every security professional knows that patch management is an incredibly important security issue and staying current on patches protects systems against the many new vulnerabilities that are discovered each year. When a vendor announces the end of life of a product, they are announcing that they will eventually no longer provide patches for that product even when new vulnerabilities are discovered. This makes it very difficult, if not impossible, to run that product in a secure manner. There's a lot of different terminology out there around end of life of a product and the exact definitions of terms vary from vendor to vendor. Let's talk about three common phrases used to describe how vendors end support for products, but you should recognize that these terms may be used differently by different vendors. The first step in ending a product's lifecycle is often an announcement of the product's end-of-sale. This simply means that the vendor will no longer offer the product for sale, but will continue to support existing customers. Next, the end-of-support announcement provides the date that the vendor will discontinue some level of product support. This announcement may be the actual end of all support for the product, or it may be the date that the vendor will stop correcting non-security issues or providing minor enhancements. When you hear about an end-of-support announcement for a product that you use, read it carefully to understand its impact on your organization. Operating legacy products runs the risk of introducing unpatchable vulnerabilities into your environment. Eventually, every product reaches the end-of-life stage where the vendor no longer supports it at all and will not release any updates, even for critical security issues. They will also no longer answer support questions other than helping customers upgrade to a more current version of the product. You should stay current on the support status of all products used in your organization by monitoring vendor announcements. For example, Cisco provides this website that summarizes all of the end-of-sale and end-of-life announcements for Cisco products in one location. In addition to well-planned end-of-support processes, vendors sometimes simply fail to provide adequate support for their products because they are understaffed or not committed to a product. This informal lack of vendor support can be just as dangerous as running an unsupported product, but much more difficult to detect. The risk is compounded if the vendor system is integrated with other components of your operating environment. Vendors may use embedded systems as components of their products that are not visible to you as the end customer. For example, a digital sign system may run on a version of the Linux operating system that's completely hidden from end-users. If a vulnerability arises in that Linux version, the digital sign system may be open to attack. In these cases, customers of the end product typically do not have access to upgrade the embedded systems, but they must rely upon vendors to provide the needed security updates. If you depend upon vendors to supply your organization with cloud services, the risk profile changes. The vendor becomes responsible for managing many risks on your behalf, and you must have confidence that the vendor is living up to that responsibility. You also need to ensure that you're confident that the vendor will remain an ongoing, viable business concern. If you use vendors for data storage, consider the risks associated with the vendor being unable to provide you with access to your data at some point in the future. You may wish to mitigate this risk by keeping backups in a secondary operating environment that's independent of your primary vendor. The use of vendors is unavoidable in modern IT environments. Cybersecurity professionals must monitor their vendor relationships to ensure that they don't jeopardize the security of their organization's operating environments. 

# 4 Understanding Vulnerability Types - 18 Configuration vulnerabilities.en.srt

- [Instructor] Configuration vulnerabilities can also have serious impacts on enterprise security. A few simple errors in a system configuration can result in very significant security vulnerabilities that an attacker can exploit to gain access to sensitive information or systems. One common mistake that IT staff make is taking a system directly from a manufacturer and installing it on their network without modifying the default configuration. This is especially dangerous in the case of devices that contain embedded computers, but are not commonly managed as part of the enterprise IT infrastructure. These include copiers, building controllers, research equipment, and other devices that come directly from vendors. The default configurations on these devices may contain misconfigured firewalls with open ports and services, open permissions, guest accounts, default passwords, unsecured root accounts, or other serious security issues. IT staff should always verify the security of devices before connecting them to the network. System, application and device configurations vary widely, and can often be very complicated. Systems that are misconfigured or configured with weak security settings can be serious problems. Small errors can lead to significant security flaws that may allow an attacker to gain complete control of the device. IT professionals should always depend upon documented security standards and configuration baselines to help them install systems in a secure manner. Cryptographic protocols are another common source of misconfigurations. If an administrator inadvertently configures weak cipher suites or weak protocol implementations on a device, all of the communications to and from that device may be subject to eavesdropping and tampering. That error may be as simple as clicking the wrong check box. Administrators must also carefully manage encryption keys to ensure that they don't fall into the wrong hands. If a private key becomes known to a third party, that person can impersonate the key's legitimate owner, eavesdropping on communications, engaging in false communications and creating false digital signatures. Along those same lines, organizations must protect the issuance and use of digital certificates, ensuring that they have strong certificate management processes in place to prevent the issuance of false certificates and protect the secret keys associated with digital certificates. Patch management ensures that systems and applications receive all of the security updates provided by manufacturers to correct known vulnerabilities. Remember that you need to patch many different components of your operating environment. Operating system patches often get the most attention, but don't forget the patch applications and the firmware of devices used throughout your environment. A single unpatched device can provide the open gateway that an attacker needs to establish a foothold on your network. Finally, account management is an incredibly important task for security professionals. If an account is improperly configured with excess permissions, the user owning that account may use those extra privileges to cause damage. This may be intentional in the case of a malicious insider, or it may be accidental when a user simply doesn't know what they're doing. Remember the principle of least privilege, a user should only have the minimum necessary set of permissions required to perform their job function. Security professionals must pay close attention to the proper configuration of systems, devices, applications and accounts, and follow the principle of least privilege to protect their organizations against attack. 

# 4 Understanding Vulnerability Types - 19 Architectural vulnerabilities.en.srt

- [Instructor] Architectural vulnerabilities arise when a complex system is improperly designed. These vulnerabilities may create fundamental flaws in a system that are very difficult to remediate. IT architecture is a set of well-defined practices and processes used to build complex technical systems. IT architects function in role similar to that of a traditional architect. Instead of putting together complex buildings, they're putting together different technologies in a way that meets business requirements. Security is one of the most important of those requirements. The key to avoiding security weaknesses in architecture and system designs is to incorporate security requirements early, making them design criteria rather than after-the-fact concerns. One recipe for disaster is designing a system first and then trying to bolt on security after the fact. When you're considering the security of a system, don't just look at the technical architecture and design. You need to think about the business processes and people surrounding the design as well. For example, if a system carefully encrypts sensitive information, but then a business process has users printing that information out and leaving it in an unsecured copy room, that data is vulnerable to theft. Untrained users and insecure business processes can have a significant impact on security. In today's world, almost every organization has thousands of systems and devices connected to their networks, and the number grows every day. This results in a phenomenon known as system sprawl, where devices are often connected to the network regularly, but they're not managed using a full system life cycle. This means that they get turned on when they're new and necessary, but they often don't get disconnected from the network when they're not longer useful. This can result in serious security issues, especially when those assets are undocumented because nobody's patching or maintaining them from a security perspective, leaving them as open holes in the organization's network security. Security professionals should assess all of their organization's architectural processes to ensure that they include proper security controls. 

# 5 Vulnerability Scanning - 20 What is vulnerability management.en.srt

- [Instructor] Modern computing systems and applications are extremely complicated. It might not surprise you to learn that there are millions and millions of lines of code contained in every major piece of software that you run. For example, the Linux kernel is the core part of the operating system that handles input, output, memory management, CPU management, and other core tasks. This central piece of the operating system contains over 24 million lines of code, and it changes at an astonishing rate. Thousands of lines of code are added, removed, and changed every day as the kernel evolves. Given the complexity of modern software, it's inevitable that developers will make mistakes, and some of those mistakes will lead to security vulnerabilities. In the security community, we have a well understood process for managing vulnerabilities. When a company learns of a vulnerability in their software, they analyze the issue and develop a fix for the problem known as a patch. They then release this patch through their update mechanism and administrators around the world apply the patch to correct the security vulnerability. From an administrator's perspective, there's a lot of work to do. Modern enterprises may run several different operating systems and hundreds of applications. They also have routers, switches, internet of things devices, software libraries, and many other components that are being patched on a regular basis. Vulnerability management processes help administrators get a handle on this complexity. A mature vulnerability management process includes scanning systems for vulnerabilities, the application of patches, tracking of remediation, and reporting of results. In this course, we'll explore all of these topics in detail. Before you can develop a vulnerability management program however, you need to have a firm understanding of your requirements. Why are you developing the program in the first place? Your first answer is probably that you are developing a vulnerability management program because you want your systems to be secure. That's a great answer, and it should be the core purpose of the program. You may also be developing the program because your company policy requires you to do so. You might work in a department or operating unit and be following a corporate mandate to manage vulnerabilities in your systems. If that's the case, your vulnerability management program probably needs to fit within the parameters of a higher level corporate program. You might need to use specific tools, meet corporate deadlines, and submit reports to a central office. And in many cases, companies develop vulnerability management programs because someone requires them to do so. There are a variety of regulations that apply to cybersecurity, and two of them have specific requirements for vulnerability scanning. The payment card industry data security standard, PCI DSS, applies to anyone who handles card information. It has detailed requirements for vulnerability scanning, which include requiring quarterly vulnerability scans of systems and networks from both internal and external perspectives, requiring new scans whenever you make significant changes to your environment, mandating the use of an approved scanning vendor for your external scans, and remediating vulnerabilities and re-scanning your systems and networks until the scan produces a clean bill of health with no significant vulnerabilities. If you work for an agency of the US government, you're subject to the Federal Information Security Management Act, FISMA. FISMA requires that you follow the security controls found in NIST special publication 800-53. This set of requirements includes a section on vulnerability management that requires that you regularly scan systems and applications for vulnerabilities, analyze the results of those scans, remediate vulnerabilities deemed legitimate, and share information about vulnerabilities with other government agencies. As you build out vulnerability scanning in your organization, you should combine three different types of vulnerability tests. Network vulnerability scans probe any devices attached to your network for security issues, while application scans test the code running on those devices for potential flaws. Web applications require specialized testing that probes for common web application security issues such as SQL injection and cross-site scripting. You should also remember that vulnerability scanning doesn't happen in a vacuum. As you interpret the results of vulnerability scans, supplement those scans with reviews of system and application configurations and logs to vet the results for false positives and other errors. No matter why you're building a vulnerability management program, the basic tools and processes are the same. But before you start, it's important that you know what rules apply to you and your organization so that you can be sure to design your program to satisfy those requirements. 

# 5 Vulnerability Scanning - 21 Identifying scan targets.en.srt

- [Instructor] As you get a vulnerability management program underway, your first step is to develop requirements for that program. You'll think through whether the program is based upon a general desire to improve security, a response to regulatory requirements, or a reaction to corporate policy. Once you've done that, your next step is to turn those general requirements into a list of the specific systems and networks that you want to scan. In order to create this list, you need to have an asset inventory that you can trust. If your organization practices good asset management already, you may find that you already have this inventory ready to draw into your vulnerability management program. You might find that your organization's configuration management tools already have a complete inventory of systems and devices on your network. And in the best case that the inventory is kept up to date with information from regular network discovery scans. However, if you don't have this capability, you may instead turn to a scan run by your vulnerability management solution. Rather than running a full vulnerability scan, which can be very time consuming. Your system probably allows you to run a lightweight scan that just searches for systems on a local network. As we work our way through vulnerability scanning, I'm going to show you many examples of running vulnerability scans using the Nessus scanner as a consistent platform. We'll cover some of the advanced features of this platform later on, but for now, I'd like to show you how to set up a basic host discovery scan in Nessus. I'm just going to go ahead and click Host Discovery here. And then I'm going to give my scan a name. This is just arbitrary. Anything that I'd like. I'll call it My Internal Network. And then I can provide the scan targets. So I'm going to use the private IP addresses of systems on this network, which is 172.31.0.0/16 Then I go ahead and click the Save button. And now here in Nessus, I have my new scan and I can see that it hasn't yet been run. So I'm just going to hit this Launch button here to launch the scan. Now the scan will start and take a little while until it finishes. As the scan runs, it populates a list of the hosts that appear on the network. These are hosts that I could then scan for additional vulnerabilities using more advanced vulnerability scans. Other scanners may also provide you with a graphic view of network discovery results. For example, here's a network map created with the Qualys Vulnerability Scanner. Once you have a solid asset inventory, you'll need to begin prioritizing those assets for your scans. This is normally done by answering questions in three key areas about each asset. You'll want to know about the importance of the system and the overall scheme of things summed up as the impact if a breach were to occur. To get at this, you'll want to be able to identify the highest level of data classification that's stored, processed, or transmitted by the system, device, or application. Clearly, you would want to assign a higher priority to systems that handle more sensitive information. Second, you'll want to know about the level of risk pose to the system based upon how exposed it is to an attacker. This is summed up as the likelihood of a successful attack. This first requires identifying the network exposure. Is the system addressable on the public internet? If it's behind a firewall, what rules exist to allow external access? You'll also want to know about what services the system exposes to the outside world. Is it a web server, DNS server, or a database server? How likely is it that an attacker will discover vulnerabilities in the services offered by the system? Finally, you'll want to know how critical the system is to your operations. Even if it doesn't contain sensitive information, a critical system might be very important in your vulnerability management program because business operations would be dramatically impacted if the system were not available. You'll definitely want to prioritize critical systems over their non-critical counterparts. Many organizations take the approach of scanning all of the systems, devices, and applications in their environment on a regular basis. That's absolutely fine, but it doesn't eliminate the need to perform an asset inventory and identify the criticality of different resources. Even if you're scanning everything, you're going to need a way to prioritize your remediation efforts, and the same criteria that you use to identify scanning targets are also quite helpful when planning remediation. 

# 5 Vulnerability Scanning - 22 Scan configuration.en.srt

- [Instructor] We just ran a simple vulnerability scan, but now I'd like to explore the process of setting up a vulnerability scan in more detail. I'm back in Nessus, and I'm going to set up a new scan from scratch. I'm going to go ahead and click the new scan button, where I'm presented with a series of templates to choose from. These are pre-configured scan settings that I can choose if I don't want to set everything myself. I'd like to look at all of the options, so I'm going to select advanced scan, which allows me to choose my own scan settings. The initial screen that I see lets me enter some basic information about the scan. I can give it any name that I like. I'm going to call this one Mike's Scan. And then I could fill in a description if I wanted to, but I'm going to leave that blank for now. The most important part of this page of settings is the targets box. That's where I configure the scope of the scan. In this box, I enter the names, IP addresses, or network ranges that contain the systems I'd like to scan. I'm going to set my scan to run on a local network. I'm going to scan all the systems on the 172.30.0.0/24 network. That's 255 IP addresses that Nessus will scan to see if systems are active, and then it will perform vulnerability scans on those that respond. Notice down here that there's a link to upload a target file. This is useful if your organization has a separate asset management tool. You can export a list of systems from that tool and import it here so that you don't have to re-type or cut and paste everything. When I'm creating a scanning program, I generally want to organize it into a series of scans that each include systems that will be scanned at the same time. For example, if I decided that I want to set the scanning frequency based upon the types of data that the system processes, I may create different scans for systems that process confidential, sensitive, and highly sensitive information. This allows me to set different schedules for each of these system groups. I can do this on the schedule tab. I go ahead and enable my scan to run on a schedule, and then I can set that schedule to have any frequency I'd like, let's say I'd wanted to scan these systems daily, and then I can configure the specific days of the week that it scans, like, we could run it Monday through Friday, and then I can set the specific time that the scan runs. And then, down in the summary tab, it just gives me an English sentence explaining how often my scan is going to run. In the notifications tab, I can set email recipients who will receive a copy of the scan report when that scan is finished. Let's go ahead now and look at some of the more technical settings of the scan. On the discovery tab, I can provide Nessus with instructions about how to decide if a system is alive on the network. I can configure the types of network pings and how Nessus should handle devices like printers and NetWare systems that might react negatively to a scan. On the port scanning tab, I can set the specific ports that I'd like Nessus to scan and also tell it what protocols do you use when scanning for open ports. The default settings for Nessus include all commonly-used ports, so I'm going to go ahead and leave that setting alone, but if your network uses custom ports, you can configure those here. In the assessment section of the scan configuration, I can set the scan sensitivity level. This is an important setting. When you're performing any type of scan, you run the risk of false alarms. These can waste the time of security analysts. By default, Nessus uses what it calls normal accuracy. Think of this as a medium setting that seeks to balance the risk of a false alarm with the risk of missing a real vulnerability. If you'd like, you can change the setting to err on the side of reporting a vulnerability, which will give you more false alarms by checking, the override normal accuracy box and then choosing show potential false alarms. Or you can make it try to avoid false alarms more than the default by choosing avoid potential false alarms. The last settings page that we'll look at is the advanced page. This has a few important settings. First, notice the first box that's checked here, enable safe checks. This setting tells Nessus to avoid performing scans that might disrupt a system. It's probably best to leave this box checked when you're working in a production environment. You may wish to uncheck it if you're scanning systems prior to their deployment in production to get the most thorough scan results possible. There are also some settings on this page that allow you to alter the performance of the scan. You can tell Nessus to slow down the scan when network congestion is detected, and you can set specific timeouts and checks to rate limit your scan and control its impact on your network. Nessus uses plugins to perform vulnerability checks. Each plugin is designed to check for one specific vulnerability, and plugins are organized by the types of systems that they affect. You'll see the settings for plugins in the plugins tab here. If there's a specific set of plugins that we want to disable, we can do that by selecting it. For example, let's say I know Amazon Linux is not running on my network. I can go ahead and actually just change that status from enabled to disabled by clicking on it, and then all of the different plugins affecting Amazon Linux are disabled, potentially improving the speed of my scan results. Vulnerability scanners offer a wide variety of these configuration options that allow you to customize the scanner's performance. If you find yourself tweaking these settings, be sure to create your own custom templates so that you can easily reuse those settings across many scans. 

# 5 Vulnerability Scanning - 23 Scan perspective.en.srt

- [Instructor] All vulnerability scans are not alike. While you may set scans to test the same systems using the same tool on the same ports and services, there are other factors that may affect what you see in your scan results. Let's talk about scan perspective. The most important component of scan perspective is the scanners location on the network relative to the systems being scanned. For example, consider this typical network diagram, showing a firewall that connects an organization to the internet, and also segments a DMZ that contains a web server accessible to the outside world. If as in this diagram, the vulnerability scanner is also in the DMZ, the scanner has unrestricted access to the web server because it doesn't need to pass through the firewall to get there. However, if the vulnerability scanner is instead located on the internal network, we have a totally different picture. Now the vulnerability scanners traffic must pass through the firewall on the way to the web server. The firewall will drop any connection attempts that don't match firewall rules and it may also perform filtering that drops traffic suspected to be malicious. That may prevent the scanner from detecting some vulnerabilities that it would have seen if it were positioned on the DMZ. And finally, if we move the scanner out to the internet, we get a totally different perspective. The traffic from the scanner still needs to pass through the firewall, but now it's subject to the firewall rules that regulate inbound traffic from the internet. Presumably those are far more strict than the rules for the internal network. So in this configuration, the scanner will likely see the fewest possible vulnerabilities. So which perspective is correct? Well, they all are. They each offer different perspectives that may be valuable to a cybersecurity analyst. For example, placing the scanner on the DMZ provides the clearest possible picture of vulnerabilities on the target system. If I want to know all of the problems that I might have, this is the way to get them because the scanner has the greatest permission to access the target system. However, placing the scanner on the internet gives me an attacker's view of my network. I can see the same vulnerabilities that an external attacker might see for running a scan from the outside. This is very valuable to me because it helps me prioritize my remediation efforts. If an attacker can see an exploitable vulnerability, I'd better fix it quickly. Firewall settings do have a significant effect on vulnerability scans. As the segmentation created by firewalls alters a systems and services visible to the scanner. Similarly, you should also be aware of any intrusion prevention systems that run on your network. If vulnerability scanning traffic passes through an active IPS, that system will significantly affect the scan results. All the scans that we've talked about so far are server-based scans where the vulnerability scanner reaches out over the network to connect to a system and then probes it for vulnerabilities. There's another technique that you can use to get a different scan perspective. Agent-based scans install a security agent on each server that can probe deeply into the servers configuration and check for vulnerabilities. These agents then report any weaknesses that they discover back to the central vulnerability management system. This provides great insight, but some organizations choose not to use agent-based scanning because they don't want to install software on all of their servers, increasing the complexity of their environment. An alternative to agent-based scanning is credentialed scanning. And this approach you provide the scanner with credentials that it can use to log on to the remote system and pull configuration information. Let's look at how we can configure credential-based scanning in Nessus. In the settings for the scan, I choose the credentials tab, and then I can choose whether I'd like to configure SSH credentials or Windows credentials. Then I simply fill in the username and password or the private key associated with those credentials and other details to allow the scanner to reach into the system and retrieve configuration information. It's a best practice not to provide the scanner with an administrative account, but rather to provide it with an account that is only capable of read only access to the system configuration. Perspective as an important consideration when designing your vulnerability scanning program. It's good practice to mix several different perspectives in your scans to get the most comprehensive picture possible of your network. 

# 5 Vulnerability Scanning - 24 CVSS (Common Vulnerability Scoring System).en.srt

- [Instructor] Let's dig into the common vulnerability scoring system, or CVSS, because you'll see that used on scan reports. CVSS assigns a score to each vulnerability on a 10-point scale. We can figure out a base CVSS score by evaluating eight different metrics and then combining the results. The first metric is the attack vector metric. This describes the type of access that an attacker must have to exploit a vulnerability. The value for this metric can be physical, meaning that the attacker must be able to physically touch or manipulate the target system. It can be local, meaning the attacker must have physical or logical access to the system's console. Or it can be adjacent network, meaning that the attacker must have access to the system's local network. Or it can just be network, meaning that the vulnerability is remotely exploitable. The second metric is the attack complexity metric. This metric measures how difficult it is to exploit a vulnerability. We assign this metric a value of high if the vulnerability requires specialized conditions and difficult work, or low if it's easy to exploit. We next look at what user level access the attacker must have to exploit the vulnerability using the privileges required metric. We assign this metric a value of high if the attack requires that the attacker first obtain administrative privileges, low if the attack requires the use of a basic user account, or none if an attacker can exploit this vulnerability without any prior access to the system. Then we assess the level of human involvement needed with the user interaction metric. This metric is set to required if the attacker must somehow get an authorized user to take some action to make the attack work, or none if the attacker can carry out the attack on their own. Those four metrics, attack vector, attack complexity, privileges required, and user interaction combine to describe the exploitability of a vulnerability. In addition to exploitability, we must also consider the impact of a vulnerability and that's where the next three metrics come into play. We look at the impact using the three elements of the CIA triad, beginning with confidentiality. We assign a confidentiality rating of none if there is no confidentiality impact, partial if the attacker would have access to some but not all information, and high if all information on the system would be compromised. We then move on to integrity and assign a rating of none if there is no integrity impact, low if the modification of some information is possible, and high if all information could be modified by the attacker at will. And finally, we look at availability, assigning a rating of none if there is no availability impact, low if performance would be degraded, and high if the attack would involve the shutdown of a target system. These three metrics, confidentiality, integrity, and availability combine to describe the impact of a vulnerability. The eighth metric, scope, captures whether a vulnerability can affect components other than the component with the vulnerability. We set this to changed if exploiting the vulnerability can affect resources beyond the scope of the vulnerability, or unchanged if the exploit can only affect resources managed by the same security authority. 

# 5 Vulnerability Scanning - 25 Analyzing scan reports.en.srt

- [Instructor] As a cybersecurity analyst, you'll likely spend a good amount of your time analyzing reports from vulnerability scans. One of your primary responsibilities may be sorting through the results of these scans and presenting information from them to a wide variety of audiences. You'll need to provide engineers, developers, and system administrators with the technical detail that they need to correct issues. You'll also need to explain trends and high-level risk ratings to business leaders. And you'll need to present security management with a picture of how well the organization is doing at managing risk. As you interpret the results of any scan report, you should first focus on five factors. These include the severity of the vulnerability, the criticality of the systems affected, the sensitivity of information involved, the difficulty of remediation, and the exposure of the system with the vulnerability. These five factors will help you triage the various vulnerabilities that you face and feed the right priorities into your vulnerability remediation workflow. Before you request remediation of the vulnerability, it's important to validate the vulnerability. This is where you go beyond the information provided by the vulnerability scanner and add some of your own security expertise to confirm that the vulnerability exists and that it was properly rated in the prioritization process. The first thing that you should check during vulnerability validation is that the vulnerability actually exists as stated in the report. Vulnerability scanners do produce false positive reports for a variety of reasons. It could be that the scanner is using a signature that's not well-defined or that the scanner is not able to detect the presence of a security control that mitigates the vulnerability. In any case, you should carefully review vulnerabilities, especially those that require extensive or disruptive remediation to verify that the problem actually exists. The best way to do this is to review the details on the scan report. Scan reports normally include a section that shows the input that the scanner sent to the target system and the resulting output. Reviewing that section is a great way to figure out why the scanner reported a vulnerability and whether it might be a mistake. For example, this scan report is showing a critical vulnerability in the version of the Ubuntu Linux kernel, running on a host on the network. Clearly, this is important to address if it's true. The CVSS score is 10.0 and there's all sorts of dire language in this report about how an attacker could take control of the system by exploiting it. If I scroll down and look at the output section of the report, I see that the scanner is providing me with a specific name of the package that's causing the vulnerability. To validate this report, I would want to review the alerts described in the report, understand the issue, and then log onto the system to confirm that it's running an affected version of the Linux kernel. Sometimes false positives are easy to clear. If I see report that a Window server is missing a Mac patch, I can probably safely assume that it's a false positive report. It's still a good idea to dig in and figure out why the report is occurring, but these things happen. In other cases, the organization might have already acknowledged that a vulnerability exists on a system and implemented a compensating control or decided to accept the risk. Be sure to track these exceptions in your scanner or in a configuration management database. You don't want to report a vulnerability that everybody already knew about. It's very important to detect false positive reports and exceptions before escalating vulnerabilities for remediation. Because you risk losing credibility if you become the cybersecurity analyst who cried wolf. If engineers and developers begin to doubt your thoroughness and screening vulnerability reports, they're much less likely to take your concerns seriously when you're raised them in the future. As you prepare for the exam, you should be familiar with the four possible outcomes for any vulnerability report. If the vulnerability scanner reports a finding and that vulnerability really exists, that's a true positive report. If the vulnerability kind of reports a finding and that vulnerability does not really exist, that's a false positive report. There are also two outcomes that can occur if the vulnerability scanner does not report a finding. If there's no finding and there was no vulnerability, that's a true negative report. But if the vulnerability scanner misses an actual vulnerability, that's a false negative report. You might find questions on the exam asking you to classify vulnerability findings using these terms. 

# 5 Vulnerability Scanning - 26 Correlating scan results.en.srt

- [Instructor] In addition to validating your scan results to eliminate false positive reports and remove documented exceptions, you'll also want to correlate scan reports with other information available to you from other sources. The first source of information that you should consult are any industry standards, best practices, or compliance obligations that are relevant to your organization. These standards may provide specific guidance on the types of vulnerabilities that require more urgent remediation. For example, PCI DSS contains some very specific guidance on vulnerability scanning. Here's a quote from the standard: "To demonstrate compliance, a scan must not contain high level vulnerabilities in any component in the cardholder data environment. Generally, to be considered compliant, none of those components may contain any vulnerability that has been assigned a Common Vulnerability Scoring System, or CVSS, base score equal to or higher than 4.0." That's a very explicit guidance that is very helpful to an analyst in a PCI DSS environment. It can be summed up by this table, extracted from the PCI DSS Quick Reference Guide. The second source of information that you should correlate is the technical information that already exists in your own organization. You should look at configuration management systems, log repositories, and other data sources that might contribute information to your scan results. These information sources can be particularly useful in detecting and eliminating false positive reports. Finally, you should also correlate vulnerability scan information with itself. Now that might sound strange, but what I mean is that you should watch for historic trends in your scans. The dashboard that you see here is an example of how Tenable SecurityCenter displays trend information in an easy to read format. If the same types of vulnerability keep arising, maybe there's an underlying issue that you should address. For example, if new web applications consistently exhibit cross site scripting vulnerabilities, you should address that issue with developers. You can address the root cause by providing developers with security training or even by creating standard input validation libraries that they can use to armor their code against attack. It's far better to stop a vulnerability in the first place than to remediate one that already exists. 

# 6 Legal and Regulatory Concerns - 27 Legal and compliance risks.en.srt

- [Instructor] Whenever we work with sensitive information, we encounter laws and regulations that govern the ways that we store, process, and transmit that information. One of the first things that we need to figure out when working with sensitive data is what specific laws and regulations apply to us. While that might sound straightforward at first glance, the question of which jurisdictions have the authority to regulate data is actually quite complicated and compliance risks can impact an organization's risk posture. Let's take a look at a simple example. Imagine that we have a company with all of their operations located in the state of California. It's clear in this case that California State law applies to them, and so does federal law written at the national level in the United States, But what if the company has a customer located in New York? Does New York law now apply as well? And if they're using a cloud provider located in Texas, does Texas law govern the data? If that cloud provider outsources to a data center provider in Florida, then what? Now, the issue becomes even more complicated when we expand internationally. The European Union says that their General Data Protection Regulation, GDPR, applies to the personal information of all EU residents, wherever they might be located. Now of course, GDPR isn't the only law that you'll need to follow. Security professionals should be aware of the different national, territory, and state laws that apply to their operations, and some regulations come from sources other than the law. For example, the Payment Card Industry Data Security Standard, PCI DSS, is a self-regulatory scheme that applies to credit card transactions worldwide. Compliance with PCI DSS is enforced by the banks that provide access to the payment card system. There's no easy answer to these jurisdictional questions. You'll need to sort through these sometimes conflicting regulations with the help of your attorneys and develop a path that helps you evaluate legal risks that's appropriate for your operating environments. 

# 6 Legal and Regulatory Concerns - 28 Legal definitions.en.srt

- [Instructor] Security and privacy professionals don't necessarily need to be attorneys, but every security professional must be comfortable with legal jargon because it's found throughout our work. Let's take a look at a few of the important legal definitions that you'll need to know when you sit for the exam. Jurisdiction is the power that a court has to render legal judgements in both their subject matter and their geographic applicability. For example, in the United States, federal courts only have jurisdiction over federal law while state courts have jurisdiction over state law. Federal circuit courts only have geographic authority over specific states. For example, the Seventh Federal Circuit Court of Appeals has authority over Indiana, Illinois, and Wisconsin. Decisions made by that court apply only within that geographic area. The US Supreme Court, on the other hand, has nationwide jurisdiction. Preemption means that law that stems from a higher authority will take precedence over laws from a lower authority. For example, the US Constitution contains a supremacy clause that says that federal law preempts any conflicting state laws. Similarly, decisions made by the US Supreme Court preempt decisions made by any lower courts. A private right of action means that individuals and corporations may bring cases to court under a specific law. If a law does not contain a private right of action, it's up to state and federal authorities to prosecute violations of that law. For example, the Family Educational Rights and Privacy Act, or FERPA, regulates the ways that educational institutions handle student records. FERPA does not contain a private right of action, so students who suffer from data breaches may not sue educational institutions under FERPA. The US Department of Education can bring enforcement actions in such a case. The California Consumer Privacy Act, or CCPA, protects the private information of California residents, and it does contain a private right of action. Under CCPA, an individual can sue an organization that they believe has violated their right to privacy if that breach involves certain unredacted and unencrypted personal information. A private right of action adds strength to a law by increasing the likelihood that an aggrieved party will bring action against the offender. Now, we also need to define the concept of a person. While this might seem like an obvious definition, the legal definition of a person is different from the common sense definition. A person may be a human being, but under the law, a person may also be a business or other legal organization that is treated as a person. The key aspects of the definition of a person under the law are that legal persons can sue or be sued, they can own property, and they can sign contracts. 

# 6 Legal and Regulatory Concerns - 29 Data privacy.en.srt

- [Instructor] All of the stakeholders in a data governance program bear responsibility for protecting the privacy of personal information under their care throughout the information life cycle. Now this private information may come in many forms. Two of the most common elements of private information are personally identifiable information, or PII, and protected health information, or PHI. PII includes all information that can be tied back to a specific individual, while PHI includes healthcare records that are regulated under the Health Insurance Portability and Accountability Act, HIPAA. The generally accepted privacy principles, or GAPP, are 10 components of data privacy that can be used to help organizations design their own privacy programs. The GAPP principles were developed through a collaboration between four major industry organizations: the American Institute of Certified Public Accountants, the Canadian Institute of Chartered Accountants, the Information Systems Audit and Control Association, and the Institute of Internal Auditors. The first of the 10 GAPP principles is management. This principle states that an organization handling private information should have policies, procedures, and governance structures in place to protect privacy. For example, the organization should clearly define the roles of data owner, data steward, and data custodian. The second GAPP principle is notice. Anyone who is the subject of records maintained by the organization should receive notice of that fact as well as access to the privacy policies and procedures followed by the organization. This is often accomplished through the Terms of Agreement for a website and a formal privacy notice. The third GAPP principle is choice and consent. The organization should inform data subjects of their options regarding the data they own and get consent from those individuals for the collection, storage, use, and sharing of that information. The fourth GAPP principle is collection. The organization should only collect personal information for purposes disclosed in their privacy notices. The fifth principle is use, retention, and disposal. When the organization collects personal information, it should only use it for disclosed purposes, and not use it for other reasons just because they already have the data. Additionally, the organization should dispose of the data securely as soon as it is no longer needed for the disclosed purpose. The sixth GAPP principle is access. Organizations should provide data subjects with the ability to review and update their personal information. The seventh GAPP principle surrounds disclosure to third parties. The organization should only share information with third parties if that sharing is consistent with the purposes disclosed in privacy notices, and they have the consent of the individual to share that information. The eight GAPP principle is security. The organization must secure private information against unauthorized access. The ninth GAPP principle is quality. The organization should take reasonable steps to ensure that the private information they maintain is accurate, complete, and relevant. And finally, the 10th GAPP principle is monitoring and enforcement. The organization should have a program in place to monitor compliance with its privacy policies and provide a dispute resolution mechanism. Each of these 10 GAPP principles plays an important role in developing a comprehensive information privacy program. Data owners should ensure that they are followed for each element of personal information under their control. If you're looking for more detailed control objectives, the International Organization for Standardization offers ISO standard 27018. This standard provides a code of practice for the protection of personally identifiable information in public cloud environments. Organizations developing and monitoring their privacy program should conduct regular privacy impact assessments to identify the privacy ramifications of their business operations. 

# 6 Legal and Regulatory Concerns - 30 Data breaches.en.srt

- [Instructor] Data breaches can have serious consequences for an organization. An organization suffering a data breach might experience reputational damage, become the source of identity theft incidents, suffer fines, or lose intellectual property to theft. For these reasons, the security policies of many organizations require immediate escalation to senior management of any incident that involves a breach of sensitive data. In the unfortunate event of a known or suspected data breach, information security professionals have a range of responsibilities dictated by laws and regulations. Like many other security and privacy regulations in the United States, data breach laws are a patchwork of regulations that apply in different ways. Some rules apply to specific industries, such as HIPAA for the healthcare industry, PCI DSS for the credit card industry, and the Sarbanes Oxley Act for publicly traded companies. Other rules apply to specific jurisdictions, such as the state by state data breach notification laws in the US, and the European Union's General Data Protection Regulation. Generally speaking, these laws apply when an organization knows or suspects that it has suffered a breach of personally identifiable information, or PII. The specific definition of PII varies from state to state, but there are several elements commonly found in these laws. They often include social security numbers, driver's license numbers, and bank account numbers, but may extend to other information as well. Some of the common requirements when an organization suspects a breach include notifying affected individuals, informing government agencies, and providing notice to the general public. Organizations often also offer credit monitoring services or other compensations to the victims of a data breach incident. As a security professional, you'll need to remain aware of the laws that apply in the jurisdictions where you do business. The National Conference of State Legislatures maintains a website that links to the breach notification laws of each US state. One quick exam tip for you. Encryption is an easy way to protect your organization against data breaches. In fact, most breach notification laws include specific exemptions for encrypted data. 

# 7 Security Monitoring - 31 Monitoring log files.en.srt

- [Instructor] System monitoring creates massive amounts of data output that cybersecurity analysts must wave through when attempting to conduct log reviews as part of an incident response effort. Fortunately, monitoring technology provides ways for us to automate some of this work. Log files come from a variety of different sources. And each of these data sources contains information that may be useful in incident response. Network logs, and in particular NetFlow data, tells us about the systems on a network that communicated with each other and the amount of information that they exchanged. This can be crucial in identifying systems involved in a security incident. Similarly, DNS logs provide information about network name look-ups, offering insight into which systems may have communicated with external systems. System logs provide insight into the inner workings of the operating system, recording security events and other activity on the system that might reveal details of an attack. On windows systems, these are called event logs. Application logs provide similar information about activity that occurred at the application level, including application logins and access to data. Web application logs might tell us about SQL injection attacks or other malicious activity. Authentication logs help us determine who may have used a centralized authentication service and what internal and external systems and applications they accessed through that service. Other specialized log files also play important roles. For example, VoIP and call manager logs provide insight into the nature of traffic on the network using SIP, the session initiation protocol. In addition to these log files, cybersecurity investigators may make use of dump files from network traffic, memory analyzers, and other sources of raw security information. Vulnerability scan output can also assist in incident response, providing clues about what vulnerabilities attackers may have targeted on a system. One of the most important technologies that supports log monitoring is a protocol called Syslog. Syslog has been around for a long time. It actually dates back to the 1980s, but variants of it are still in widespread use today. The Syslog standard defines a very simple format that's used to create standardized log messages. Each message consists of four components. The header is the first component. The header contains information about the time and source of the message. This includes a timestamp as well as the IP address and process ID that originated the log entry. The facility is a 24-bit code that describes where the message came from using a number between 0 and 23. For example, facility 0 indicates that the message came from the kernel. Facility 1 indicates a user level message. And facility 2 indicates that the error came from the mail service. The third component is the severity, which indicates how serious a messages. I'll explain this more in just a moment. And the fourth component is the message itself. This is where the process that creates the log entry can include information that explains the purpose of the message. Now, I just told you that the severity level of Syslog message ranges from 0, an emergency, down to 7, a debug message. As the number gets higher, the severity of the message decreases. It's common to use severity as a filter when analyzing Syslog messages. For example, I might set an alarm to notify administrators when a log server receives a Syslog message with severity two or lower, indicating that the situation is critical or worse. This chart shows the definitions of each Syslog severity level. Syslog is supported by default on all Linux systems. And it's the defacto standard for sending and receiving log messages between applications, systems, and devices. Syslog forms the foundational core of many security tools, resource monitoring tools, performance managers, and other security services. Now there are actually three different versions of Syslog out there. The original Syslog is actually rarely used today because it's been replaced by newer standards. The first of these, syslog-ng, added encryption and reliable delivery to Syslog in 1998. And this was further enhanced by the Rsyslog standard in 2004. Today, most Linux systems support either syslog-ng or Rsyslog. Now, if that isn't confusing enough, there is another tool out there called journalctl that stores log entries on Linux systems using the journal format. While Syslog uses text-based logging, the journal format uses binary files. As we manage log entries, one of the most important consideration is the retention of those logs. Logs take up space, and we generally don't keep them forever, but we also want to preserve them long enough that we have them if we need to dig back into history as part of an investigation. Log retention decisions should be made deliberately and they have to balance security needs with the cost of maintaining logs. Tagging is another important log management concept. We can tag log entries with different fields, such as the name of the application generating the log, the user involved, and other metadata. These tags make it easier to sort and filter logs during analysis. The NXLog centralization tool is a log management tool that crosses platforms allowing the logging of records from Syslog sources, as well as Windows systems and other devices. NXLog moves us towards the concept of a centralized logging system, which is the subject of our next video. 

# 7 Security Monitoring - 32 Security information and event management.en.srt

- [Instructor] Now you know that log files are an important security control, because they allow IT professionals to detect suspicious activity taking place on their systems, networks, and applications. However, if you're like most security professionals, you simply don't have the time to do a thorough job of reviewing those detailed logs. There are just far too many log entries generated by systems every day, and trudging through them would be tedious, mind-numbing work. And fortunately for us, computers are very good at tedious work, and most organizations now go beyond the simple reporting and alerting mechanisms that I discussed in the last video and apply artificial intelligence approaches to the problem of security log analysis. Security information and event management, or SIEM systems, have two major functions on an enterprise network. First, they act as a central, secure collection point for log entries from a variety of sensors. Administrators configure all of their systems, network devices, and applications to send log records directly to the SIEM, and the SIEM stores them in a secure fashion where they're safe from unauthorized modification, and they're available for analysis. Second, these systems apply artificial intelligence to correlate all of those log entries and detect patterns of potentially malicious activity. Now the great thing about a SIEM is that it has access to all of the log entries and alerts from across the organization. In a hierarchical organization, network engineers might have access to firewall logs, system engineers might have operating system logs, and application administrators may have application logs. This siloed approach means that attacks may go unnoticed if the signs of the attack are spread across multiple departments. Each administrator may see a piece of the puzzle, but they can't put the whole picture together. The SIEM has all of the puzzle pieces, and it performs an activity known as log correlation to recognize combinations of activity that may indicate a security incident. For example, an intrusion detection system might notice the unique signature of an attack in inbound network traffic, triggering an event within the SIEM that pulls together other information. From there, a firewall may note an inbound connection to a web server from an unfriendly country. The web server may report suspicious queries that include signs of a SQL injection attack. The database server might report a large query from a web application that deviates from normal patterns. And a router might report a large flow of information from the database server to the internet. In isolation, each of these activities may seem innocuous, but when the SIEM puts those pieces together, a pattern of suspicious activity emerges. The SIEM consolidates all of this into dashboards that provide administrators with a centralized view of the network. The dashboard may generate alerts to administrators when unusual activity occurs, facilitate the analysis of trends on the network that might impact security, and offer adjustable sensitivity to tune the frequency and quality of alerts sent to administrators. SOAR platforms go beyond the capability of SIEMS to further automate security operations. Now the acronym SOAR stands for security, orchestration, automation, and response. And you can think of a SOAR platform as a greatly enhanced version of a SIEM. SOAR platforms allow you to not only correlate security information, but also to automatically respond to specific circumstances, and they do this by facilitating two different types of response. Playbooks are process-focused responses to security events. They may include a combination of activities performed automatically by the SOAR platform, as well as human steps that play an integral role in the process. Playbooks should tie directly to an organization's incident response policy and procedures. Runbooks are completely automated steps the SOAR platform performs when triggered by an event. This may include gathering additional information for analysis, augmenting log entries, isolating suspect systems, and notifying administrators of the activity. Runbooks are meant to execute automatically and quickly to rapidly facilitate a response and aid human investigators. 

# 7 Security Monitoring - 33 Continuous security monitoring.en.srt

- [Instructor] Continuous security monitoring approaches take security monitoring to the next level. Instead of simply focusing on the periodic review of logs for unusual activity, they conduct this analysis in real time and can even take action in response to suspicious events. Here's a more formal definition of continuous monitoring from NIST. Information security continuous monitoring is maintaining ongoing awareness of information security, vulnerabilities, and threats to support organizational risk management decisions. As with many other information security activities, NIST provides a framework for developing a continuous approach to security monitoring. They begin with three core characteristics of the continuous monitoring program. These should map to an organization's risk tolerance. You need to make sure that the continuous monitoring activities you undertake are appropriate for your environment. Security is an ever-changing field and businesses evolve as needs change. Continuous security monitoring programs must adapt to these ongoing needs and management must play an active role in continuous monitoring activities, providing leadership and resources. Around these core principles, we have the six steps of the continuous monitoring process given to us by NIST. Define the continuous monitoring strategy based upon risk tolerance that maintains clear visibility into assets, vulnerabilities, threats, and business impact, establish a monitoring program by outlining the metrics in monitoring and assessment frequencies, implement the program by collecting the metrics, performing the assessments, and building reports in an automated way as much as possible, analyze and report findings from the collected data, respond to those findings by mitigating, avoiding, transferring, or accepting the risk, and review and update the monitoring program, adjusting the strategy and maturing measurement capabilities. As you perform security data analytics, you will need to aggregate and correlate data from a variety of sources. You can use security information and event management systems to assist with this task. In some cases you'll want to perform a simple point in time analysis, looking at the data immediately surrounding a specific event. That's very helpful when you're conducting an incident investigation, for example. Continuous monitoring approaches require the use of other technologies, such as artificial intelligence and machine learning, to correlate data over time. Anomaly analysis looks for data points that stand out from the dataset as clear outliers. For example, you might look at this chart of bandwidth utilization and notice that there was some unusual activity around January 13th when inbound network traffic, represented by the red line, spiked for what looks like an entire day. Those data points only stand out when you compare them to the rest of the dataset. Anomaly analysis is also known as heuristic analysis. Trend analysis looks for historic changes over time. For example, you might look at this data on the number of account compromises that occurred in an organization over a year. Clearly, there's an interesting trend here. The number of compromises was typically somewhere in the 20s until the fall, when it suddenly plummeted. This might've been due to the implementation of a new security control or some other reason. If you don't have an explanation readily available, something like this would clearly merit an investigation. Behavioral analysis looks at the activity of users and identifies suspicious actions. This might be done using signatures or heuristic analysis. For example, you could apply heuristic anomaly analysis to user login times to learn that I normally log into my computer around 8:00 a.m. each weekday. If I suddenly log in at 3:00 a.m., that's a behavioral anomaly that merits investigation. Finally, availability analysis provides technology leaders with key information about the performance of their systems against service level agreements. Availability analysis depends upon monitoring systems that continuously monitor system status and detect periods of downtime. 

# 7 Security Monitoring - 34 Visualization and reporting.en.srt

- [Instructor] Security monitoring efforts generate a large amount of information that may be useful to analysts investigating a security incident or simply monitoring enterprise cybersecurity. Machine and application logs, packet dumps, and the output of security devices all play an important role in security event data analysis. As you respond to a security event, you'll need to gather and analyze information from a wide variety of sources. You've already learned how server and desktop operating systems generate massive amounts of log information that may contain valuable security data. These log records provide valuable insight into the activities that occur within systems and applications and they're particularly useful when reconstructing the sequence of events that took place during a security incident. In my course covering SSCP domain six, network and communication security, you'll learn more about network monitoring techniques, including the use of packet dump tools to capture, display, and analyze network traffic. And in my course covering SSCP domain four, incident response and recovery, you'll learn about forensic techniques used to gather machine data and other information in the wake of a cybersecurity incident. As you gather and analyze information from these various sources, perhaps with the assistance of a security information and event management solution, you'll be asked to reconstruct the story of a security event and put it in terms that the organization's leaders and other non-technical people can easily understand. Communicating findings to non-experts is a challenging task for many cybersecurity experts, but it's also one of the most important things that we do. Here are a few tips that may help you get your message across. First, eliminate jargon from your reporting. Remember, the people you're speaking to are experts in their own fields, but they may not understand the acronyms and technical terms used in cybersecurity. Most of the time, you can simply eliminate the jargon. Along those lines, simplify things as much as possible. You want to be accurate, but your main goal should be to help leaders understand what happened, the impact of the event, and what needs to happen next. Third, remember that a picture is worth a thousand words. Use visualization whenever possible to explain technical concepts, summarize results and present findings. For example, if you're describing a traffic surge associated with a denial of service attack, don't just throw around numbers. Include a graph that clearly shows the traffic spike. And finally, make clear recommendations. It's not the time to be wishy-washy. You're the expert and leaders are looking to you for your expert opinion. Tell them what you think they should do and why your recommended course of action makes good business sense. Cybersecurity experts often struggle when trying to communicate the results of their analysis to non-technical audiences. Take the time to understand your audience and clearly communicate concepts in language that they understand. 

# 7 Security Monitoring - 35 Compliance monitoring.en.srt

- [Instructor] Security professionals also perform monitoring in an effort to ensure that systems and applications remain compliant with various standards. Compliance monitoring occurs for two different reasons. First, organizations may wish to ensure that their systems and applications comply with internal standards and baselines. If the organization has a standard requiring the use of current anti-malware software on all systems, compliance monitoring can verify that the software is present on every device in the organization and that each device has recently updated signatures. Second, organizations may use compliance monitoring to verify that they remain compliant with laws, regulations, and contractual obligations. Organizations handling credit card data, for example, should use compliance monitoring to verify that the configuration of all systems they operate remains compliant with the payment card industry data security standard. An organization's approach to compliance monitoring may vary depending upon the importance of the compliance obligation and the level of risk involved. For example, in a low-risk environment, administrators may simply run a report once a month to identify noncompliant systems and begin any required remediation. If compliance is critical and time-sensitive, administrators might configure compliance monitoring systems to immediately report anomalies and automatically open trouble tickets, notifying and dispatching a technician to correct the issue. As you conduct compliance monitoring, you may look for different events. The events of interest to your organization may differ depending upon your specific compliance obligations. Common events of interest include anomalous activities, such as unusually high network traffic, late night logins from abnormal sources, or high CPU utilization on a server that's usually inactive. Intrusions are clearly events of interest to security analysts. If an intrusion detection system triggers a high confidence alert that an intrusion is underway, that's of interest to any cybersecurity professional. And finally, unauthorized changes to systems, data, or applications are also of interest to security analysts. Integrity monitoring software can watch different environments for unexpected changes and notify administrators of suspicious activity. As with any compliance-related effort, the scope of your organization's compliance monitoring will depend upon the specific laws and regulations that you're subject to, your operating environment, and your risk tolerance. 

# 7 Security Monitoring - 36 Legal and ethical issues in monitoring.en.srt

- [Instructor] Security monitoring provides analysts with access to a wide variety of information. Let's think for a moment about some of the kinds of data that we have in our log files. We might use a tool like Wireshark to sniff network traffic giving us real-time access to packets that travel on the network. We can use this access to reconstruct a user's activity and see everything that they send, and receive on the network. We also have access to firewall logs that capture connection activity to and from external systems, giving us an idea of the systems involved in those communications. Other log records provide other personal and sensitive details, we might have access to a user's browsing history, the contents of files that they store on servers, personally identifiable information stored in databases, and geolocation information for their mobile devices. It's important to remember that just because we can access this information doesn't mean that we should do so. The technical ability to access information doesn't mean that it's legal, or ethical to access it. Whenever you're designing a security monitoring program, you should do so with advice from legal counsel, who can help you understand what is, and is not permitted by local law. Remember, there may be different limitations on your monitoring in different jurisdictions. If you work for a multinational corporation, you'll need to ensure that your activities comply with the laws of all of the regions where you operate. These laws may place restrictions on the types of information that you collect, the length of time that you store that information, your ability to transfer information across national borders, whether you must notify users of monitoring activity and the types of analyses that you may perform. And once, you've cleared that legal test, you should also think about any ethical issues involved. While security monitoring activity may be legally justified that still doesn't mean that it's the right thing to do. For example, you might be permitted to monitor user web activity on your corporate network, but you might choose not to log website visits because you consider it an unethical invasion of privacy. Now, there were a lot of gray areas when it comes to the legal and ethical issues of security monitoring, in my opinion, it's best to err on the side of transparency. If you find yourself engaging in monitoring activity that you'd like to keep secret from users, well, there's a good chance that it's not legally or ethically permissible. 

# 8 Conclusion - 37 Continuing your studies.en.srt

- [Mike] Thanks for watching my SSCP risk identification, monitoring, and analysis course. It's been my pleasure to join you for this journey through the world of cybersecurity risk management. I hope that as you've completed this course, you found it interesting and helpful in preparing for the SSCP exam. You should now have a solid foundation for the risk identification, monitoring, and analysis domain of the test. If you're following my SSCP course series in order, you've now finished the third domain and you're ready to move on to domain four. You can now turn to the SSCP incident response and recovery course. Good luck with the rest of your test preparation. 