## 01-Welcome__Introduction

### 01-Program_Overview

#### 15_516x- Week0-1 Program Overview-en

EGOR MATVEYEV: Hello, everyone, and welcome.This course is part of a MIT's MicroMasters Programin Finance.To the learners who have taken other courses in the series,welcome back.To the learners who are joining us for the first time,I would like to welcome you to our MicroMasters Program.My name is Egor Matveyev.I'm the executive director of the MicroMasters Programand a faculty member of the finance group at MIT SloanSchool of Management.I joined the finance group at MIT Sloan in 2017.I have taught various finance courses in our MBA,Masters in Finance, and MBA Sloan Fellows Program.The scope of my teaching includes introductory classesto MBA students and Sloan Fellowsas well as an advanced elective in corporate finance.I also teach an MIT Sloan action learning coursein corporate finance and investment banking.My academic research covers areas of corporate finance,corporate governance, organizational economics,and asset management.In this video, I would like to give youan overview of the MicroMasters Program in Finance.Our program consists of five courses: foundationsof modern finance part one and two, financial accounting,derivatives markets, and mathematical methodsfor quantitative finance.By successfully completing all five courses,you will earn the MicroMasters credential in finance from MIT.How does completing the MIT MicroMasters Program in Financebenefit you?First, it can be used to advance your career.All of our courses have the same rigorous contentthat we teach to our in-residence studentsat MIT Sloan.In all our courses, we have developedindividual proctored exams that allow us to test your knowledgeand allow you to show your understanding of the subject.Our testing process is rigorous and complieswith our internal practices for MIT students.Earning our MicroMasters credentialwill allow you to demonstrate your finance knowledgeand skills at the level of MIT Sloan.Second, this MicroMasters credentialcan be your first step in earninga master's degree in finance either at MITor at our pathway universities.If you're currently a sophomore in an undergraduate program,starting our MicroMasters program nowwould allow you to complete the programby the beginning of your senior year,right in time for your applicationsto Masters programs.At MIT Sloan School of Management,learners who earn Micromasters credential in financeare eligible to receive credits for four coursesupon acceptance into the program.This would allow you to waive the Summer termand accelerate program completion.The list of pathway universities that accept our MicroMasterscredential is growing and is available on our website.Even if you are not currently interested in a full Master'sdegree, our MicroMasters credentialmay give you an edge in the labor marketas our community of credential holdersgrows and more employers become familiarwith the rigor of our content and testing.You are also welcome to take our individual courses.For example, if you already have a strong general foundationin finance and you would like to deepenyour understanding of derivative securities and markets,you can take our derivatives courseand earn a certificate specifically for that course.We're glad you're with us.Welcome to this course and to our MicroMasters Program.

### 02-Course_Overview

#### CourseOverview-en

PAUL MENDE: Welcome to 15.455x, Mathematical Methodsof Quantitative Finance.I'm Paul Mende, and I'm your instructor for this course.The main topics that we cover are probability, time seriesmodels, discrete-time stochastic processes,continuous-time processes, linear algebra,and optimization.Our approach in this course is to develop mathematical methodsthat are applied in finance.We're oriented toward practical and innovative problem solving.So we'd like you to understand where the ideas come from,how to use them, not only in standard situations,but in novel ones, where maybe someof the standard assumptions don't apply.We'll survey the key ideas and tools and methodsin each of these areas.And we'll provide a foundation for applicationsin industry and research and for further study,depending on where you are in your careerand where you are in your studies.Learning in the class is very much hands on.You'll be doing examples, you'll be doing problems,you'll be doing applications.And mostly, you should be asking questions all the time.Where does this apply?What do the results mean?What are some counterexamples?How do we generalize?We begin with probability becauseof the basic observation that financial datais noisy and financial data--excuse me, financial decisions, more generally,are characterized by uncertainty.So we need probability.Probability is the language of uncertainty.And we want to ultimately be describing an uncertain worldand making good decisions under uncertain conditions.So we begin with the basic reviewof probability and a few key ideasthat we'll be building on to describe how events unfoldin a sometimes noisy world.Look at discrete-time stochastic processesthat characterize the evolution of random variablesto describe financial and econometric quantities.We want to think about the entire past, present,and future trajectory of different quantitiesof interest.So we'll be developing some specific time seriesmodels that find a variety of applications.We'll be looking at numerical, as well as analytical,techniques to solving closed form, to solve numerically.We'll see how to estimate parametersand how to identify what might be the appropriate modelfor different situations.We'll then take a look at things in continuous time,and we'll see it's much more interestingthan simply your ordinary delta t goes to 0 limit.We'll see stochastic processes become fractals,and we need a whole new calculus, the ito calculus,to describe stochastic financial variables.So we'll develop that.And then we'll see how we can go from these stochastic equationsback to more familiar partial differential equationsand look at some of the key equations thatare important in finance and some that have applicationto important areas, such as derivative pricing,option pricing, and so on.We'll look at linear algebra, because pricing relationshipsand many other relationships among financial variablesare linear.And linear algebra captures the essential relationshipsand constraints among financial quantitiesto identify what are independent drivers, to identifyhow many independent securities might be in a market,and we'll look at applications, such as market completeness,security replication, and arbitrage.Finally, we'll look at optimization.Whether it's trading, investments,or other kind of decision making under uncertainty,we'd like to take the best action or find the best policy.We often have to do so in the presence not only ofuncertainty, but constraints.So we'll take a look at constrained optimizationin single and multivariate settings,in a single period settings, and over multiple time horizons.

### 03-Academic_Integrity_and_edX_Honor_Code_Pledge

### 04-Financial_Assistance

## 02-Prerequisites_and_Resources

### 01-Prerequisites_and_Resources

## 03-Entrance_Survey

### 01-Entrance_Survey

## 04-Week_1-Probability

### 01-Overview

### 02-Lecture_1

#### Prob01_S01_v3-en

PROFESSOR: Let's look at some of the basic objectsand terminology in probability.A random variable is really a function.We could really call it a random-valued functionon the sample space.So the sample space is a set of all events,or possible outcomes of experiments,or possible observations that we might have.And we want to assign numbers to themso that we can do some math, so that we can do some analytics.So for example, if we have the abstract outcomes of successor failure in an experiment, or we flip coins,and we have heads and tails, or we roll dice,and we get one of sides to come up,we are used to assigning numbers to those.And those numbers are the random variables.So I've given a couple of examples right here.In the case of heads and tails, wemight assign them 1 or minus 1.But there's nothing special about that.You could pick a different random variable wand pick different values, 12 and minus 3, if you'd like.Z is also a common random variablethat we see where we have two outcomes,and we think of them as being success or failureof an experiment.They might be gains or losses on an investment.Again, two states, we map the two possible statesto two possible numbers.We could have a large number of states,and we could combine different kinds of outcome.We could add two dice together, wecould add a coin flip and a die, and we might alsohave continuous outcomes.So they don't need to be discrete.What's the probability?Well, we describe the probabilityof an outcome as a number that weassign to a random variable taking a particular value.So for example, in the case of a fair coin,the probability of observing X equals 1 would be 1/2.For the case of Y equals 2, in the case of our dice,we know that we would only see that in 1out of 36 times when both the dice come upwith 1 on one side.We can compute functions of a random variable as well,and we'll have more to say about this later on.But for example, if we take X squared,the probability of observing X squared equals 1is 1 because X could be plus 1 or minus 1with equal probability.And either way, X squared is equal to 1 and so on.

#### Prob01_S02_v3-en

PROFESSOR: We have continuous random variables thatdon't have discrete outcomes.They can take an uncountably infinite number of variables.The classic case is a uniform distribution.For example, we might think of the interval between 0 and 1with all values being equally likely.Because they're uncountably infinite,the probability of finding any one point,which is equal likelihood for any other point,is proportional to 1 over the numberof points, which is infinite.So the probability of any particular observation is 0.We say that if a given point has "measure 0", that doesn't meanit can't be observed.What it means is that we really should ask a better question.Rather than asking about the chanceof finding an exact value, an exact real number,we can ask about the probability that it lies within a range.And there, for that, we have a probability density function,p of x, that describes the probability of findinga value, the particular value x, in an interval with dx.And in the case of the uniform distribution, p of xis just a constant.It's equal to 1.But more generally, we define the probabilitythat the random variable x, is observed between two valuesa and b, when x is continuous, by takingthe integral between a and b.Probability distributions need to satisfy two properties.First, probabilities need to be positive.Second, they need to sum to 1.So we don't have a definition of negative probabilities.But we do require that the probabilities sum to 1.And we think of that as saying that our sample space isappropriately designated, and our probability functionis a reasonable description.If we assign a probability to everything and probabilityequals 1, it means that something happens.So in the case of a discrete distribution,the probabilities sum to 1.In the case of the continuous distribution,they integrate to 1.We sometimes think about the cumulative distributionfunction, which is the partial integralof a continuous function or a partial sumof the discrete function.It's the probability of observingthe random variable, big X, takinga value less than some particular value, little x.So we can think of that in the case of a distributionas integrating in the continuous case,from minus infinity up to the value x of interest.And if we let x go to infinity, that thencovers the entire support of the probability density.And it should be equal to 1.Obviously, this is closely related to p of x.And we can go backwards just by differentiating.So because f is the integral of p,we have the p is the derivative of f.Now that's trivial from the definition.But there are certain cases whereit's easier to construct f than p,and this formula lets us recover p by differentiatingthe formula for f.Also, just from the fundamental theorem of calculus,there's a convenient formula for the probability.If we know what big F is, if we knowwhat the CDF, the cumulative distribution functionis for a given distribution, then we can justtake f of b minus f of a.That computes the value between the two limits of integration.It's the same value that we wouldhave for doing the definite integral from a to b.Sometimes we'll want to change variables.And if we do that, we need to be aware that the probabilitydensity is the density in the sensethat we need to integrate it.So we need to change not only the x in p of x,but we need to change x in the differential thataccompanies it.So the rule for change of variables is very simple--that if we change variables, if we replacex by y, which is some function of x, thenwe define a new probability distribution for ysimply by saying that g of y dy, whatever g of y is,had better capture the same thing as p of x dx.So that means that p of x is of why doy we divide both sides by dy.And we can write this saying g of yis p of x divided by dy/dx.Now, if we're given a function y of x,we can compute the derivative.We take its absolute value in the eventthat y is a decreasing function of x.So probabilities, remember, need to be positive.If our change of variables goes in the opposite direction,if it decreases as a function of x,the absolute value makes sure that we get a positive sign.And we need to take special care and break things up piecewise,in the event the y of x changes sign,that there are places where the derivative vanishes.But that's not really going to happenin the financial application.

#### Prob01_S03_v3-en

PROFESSOR: We use probabilities to serveas weights for computing weighted averages.And these, we call expectations.These expectations are going to bevery important for what we do.In fact, our next slide, our next propositionis going to give us a shortcut through a lotof complex mathematics to get straight to the analytics wewant in terms of using expectation values insteadof full probability distributions.So the important thing is that an expectation valuecan be thought of as a kind of a weighted average.In the discrete case for any function,f of x, the expectation that I write with E and bracketsaround it, is a weighted average over the possible states,the possible allowed values of the random variable, xsub k, however many there are.And it's the value of f at each of the possible valuesof the random variable, weighted by the probability of observingthat variable.So it's a weighted average.If f is 1, identically, then, the expectation of 1has to be equal to 1, because the probabilities sum to 1.In the continuous case, it's even more elegant.This just becomes an integral.So we integrate f of x times p of x dx.And again, if f is just 1, then the integral of p of x dxhas to be equal to 1, the normalization of probability,and we get 1.So expectations are weighted averages of functionswith probability numbers.But the important thing is that they're numbers,they're not functions.We do a definite integral.We do a definite sum.So p of x is a function.The expectation of some function of x, though, is just a number.The classic example is the mean of the distribution,which is just the expectation of the random variable itself.And we have lots of different notations for expectations,and I'll just give you a few of them.One of them, for the mean in particular,is often denoted by mu.And that's going to be our definition for E of x.Sometimes this is written as x-bar.Sometimes it's also written is x inside angle brackets.All of these things mean the expectationof x for the mean value.And we'll use the angle brackets a little bit more just when wewant to simplify the notation.Generally, we'll be using the E notation.So in this case, in the case of the discrete,it means the sum of x times p of x.In the integral case, it just means x p of x dx.So in the case of a discrete sum--if there are a finite number of states,we're always going to get a finite result.When we have integrals, even though we requirethat p of x be an integrable function,it's possible that x p of x might nothave a convergent integral.So it is possible to have a perfectly well-behavedprobability distribution where the mean doesn't necessarilyexist.Similarly, we can generalize to the moments of a distribution.And those might not exist in the caseof a continuous distribution.So the moments just generalize.Instead of e of x, we take the expectation of x to a power--in this case, x to the lth power.So this is our definition of the lth moment.And you might not be surprised to knowthat if we know all of the moments,then we can read to reconstruct the full probabilitydistribution itself.Think of it as a kind of Taylor's theorem.And we'll see that when we look at generating functionals.So we can go back and forth from momentsto the full distribution.But if we're interested in a particular moment,here's the formula for how we compute it.So expectation of x to any power isfor the continuous case, integralof x to the l p of x dx.Now, the most important property of the expectation operator--because it's either a sum or an integral,is that it obeys linearity.And linearity means we have the following two properties--first, the expectation of any scalar, c, times any functionf, is just the scalar times the expectation.And if we have the sum of any two functions, f and g,the expectation of the sum is the sum of the expectations.That's simple property, that the sum of that expectationis the expectation of the sum, willlet us bypass a lot of complicated calculationsthat we'd rather cut through.Now, there are some moments and algebraic functionsof moments that are particularly interesting.And maybe the most important one in financeis the variance or its square root,which is a standard deviation.So the variance is related to the expectationof x squared by the expectation of xsquared minus the square of the expectation.But to get there, let's look at how we formally define it.The variance of x is the expectationof x minus its mean, the whole quantity squared.So if x were not random at all and were equal to m,this would be equal to 0.We look at x minus mu to measure how much xdeviates from its mean value.We take the square so that we don'thave positive and negative fluctuations cancelingeach other out.Once we have this definition, the rest of thisis just algebra.So what we do is we expand out the quantity in parentheses--x minus quantity squared.We expand it out it's a quadratic.We use our rule for linearity, that the expectation of the sumis the sum of an expectation.So we get the expectation of x squaredminus 2mu times the expectation of x plus mu squared.This is just a constant.Expectation of x squared minus--now, I have minus 2mu, you but e of x is mu.So this is minus 2mu squared plus minus square, gives mea minus mu squared.And of course, mu squared is the same thing as the expectationof x squared.So this is a good rule for calculation.The variance is the expectation of the square minus the squareof the expectation.And we often use the square root of the variance, whichplays the role of the volatility in lookingat financial processes.And one reason we do that is that the square roothas the same units.It has the same dimensions.We measure it the same way as we do the random variable itself.So if x is in dollars, sigma is in dollars.If x is annualized return, then the standard deviationis also in the same units.So we might say, for example, that a given stock hasan expected return, a mean return in a probabilitydistribution of 10% per year, with a sigma or standarddeviation of 30% per year, which is a little bit easierthan the square of 30% for the variance.Now the moments and particular combinations,linear combinations, of them, helpus characterize some of the properties of a probabilitydistribution.And we're going to see that we'regoing to get quite far using only a fewof the lower moments.And we won't need all the detailsof the full function, p of x.There's a lot of universality in low moments.So in addition to the variance and the mean,the next two moments of interest are the main ones.Then we can kind of stop.The third moment gives us what's called the skewness.And the skewness is an asymmetry parameter.It tells us whether we're more or lesslikely to see things above the mean versus below the mean.So a skewness of 0 is what we'll find if a probabilitydistribution is symmetric.And that's because it depends on an odd power of x minus mu.Notice that after the variance, the skewnessis defined in a way that's dimensionless.That is if x is in units of dollars or of return,sigma has the same units of 3 powers in the numerator, 3in the denominator.So s is a pure number.Similarly, the kurtosis involves the fourth power.And to make it dimensionless, I divide by four powers of sigma.Sometimes you'll see this called the excess kurtosis,with the minus 3 subtract it off,and the non-excess kurtosis, just without the minus 3.We like this definition because as we'll, see,for Gaussian distributions, for a normal distribution,the skewness and the kurtosis measured in this wayare both equal to 0.

#### Prob01_S04_v3-en

PROFESSOR: What if we've got more than one random variable,as we often do?Well, if we have two random variables,they could be independent, but they might not be independent.And one of the measures we have for howtwo different random variables might be related to each otheris to look at an expectation, as well.It's to look at the expectation of a bilinear product.So the covariance of two random variables x and y,which I sometimes write in this notation, covarianceof x and y, is the expectation of x minus its mean,times y minus its mean.Now if you expand this out and do the same trickthat we did for the variance, youfind that this can be simplified to bethe expectation of the product minus the productof the expectations for two variables, x and y.This has units, unsurprisingly, the unitsof x times units of y.So if x is in dollars and y is in yen,the product is going to be in dollars times yen.We often like to have things in dimensionless units.So we define the correlation to be the covariance dividedby the square root of the variance of xand the square root of the variance of y.That makes the correlation a dimensionless number.And in fact, it's bounded between minus 1 and plus 1for the correlation of two random variables.Notice that we can rewrite this by takingthe square root of the variances,writing that as sigma x, sigma y.Because those are constants, I can bring theminside the expectation.And I can write the correlation as an expectationin this interesting way.It's the expectation of x minus mu over sigma times yminus mu over sigma, where the mu and the sigmaare for the y distribution.And each of these quantities in parentheses,you'll notice has 0 mean, because I've subtracted offits mean.And it has unit variance, because I'vedivided by the variance.Now if the random variables are independent of each other,then these expectations factorize, and we'll get 0.So if the variables, x and y, are independent,then they're covariance and correlation are 0.What about the other way around?Well, the other way around is different.So it is possible to have vanishing covariance,but not have the variables be independent. .Let's take a look at a quick example.If we have x to be a function that takes,let's say, plus or minus a with probability p1,and it takes plus or minus b with probability p2,then we can see that it's mean has to be 0,simply because it's symmetric.It's equally likely to have a positive numberand a negative number.Now what if we define y to be x squared?So if y is a function of x, it's not independent.It's completely dependent.If we know what x is, then we know what y is.It's the square the value of x.So in this case, this would be a squared with probability 2pi1,because whether it's plus or minus a, eachwith probability pi, y is going to have value a squared--and similarly for b.So its mean is not going to be 0 because yis a positive function, and we can compute its mean.And now if we go and compute the covariance,and we put in the numbers, we take the probabilityweighted average of the functions,we find that the covariance of x and y is 0.So if the covariance vanishes, it does not imply independence.Independence implies vanishing covariance, but notthe other way around.So let's summarize-- random variables are functionsthat assign probability to events or outcomesin the sample space.They can be discrete.They can be continuous.They can be a mix of both.We describe the probabilities by a probability distribution,which could be discrete.It can be continuous, but either way, it's sumsor it integrates to 1, and the values are always positive.Expected values or expectations-- and I'lluse those interchangeably-- are weighted averages, wherethe weights are taken from the probabilities.The moment of a distribution are the expectation,not of some general function, but in particular, of powersof the random variable.The first power, x to the 1, gives us the mean.X squared minus the constant gives us the variance.We can do x cubed, x to the fourth, and so on.So the variance, skewness, and kurtosisare simple functions of the moments that are used,the second, third, and fourth moments of the distribution,and they help us characterize the shape of the distribution.And if there are multiple random variables,we define using expectations again, the covarianceand the correlation.And for independent random variables, those vanish.

#### Prob02_S01_v3-en

PROFESSOR: Let's take a quick lookat some of the common distributionsthat we see in finance.First, uniform probability distributionis always our starting test case.The probability density p of x is equal to 1if x is in the interval between 0 and 1, and 0 otherwise.We compute the probability for X to lie between two valuesa and b by computing the interval.So this one is obviously just b minus a.How do we get the cumulative distribution functionfrom minus infinity to x?Assuming that we're inside the interval wherex is between 0 and 1, this is just the function x itself.What about moments?Well, we do the integrals The mean is the integralof x p of x dx, and that's 1/2.We can obviously do these integralsin closed form for any value.So for x to the l, we get the l-th moment is 1 over l plus 1.And for the variance, for sigma squared, we use our definition.It's the integral of p of x, which is 1,times x minus the mean, so x minus 1/2 quantity squared.Do the integral, and we get 1/12.The binomial distribution is very importantsince it describes random walks and it'sused in the binomial tree model for option pricing.So the binomial distribution provides a model for anythingthat has two possible outcomes-- success or failure,they're typically called.But we could be thinking of heads or tails,we could be thinking of something going up or down,or left or right, or two possible outcomes, win or lose.But they don't need to be symmetric.So for example, if we put our money on 19 in roulette,it could be 19 is one state and not-19 is the other state.So lots of possible examples where wehave two states of the world.What we do is we define the probability for one stateto be-- we'll call it p-- the probabilityfor the complementary state to be 1 minus p,and then we'll imagine that we repeatthis a certain number of times.And we want to know-- our question for the binomialdistribution is--how many successes and failures do wehave out of the given number of experiments,out of the given number of trials?So imagine that we do the experiment n times.And we want to know, what's the probability, if I do this ntimes, of observing k successes and n minus k failures?So if I flip a coin 10 times in a row, n is equal to 10.If I want to know the probabilityof getting 5 heads and 5 tails, I would take k equals 5.If I want to know about getting 2 heads and 8 tails,I would take k equals 2.So how do we compute the probability?Well, it depends.Probability is a function that depends on k.But it has two parameters, n and p, that are held fixed.So n could be 10, p could be 1/2,for the example of flipping a fair coin.But actually, n can be any integer,and p can be any number between 0 and 1.So we can see that if we want all possible waysthat in n trials we could have k successes,the number of ways of doing that is nchoose k-- n factorial over k factorial n minus k factorial.And by properties of combinatorics and factorials,that's the same as n choose n minus k, of course.Now, we're going to weight that by the probability of successto the k-th power.Because these are independent events happening separately,the probability of having it happen k times are itneeded to happen each of k times.So the probabilities multiply.So in the case where I have k successes and n minus kfailures, I'm going to have p raised to the k,q raised to the n minus k will be that probabilityof a particular event, and the multiplicitywill be n choose k.Now, what's the mean of that expectation?Well, we could compute it.And let me just show you how it's done the hard way.And very shortly, we'll find a much easier wayto do it, which will generalize.And that's what we'll be doing for the restof our calculations.It's both easier to compute and it opens doorsto some other properties of stochastic processes.So the hard way is we use the definition.So the definition is that we takethe mean is defined as the expectation of X.So we take the value of X, we sum over all possibilities.We take the value times the probabilityof finding that value.So we could have k could be 0 successes up through infinity,theoretically, and we would compute this sum.Of course, it can't really go to infinity.If we have n trials, k can either be 0 through n--so we can cut off our sum at n on the upper end of the limit.And if k is equal to 0, that termis not going to show up either, because kequals 0 would just drop out because of this factor here.So let's write our sum from k equals 1 to nand then plug in our definition.So we've got our factorial, k factorial n minus k factorialon the bottom, n factorial in the numerator times the kprefactor here, p to the k, q to the n minus k.I can rearrange the terms a little bit.I can cancel a k in the numerator and the denominatorhere.See if my magic screen will cooperate.Here and here, we can cancel out a k to get k minus 1 factorial.And now to neaten things up, I'd like to write this as n minus 1factorial times n.That's the same thing as n factorial.So written in this way, I'm gettingready to shift the variables.So I've written this in terms of n minus 1 choose k minus 1.And I've pulled a factor of n out in front,and I'm also going to go ahead and pull a factor of pout in front as well, so that the coefficient up here isk minus 1.I can then redefine my variables, k prime and n prime.I notice this whole expression right hereis the same thing as my function f, justin terms of new variables k prime and n prime,where k prime is k minus 1, n prime is n minus 1.And then that entire summation is just equal to 1.So after going through all the combinatorics, allthe shifting around of variables,I get a very simple result--that the mean value is n times p.And if you think about it, of course it is.We have probability p of seeing a success.Let's say the probability is 1/10.We maybe do the experiment 100 times.What would we expect to see?Probably about 1/10 of 100 mean value of n times p.

#### Prob02_S02_v3-en

PROFESSOR: The next distribution that's common everywherein finance and statistics and in many other areasof applied mathematics is the Gaussian distributionor the normal distribution.And I'll use the two terms interchangeably.So the normal distribution is the famous bell curvethat we see over here, OK?So the bell curve is symmetric around 0.It has a width like, goes all the way outto minus infinity and plus infinity.So it's unbounded.But most of its support--99% of its support lies between plus and minus 3.And the tails get short very quickly.What's the functional form of it?Well, it's e to the minus x squared.Specifically, we can write this as e to the minus xminus mu quantity squared over 2 sigma squared.And mu and sigma have a particular meaning.If we set mu to 0 and sigma equal to 1,we would have this standardized form, whichI've written in terms of z.And generally, I'll try to reserve z for this special formfor this standardized random variable where in terms of z,this is peaked at 0.And its width-- its standard deviation,which we can compute, is equal to 1.If I replace z by x minus mu divided by sigma,I can recover this form here.And if I remember to use my change of variables formula,that's where this sigma squared under the square rootin the denominator comes from.But there's a good physical interpretation of mu and sigma.So the mu is the center of the distribution.Because exponential will decrease as its argumentincreases, the largest value the exponential takesis when either z vanishes down here or when x is equal to mu.And that corresponds to the peak of the distribution here.Or at the peak of these different distributions,each of which is computed for a different value of mu,mu tells you where the center of the distribution is.So if we want to shift the distribution left or right,we change mu.If we want to change the width of the distribution,we change sigma.A small sigma is a narrow distribution.A large sigma is a wide distributionbecause the area under the curve needsto equal 1, the curve if it's wide,it's going to be lower down.And if the sigma is narrow, then it's going to be peaked.And the center will be higher.There are a couple of handy formulasfor checking the normalization of the Gaussian.And you should get familiar with doing small scale integrals.We'll be doing them a bit.But handy formula for getting the normalizationare a definite integral with this generating function.There's a trick for doing this using polar coordinates.But for right now, you just need to know the resultbecause you can get everything you need from this that if youlook at the integral of e to the minus ax squared,we notice that this is a definite integral.But it contains a as a constant under the integral.So the integral is a function of a.And the function is square root of pi over a.And that's what gives us that normalization factor,the 1 over square root of 2 pi sigma squared.And so that when we integrate the probability density,it integrates to one the way it has to.And if we need to get higher moments,we can do it by differentiating.So, for example, you notice that if I differentiate the integralwith respect to the parameter, if I compute dI da--or actually minus dI da, OK, I can move the derivativeinside the integral.The coefficient of a in the exponential is x squared.And that gives me the integral of a squarede to the minus ax squared.And that we recognize as the expectation of x squared.So I can get moments by taking derivatives.And we'll see how to generalize this as well.What about the cumulative distribution function?Well, F of z in this case, which is sometimes known as capitalphi--in some places, you'll see it written with the letter Nand sometimes related to a function knownas the error function-- is a definite integral.We integrate from minus infinity to infinity [correction: z]of e to the minus z' squared over 2.And that gives us this distribution function.You notice that if we differentiate the integralwe get back our probability density.So this gives us the probability that the random variablewill be between any two points.Or for F of z itself that it will beequal to the given z or less.The log-normal distribution shows up in finance as well.We often look at logarithmic returns.And our standard model for return distributions on assetsis a starting point to see if the logarithmic returns mightbe normally distributed.And that distribution is called the log-normal distribution.The way it's defined mathematicallyis simply to define X to be log of Y.And we can compute x is log of y herefor a probability density and substitution,apply change of variable formula.And we see that we get this form right here.Now, computationally, this is just to change the variable.So if we're going to compute moments,we can use whichever variables we prefer.And the usual application of this is in looking at returns.So we often have a relationship between the simple returnsthat we designate by R, simple returns on an asset.And the logarithmic returns are definedto be e to the little r minus 1 is big R.We'll see in more detail how that works with pricing.But we can compute with respect to either distribution.Remember that the moments are just numbers.And whichever way we choose to do the integral-- whateverchanges the variables we make in the integral--it isn't going to change the final result.

#### Prob02_S03_v3-en

PROFESSOR: The Poisson distributionshows up in looking typically at the arrival of eventsor at jump processes.So we look for the arrival of a jump,maybe in a market price, or the arrival of an event,such as a credit default or customersarriving or customers departing, for ordersarriving at an exchange.So we often apply it where we're thinkingof continuous time and discrete events arrivingat some unknown interval.And we use a Poisson distributionto model those intervals.So mathematically, the Poisson distributionhas two parameters, two values.And sometimes it's convenient to think of it as a functionof one or the other.But we have k, which is an integer, and lambda, whichis a real valued variable.And the probability is e to the minus lambda, lambdato the k over k factorial.So when we're looking at arrivals,we apply that by thinking of lambdaas being an arrival rate.And we replace lambda by lambda tas being the number of events thatmight arrive during a particular time interval, t.And we would use this probability distribution.What are its properties?Well, the mean value we just compute.We sum over k, over all the possible k's timesthe probability of observing each k.And we find the expectation of X, the average value of k,is just equal to lambda.And if we do the calculation for the second moment,we do the math and we compute this sum.And we find that it's lambda plus lambda squared.If we then go and compute the variance--remember that the variance is the expectation of the square,lambda plus lambda squared, minus the squareof the variance, which is lambda quantity squared.And what we get is that sigma squaredis equal to the lambda, which is actuallythe same thing as the mean, interestingly.Now, the Poisson distribution is also a special case.It's the limiting distribution when n goes to infinity,of the binomial distribution, in this special case wherewe let n go to infinity and the probability go to 0,holding their product fixed.So in that case, we can show that we recovered the parceldistribution.And an example of where we could apply it numericallyas a useful distribution-- because the binomialdistribution is pretty hard to computewith all those factorial when n gets large.So this is an easy thing to compute.Remember the k is typically going to be a small number.But n going to infinity going to 0or n very large, p very small, we can just take their product,hold it fixed, and get a good calculation,a good approximation from the Poisson distribution.For example, if we have a classroom that has,let's say 65 students and we ask who has a birthday on a givenday, if we assume birthdays are equally likely to beon any day of the year, an approximation, 1/365,65 students, we would compute lambda as n times p.We could ask is 65 close to infinity.Well, let's take a look.If we compute n times p for this particular values,we get the lambda is 0.178.And if we compute the exact Poisson probabilityand compare it to what we would getfrom the exact binomial formula, we compare itto the Poisson approximation, we find outfor 0, 1, and 2, that these approximations are pretty good.They're good to three decimal places at least.And that's only for an n of 65.The Poisson distribution does have different qualitativebehaviors depending on the value of lambda.So when lambda is small, the valuesare always decreasing in k.When lambda gets to be above 1--and here, I've taken this upper graphis the value that we used in our previous birthday example--down below, I multiplied it by a factor of 10.And now we see that when lambda is greater than 1,it's a skewed distribution with the long tail off to the right.And here is our mean value, is lambda.And we notice that we said that our mean value wasgoing to be lambda.If lambda is less than 1, then that'swhy the whole distribution is bunched upon the left-hand side.When lambda is greater than 1--in this case, lambda is 2.And we see that the p value is around 2.There are a bunch of combinatorial formulasif you want to play around with those.I've just put these in here for completeness.And you can check.But as I said, we've got a couple of tricksup our sleeve that will save us from doinga lot of combinatorics for computing moments in a bit.Finally, I want to say that when itcomes to looking at distributions,that not all distributions are as well behaved.And some of them are going to be exceptions to our ruleabout being able to only look at moments.And the problem is, the thing thathappens that's interesting, is that sometimes those momentsdon't exist.And I mentioned before, that we could try to compute the meanand have the integral diverge.Well, here's another example of that.Here's a very nice looking probability distributionfrom a distance or at a low resolution monitor.You might think this looks like a bell curve.But it's not.So this distribution is given by this function.It's a constant times that constant squared plus xsquared.And asymptotically, as x gets large,it doesn't behave like a Gaussian thatfalls like e minus x squared.It falls off much more slowly with a power.So asymptotically as x goes to plus or minus infinity,this function decreases as 1 over x squared.And you can see what the problem is right away.If we want to compute the expectation of x squared,the integral won't converge.If we want to compute even the expectation of xor of x the fourth and x to the eighth,the integral is going to diverge wildly.So the probability distribution is fine.It sums to 1.There's no problem.We can compute the probability of being in a given area.But none of the moments exist.If we were to see things like this in data,if we were to look at observations like let's say,stock returns that were drawn from a distribution,such as this that had power-law tails.What would we see?Well, qualitatively, like a normal distribution,most of the event, we'd see a single peak.Most of the events are near the center.But fat tails means that extreme eventsoccur quite likely, much, much more often thanunder a Gaussian distribution.They don't occur that often.After all, the tails that values outthere are smaller than the central values.But the area under the curve going out from any given pointis divergent.The weighted averages are divergent sothat the power-law tails are giving usmore and more of the contributionsto analytical quantities of interest.And if we were to try to estimate the volatility usingour standard metrics, we would get finite numbersfor any finite number of observations.But as we increase the number of observations,rather than having convergence, wewould see divergence in the results.So quick summary-- some common probabilitydistributions that you've seen before in your probabilityand statistics classes.These are the main ones that are important in finance--uniform distribution, binomial, Poisson, normal, and Lognormal.These all have well-defined moments,or some interesting limits where we can go from one of themto another.And they appear in all kinds of applications-- option pricing,credit defaults, jump processes, lotsof models of asset pricing, and a forecast in future returns.The Gaussian distribution is the most specialof all because of the Central Limit Theorem,which we'll see the Gaussian distributions is universal.It shows up in places, even where we might not normallyexpect them.Picking which distribution to use for modeling a givenproblem partly depends on the theory and motivationbehind the problem that we're looking at,but it always depends on the empirical behavior.So we can't just postulate that things are normaland that they are log normally distributedand assume that all will go well.We'll need to check that that's how the real world behaves.

#### Prob03_S01_v3-en

PROFESSOR: Now let's look at sums of random variables.And this is going to open the doorto our construction of discrete time stochastic processes.We're going to use a basic property for probability,that if we have random variables,we can add them together to get new random variables.We'll see that we'll do everythingin terms of the expectations, whichare going to be easy to compute using linearity.And you're going to have really interesting behavioras a function of the number of items in our sum.So when we have several random variables,we construct a new one just by adding them together.So imagine I've got a collection of n random variables--xyz, X1, X2, X3, X4 to the Xn, and I define their sum.There are lots of other functions we could talk about.We could take products.We could do all kinds of polynomialsor transcendental functions, but we'regoing to only be talking about the sumof basic random variables.Now in certain cases, we could ask what the full probabilitydistribution is S, in terms of the probabilitydistributions for X1, X2, X3 and up through Xn.They have a definite probability distribution.So that determines what happens with S.But in many cases, we don't need to knoweverything about S. We just need to know about its moments.And those are easy.They're easy because we can use linearity.What we do is we apply the expectation operatorto the sum, and we see that the expectation of the sum isthe sum of the expectations of the individual X's.So the full probability distributioncan be quite complicated.But what we need to do is to get the mean value,we just add the means of the individual variables.Now due to the Central Limit Theorem,this is actually often all we need,because we get a tremendous amount out of this.If we n is a large number, then the sum of random variablesis going to converge on a Gaussian random variable.That's the distribution of S will approach a Gaussiandistribution, regardless of what the X initial distributionsare.And we'll see that in just a moment in pictures,and then in a subsequent video, I'llshow you how you can derive that.But let's take a look first, at wherewe might apply this sum of random variablesin financial terms.So one case is when we look at portfolios.So suppose we have a portfolio that consists of N assets.And let's let w represent the weight of asset,i, within a portfolio.So i runs 1, 2, 3, 4 through the number of assets we have.Suppose we have stocks in the Dow Jones Industrialaverage-- i would run from 1 through 30and would be equal to 30.Let's let r sub i be the return on that asset.And let's think of it as being a random variable.So each of the stocks is going to havean independent probability distribution.And each probability distributionhas a mu_i which is the expectation of R.And it's got a variance, sigma i squared, whichis just a variance of the random variable, R_iSo what's a portfolio?A portfolio is a weighted average of stocks.So here our weights are not probabilities,they're capital allocations to a portfolio so the ruleand this is just arithmetic that the returnon a portfolio the simple return on a portfolio in a givenperiod is the weighted average of the returnson the individual assets.So we've got this bilinear form.We've got a linear combination of the returns--w1R1 plus w2R2 and so on.So we have a linear combination of random variables.So it's not just a sum, it's a weighted average.What's the expectation of R?Well, that's the portfolio, mean return.And the expectation of R using linearity,is the weighted average of the expectationsof the individual stock returns.No surprise-- the expected return on the portfoliois the weighted average of the expected returnof the individual stocks.So that's a case where we don't know what the full returndistribution is.But we've related the mean of the portfolioto the mean of the individual stocks.What about the variance?Well, if the variables were uncorrelated,that would be one thing.But that is not the case with most financial variables.And certainly, it's not the case for asset returns.So let's take a look at what happenswhen we compute the variance.What we'll see as we define the variance of our portfolio,R_p Remember that R_p is just this weighted average.So when we take a look at R_p minus mu_pwe can expand that out in terms of our individual stocksin this way.And if we expand out the quadratics--so this is a quadratic.We expand out all the terms and wegroup them together, we get two kinds of terms.We get diagonal terms.We get an i with itself gives a set of n terms, w_i squaredtimes the expectation of R_i minus mu_i quantity squaredplus all the cross terms that come from i not equal to j.These terms, you'll notice, are a weighting factor,w_i squared, times the variance of stock, i.And the cross terms give us for each i not equal to j or twicefor each i less than j, wiwj times the covarianceof R_i and R_j.And that just comes from expandingout the polynomial inside the expectationhere, and grouping the terms together.We can rewrite these two terms in terms of sigma squared.Sigma i squared is the variance of R_i.And using our formula for the correlation,we can relate the covariance to the correlation by noting thatthe covariance is just sigma_i sigma_j ,times the correlation of i with j,which I've denoted here by rho_ij .So you notice the structure of the formula that we have.The return on the portfolio is quadratic.Excuse me, the variance of the portfoliois quadratic in the weights.It has a term in w_i squared times the sigma is squaredfor each of the stocks, plus twice w_iw_j, sigma_i sigma_j ,rho_ij .So if the stocks were uncorrelated,we'd only have the first term.And if the w's were 0, of course, this would vanish.A couple of special cases of this are worth keeping in mind.One of them is if the correlationsrho_ij were equal to 0, then we see we have the first term.But notice that it becomes the sum of a bunch of squares.On the other hand, if rho_ij in this expression,if these were all equal to 1, then younotice that this becomes an expressionfor a perfect square.If rho_ij is equal to 1, then the variance of the portfoliois the weighted average squared.So it's the square of the sum insteadof the sum of the squares.Finally if the correlation were 0and everything were the same-- all the stocks were the same.They all had the same volatility.They all had the same variance.And the portfolio were equal weighted, what would we see?Well, if the portfolio is equal weighted,each stock will have weight 1/n.If the sigmas are all equal, we can give them the name.If the sigma i's are all equal, let's call it sigma 0.And now, this formula here, if we bring it down and substitutethose in, we see it as a portfolio value becomessigma 0 squared divided by n.That is we've got 1 over n squared.But there are n identical terms in the sum.So we get sigma 0 squared over n,which means that the volatility of the portfoliois proportional to 1 over square root of n.That means that as n gets large, the volatility in the portfoliogoes down.And this is the basic idea behind portfoliodiversification.

#### Prob03_S02_v3-en

PROFESSOR: Now, that's for a special case of a portfolio.And I said we'd look at a large number.If we take a look at two random variablesand we want to compute the full distribution,I said that we could do that, rather than just computingthe mean and the variance.But it does get complicated pretty quickly.Let's start with the simplest case.The simplest case would be two random variables.And two is not a big number.And let's let them both be uniformly distributed.So to compute the probability function--which is going to have this shape down here by the timewe're done, this is our result--what I do is I compute the cumulative distributionfunction.I have to do a double integral in dx and dy.I have to pick particular regions of integration.And I have to do this complicated integral, whichis known as a convolution.But I can do it in closed form for two variables.I get this result here.And it looks the probability distributionhas this triangular shape.And it's done.So we've got it.So it can be done in this case.But now imagine doing this for three,four, five, six variables.Each one is going to look different.So that's more work than we want to do,and it's not going to be necessary.It's both more work and less intuition.However, if we just want to check our intuitionand run a quick numerical simulation to takea look at this, we can do this here,with this command in the R programming language.And I'd encourage you to setup and install R and RStudioand to run this.The function that we want here that we'llbe seeing when we discuss Montecarlois, pick a random variable from a uniform distribution.So this looks like it says "run if,"but it's "r unif," from uniform distribution.So here, I've picked 10,000, excuse me,100,000 random numbers for X_1 I picked 100,000 random numbersfor X_2 And I'm looking at a histogram that gives mea discrete approximation to the probabilitydistribution for their sum.And you can see that it looks approximatelylike the triangular distribution that wesolved for in closed form.Now, let's come back to the binomial distributionthat I talked about earlier wherewe computed the mean value doing a lot of combinatoricsand shifting around the variables in some kindof mysterious ways.If we want the mean and the variancein the binomial distribution the easy way,we just apply linearity to a sum.So how do we think of the sum?We said that we wanted to compute successesas positive successful outcomes.And we wanted to count them up versus the number of failures.So one way we can do that is by having the variable X_1 X_2X_3 represent the outcome of the first, second, or thirdexperiment.And we'll let a plus 1 designate a success,zero designates a failure.And then adding together all the axesis a variable, S, that counts the number of successes.And notice it doesn't matter in what order they occur.If I get success, success, fail, fail, fail, fail, fail,it doesn't matter where those two successes come.It could be fail, fail, fail, fail, fail, success, success.Anywhere they are, they get the same value of SSo what's the expectation of S?What's our mean value?Expectation of the sum is the sum of the expectations.And each of these is equal to p, because Ihave probability p of getting a 1, probability 1 minusp of getting a 0.So the expectation of X_1 is p.The expectation of X_2 is p.Each of the expectations is p.I've got n of them, n times p.We're done.OK?So I've shown that down here.So the expectation of X_1 is p.And we're going to do the variance in a moment.So let's continue the expectation of X_1 squared.How do we compute it?We use our rule that the expectationis the probability-weighted average of the thinginside the expectation.So with probability p, I get a 1.1 squared is 1.Probability q, I get 0 squared, and that gives me a p.OK?So the expectation of any of the X's is p.The probability of any of the X squareds is p.And if I take two different X's, the expectation of X_1times X_2, well, now they're independent random variables.So they could both be 1, with probability p squared.p that the the first one is a success, pthat the second one's a success, is p squared.And then I would multiply that times X_1 being 1 and X_2being 1.And then everything else here, successfail, fail success, and fail fail,those all have 0's in them.So those all drop out.So the only term that survives is this one,and that gives me this result.So because these X's are independent of each other,and because they're identically distributed--any one of the X_1 is the same as X_2 Or X_3 or X_7--I have these results and I can apply them.So now let's apply this for the calculation of the variance.We're just going to do a little bit of algebra.It's almost as easy, no combinatorics involved.Well, a little bit of combinatorics.But no factorials, not like we had before.So the definition of our varianceis that the expectation of the random variableminus its mean quantity squared.Or it's the expectation of the variablesquared minus the mean squared.So that's what we use here.We can expand out this sum into n terms with an X squared.So these are all going to be identical.They're going to be n terms.I'm going to have X_1 squared, X_2 squared, X_3 squared.I'm going to have n of them.So let me just take n times the first one.And then I'm going to have the cross terms.I'm going to have n choose two possibilities.But actually, I'm going to get X_1 X_2 and X_2 X_1.So I'm going to have twice n choose two, which just gives men times n minus 1 cross terms.OK?And each of the cross terms is going to be the same as 1 2.So 1 2 is the same as 2 3 is the same as 4 6.They're all the same.So I'm going to get n times p plus n n minus 1 times psquared.And then I'm going to subtract off my previous result squared,which is np quantity squared.And when I combine the terms, I get my final result, npq,or our final, final result that the standard deviationis the square root of n, square root of n times p times q.Remember that p and q, q is 1 minus p. p and q are constant.So this says that the variance is proportional to nand that the standard deviation isproportional to the square root of n.

#### Prob03_S03_v3-en

PROFESSOR: Now, in expanding n, we'lloften want to take a look at what happens as n increases.And I'd like to show you that in pictures right nowon the computer, doing a simulation in R.And for the full binomial distribution,we run into a problem when we put iton the computer, which is that if we write outall the factorials, the factorials quicklyoverrun the machine limit.But the combinations are usually well behaved,so we use a function that's built for this purpose.We'll use the function in R called choose.So choose(n,k) is what you would expect.It's n choose k in a way that doesn't blow upfor moderate values.And dbinom is the distribution functionfor the binomial of k, n, p using the same definitionsthat we had here.So what I'm going to do is I'm going to picka particular set of values.I'm going to get n equal 1, 2, and then we'regoing to keep going.I'm going to jump.We're not going to every single value of n.But I want to start at n equals 1, 2, 5,and quickly get to 1,000, and I'dlike to see what happens to the binomial distributionas n gets large, holding p and q fixed.And the values I'm going to pick, we'll let p equal 10%and we'll let q, therefore, equal 90%.So we have a 10% chance of success.And remember, the binomial distribution tells usif I've got a 10% chance of success per trial,if I do n trials, what's the probability of getting 0through n successes?So if I've got 1--if I run n equals 1, I could either have 0 or 1.And if it's a 10% chance of success,I have a 90% chance of failure.And here they are.So this is a 90% failure.Probability of 0.And here's a 10% chance of getting 1.For n equals 2, I still have 81% chance of failure.I have a 1% chance of two successes,and the rest of the probability distributionis here that I have one success and one failure.This is for n equals 5.n equals 10.And notice that when we've gotten--once we get to n equals 10, the largest valuenow is not the smallest value.So instead of the whole probability distributionbeing bunched up to the left-hand side,where's the mean value?n times p.p is 10%, n is 10, it's at 1.That's right here at the largest value in the distribution.Let's keep going.This is for 20, 50, 100.And now by the time we get to 100, take a look at there'sthis large tail off to the right-hand side, whichisn't even visible because these areless than 1 pixel high with the resolution of your screen.So it's possible in 100 trials, in this case for n equals 100,that you might get more than 24 trials.But the probability is so small that wecan't see it on this scale.Notice something else interesting is going on.This distribution, where it is active, first of all,it's peaked around where?It's around 10.p times n is 10, and that's about where the peak is.But notice the distribution for the part of itthat's noticeably non-zero is looking much more symmetricbetween the values less than 10 and the values above 10if we don't pay attention to this big right tail over here.And this is for 1,000, where we have things centered on 100.And again, the distribution is gettingvery tall and very narrow.So for fixed p, the distribution initially decreases.As n increases, the distribution stayscentered near np, which is consistent with whatwe computed analytically for the mean value.The distribution gets narrower and more symmetric.And this is an illustration of two important limit theorems,just done in pictures.We haven't done a mathematical derivation by any means.The first one is known as the law of large numbers.The law of large numbers says that as the number of trialsgets large, you're going to see the mean value of the numberof the realizations in experimentsis going to approach a theoretical mean.Another way to say that is that the probability of observingthe mean deviating from--the average value deviating from the mean value,the expectation of the probability distributiongoes to 0.And that's why the probability distribution is narrowingaround that mean value.The other one is the central limit theorem.The central limit theorem says that as weadd more and more variables, the shape of the distributionapproaches a Gaussian distribution,or a normal distribution.Now, to see that a little bit more clearly,let's change variables to what I'll call a scaling variable.And what I'm going to do is because as n gets large,the interesting value of k is going to be the one near np,near the mean, let's pick a value that's centeredright around where we want it.So I'm going to define this scaling variable z to be--I'm going to use this to replace k.So what I'm going to do is I'm goingto subtract off the mean value.So the numerator, k minus np, sayshow far my k is away from the expectedvalue, which is n times p.And then I'm going to divide it by the standard deviation.So that gives me kind of units as to how far away I am sothat that also scales with n.And let's see what happens if I do that.And the code is here, which you can take and copy and pastefrom the website, or you can retype it--it's just a couple of lines of code-- and run it yourself.Or I'm sure you can write better code than mine.So give it a try.Let's look in pictures at what happens now.So starting out, we see the same picture--n equals 1, n equals 2, n equals 5, n equals 10.And now what's happening is we've recentered thingsso that the whole distribution is stayingon a similar kind of scale.As we keep going, n equals 20, n equals 50, 100, and 1,000.And now we've got something that looks symmetric.It looks Gaussian.It's our favorite bell curve.Now, it's not exactly the bell curve, to be sure.It doesn't go to minus infinity or plus infinity.It only goes to 0 on the left and the mostwe could be is 1,000 on the right.So the midpoint is centered where we'd expect,at n times p around 100, but it is not the exact Gaussiandistribution.It looks like it just because of the scale on the computer.We don't see the behavior of the tails.We need different graphics, transfer it--different plots with different transformations,such as qqPlot to see the behavior of the tailsor to look more carefully and analytically.But in the bulk of the distributionwe've recovered, we see the central limittheorem in action, where adding togethera bunch of non-Gaussian random variables,non-normal variables, each of the variablesalso is very skewed.It's 10-90%, so it's not equally likely up or down.Nevertheless, when we add 1,000 of them together,we get something that looks Gaussian.So this is what's going on with the central limit theorem.So the distribution, if we wantedto write down an approximation for whatthe limiting distribution is, we could approximate our functionf of k and n, p by introducing the scaling variable z subk as I've defined it.And in terms of z sub k--so we could substitute in those values--this function is approximated by a standard Gaussiandistribution, 1 over square root of 2pi, eto the minus z squared over 2.We can see that this is a good approximation in lotsof practical examples.Here's one that we took a look at it at Sloanwhen we were trying to figure outif there were enough Bloomberg terminals for the students,back when we used to show up in the buildingbefore the pandemic.And the class size for a master of finance programwas about 120 students.We had nine Bloomberg terminals at the time.I think we may have more now.And suppose that they independentlywanted to use a terminal with probability 7 and 1/2%.So we'd want to know, what's the cumulative probabilitythat nine or fewer students wouldwant to use it at the same time, if therewere independent demand?We could have 120 students all show up at once,but that's very unlikely.So the binomial distribution letsus compute, what's the probability of 0, 1, 2, 3,up through 120, and we can sum that up and get an exact answerfrom the binomial distribution.But in fact, we get an almost exactlythe same answer by using the normal distribution to plug in,and you can see on this plot whereI've shown in red sort of the integralup to the point of interest that the distribution looksGaussian, and we get a very good result from the Gaussiandistribution.So let's summarize what we've saidin discussing random variables, because this is our jumping offpoint for looking at random processes that describe lotsand lots of behavior in financial markets,and help us think about financial decision making.Any set of random variables can beused to construct a new random variable, their sum,just by adding them together.We could ask about the distribution of this S.If we want to compute it, we needto do convolutions of the probabilitydistributions of each of the axes,and that means n fold multiple intervalsin n dimensional space, which is hard.But for most of our applications,we only need the moments, like the mean and the variance,and that we can compute just from what we'relooking at in terms of the mean and the varianceof the individual random variables.And that's easy.So the moments of the new random variableare computed by linearity.And if the variables are IID, if they'reindependent and identically distributed, that is,this collection of n variables are not justn variables from completely different corners of the worldbut they're the same kind of variablerepeatedly, then as n gets large,this sum S is going to have a full distribution that'sgoing to in limit approach a Gaussian distribution.So we will know its full distribution in that case.We still get the moments, of course, but in special cases,we get the full distribution.The application we're going to be looking at in our next unitis the construction of stochastic processes,and those have exactly the structure we've looked at,but where the variables are orderedand they correspond to informationbeing revealed over time.So X_1 would be an information that was available on day one,X_2 would be new information that arrived on day two,and so on.So we'll be interested in using this structure, the behaviorof sums of random variables, to seehow information evolves in time to see how valuationis done when the dynamics of these processescan be fully described.

#### Prob04_S01_v3-en

PROFESSOR: Let's look at a little bit more detailat generating functions and central limit theorem.We'll be doing this using Fourier transforms.So if you've never seen a Fourier transformwith a complex analysis, you can either skip this partor just watch and take a look at it.This is background material, it'snot essential for what we're going to be doing.But for people who have done this math and whoare familiar with it, it's an interesting wayto see how the central limit theorem emergesfrom some simple calculations.So you may have seen in a statistics or probabilitycourse, the moment generating function, that'sthe expectation of e to the X. And here, we'regoing to do a slight variation of it.We're going to introduce i, the square root of minus 1.So this is going to look like complex analysis.But don't worry, there won't reallybe any imaginary numbers in our financial market.The only imagination is, maybe, the richesthat we would like to be thinking about getting.But everything else is going to be brutally real.Nevertheless, it's a good mathematical trickbecause Fourier transforms, as we'll see,have some nice properties.So the characteristic function serves the same roleas the moment generating function.That is, it lets us summarize allof the moments of a distribution.So the idea is that we can describe the functionby-- if we look at the expectation of eto the itX, where X is our random variable,and we expand out that exponential in a Taylor series,we get 1 plus itX plus 1/2 i squared t squared X squared,and so on.And then we apply linearity, and wecan see we're going to get a term with expectation of X,one with expectation of X squared, onewith expectation of X cubed.And each of those has a coefficient, t, t squared,t cubed, and so on.And by differentiating with respect to the t's, wecan recover the individual coefficientsor the individual moments of the distribution.So this is the same thing as a moment generating function,just with these extra powers of i tucked in.So this is especially useful if we can do it in closed form.So for example, in the case of the binomial distribution,where we can write down the probability distribution herefor each value of k, then we can sum over k equals 0 to n.It gets cut off, we don't need to go all the way to infinity.And we can actually do this some in closed form.Because, notice, that the e to the itk is e to the itraised to the k-th power.I just regroup those together over here and do the sum.And that's where the binomial distribution gets its name.It's the expansion of this binomial, this quantity pe to the it plus q raised to the n-th power.So that's it.That's in closed form.That's the characteristic functionof the binomial distribution.So if I want to get the moments from it, I take derivatives.So the first moment--so if I look up here up top, if I pick a value of l. lequals 0, 1, or 2.I come down here and I take zero derivatives or Itake one derivative times a minus i.And that gives me np.I take two derivatives with a minus i squared,which gives me a minus 1.All you need to know is that i isthe square root of negative 1.And here, I get npq plus n squared p squared, which iswhat we saw earlier, and so on.So this is just a nice way of encoding allof the moments in one place.And then we recover them by taking derivatives,if we can compute that in closed form.In the case of continuous distributions,the expectation of e to the itX takes the form of an integral.And this intergral over here on the leftis known as a Fourier transform, up to some constantsthat we sometimes normalize with.This integral from minus infinity to infinity of eto the itx p of x dx is the Fourier transfer of p of x.And it's denoted by this function p tilde of t.And of course, doing the same rule as before,where we expand out this e to the itx in this Taylor series,interchanged the order of the summation and the integration,we see that this can be written as an infinite sumof expectations.And if we want to invert or if wewant to identify a particular expectation,second the expectation of X squared,it's the coefficient of t squared.The way we get it is we take two derivativesand then set t equal 0.And then we've got these extra i's that are out in front.OK?So that's just an ordinary moment generating functionfor discrete and continuous examples.Why is it useful?Well, it's really useful for sums of random variables.And the reason is that when we havethe sum of random variables, say, x plus y,that the full probability distribution isa convolution of the two probability distributions.So if x_1 and x_2 are arbitrary variables, the probabilitydensity function for y is going to be the integral of pof x_1 times p_2 of y minus x_1, whereI integrate dx_1 to get a function of y.And that's a complicated interval to do.And then I do that for more and more sums.But these Fourier transforms have a marvelous property,which is that the Fourier transform of a convolutionis the product of the Fourier transforms.So the Fourier transform for p of yis just p_1 tilde times p_2 tilde.We just multiply them together.And that makes it easy.

#### Prob04_S02_v3-en

PROFESSOR: Gaussians are very special,because the Fourier transform of the Gaussianis actually also a Gaussian.And you can check that by doing out the intervalsor taking a look at your favorite table book.Notice that if this is our usual friend on the left,the Gaussian distribution-- notice where the sigma appears.It appears in the denominator of the exponent.The Fourier transform over here, is a function of t.So it's e to the minus t squared times something.But the sigma squared is in the numerator of the Fouriertransform, not the denominator.And they both have a 1/2.So the first one is x minus mu quantitysquared over 2 sigma squared.This one is t squared sigma squared over 2in the numerator plus i.There's our complex value--i times mu times t for the case mu is non-zero.But basically, it's a Gaussian form.It's of the form e to the minus t squared.What that means is that if we havea sum of n random variables, what'sthe probability distribution of the sum?Well, the p-tilde is going to be the product of all the p's.Those are each Gaussians.So for 1, 2, 3, 4 up through n, I multiply together,the Fourier transforms, exponential with sigma 1squared t plus sigma 1 squared t squared over 2, plus i mu 1t.And the same thing with 2 and the same thing with 3 and soon--the product of exponentials the exponentialof the sum of the exponents.So we can combine these things up in the exponent here.And these simplify-- you notice that theytake the form of the exponential of minus 1/2 somethingtimes t squared, plus something else times t.The coefficient of t squared is the sum of the sigma squared.So we could define a new thing, wecould call sigma hat squared, to bethe sum of the sigma squares.And we could define mu hat to be the sum of the individual mus.But the important thing is that we can rewrite p-tildein the form of any one of those individual p-tildes.That is it's a Fourier transform of the Gaussian.So this shows that the sum of Gaussian random variablesitself, has a Gaussian distribution.It also tells us what the parametersof that new distribution are.If they're identical random variables,if all of the mu's and sigma were equal for 1, 2,3 4, 5 6, 7, then when we add togethern identical Gaussian random variables that are allindependent, their mean is N times the meanof an individual one.Their variance is N times the sigmasquared for an individual one.And therefore, their volatility, their sigma,is the square root of N times the sigma of oneof the individual random variables.Now because the Fourier transforms multiply,their logarithms add.So we define something called the cumulant expansion, whichis convenient when we're taking logarithms.And here, p-tilde is the exponential.So before we expanded, that we hadan exponential the other way, thisis the exponential of a sum.And these C coefficients are particular linear combinationsof expectations.They just group together in a very convenient wayfor certain applications.And this one you'll see right here.So here are some examples of where we would apply thisif I want to get the--so to extract the C's, what I do is I compute p-tilde.That's just a Gaussian, for example--in the case of the Gaussian, it couldbe any of our other examples.We take n derivatives of the logarithm of p.And then we have our pre-factor of the i's.So the first few terms are C1 is just the expectation of X. C2Is the variance.It's the expectation of X squaredminus the square of the expectation of X.C3 is a bit more complicated.It's the expectation of X cubed minus 3 times the expectationof X times the expectation of X squared, plus twicethe mean of X, the expectation of X quantity cubed.And for C4, we have this other complicated algebraicexpression.But it's a particular linear combination.Now, what's nice about these combinations,is that they take a very simple form for Gaussians--namely, they're all 0 after the second one.So in the case of a Gaussian, all of these higher cumulant,C3, C4, C5, C6 are all 0, whereas the individual momentstake some values that we could compute.So in this particular grouping, for a Gaussian distribution,we have C1 and C2 are non-zero.For a general function, It could be--these are just some numbers we couldcompute using the formulas on the top of our screen.Now, here's a way to see the Central LimitTheorem and how it comes about.If we take a look at the cumulants for sum of N IIDrandom variables, because they're identically distributedand because the cumulants add, the nthcumulant it's going to be N times oneof the individual ones.So they just add.So we just multiply times N and that's it.OK so if we know the C sub n's for one of the variables,we know what it is for a sum of N of them, big N of them.We just multiply times the number of random variablesthat we have.Now we can normalize these.These are going to have dimensions-- remember,they depended on powers of X. So let's turn theminto pure numbers by dividing by powers of sigma,same way we did in defining the skewnessand the kurtosis, originally.But now when we do this, if we wantto relate these dimensionless numbers for our sum,to the corresponding dimensionless numbers for oneof the individual random variables,there's a pre-factor that comes from all these powers of n thatare over here and from our sigma.And it goes as 1 over big N to the n over 2 minus 1.And when the cumulant is greater than 2, for n greater than 2,these are positive powers in the denominator.And that means that as big N goes to infinity,all of these scaled cumulants vanish.And that's how we can see that the distribution hasto become Gaussian.If we had done this in terms of the moments,it would have been much more complex.The cumulants group things together very nicely,so that everything above 2, everything that doesn'tlook like a Gaussian goes away.So in this way, we can see that the cumulant expansionuniquely defines the probability distribution.When big N goes to infinity, there's a universal behavior.And everything greater than C2 vanishes,and therefore, whatever the original distribution was,it looks like a Gaussian distribution.Now there are a whole bunch of caveats.And let me just mention two--one of them is that this just tells youthat if N is sufficiently large, the distribution willapproach a Gaussian.But it doesn't tell you how large and needs to be.And the convergence isn't uniform.So for large values of the random variable awayfrom the mean value, the convergence is much slower.And it's much faster in the center.So the rate of convergence is uniform,and we don't know how big N needs to be for that.Also, this is subject to the cumulants existing.So if we have things like the fat-tail distributionwe looked at earlier, then all bets are off.This scaling argument won't work.So for nicely behaved functions where the moments exist,the cumulants will exist.And the Central Limit Theorem gives us that important result.Here's an example of a bunch of random variables.And how large does n need to be close to infinity?I don't know.How about 6?This used to be a poor man's random number generator.Add together six uniform random variables,and see what the distribution looks like.Here's some R code to do that.And I overlain the results with a exact Gaussian function.Not bad-- certainly for eyeballing.Again, there's the caveat that any finite distributionis going to be bounded.In this case, if I have six uniform random variables,values can't be smaller than 0, can't be bigger than 6.But in the places in the center of the distribution,we're actually getting close to the shape that we would expect.So here, I've done 100,000 simulations of adding togethersix uniform random variables.And the distribution we get is anything but uniform.It looks quite Gaussian.So let's just summarize.The characteristic function of a probability distributiongives a compact formula for generatingall of the moments of the distributionby taking derivatives.For continuous random variables, if we computed in closed form,we find that we're in the domain of Fourier transformsand complex analysis.So if that's something that you've seen before,you know how to do these calculations.And you know when these integrals convergeand how to compute them.Gaussians are special in a lot of ways.First, the Fourier transform of the Gaussianis also a Gaussian.And that means that the sum of Gaussian random variablesis always a Gaussian, not just for an infinite numberof terms, but for any number of terms.The Central Limit Theorem tells usthat if we add together a large number of any IIDrandom variables, that will get somethingthat will approach a Gaussian.So Gaussians really are universal.When we look at adding together a large number of influences,such as economic factors and drivers, behaviorof lots of market participants-- when we add togethera very large number of random shocks and influencesfrom independent sources, there's a good chancethat we might see Gaussians start to emerge,even if the underlying behaviors haveno connection with the Gaussian distribution at all.

### 03-Recitation_1

#### Rec01_S01_v2-WaitingTimes-en

PROFESSOR: Finance involves a lot of uncertainty,and we use language of probabilityto model that uncertainty.The common distributions of finance occur in many ways,sometimes directly and more oftenas the building blocks for more complicated processes.So let's take a look at a couple of examplesof how we compute expectations from distributions,how we can solve some interesting problemsfrom some simple ones.And let's start thinking ahead alreadyas we review probability to thinking about how we'regoing to use these basic tools of probability to describeprocesses that evolve over time, wherewe need to think about uncertaintyover multiple horizons in the futureand where information may arrive graduallyfrom one point to another and get incorporatedin our description.So our starting example, let's just think of a random variablex, a binomial random variable where I have probabilityp that we sometimes call success of gettinga 1, probability q which is just shorthand for 1minus p of getting a 0.The typical question we ask and that we saw in lectureis, what's the probability of observing a fixed number,say, k successes out of a total number n of trials?So to do that, there are two common things we do.First, we ask for a given sequence,what would be its probability?Well, if there are k successes and thereare n minus k failures, then the probabilityhas to be p to the k q to the n minus k.Because the events are independent,our probabilities multiply.And then, there are a lot of different ways of doing that.How many?Well, we've got a sequence of n events.The 1's could be placed at any orders between them.The number is n choose k probabilistically,and this is the familiar binomial distribution,sometimes written k of n with parameter p,the probability for success.Now, suppose we ask a different question.Suppose we ask how long it would take us to observe success.That is, we don't know what n is in advance.We'd like n to be the outcome.So n is our random variable or wemight call it T to think about a waiting time.So let's call T the waiting time.And that's how long we would need to wait for success.So what might happen?Well, we could have it happen on the first event.So we could have a T equals 1, we get a success,and that could happen with probability p.It could happen on our second trial.T equals 2.That is, we could fail it first--have a failure and then a success.And that would be probability q times p.Third trial, if it happened at T equals 3,we would have fail, fail, succeed.That would be q squared p.And in general, we can see that for T equals n,we're going to have probability q to the n minus 1 p.That is, we have a string of n minus 1 failures followedby a success, and this is the geometric distribution.So we have that the probability that the waiting time isequal to some particular n is given by q to the n minus 1 p,or we can write that of course as 1 minus pto the n minus 1 times p.So how long should we expect to wait on average?Let's compute.When in doubt, compute.The expectation of our waiting timeT is going to be the probability weighted average of the waitingtime.So we have a formula for that.So we can write this as the sum from nequals 0 to infinity of n times q to the n minus 1 p.Now, if we look at this, we noticethat this combination here looks familiar, doesn't it?It's the derivative of q to the n.So we'll use a trick.What we're going to do is we're goingto write it as a derivative.And then, because q is positive and less than 1,the sums are convergent.And we'll interchange the order of differentiationin summation, which will give us somethingthat will be a nice, quick answer and something thatgeneralizes for more complex cases.So let's see how that goes taking, it step by step.This is equal to--I'll pull the p out in front times the summation of dby dq of q to the n, which I'll write as p dby dq times the sum of q to the n.And the term in parentheses right here is a geometric sum.So we can do that sum.This is just p times 1 over 1 minus q.And its derivative gives us 1 over 1 minus q squared.Now we remember that p plus q equals 1, so this is p times 1over p squared.Therefore, we find that the expectation of Tis equal to 1 over p.So this should make some amount of sense.First of all, we see that as p gets small,the expected waiting time gets large.If we have a 1 over 6 chance of throwinga seven with a pair of dice, we wait on average six turnstill we get that.If we're looking for a set of two aces and playing poker,then we'll have to wait on average 221 turns.Now, it's important to note that in both these cases theysatisfy the Markov property, whichsays that there's no memory of what happened before.That is, if we just got a pair of acesour expected waiting time for another pair of aces is 221.But if we've been waiting 220 hands,we still have an expected waiting time of 221.Regardless of what came before, the future expectationsdepend only on the present-state variables for where we are now,not on how we got there.And this notion of Markov processeswill be important for characterizingdifferent kinds of time evolutionand for the way in which informationgets incorporated into interesting financialvariables.So when it comes to games of chance,certainly we know that in a fair gamethat the next outcome is independent of the ones thatcame before, that each one should be independent.Let's now extend and ask, what wouldbe the variance of the waiting time?So for the variance, let's rememberthat the variance of the waiting time or for any random variableis the expectation of the variableminus its mean value, which here I justto simplify the notation.Instead E of T within the expectation,I'll just call T-bar quantity squared.And we have the general property for all expectationsthat the variance is the expectationof the square minus the square of the expectation.Let's just review that.This is expectation, and I'm goingto expand out the quadratic.T squared minus 2 T-bar T plus T-bar squared.Remember, the T-bar, the expectation of T,is just a number, whereas T is a random variable.Now applying linearity, we have that the expectation of the sumis the sum of the expectations and the expectation of a scalartimes an expectation-- we just bring the scalar out front--plus T squared.Now, we notice it in this second term, right here,that we have T-bar times T-bar.That is, this combines to be minus 2 T-bar times Tbar, which gives us minus 2 T-bar squaredplus T-bar squared.Minus 2 plus 1 is minus 1.So we have that this is equal to, as advertised,the expectation of the squared minus the squareof the expectation.So how do we apply that to our Bernoulli trial case?Well, we'd like to find the second moment.T-bar, we've already computed.It's 1 over p.So T-bar squared is going to be 1 over p squared.So we'd like to do for our Bernoulli case iscompute the second moment.So we'd like to compute expectation of T squared,and that's the second moment.So this is going to be the sum from n equals 0to infinity, this time of n squared times the probabilitythat T equals n which is the same as we saw before.Now you notice we're not quite in as good shapeas we were before because I have n squared instead of n,and this quantity here is not just the derivative of qto the n.But we can come close.We can still use a derivative trick in a slightly differentformula.And what we'll do is we'll notice that every timewhen we took a derivative once, we brought down a power of n.If I want repeated derivatives, Iwould-- if I just keep taking repeated derivatives,I'd end up with n factorial which isn't what I want.So if I take a derivative but multiply back by q,then I will have what I want.So let's take a look.So specifically, let's look at the more general problemof computing, say, the moment T to the power r--and that I can write as--let me take out this p here.And let me take out 1 over q out front.So let me write this as p divided by q timesthe sum from n equals 0 to infinity of what wouldbe an n to the r q to the n.And I'm going to write that in the following way, q d by dqwith this operator raised to the r-th power times q to the n.So if r is equal to 1, I take q d by dq.d by dq gives me an n times q to the n minus 1 multiplied by q.And I'm left with n with a single power of n in front.If I do that repeatedly-- twice, three times, r times--each time I act with the operator qd by dq, I'll bring down in front a power of n.So this is going to be equal to--this is going to be the same thing as p over qtimes the sum of n to the r q to the n.So obviously, we can apply this in the special casewhere n equals 2.But we want to do one more thing, whichis to do our derivative trick--so where we interchange the order of the derivativeand the summation.So let's put this in the form p over q q d by dq.Let's take this operator to the r-th power times 1 over 1minus q.So here's your chance.Take these formulas that we have here.Take a moment right now to go ahead and compute,what is the variance of T?So compute the expectation of T squaredand subtract the expectation of T quantity squaredand express the results in terms of our original probabilityvalue p.Hit pause now if you haven't got it yetand you want a little more time to work it out.But the value that we have is we have nowthat the variance of T for the waitingtime for a success in a single series of Bernoulli trialsis going to be the expectation T squared minus the expectationof T quantity squared.And this is equal to 1 minus p over p squared.So we have a general formula that wecould extend to computing higher moments,and we can apply this to other settingswhere perhaps a Bernoulli process like thismight be part of a more complex sequenceof conditional probabilities.

#### Rec01_S02_v1-Rdemo-en

PROFESSOR: Let's take a look togetherat the code for simulating the scalingof the binomial distribution in R. You can install RStudio.It's freely available for PCs, for Macs, for Linux.And when you install it and you open it up,you should see something like this.So there are four panes.On the left-hand side, on the lower leftis the console area, which is where we'll type commandsinteractively.On the upper part is where you'll see source files.And this is the code that is in the slidesas during recitation.On the lower right is where plots will show up,where help information is given, where you can see listof installed packages that are partof your particular installation.And on the upper right is where you can see the variablesyou've created.So let's take a look through the code one step at a time,run it together.You should do this along with me, or after watchingthis short video.And go in and tweak the code.Tweak the parameters.Run it yourself.You should get your hands on with the code.Try it out.There's nothing special about R, necessarily.But it's a great language to learn.It's very practical.If you don't know it, now is a great chance to learn.And in the finance industry, you willfind that while people may have all kinds of different opinionsabout what the pros and cons are of different computationalenvironments, usually on the job, you don't get to choose--or even if you're in charge, you'lleventually have to interface with the counterparty who'sgoing to have another choice.So it's always good to know new languages,to keep the ideas separate from the particular codeimplementations, and ready to pick things up and try themout, particularly when you've got a problemto try as, you do here.So let's do this together.Anyway, so let's go through a demonstration.So the first thing, which is a bit R-specific,is I'm going to define a list of values that I want to try.So nlist is going to be the name of my variable.The left assignment arrow, the less than dash,you can use in the equation.That works fine.That's a symbolic thing, and it's conventional in R.And then the c operator concatenates the list operator.It creates them.So my list consists, instead of going every step, one, two,three, four, five, up through 1,000.I just picked some convenient samples.In RStudio, I can take this--I certainly could take this line,and I can type it in the lower part and run it.And if I type n list, I'll get my values out.And you notice that in my list of my environment variables,it showed up here in the upper right.However, if we're working with code,and you've got more than just a couple of lines interactively,you may find it helpful as I do to open a new window for an Rscript as a scratchpad.Or in more structured examples, in R notebook.Keep them up here, and then if youwant to run something that's highlighted up here,you can highlight one or more lines of code.Click on run, and it will run your selection.So let's take a look for those values of n,I'm going to define my probability to be 10%.And we can change that in a moment.And then I've got a for loop.So the for loop is going to take nto run through all the values in the list.And then the contents of the for loop are enclosed in brackets.So white space is not important.Unlike Python, indentation is justfor the convenience of user.It's not read by the language.So everything between those two bracketsis repeated within the for loop.I'm going to go let k go from 0 to nis going to be a list of all the integers.If you want to see what that looks like,if you just type 0 to--oops, 0 to 5, it will give you the value 0 to 5.Or 0 to 12.It will give you 0 to 12.So what we're doing is for each value of n--so for n trials, we're going to let k go from 0 successes upthrough all of them being successes.You could think of the number of headsin n flips of a biased coin.And then we're going to compute the probability for each onefrom the binomial distribution.Now this is a built-in function in R.And if you want to take a look at what it is for any function,you can type question mark dbinom to get the description.Or over here in the help panel, youcan just type in what you want.So if you want to see for any other distribution,for the data distribution or so on, you can get its details.So this is all the details you needfor the binomial distribution along with some examplesand some references.So we're going to use binomial distribution.The conventions are the same ones that we use.F will be our distribution function.K is the number of successes.N is the total number of trials.P is the probability of success.Then having done that, we just need to draw some pictures.So we'll use the bar plot command,and you can read about that here.I'm going to use, for now, the basic base package r commands.There's other popular packages, like ggplot,which have much more sophisticated and interestingaesthetic options.But we'll just get our base results for right now.So the barplot is going to plot the values of f.It's going to plot the names label--is going to give the labels that correspond to each bar.And then xlab and ylab are the labelson the plot for the x-axis and the y-axis labels.Main is the title of the graph.And this paste command concatenatesa bunch of string variables and numberstogether, so that we can get numerical values on our plot.And then readline() is just a pause command.It waits for input at the keyboard,so that we can build the graph successively, as I showed you.So let's take this whole thing.I'm going to select all of this text.I can include the comment.And I'm going to hit Run.And now, down at the bottom, it'swaiting for me to hit a key.So if I want to expand this graph so it fills upthe whole thing, these little icons over here will expand it.If I want to see both of those at the same time, I can do it.And I can resize the window between them.For right now, let's make this big.Let me resize this to give us a little more room.So what we can see here is two plots.I've done one trial.There's 10% probability of success.Therefore, the chance of zero successes is 90%.The chance of one success is 10%.No surprise there.Now I'm going to click, put focus in the lower right,and hit return.And it draws the next.So this is incremented by 1.So now we're looking at n equals 2.There are two trials.I could have zero, one, or two successes.The probabilities are 81%, 0.9 squared, down to 1%for the chance of getting two successes.If we keep going, these are the different values.And as I hit return each time, yousee the graph drawn in the way that we did in class.OK, so I can go all the way to the end.Now if you want, you can go in, and youcan pick a different number.You could pick that this could be, let's say 30%.And rerun the whole thing to your heart's content.And if we rerun this now, we have-- that's for one,two, five, 10, 20, 50, 100.And you see the features we saw in class, which are,we started with an asymmetric distribution.And we're getting something which is actually fairlysymmetric about the mean.It's also looking pretty Gaussian, isn't it?We'll see in a moment how we can rescale the variables to getthe true universality behavior that we expectfrom the central limit theorem.Keep in mind that whenever we're running a numerical simulationnow, whenever we think about either using a random numbergenerator to get Gaussian variables or lookingat the relationship between binomial,binomial tree models and Gaussian distributions,the binomial distribution with a finite number of steps cannotgo from minus infinity to infinity.Can't go negative at all.And in this case, the maximum value that we could havewould be 100.Given that the probability of being in the tailsbecomes very, very small very quickly,we wouldn't see that on the graph.But remember, in finance we often care about rare events.And getting the probability of rare eventswrong on a picture like this might not seem that big a deal.It's a rounding error in the numberof pixels in the corners.But in finance, the consequences are oftenproportional to the distance away from the mean.So we frequently run into situationswhere we have events of interest thathave very low probability but very high consequence.Multiplying the two together gives usan economically significant number.So we can't just look crudely at pictures on a graph like this.OK, so if we keep going, that's 1,000.Now let's take a look at our scaling variable.Remember what the basic idea was?We want to have the scaling variable, under whichthe distribution looks stable.It doesn't keep shifting around and moving to the side.And there's one thing that we mightwant to keep in mind, which is that we alwayshave, for any random variable x, that where its moments exist,if we have x, and we can compute its expectation--let's give that a name.Call it mu, or x bar.And we can compute its variance, and let's assumethat that exists also.And let's give it a name.Let's call it sigma squared.That if these are-- if mu and sigma areany numbers for our distribution,we know that for our binomial distribution,the mean is n times p.We know that the variance is n times p times q.But for any values of mu and sigma,we can take any variable x where mu and sigma exist,and define standardized variable.And we do it in a very trivial construction.Let's call it define z to be x minus the mean of x.Guess what?The mean of that variable by construction is 0.What about its variance?Well, its variance is going to be sigma squared.So let's just divide this by sigma.And if this is a definition, this variable zis always going to have 0 mean and unit variance.So let's go back to our example.And now let's look at our code for rescaling the sequence.In here, we're going to look at the same set of values.But now what we're going to do is, after we define k,we're going to define z to be a rescaled variable.That is we're going to take k, we'regoing to subtract its mean, and we'regoing to divide by the square root of the variance.And then we're going to plot the results.OK.I'm going to cut off--so we're going to cut off our graphat values of plus or minus 5, just so that we can seeeverything that we're doing.And now, if we take our list, let's run this again.Same commands.So this time z is going to be our scaled variable.F is going to be the binomial distribution,and let's take a look at the plot.So I've highlighted the text here.I'm going to hit run.Oops, let's make sure that we get that right.We need to highlight the entire thing, includingthe top definitions of those variables.So let's do that, and hit run.And you could run these one at a time or type them in.So here is, in terms of our scaling variable.So here we've got for n equals 1,and I've set p back to point 1.And now for n equals 2, n equals 5, n equals 10, n equals 20.And now you can see that within the same picture,our graph is staying centered.And as I get to larger and larger values,we see that we've reached the central valueto be in the middle of the graph to be our rescaled variableequal to--centered around 0, around the mean value in termsof our rescale variable.And our shape is looking quite Gaussian.Try it out yourself.Change the numbers.And play with the code.

### 04-Problem_Set_1_9_Questions

## 05-Week_2-Introduction_to_Discrete-Time_Stochastic_Processes

### 01-Overview

### 02-Lecture_2

#### TS01_S01_v1-en

PROFESSOR: Let's take a look at the random walk model, whichis going to be our first and most basic exampleof a stochastic process, and it'sbuilding block for many more complex modelsand finance, as many applications in other fieldsas well.So the first notion that we want to examineis that of a stochastic process.So a stochastic process is a time dependent random variable.So we saw random variables x, y, z before,and they occurred individually, we could add them up.But now imagine, that we have one that's labeled by times.So for each time we get a different value.Now there are two important different cases.One of them is where time evolves continuously,and our variable S of t can be thoughtof as a function of a continuous real variable t.The other case, is where t evolves discretely.And we have a sequence of points S 1, S 2, S 3 and so on,that are separated in time.When these are taken at uniform intervals,we use these as the basis for a time series model.After all, when we talk about time series data,we think about a sequence of observations, usually labeledby an integer, and sequential in time.And typically, considered a uniform intervals, or at leastwe like to think of them as uniform intervals.So the continuous time is more complexand uses different mathematical tools.So we're going to deal with that later.Within the discrete case, what are someof the attributes and properties that we'd like to be aware of?Well, we're going to label these with integer indices,and there are cases where something mightbe a finite or infinite length.But we'll typically pick an origin, we'll call time 0,and then we'll go forward from there.We think about these being equally spaced,but all that's required is that, the applicationsview them as equally spaced.An example from finance, in the equity markets,is its conventional to look only at market day.So we exclude weekends and holidays, and numberof the days sequentially.That doesn't apply, for example, for earning of interestthat happens on a calendar day basis.But we might still label points 1, 2, 3, 4, 5, 6, 7, 8, 9,10 to cover a two week period, even though the period is14 days and the gap is longer over the weekends.The choice of origin is going to depend on our convention and/orapplications.We'll see interestingly, you mightwant to keep an eye on this, usually it's not a big dealand it's usually obvious where to begin.But some of the mathematical properties strictly speaking,such as stationarity, require series to be infinitely long.And, of course, that's not true in financial applications.Markets haven't been around infinitely long,and we usually don't want to go backto the beginning of time in any event.Moreover, when we look at how to simulatesome of these processes, put them on a computer,we're not going to be able to deal too easilywith infinite processes either.So although the choice of an originis different from whether the integers runfrom minus infinity to infinity or from 0 to infinity,there are distinctions in the mathematics,for a financial applications they shouldn't matter.But it's something that we ought to check, as we go.Now discrete time processes.So we're to be talking about our often constructedby taking an existing value and adding a new increment.And this gives us a recursive definition, a building block,a building method for a series.So we start with a particular value,we add a new increment x, that gives us our next value,we add 1 and so on.So we can also--we can either think of a recursive definition.Or we can just think of the value at a given point,as the sum of all the increments that have come to that point.Now of course, if we have the sequence S 1, S 2, S 3, S 4,we can recover the increments by differencing successive ones.And we'll see that that's very natural,when we look at asset prices.That the difference between price observationsor their logarithms, will be related to the returnsover a given period.Time series are used for modeling processes that evolveor that are observed discreetly in time.So what we care about is that thereare discrete observations, discrete moments wherewe might observe, measure, or drawa value of a random variable.It could be, that there's somethingthat's happening continuously, and we justobserve it periodically.Or it could be a process that's genuinely discrete.Also the values themselves can beeither continuous or discrete.But the characteristic of a time series,is that there are discrete values.Now because of that, we often do describe themin recursively, where we think about what the previous valueis and there's some innovation.And this gives us--when we think about this constructively,notion about how things do evolvein time and about how information arrives.So we're always building on the past,we're never drawing information from the future.What does it mean to solve such a model?Well, what we'll see is that, willbe interested in the entire sequence of random variables.and it's often more natural to think of the entire trajectory,the entire path.But at a minimum, what we want to askare some description, some attributes,some properties of the distribution of not yetobserved values, and possibly to constructprobabilistic forecasts for what they might be.Some examples of things that couldbe modeled via time series that evolve in time thathave this cumulative nature, we mightbe looking inside a corporation and its cumulative revenues,or its income or its profit.And we might take its values, such as I 1, plus I 2 plus I 3,say quater 1, quater 2, quater 3.And adding up to the cumulative revenue for a firm,we might be interested in the evolution of stock pricesand more of a lot more to say about this later on.If we think of little r as representingthe logarithmic return of a stock price,then we can see that actually, wecould write the value of the stockprice at time t as an initial valueplus the cumulative effect of returnsduring period 1, period 2, period 3, period 4.We'll be coming back to this very quickly.And the simplest model of all, is the random walk model.

#### TS01_S02_v1-en

PROFESSOR: So what does random walk model consist of?It's a sum of IID random variables.IID means independent and identically distributed.By independent, we mean that the z1, z2,z3 are independent random variables like twodifferent dice, two different flips of a coin,or two different coins entirely.So the individual z's have nothing to do with each other.But we are putting them together in a particular sequence.Identically distributed means that theyeach are drawn from the same probabilitydistribution no surprise there.What are the attributes of this sum ST where I takeit to be z1, plus z2, plus z3?Because the variables are independent,the values that we have don't depend on--the new values that get added don'tdepend on the previous history.So each new increment can be added independentlyof what came before.The other thing is the importanceof the identically distributed partis-- it means that the evolution in time is uniform.And we call this property stationarity.It doesn't mean that the model is static.It doesn't mean it's deterministic.All it means is that if we look at the values between any twopoints in time, the properties depend onlyon the differences in the point in time,not on some absolute point in time.So any given three-step period is going to be equivalent.One of the things we're going to seethat's fascinating about the random walk modelare some of its aspects of universality.There are a lot of features of itthat are really independent of the micro-level.And that's going to be interestingfor us starting out right now.And it's going to be something we'lltake advantage of when we take the limit of this modelto go to continuous time a little bit later in the course.So it's easy to generalize for financial applications.This bare-bones model is going to be a little bit simple.But hang on a very short time, and we'll add in two parametersto make it useful for finance.The random walk appears in many other contextsin applied mathematics, and physics, and engineering.And it's the building block for more complex models.So we're going to start to get to know it well.Then we'll see how to build it.Although this model doesn't have any memory of the past,we'll see that models that do haveinteresting non-trivial causal structurecan be expressed in terms of building blocksthat do come from what we'll see in the random walk model.So what we're going to do is we'regoing to start with the simplest of all random variables.We'll call these standardized random variables,and we'll denote them by the letter z.And they've got these properties.First, they're mean is 0.So these are unbiased.They're equally likely to be positive or negative.The average value is 0.Their variance is 1.So they have a standard amount of randomness, a standard stepsize for these given increments.And for our independence part, the correlationof any two random variables taken at different pointsin time is 0.So we can summarize these three properties symbolicallyin this box.We've got that the expectation of z is 0.The expectation of z squared is the variance.Remember that the variance is the expectationof the square minus the square of the expectation.The expectation is 0.So expectation of z squared is the variance.It's equal to 1.And, because z of t and z of t prime,if t and t prime are two different times,are two independent random variables,the expectation of the product is equal to 0.And this is the same as their correlationwhen they have mean 0.And remember for independent random variables,the expectation of a product is the productof the expectations.Each of the expectations is 0.0 times 0 is 0.So what are some examples z's that we could use?This is all we need.We only need the things that we have here in this box.So one example, the classic random walk,is something like a coin toss.We take a step to the left, to the right.We go up.We go down.We move plus 1 or minus 1 with equal probability.So we can model that with the discrete random variable, zt.zt takes values plus or minus 1 with equal probability.Obviously, it satisfies these properties in the box above.Another example is a continuous z, a Gaussian random variable.This one is also going to be normalized.So zt is drawn from an N 0, 1 distribution with mean 0,variance 1.And it's probability distributionis the usual Gaussian form normalized.So e to the minus z squared over 2 is the probability density.The expectation is 0 because this is an even function.And to show that its variance is equal to 1involves doing a definite integral.So everything that we're about to seewould be true with either of these variables.Notice that they're quite different in detailthat the first one, the discrete one,will only allow our sum to have discrete values.The second one is continuously distributed.Our trick-- and we're going to be coming back to this againand again--is that, when we're interested in a sum of random variables--this is our S of T--we're not going to ask for the full probability distribution.We're only going to ask for the mean and the variance.We're only going to ask for the individual moments.And the detailed distribution couldbe complicated in the case of the plus or minus 1.We have a binomial distribution.It's easy to work out the combinatorics.It's a lot more work than what we're going to do.And we're not going to need the more fine grained detailof all the higher moments.For the Gaussian random variable,it's kind of a special case because, as you may know,the sum of Gaussian random variables is Gaussian.So there's some special results there.But any z that satisfies these propertieswill work for what we're about to see.So what's that?Let's take a look.We'll consider the sum of random variables.ST is z1 plus, z2, plus z3.And we're not going to ask about the distribution of S of T.But we're going to ask about its mean and its variance.So what about the mean?For the mean of the sum, ST, We have a very simple result.Remember that expectation is a linear operator.That means that the expectation of a sumis the sum of the expectations so the expectation of STis the expectation of z1, plus the expectation z2, plus da,da, da, da, up to the expectation of the final one.Since each of these expectations is equal to 0,your sum is equal to 0, no surprisethere really if you think about it.This is unbiased.We add together a bunch of unbiased random variables.The mean value is the same as the value of each of them.It's 0.What about the variance?The variance a little more interesting.So for the variance, we have the expectation of S squared.Again, we're able to simplify this because S has mean 0.So let's just plug it in.Expand out this quadratic.So the term in parentheses z1, plus z2, plus zT,all the way up is S of T. We take the square.Let's expand that quadratic, and we get two kinds terms.And then we apply linearity.That is, for each of the terms, the expectation of the sumis the sum of the expectations.So we have two kinds of terms.We have these squared terms whereas z1gets multiplied times z1.And I have these terms here, whichare the expectation of one of z's with itself, z1 squared,z2 squared, z3 squared.And I have T of these.And I could have the cross terms,where I have z1 with z2, z2 with z3, z4 with z7, and so on.Each of those appear twice.There are T choose 2 of those terms.But wonderfully in this product, each of these is equal to 0.So every single term in this second sum is equal to 0.And the first consists of T terms, each of whichis equal to 1.So the result is the variance of ST,the sum of the random variables, is equal to T.So here's our basic result. The mean of the random walk is 0.The variance of the random walk grows linearlywith the number of steps.And the standard deviation, whichis the square root of the variance,grows with the square root of T. Let's summarize.The random walk model is constructedas a sum of IID random variables.We take a bunch of z's.We put them together.And S1 is z1.S2 is z1 plus z2.S3 is z1, plus z2, plus z3, and so on.It's a simple example of a discrete timestochastic process.Rather than asking for the complete distribution of ST,we ask about the moments.We ask about the mean and the variance.And those are computed very easily by linearity.The mean is 0.The variance is proportional to the number of steps.And we've done this all using standardized random variable z.They could be continuous, discrete.They could be anything that satisfiesthese basic standard properties.Namely, the expectation of z is 0.The variance of z is 1.And the expectation of two different z'staken at two different times is equal to 0.

#### TS02_S01_v1-en

PROFESSOR: Let's generalize the random walk model nowby adding two parameters.So what we'll do is we will take our basic standardized randomvariable, z, and we're going to multiply it times 1constant called sigma.And that's a scale factor.And then, we're going to add another constant, mu.So it's very simple-- just a linear generalizationof our previous z.So we'll call this linear combination sigma z plus mu.We'll give it a new name.We'll call it r.We still have the property that the stepsare independent in each time period.That follows from the independence of the z's.So the z's are our same old friends the z's we had before.And the new random variable, not surprisingly,is going to have a different mean and variance.The two parameters that we have, sigma and mu,are going to be interpreted in financial applicationsas parameters that describe risk and return, which are the twobasic elements we need of course, for understandinginvestments, for understanding financial markets.And this is the simplest non-trivial modelthat we've got.So let's see where that takes us.If we want to match this on-- just to give you a heads upfor where we're going--consider stock prices.Observe regularly, say daily--P1, P2, P3 are different stock prices.And we can think of the return from one period to the nextas being possibly modeled by a random variable.We don't know in the future what'sgoing to happen from one day to the next.We can ask what's the distribution from whichthese variables are drawn.And if they are drawn from an IID distribution,if they're independent and identically distributed,what would be the consequences of compounding these returnsover a long period of time?The identification we typically makeis to identify r sub t, which I've denoted with a little r,to be the logarithm of the price ratio.And this is close to the simple return numerically.But we'll see that this is a bettermodel both empirically and theoretically.We can go backwards from these returnsto the prices in the same way that we mentioned before,that we can add and iterate the process if wehave a recursive idea of what the returns areand the prices are.And we can build up the price seriesby looking at a compounded sum of returns.Because we've taken the logarithmto get the little bars, we exponentiate to get the prices.So this is how we can think about wherethese r's in this generalized random model,these r's are going to fit in to a model for asset prices.Now, since the expectational operator is linear,we're going to generalize our previous results.It will be almost as easy as what we did before.So we have that the return is just a constant time z plus mu.We know that the expectation of a constant,and we know the expectation of a sumis the sum of the expectations.So the expectation of the sum is mu plus sigma timesthe expectation of z.And we remember that the expectation of z is 0.So very simply, the expected return of r sub t is mu.What about the variance?The variance is defined as the expectation of the squareof the variable minus its mean.We just computed the mean on the line above.And r minus mu is sigma z.We take that squared.The constant, sigma squared, comes out of the expectation.The expectation of z squared is 1.So we're left with the variance of r is sigma squared.And then our last relationship among the z's translates hereas well.And this gives us the covariance of twor's taken at different periods of time.The definition of the covariance is the expectationof the product of two random variables,relative to their means.Because rt and our rt prime have an arbitrary time index,they have the same mean.And this is just the same thing as the expectation value.It's proportional to the expectationvalue of the zt equals zt prime at two different times.And that's equal to 0, as we've seen before.Now, here's where it gets interesting.Let's take a look at what happens when weadd a bunch of them together.So let's look at defining a new thing I'll call X big Tto be r1 plus r2 plus r3.And what we're interested in is the dependence on time.So the r's are independent of each other.But we'd like to know how the distribution of Xdepends on the moments of the individual r's,and in particular how it depends on how many of themwe have-- that is what's the time dependence.So once again, we use linearity.We take expectations of both sides of this equation,and we expand out.What do we find?First, for the mean, the expectation of XTis the expectation of r1 plus expectation of r2 and so on.Each of these expectations is identical.This is mu plus mu plus mu, T times.And that gives us T times mu.So remember that our standardized,our pure random walk standardized, justthe sum of the z's had been 0.Now we have a slightly different result,because each of the r's has a non-zero mean.The result is T times the individual mean.How about the variance?The variance is only slightly more complicated.We just need to do a little bit of algebra.The variance, as always, is definedas the expectation of the square of the variable minus its mean.We just computed the mean.It was T times mu.Now, here's a convenient trick.Let's write it out.Let's write T mu is mu plus mu plus mu plus mu.And let's expand out X. So that wecan group this together in these suggestive and interestinggroupings, as the expectation of r1 minus mu plus r2minus mu, plus, and so on up to rT minus mu.So each of these things--r minus mu as a unit, is the random componentof our process.We can think of mu as being a deterministic piece.It's the amount that gets added in every single period.And we're also getting a random component.That's our sigma zT term.So these are the sum of these random variables.Since each of these r minus mus is a sigma z1, sigma z2, and soon, we have a sigma squared that pulls out of the expectation,because it's a constant multiplier.And then, we got to use our previous result--that we have the expectation of the sum of z's quantity squaredis just T. So, now we have this scale factor of sigma squared.And that's our basic result for this generalized random walk.So to summarize-- the generalized random walk modelis constructed as a sum of IID random variables,r1 plus r2 plus r3.Each of these generalizes our standard zby multiplying it times 1 constant, sigma,and adding another mu.We can think of these as being related to volatility,the risk associated with an investment,and mu, the constant deterministic returnthat we would have if we turn volatility off.The mean and the variance are linear in time.So as before, we apply linearity and compute expectations.Notice that we're not computing here, the full distributionof x.And we haven't used the full distribution of the individualr's.We've just used the mean and varianceof r's to get the mean and variance and covariances,and those properties for x and T.Our basic result that's going to beimportant for financial applicationsand for our intuition about randomnessand financial markets, is that the meanis proportional to time.And the variance is proportional to time,which means it's square root, which we associatewith the volatility grows as square root of T.That is the volatility, the standard deviation of x sub T,is sigma times the square root of T.And square root of T, as it gets large,grows more slowly than T.

#### TS03_S01_v1-en

PROFESSOR: Let's generalize further by lookingat linear time series models that go beyond the random walk.We want to capture correlation across time.And we saw that one of the things thatwas a property the random walk model,the generalized random walk model,was that the increments were independent, they were IID.And simply, multiplying by constantand adding a constant to our zs didn't change that.So in the generalized random walk model,we can have a non-zero mean, we can have a non-zero volatilityor randomness.But the increments are still independent of each otherover time.For many things, so we do want to have dependence over time.We'd like to have causal influences,we want to be able to propagate information across time.So we need more complex models.The great thing is, that we can build them out of the pieceswe've already seen.Our main friend here is going to be linearity.And let me just give you a couple of examples.One of them is the so-called MA 1 model, whereMA stands for moving average.And the idea here is that the return in a given periodor a realization of a variable--let's be general.Let's say that r is something that looks like the random walkmodel, mu plus sigma z t, plus I'mgoing to add a new term on the right hand side.And the new term on the right hand sideis going to be a constant phi, justsome other constant parameter, some scalartimes a previous value of z sub t minus 1.So notice that by the time we get to time tand we're waiting to see what new realization,we're going to have this random variable z sub t.This variable will have already been observed,it will be in and constant.And that means that over different periods of time,the rs are not being drawn from the same distribution.So the model is not IID.We can get into more complex examplesas well by letting other features vary with time, notjust the constant offset to a random variable,but the size of the randomness itself.And this is an attribute of the so-called GARCH models.And in a GARCH model, it's really a two component modelwith two random variables.It looks deceptively simple, so letme show you because you'll get the intuition right away.The idea is that in the model, that the return isa random walk form mu plus sigma times z sub t.The difference is, that the coefficient sigma now itselfhas the time dependence.We then need an equation to specifyhow sigma evolves with t and that'swhat defines the GARCH model, and thereare different possible dynamical models.But you could think of this as saying,that within each period say each day or each month,there's a generalized random walk process.But the parameters of that random walk change from one dayto the next.The sigma's change.Another way to model causal influences,is to have other terms on the right hand sidenot just previous values of z, but wecould have previous values of the variable of interestitself.So we could generalize, and have this model of this form.This is called an autoregressive model,and it's of order P, which simplymeans that the coefficients c 0, c 1,c 2 up through c P that at least c Pis non-zero, that these has this non-trivial structure.But the idea is terms on the right handside are now lagged versions, they'rereferring to previous values not of the zs,but of the variable in question.In this case, R sub t.And the right hand side I have, 1 period before all the waythrough t periods before.Again, those are telling us that the present valueis going to depend on what happened in the past.So there will be a causal relationship.Plus it's not deterministic, it is random.Plus in each time period, we're getting a new kick--a new kick from z, which is goingto z is going to be a standardized random variable,identical and independently distributed with mean 0,variance 1.But we have a scale factor sigma,that lets us generate the size of the kick.And although z has no mean, the c 0 and potentially otherterms do.So this is a generalization and itwill have some causal structure, and we'll take a look at this.We can go further and combine both of the twothat we had before.And this is known as an ARMA modelfor AR autoregressive moving average of order P, Q, wherewe've got a bunch of terms.All I've done is I've combined these twoforms, on the top line I've got c 0 through c P,adding lagged values of the past variable R,plus I've got Q terms with past values of the variable z.These models have in common that they have a linear structure.So what we're doing is we're just adding a bunch of stuffto the right hand side.That means we can apply linearity.The terms have are all of the forma constant, times a random variable.And whether that variable dependingon when we take the expectation, whether it'sconditional or unconditional expectation,we'll either treat those as being unknown or being known.But the causal, the time ordering structureis clear, the things on the right handside all refer to times before time t that's on the left handside with one exception.There's one term the sigma z t term it's new,it's sometimes known as a shock or an innovation thatoccurs in each period.So we have that basic linear structure,we have the past values on the right handside that are going to determine subsequent outcomes.They're going to be part of the evolutionof future random variables.And the coefficients need to be specified or determined,and we'll see that they often have natural interpretations.How do we solve such a model?Well, we take a look using our old friend linearity.We use the recursive structure of the definitions, thatis that each period in time t refers to previous periodsfrom the past.And we use one new property that's called stationarity.Stationary means time and variance.It doesn't mean that the process is static.What it means is, that the probability distributionsdon't change over time.So think of going into a Casino, youwould like the games to be stationary,the probability on the dice, it shouldbe the same every day on every roll that it was before.The probability on the roulette wheel,should be the same on every turn that it was before.The probability on the decks of cardsin a poker game or a blackjack game,should be the same as they were before.All right.Blackjack, we would have to assumethat we're reshuffling after each turn for that to be true,for that to be stationary.Otherwise it would be a non stationary process.So stationarity means, that the probability distributionis the same.It does not mean that the outcomes are the same.Now where stationarity is a strong condition,and we don't need anything that strong necessarily.We're going to use a weaker condition that is appropriatelynamed weak stationarity, and we'regoing to say that a process is weakly stationary, if justthe first and second moments are stationary, that is theretime translation invariant.And that's good because we're going to play our usual game,instead of finding out the entire distributionof our process.The whole probability distribution,we're going to ask about its mean and its variance,we're not going to know what the fourth, eighth, tenth,and in moments are to all orders.So to see this, let's take one case and do it in detail.And the case, we're going to do in detail, is the case of AR 1.The AR 1 structure looks like this.It's got one term has just two coefficients.There's a constant, plus c 0 plus another proportionalityconstant c 1, times the previous values observation, plus wellour old friend sigma.So a third constant actually, times a random shockthat occurs in each period.

#### TS04_S01_v1-en

PROFESSOR: We solve the AR 1 modelby applying the expectation operatorto both sides of the equation.So doing that, we use linearity.We take expectations term by term,and we see that the expectation of R sub tis c times the expectation of 1, whichis just 1 plus c 1 times the expectation of R t minus 1,which we don't know.Plus 0, 0 trend expectation of the standard variable z t.So what we're left with, this interesting expression.We have the expectation of R t as a constantplus another constant times expectation of R t minus 1.Now here's where we used stationarity.It says, that the two expectationson the left and the right, are the same as each other.We don't know what they are, but wedo know that they're the same.So we can solve algebraically for themby rewriting on the right hand side.c 0 plus c 1 expectation of R sub t, and solving for R sub t.So we substitute, and what do we find?We find that we now have an expressionfor the mean, the expected value of R sub t in termsof the basic parameters of the model.c 0 over 1 minus c 1, and sigma doesn't appear.So we've solved for the first moment of R tby using stationarity, and this isa trick we'll continue to use.We take things, we plug in our basic equation for the Rs,we expand out the things inside the expectation.And then as needed, we apply stationarity.Now for convenience, instead of this handful of symbols,it's the mean value of R t.So let's give it a new name, let's call it mu.And for interpretations for physical and financialinterpretations later on, I'm goingto take the innocuous and boring sounding c 1.And I'm going to give it a new name,I'm going to call it minus lambda.So in terms of these variables, we can rewrite our AR 1 model.And you can check this, by checking the variables.In terms of an expression on the left and the right hand side,that both are written in terms of this combination R minus mu.And on the left hand side, it's a time t and the right handside it's R t minus 1.So we have the usual typical recursive structurethat we've been seeing.Plus the shock term, the sigma z t.So how do we want to interpret this,this is a model that's often usedfor modeling mean reversion.We think of mu as being the mean of our process and Rt minus mu or t minus 1--R sub t minus 1 minus mu, are the variables differencefrom the mean value from mu.So if R at each time were exactly equal to mu or minus muwould be 0.However, and it would stay 0 for the recursion, if for example,if sigma were equal to 0.But because there's randomness, there will be changes.So the real driving variable here, the real thingto keep an eye on, is R minus mu,that's what's moving things.So what does it say?What about the minus lambda?And why have they written it this way?Well, let's think of lambda as being a positive constant,we'll see in a few moments the only requirement isthat the absolute value of lambda be less than 1.So lambda can be negative, but the usual applicationsit's positive with the sign convention, where I've writtenminus lambda on the right hand side.So here's how we can think about it.We can say that for a positive value of the coefficient mu,the first term on the right hand side says,that if R in the previous period exceeded its mean,if it was larger, then we multiply times the negativeconstant --minus lambda.And that pushes it in a negative direction.What is it pushing in the negative direction?Well, the thing on the left hand side,which is the subsequent periods change in the valuerelative to its mean.So this says, that if we overshootthe mean in one period, will we push downtoward it in the other.If we undershoot, if R period t minus 1 was less than mu,then multiplying the term in parentheses timesc minus lambda, will give a positive number,and that will tend to increase the value towards its mean.And in each period we get a random shock,we get a new sigma z t, but that's symmetricallydistributed.It's just as likely to be positive or negative.Now that we have that structure, wecan solve the rest of the model 2 for the remaining moments.That means that we can solve for the variance,and it's square root, the standard deviation.And we can solve for covariances.And in this case, in the times series context,these are called autocovariance.Auto, because we're computing and R with an R,just the two different periods in time.Instead of computing the covarianceof two independent random variable to random variables,maybe not necessarily independent x and y,where we compute covariance of x and covariancewith-- the variance in x and y, is taking the expectationof the product of each random variablerelative to its own mean.We do the same thing here but, where the two variablesare taken at two different points in timewithin the same time series.OK so how does that work?Well, we'll start with the variance,and we'll give it a name.We'll call it gamma 0, and you'll see why in a moment.So the variance of R is defined as usualas the expectation of the square of R t minus mu,where R t is taken relative to its means,so we take the expectation of the square.Now for R t minus mu, we're goingto substitute in our equation of motion.We're going to substitute in, the expressionfor R t minus mu, in terms of the previous valueson the right hand side.And will expand it out, take expectations term by termand what do we get?Well, one of the terms we get, we recognize this first termhere, is lambda squared or properly minus lambda quantitysquared, times the expectation of R t minus 1minus mu quantity squared.And this expression taken as a whole from stationarity,is also gamma 0.It's the thing that's on the left hand side.The term over here from the z squared,gives us a sigma squared down here,this should be a sigma squared up here.Apologies for the typo.And the cross term vanishes.So at the end, we have the gamma 0 can be written,because we solve this equation algebraically for gamma 0,and there's a gamma 0 on the right.And we get the gamma 0, the variance of R,is sigma squared over 1 minus lambda squared.So what we see is first of all, that it'sproportional to sigma squared, which we would expect.This is the variance of the process.The bigger sigma is, the bigger gamma 0 is.We also see the special case, the random walk.If we set lambda equals 0, we shouldget our usual generalized random walk result, and we do,we get the gamma 0, the variance of R, is sigma squared.But now look at the denominator.We notice the denominator blows upif lambda gets to be larger than 1 or less than minus 1.So this will only be defined for values less than that.How do we know it doesn't make sensefor values larger than that?Well, there's an easy interpretation.Remember that lambda is telling ushow much of the previous periods resultis going to contribute to the next periods result.And when that's less than 1, it meansthat affects that shocks tend to die offover time in the absence of the new shocks thatare arriving via the new z ts in that's reasonable.However, a case for lambda greater than 1 into the shocksget amplified, they get bigger and bigger.So that once a shock enters the system, it runs awayand it takes over the system.So the result would not be convergent.So even though it's a formal recursion,the recursion doesn't actually exist.So the most typical case as I said,is going to be lambda positive.But in any event, we're going to have lambda less than 1in magnitude.Now we don't need to stop there.We can now extend our result to lookat what happens, when we consider R istaken at two different times.And we'll use the notation gamma subK to denote the autocovariance.That is the covariance of R t with an R t at laggedby K times steps.Remember that because it's stationary,that means that this doesn't depend on tit only depends on K.So the correlation between R 1 and R 3,is the same as the correlation between R 21 and R 23,it doesn't matter.All that matters, is how far apart they are in time.So we can think of K as being a delay, or a distance,or a length of time, over which information propagates.How do we solve?Well, we use our same friend, plugging in and applyinglinearity and stationary, the difference this time is.That instead of substituting the equation of motion everywhere,we do it in one of the two terms.So it goes like this gamma K is definedto be the expectation of R t minus mu and R tminus k minus mu.We'll leave the first--works for me.We'll leave the second factor alone,and the first one will apply our equation of motionfor recursion.So we'll plug in just for this.So we have the lambda term minus lambda,times R t minus 1 minus mu.And then there will be another term with z,which vanishes, because as we saw in the cross terms vanish.And here by stationarity, this isjust dependent on the difference in times between these two Rs.And that's K minus 1 steps apart.But that's just our with minus lambdaat times, our expression for the autocovariance gamma subk minus 1, where there was one time step in part.So we've got is recursion by substitutingin the equations of motion, we can relate gamma Kto gamma K minus 1.And the rule is, for every K that you increase, you multiplytimes a factor of minus gamma.So we would expect to see a function of minus gamma raisedto the case power, which we do down here in our final result.And we're able to tie off this series,because if we think about doing the recursion backwards.When we get to gamma 0, we can stop.We know what gamma 0 is in closed form.So our final result for any K, any finite Kis that, gamma K is minus lambda to the K-th powertimes the variance.And explicitly, that's minus lambda to the K-th power,1 minus lambda squared times sigma squared.So this is the lag-K autocovariance,and if we think of this now not as a function of lambda,but is a function of K, we see that-- remember lambdais less than 1 in magnitude, this tells usthat the influence is dying off as K gets larger and larger.OK, but it does persist over time.Therefore, this model allows for thereto be a causal connection between observationsand one period, and observations in all prior periods.And we have a very specific way, that they're relatedthat the information dies out.So let's summarize what we've donein looking at our structure of time series models.We've seen that we can construct time series models by buildinga bunch of linear terms, that generalize the pieces wesaw from the random walk.The pieces that show up in our recursive definitionson the right hand side.Include shocks, that is sigma z t terms,we're adding new and new random informationat each point in time.They can include past observations of the zs, thatis previous period zs.And they can include past observationsof the variables themselves, and everything can havean independent coefficient.So those are the basic ingredientsof this class of models.As long as they are linear in terms of the random variables,we have a good chance of solving them using the techniquesthat we worked out in detail for AR 1.These models have temporal correlations that'sbuilt into their structure.So they're written recursively, whichmakes a compact definition, it meansthat we can solve them and think about them one period ahead.But it also means that when we make assumptionsabout stationarity of the series,that we have good tools for solving them.And understanding how to interpretthat as the propagation of informationforward in time and the decay of the influence of shocksover time as well.The example we looked at in detailwas AR 1, which we used for mean reversion.And this model, this structure shows upin many areas of finance econometricsand in other areas of applied mathematics.The model is for where we have randomness thatenters through this noise term.But where there's an influence--where the influence of new informationtends to die out over time.So the way in which we model this and describeit is in terms of the relative displacement from a long termmean average.And the minus lambda says, that whenwe see shocks in one period, theytend to get damped out, in the following period,in the absence of a correction.OK, so we apply weak stationarity,that gives us the first and second moment.It doesn't tell us everything about the full distribution.Fortunately, for us, that's what we're usually interested in.One last detail to keep in mind is that the lag variables--will sometimes think about in two different ways,and mathematically we'll treat it in two different ways.One of them is as in the equations we wrote down,we think about them as the different periods is allbeing unobserved, they're all random variablesthat have not yet been drawn from their distribution.There are no observations that have yet been made.And those expectations that we tookare called unconditional expectations.But we'll see that sometimes when we actuallywant to look at data, or if we wantto use Monte Carlo techniques to generate simulated data.Well, think about these a little bit differently,we'll ask, what's the expectation for the futuregiven that we're currently at a particular time t,and that everything at earlier times has already transpired,has already arrived.And in that case, we take the values of the earlierrealized numbers to be constants.And the things that are unrealizedare things that are in our future.

#### TS05_S01_v1-en

PROFESSOR: Monte Carlo simulationmeans we use computers instead of our pen and paper,to work out consequences of probability modelsand stochastic processes.What we do is, we simulate stochastic processesby drawing random numbers using the random numbergenerator on a computer.And this can be found in most programming languages.This provides us with really an idealized testlab for exploring some of the ideaswe've talked about and for much more advancedfinancial applications.The reason is, that because we'redoing the simulation ourselves, because we'redeploying the random number generator that we'reparameterized, that we're coding,we know where the data comes from.In the real world we don't know the true data generatingprocess, that's part of the subtlety and art in modelbuilding as we try to infer that, that'swhat we're trying to solve.In the Monte Carlo lab, we assume that that's known,and we'll see it still gives us our handsfull of a lot of things that we need to check out.But if we can't understand and do the analysis with datathat we've generated ourselves, wehave no hope for doing it in the real world.On the other hand, doing things thoroughly in a test lab,gives us great idea about the abilities and limits of someof our analytical tools.So we'll find out how much accuracy and precision,we can have in different kinds of simulation settings.So the idea is, that we're going to assume a particular model,we're going to assume that we know the way the world works,and we're going to generate data that is consistent with that.So those properties will all be true self-consistentlybecause we built the model that way.We can then for some purposes, forgetthat we knew where the data came fromand analyze it as if it were real world data.But typically, one of the applications that we'll do,is we'll generate a large number of possible outcomes.So think of doing a simulation for the evolution of a stockprice, or an entire stock market, or some other assetprice.In the real world we only get to see history once,and when we look at actual historical data,we only have one history.We can't redo the experiment.We might be able to get more data,by looking at different time periodsor going further back in time.But that's not the same thing, as repeating everythingunder the same conditions.So here will be limited only by our computersabilities and the time we're willing to commit to it.But the usual process, involves taking a large numbersay, 10,000 or a million different simulations.And constructing what we'll call an ensemblea set of possible hypothetical paths that might havehappened, each of which typically being equally likely.And then, instead of what we've done so far,where we've computed properties of a distribution.Like moments in the distribution, mean,and variance by doing mathematical expectationsagainst a known probability density,here we're going to do statistical calculationsagainst the empirical data set that's been generatedthrough our Monte Carlo data.And what we'll see is, that the results typicallybecome more precise as we look at more and more data, whichis only limited again by our computational resources.So I'll show you some examples, and I'll youshould run them yourselves.So I'm providing some code here, and youcan take a look at in the R programming language.And you can play around with all the parameters.And you can take a look at what happensas we increase the number of simulations,or as we change some of the parameters.So it's a great chance to try some things outin a different setting apart from the pencil and paperthings that we've done before.To build applications that we haveare going to include asset price dynamicsthat we'll look at now.Option pricing, which we'll look at a little bit later on.And many applications in portfolio and risk management.

#### TS05_S02_v1-en

PROFESSOR: So most computer languages, including R,have functions that generate random numbers.Now in R, the main ones to take a look at,are the function sample, which returns discrete values.So if you want to pick from a list,0 and 1 could happen with probability p and 1 minus por values 1 minus 1, values 1, 2, 3, 4, 5--if they're discrete, we can use the sample function.And we can sample with or without replacement.For Monte Carlo applications, we typicallysample with replacement.We're not exhausting lists.We're generating things consistently over time.Two other functions-- the runif--that's not run if, which looks like itcould be a reasonable command--returns random numbers with a uniform probabilitydistribution.So these are real numbers bounded between 0 and 1.And rnorm generate things drawn froma normal or Gaussian distribution, with mean 0and variance 1.There are a bunch of parameters that you can use to tune this,such as setting the mean and varianceof the normal distribution to something else.Now we have to keep in mind that the random number generatedby a computer are not truly random.These are approximations.And there are a lot of limitations.So you need to keep in mind what the real world limitations arein our hypothetical world of Monte Carlo simulations,namely what are the limitations of computers.So a few things to keep in mind include--we can't do real numbers on a computer.We can only do finite precision.Now double precision, 15 decimal digits, is pretty good.But it's not infinitely divisible.So some of the things that means arethat if we're looking say, at a uniform distribution,we can't get every possible number.And in a true uniform distribution,the probability of getting any particular numberis measure zero, and that won't be the case.We'll have some finite probability.When we think about not only the find greatnessfor real numbers, we also should think about their boundedness.So a Gaussian random variable could go from minus infinityto infinity.We knew that it's very unlikely that itgoes outside of say, plus or minus 3 or plus or 6,but we could get a value that could be arbitrarily large.And computers don't do arbitrarily large.They have very large numbers.So we need to keep in mind that anything that we generateis going to be truncated and finite.And that's particularly important in risk applications,where we're studying the occurrence of rare events.Because there may be events that the computer's actually notgenerating that are very, very unlikely.So we need to keep that in mind.That's part of the limitations which will qualify our results.And we can take account for our approximations.So there are many subtleties here,which we won't be going into.But I do want to mention them so youcan do further reading if you want to apply thisto more advanced applications.So here are some basic functions that I commonly use in R,and that you might find helpful as well for getting started,for generating some random numbers.And we'll take a look at some examples.In just a moment.The first example that we have hereinvolves taking a look at generating a matrixof independent random numbers.So let's think of z as being our typical standardized randomvariable, or actually in this case, not standardized.This is going to be a uniform distribution.It will be standardized in a moment.But z is some random variable, drawn from some distribution.In this case, a uniform distribution--so it's uniformly distributed on 0 and 1.Now what I'd like to do is I'd liketo pick Nt, the number of time steps,and I'd like to think of orientingthis as a matrix, where I typically think of time serieson a computer as column vectors.So I think of aligning the successive elements from topto bottom, from oldest to newest--1 2, 3, 4, 5, all the way up to Nt.And for efficiency, we're going to run many simulationsin parallel.And I'll think of Np as a number of sample pathsthat we're going to generate.So as far as the computer is concerned,Nt times Np, they're all independent random numbersanyways.It hardly matters.How I choose to arrange them for convenience is it a matrix.And these are the conventions I'lluse always for time series.So time goes down.Each column represents an independent time series.And in this case, the columns representdifferent possible realizations of our price paths.So the first line gives us a matrixof Nt times Np independent, pseudo-random drawsfrom our distribution.The next example right here, shows a waythat we can turn things into discrete random variablesif we have a uniform distribution.And of course, the sample function I mentioned earlier--there's an easier way to do it.But there are simple sometimes to code things usingcontinuous distributions, and take the discrete caseas a special case, rather than writing different functions.It doesn't make any difference.You can do whatever you prefer.But in this case, what I've done isI've shifted it so that with probability p,I get a positive number.With probability 1 minus p, I get a negative number.And then I take the sign of that.Notice that there is a small problem, potentially here,with 0, which shouldn't be allowed.And the sample function won't run into that trouble.But rather than making the function complexwith lots of parameters, it's easierto do simple linear transformationson the variables to move them into a range we want.So typically, we want to shift the endpointsand re-scale things.For example, instead of plus or minus 1, I might want 0 and 1.And these are related so that the x on the lineabove gives me new variable i, that just shifts the values.So when x is 1, u is 1.When x is minus 1, u is equal to 0.The next line right here, gives us--this looks a little bit more complicated.But this is an example of one way,among many, that you can generate data, whichis normally distributed with a given mean, mu, and a givenstandard deviation, sigma, and again, arranged in matrix form.And then finally, this is our specific--but it isn't required.We can do this iteratively, but it's very convenient--is way of applying a cumulative summationfunction to aggregate our returns.And this is typically what we lookat when we're doing asset price dynamics and price simulation,we're going to add up successive returns.So we'll have r1, r1 plus r2, r1 plus r2 plus r3, and so on.So this is r-specific.And this will generate-- typically,what we have if r is our matrix of returns,this will do a cumulative sum in the time direction.That's what the second argument here is, 2.And this applies it across the entire matrix.And then we exponentiate, as we'll see--if we're simulating log returns, we'lltypically want to exponentiate the cumulative sums and returnsto get the actual asset price paths.So let's look at some examples.In this case, this is code that generatesa simple 20-step random walk with equal probabilityfor going up and down.So notice-- I define up top what the probabilities are.And it's conventional sometimes, to call with a probability, p.And the probability of the opposite outcome, q.1 minus p-- it's not required.You can code it any way you'd like.And the number of times steps is 20.For simplicity, I'm picking only one sample path in this case.Here's my assignment to z of a set of random numbersthat are drawn.Here, I'm mapping them to the range I want.I initialize a set of partial sums, s, to be 0.And it's important to keep in mind that we usuallywant to start at time 0, with a fixed value.So in order to have N sub t steps and returns,we need Nt plus 1 placeholders for the actual valuesof our state variable.So if we want to have, let's say, 252 daily returnsfor a stock price, which is typicalfor an annual simulation, then weneed 253 values for the price.Because the first one will be p0 will be initial price.And then we'll have the next one.So it's always one less return than the number of pricesthat we have.So, now that we have it initialized,let's just run a simple for loop.And at each step, we'll say that the value at step k plus 1,at the next step, is wherever we werein the previous step plus the random value that we had.Where I've written this with the argument having commaand then a blank in R, is the syntax meaningdo it for this row and for all of the columns.In this particular case, we have N sub p is 1.There's only one column there.But in general, this is going to be the format that we'll use.And then we can take a look.And behind me, is an example of what a 20-step random walklooks like.When you run it-- each time we rerun it,we'll get some different value.,Now, let's take a look at how we might do thisif we want to get a little bit closer to finance.One of the things we'll do is let'spick a particular number of time steps.I like 252.252 is the standard convention for modeling daily returns.The idea is that we have approximately 21 trading days,excluding weekends and holidays on average in a month.12 months-- that gives us 252 trading days.And we're going to treat weekends as being nonexistent.So we'll assume that everything is homogeneous from Fridayto Monday, and that we keep going.The number of simulations I'm going to runis going to be 10,000 simulations, whichis a good starting point.It's kind of a handy number, a good balance between beingtractable and being accurate.Just as a rough rule of thumb--the accuracy of our results typicallyis going to scale with 1 over the square root of the numberof simulations that we do.So 10,000 means that we can get things that might be roughly 1%accurate to a range of 1%.A million would be better.A billion might be even better.But that would take a very long time to run on most computers.So I like to start at around 10,000,And then work from there as far as needed.So now I've got a bunch of random numbers.I'm going to treat these again, as discrete values,plus or minus 1.So this is a random, discrete random walk,where we're going by discrete steps up or down.And then I'm going to run this, but now, over many paths,over time.And I have each location is the previous one.And what does that look like?Well, now I can get my ensemble of paths.I have 10,000 of them.That would make for a pretty cluttered diagram.So I've drawn three of them here.And you can see that if these were stock prices,you might feel very differently about them but.These are all three paths drawn from the same distribution.OK, in this case, the distributionis equally likely to go up or down.So the fact that one of the paths went up, one of themended up at 0, and one of them ended up very negative,is just quite literally the luck of the draw.

#### TS05_S03_v1-en

PROFESSOR: Now, how do we apply thisto real world modeling for asset price dynamics?So, a typical model and kind of the most common modelin finance and in applications like option pricing,is to start with the idea that returns are lognormallydistributed.That is the logarithmic returns are normally distributed.And of course, whether or not this is a good model,is an empirical question.We need to look at actual data.But let's start here for a simulation process,and see what some of the paths look likeand see what some of the consequences are.So we draw our returns from a lognormal distribution.And of course, this is the same thing as our random walk modelthat we've seen before, except so I have returns drawnfrom a normal distribution with mean mu and variancesigma squared.And that's the same as writing rt equals mu plus sigmazt, where z is drawn from a standardized normaldistribution.Now these are logarithmic returns.And the returns are defined in terms of the logarithmof the price ratio of a day.And this is approximately equal to the simple returnfor small values.And we can invert this.So if we look at the recursion, wesee that the price today is yesterday's pricetimes the next return.And if we keep iterating backward farther and fartherin time, we get this result, whichwe'll use as the basis for our Monte Carlo,namely that the price at time t, isequal to an initial price, P0 times the exponentialof the sum of returns.And these individual r's are drawn in each period.We take their sum.We exponentiate, and that will give us the price.So here are the steps that we use for generating Monte Carlosimulations.We first decide what the parametersare for the underlying distribution-- like whatare mu and sigma?Where should they come from?What units are they in?We need to scale them appropriately for the samplinginterval.So typically, for example, we take mu and sigmato be our given annualized units.For example, a stock might have a 10% annual return,with the volatility of 30%.But if our individual time steps are on a one day level,then we need to change the parameters in orderthat they make sense for the one day period.Then we draw numbers from our distribution.We use the scaled parameters to simulate our distributionand how it evolves over time.We construct the ensemble of paths.And then once we've got this at say, 10,000 possible paths,we're going to compute analytics based on it.So if we want to know what the variance of the terminalreturns is, we just compute it by takingthe statistical calculation of the variance on the valuesthat we've generated on our actual sample data.So here's an example of how we could do that.So let's take the parameters I just mentioned.The sigma of 0.3 has annualized volatilityof 30%, an annualized return of 10%.Now how should we scale these?Well remember, we want the annualized return to be 10%.So that means since we know that if we do a whole bunch of timesteps, we know that the mean scales linearly with time.That means that the return on each dayshould be mu, 10%, divided by 252,which we can write as mu dt.This Is our constant term.So we've re-scale the constant in our r equalsmu plus sigma z, to be mu delta t.That's going to be 10% over 252.So over a year, we'll get the right number.And then for the coefficient of z,we need to scale by square root of t.So in the Monte Carlo simulation,we're going to take our normalized z--this is just drawn from a standard normalizeddistribution.And we multiply it times sigma times the square root of 1/252,which is about 15.87.The square root of 252 ends up showing up a lot in Monte Carlosimulations and in conversions.So it's good to get that number in mind.So I've written down two different ways that we could dothis in R. One of them is simply,we start with normalized z's.And then we scale them.We add a constant, mu dt, plus our normalized variable z,times sigma square root of dt.Or you can use the parameters in R.But this ends up again, being more language-specific,because there are optional argumentsfor the normal distribution, wherethe first argument is the number of random numbers you want.The next one is what's the mean.The default is 0.The next one is what's the standard deviation, sd.And again, the default is 1.So either of these lines will produce the same numbers.Then we take the same thing we did before.S is an initialized matrix to holdour partial sums, our partial cumulative sums of results.We work through iteratively step by step--t from 1 up through Nt.And then we take our result and we exponentiateit to get our price paths.And again, I've shown you a couple of sample paths here.And if I told you that these were three stocks, whatdo you think?You might think gosh, that one in red--that looks like one that went for a really wild ride.Maybe it showed up on Reddit somewhere.And it rose, and it crashed and burned.And the green one is some company that's struggling.But in fact, all of these came from exactlythe same data-generating process.Now, let's take a look at some of the resultsthat we have from our distribution.One of the things we can do-- rememberthat P holds our price paths.And the terminal values of the price paths,we started with an initial value of 1. ,Remember the initial return was 0.So we exponentiated the initial value, P0 was equal to 1.We could have multiplied it time some other constant.So the terminal value minus 1--the terminal value here minus 1 is the simple returnon the stock over a one-year period.And we can see right here, the histogram in blue of the data.This is showing the distribution of one-year returnsunder our model.So we notice that this distribution is not normal.The red line is showing a normal distribution.But we can see that there's a positive mean.And there we go.So we have the center of this is positive.There's a certain width to it.But it's not symmetric.You notice that the distribution is definitely skewed,with a large right tail.And of course, the lowest value can't be below minus 1for what we've done.Because the price can't go below 0.So what I've done and the red line, is I'vecompared this to a normal distributionthat has the same empirical observedmean and standard deviation.So we can obviously see by looking at it,that this is not normal.Now remember, these are the simple returns.And they're not expected to be normally distributed.If I take the logarithm of the returns and compute,then things would match up rather nicely.But again, we could ask how nicely should they match up.What level of variance would I expect?If I had done less than 10,000 simulations,this would be a more ragged plot.If I were to do a million simulations,we would find it would fit quite nicely under the curve.So depending on our application and our patience,that will dictate the number of simulations that we might do.Now in this particular case, we do have closed form numbers.So we can compare, we can computewhat the mean and standard deviation or the varianceare with the results that you wouldget if you did a whole bunch of Gaussian intervals.I don't know about you, but sometimes Gaussian integralscan be tedious.Certainly, look at the answers in a book.But if you want to do the Gaussian integrals,you can do that.Monte Carlo simulation can be very quick.And we can add numbers.So let's see how they compare.And this is helpful for cases where we'll oftenapply Monte Carlos, where the closed formsolutions are either too difficultor they don't even exist.So for example, I compute the mean empiricallyof the R's as 1.547869.And the theoretical result, whichis written down below by doing the actual expectationand doing a Gaussian integral, the expectation in factis e to the mu plus sigma squared over 2 minus 1.That's because the little r's are logarithmic,and the big R's are not.This is approximately-- we can expand this outin a Taylor series.But this is the exact result. And wecan see that we're pretty good two and almost three decimalplaces--0.156.And if you run it, you'll get of course, a different numberfor the first one.And you can try this here.How about the variance?Well again, there's a particular result for the exact value.And the numbers that we get here for the standard deviation,I've taken the square root of the result for the variance.And again, these look pretty close.So that's the idea.We have two different ways of computing the same thing.One of them is doing a bunch of Gaussian integralsin closed form.The other one is we do a whole bunch of simulationson the computer, and then take.Some averages and standard deviations.You notice that compared to the doinga Gaussian integrals, which is funif you like doing integrals.But here, we have a little bit morewhen we do some visualizations, a little bit more idea asto what's going on.Like here's the spread.These are all the things that could have happened.Sometimes the individual price paths can look really striking,and we can learn some things by looking at our data.We can keep going.This is the empirical cumulative density function,which can be done in R. It dependson how we do it as a plot of the cumulative distributionfunction, which is equivalent to integrating upthe integral from the left.And another quick and dirty way of lookingat the data, sort of a transpose the previous one,is to plot the sorted returns.So I've done that here this commandwill work in R, that we can use do a barplot or any plotting package you want in R or another language,where I sort the returns in order--remember that the Monte Carlo, the 10,000 pathswe're not ordered in a particular way.Let me sort them in the outcomes from lowest to highest.And this is a different way of visualizing the distribution.This is actually an interesting wayof looking at actual financial returns.So we see that we go from smallest to largest.And we get a characteristic kind of S-shaped curve.And we can see there are big outliers on the upper endof the distribution.We can also take a look at thingsto compare to a normal distribution.A Q-Q plot-- in this case, Q-Q norm is a special case in R.But a Q-Q plot typically lets us visualize a comparison of twoprobability distributions.And the idea is that if in this case, wherewe're comparing with the normal distribution,if the data were normal, it would lie on a straight line.Q-Q plots are especially helpful if we'relooking at deviations in the tails of the distribution.A histogram is not so great for lookingat outliers in the tails, because the tails are small.Rare events are rare.And visually, they're going to show up as maybe 0 or 1pixels on our screen.A Q-Q plot emphasizes the tails and itkeeps the boring stuff in the middle, whichis most of the data, of course.But typically, the middle of any Q-Q plotis going to look like a straight line somewhere.And then the deviations in the tailstell us something characteristic about how we departfrom normality, potentially.

#### TS05_S04_v1-en

PROFESSOR: Now, we can also extend our processto things that are our approach, to thingsthat are not just random walks.In fact, the random walk is a bitof the special case for a bunch of reasons.One of them is that, because the returns are all independent,I didn't need to do the for loop.I could have used some matrix algebra to do everything in onefell swoop.And you might have noticed, that because I'm adding together,in my last case, a sum of random variables,the sum of random variables of normal random variablesis a normal random variable.That's very special for Gaussian distributions,and I didn't need to iterate things at all.So, just to show you why the method matters morethan the particular example, let'stake a look at an AR(1) process which is defined recursively,but where the value in each step now doesdepend on the prior history.So it's essential that we construct the simulationby running forward in time.So, here are some parameters that we can have.We can keep our Mu value, again, annualized at 10%.We'll let the lambda value, which is a pure number,be the strength of the mean reversionand I'll set that initially at 40%, to of 0.4.And this, again, is something I'd encourageyou to try out in the data.So now, when I run things, I replace my generating functionby the iteration for the AR(1) process.So here's my lambda and, again, youcan check the special case where lambda equals zero,it should recover a random walk, and I can generate--So if I think of these, this is convention, it's Monte Carlo.We could do it we want, but if I think theseas being simple returns, just how this model is oftenapplied, I can turn them into logarithmic returnsand then look at some sample paths in their distribution.So the first thing you'll see on the left and on the right.On the left, we'll see a bunch of sample pathsthat don't necessarily look different from whatwe saw before.It's kind of hard to tell by eye whether we'relooking at something that has mean reversion in the presenceof the significant amount of randomness.So, looking at it by eye isn't really going to help us.When we look at the histogram of the data,we see again a little bit of a departure from normality.But where things really get revealedis by looking at serial correlation and coefficient.So we ask about the correlation between the returns in oneperiod and the returns in the next period.And here are two different exampleswhere, in the case of a random walk,this left hand graph, we have the, first,is the correlation of the series with itself, whichby definition is equal to one.Each of these other terms, which is labeled by a lag variable,is the correlation of our simulated resultswith the same series offset by one-time step 2, 3, 4, or 5.And one of the interesting thingsthat we see here is the time one lagfor our auto-regressive process, and that'sexactly what we built in, was the return on one day.It starts with minus 40% of the previous day'sreturn plus some randomness, and that's what we see here.On the right, I've fiddled with the parametersand you can try this too.And we can crank up the lambda and we can crank down the sigmato turn off the randomness and see what the interplay isbetween the two.The Mu is actually not that interesting.It drops out of all the correlations.But what we're often facing is, how bigis the randomness in a financial price process comparedto other drivers in the marketplace, other factors,other correlations, or something like a restoring forcelike mean reversion.So let's summarize what we've talked aboutin looking at Monte Carlo methods.Monte Carlo uses computer random number generatorsto simulate data for a given model,and we can apply this to a wide variety of modelsand compare across models.The simulations give us an idealized testing environmentbecause we know what the data generating process isand this is our best case.Usually, we don't know what it is.So, this way, we can at least look at the best caseand make sure that we could correctly identify our data.For example, you could imagine starting.If we wanted to do model identification,we could generate some data and then pretendthat someone had just handed us the data without knowingwhat model it came from.Could we correctly identify what the model is?We also have the advantage that wecan run lots of different simulations,and real financial market data doesn't allow that.We don't get to rerun the experiment.Even if we figure out what happenedand why in the past, that's not-- there's no guaranteeit's going to repeat again in the future.At least, in the lab, we can do thatand try it and check that our ideas are workingthe way that we would expect.When we apply this to asset price dynamics,we do it by drawing successive period returnsand then constructing the price processas it goes forward in time.And those could be independent or theycould be correlated returns.When we go to compute analytics like meansand standard deviations and variances and Sharpe ratiosand kurtosis, and so on, we do thatnot by doing Gaussian or other integrals in closed form.We do it by computing statistics on the realized data.The results are subject to sampling error, of course.Because they're statistical, theycan be improved by doing more simulations.But there are also important machine limitations,some things we can't ever solve like the factthat we can't exactly represent real numbersor unbounded numbers on the computer.And, we also might find that some of these thingsare not necessarily efficient if we do them in a naive way.And there's a very large literatureand a lot of techniques have been developedfor doing Monte Carlos in more efficient waysand to get better accuracy for the same amountof computational effort.

### 03-Recitation_2

#### Recitation02a-Ex1-en

PROFESSOR: Exercise.Let's let xt be defined as z cosine omega t plus z primetimes sine omega t, where omega is a constant--and think of it as a frequency, let's let it not be a rationalmultiple of pi--and let's let z and z prime be independent,normalized, random variables.So show that xt is weakly stationaryor if you don't think it is, show that it's not.So pause the video, take a few minutes,and see if you can work it out.And then we'll do it on the board together.OK, let's take a look together.So first of all, let's compute the mean and the variance.So the mean is going to be 0 because zand z prime each have mean 0.So we can compute that e of xt is going to be cosine omega t--which is just a scalar with respectto our random variable--times the expectation of z plus sine omega t expectationof z prime.And this is 0, and this is 0, because those have mean 0,and therefore this is equal to 0.OK, that part was easy.How about the variance?Well since the mean is 0, the variance of xtis going to be the expectation of xt squared.And again, what are we going to see? xt squaredis going to have that expression on the top, this expression.We're going to have this term, squared, this term squared,and a cross term of this with this.The cross term is going to have vanishing expectationbecause it will be an expectation of z and z prime,and what we'll have is going to be--just by doing it out, this is goingto be the expectation of z squared times cosinesquared omega t plus--let's try this here--plus expectation of z prime squared times sinesquared omega t plus the vanishing term, whichis going to be 2 cosine omega t sine omega t expectation of zz prime.In this last term vanishes, because that'sequal to 0 because z and z prime are statistically independent.Now this term here is equal to 1,this expectation is equal to 1, so we'releft with cosine omega t squared plus sine squared omegat, which is just equal to 1.Let's keep our colors consistent if we can.And that's equal to 1.Now let's look at the two point function,or the autocovariance function.So we will look at the expectation of xtwith xs where t and s are just two different arbitrary pointsin time.We could do t and t minus k, but let's write itout this way for the moment.OK?So we just substitute in, and this is our basic trickfor most of these.We just substitute in the defining equations,we do out the algebra, we apply linearity,and we compute the expectations in terms of our buildingblocks, which usually we can reduce to basic z's.So we'll be doing this trick again and again.The one other trick that will be doing that you saw in lecture,is will be using stationarity and recursionto sometimes replace something with a tby something with the t minus 1, or will take somethingon the right hand side and use it to substitutefor the left hand side.But here we're just going to do a straight calculationfor this problem.So what's xt?Well xt was given by the z cosine omegat plus z prime sine omega t.And x sub s is given by the same thing,just with t replaced by s, z cosine omega s plus zprime sine omega s.And let's close all our brackets.And now what are we going to have?Well we're going to have the two z's will come together.So we're going to have the expectation of z squared timescosine omega t cosine omega s.And if you can see where we're going with this,I'll write this out just this one timeand then I'll start doing these a little faster.We're going to have also expectationof z prime squared times sine omega t sine omega s,and then we have the cross terms,which involve z multiplied by z prime and z prime multipliedby z.But we don't need to keep those, weknow that the expectation of z times z prime vanishes.So what we're left with here thenis cosine omega t cosine omega s plus sine omega t sine omega s.And if you recall from trigonometry,that's the formula for the difference of angles.So this is equal to cosine of omega times t minus s.Now the exact form is not that important,although it's kind of cute that this comes out.The important thing is that it depends onlyon the difference t minus s.So stationarity is the property that if we shift t and s--if we shift these two points by an equal amount,that all the expectations of the probabilitydistributions, at least the first and second moments allstay the same.And here that's satisfied.We see that the mean was 0, the variancewas 1 independent of time, and the two point functionwhich does depend on time, does so onlythrough differences between those two points.

#### Recitation02a-Ex2-en

PROFESSOR: Consider a stationary process.xt is epsilon t plus theta times epsilon t minus 2, where thetais a constant and epsilon is a 0 mean random variablewith variance sigma squared.So this is a notation you'll often see in the literature,and you can be tempted in fact, you can just rescale the sigmaand re express things in terms of a completely standardizedrandom variable z.They're just simple linear transformations.But in this notation, we would typicallywrite that the expectation is 0, that the variance is sigmasquared, and since the mean is 0 the covariance of epsilon tand epsilon s is equal to 0 unless t is equal to s.So when t and s are different we get 0,and when t and s are equal, we get the previous result.We sometimes write those in a compact notationusing the Kroncker delta notation,where that's simply defined here.This delta t sub s just is somethingthat's 1 when the indices are equal and it's 0 otherwise.So here's our question.Is the series x sub d stationary?And find the mean, the variance and the autocorrelationfunction.So why don't you pause the video, solve these questions,and then come back and we'll do it together on the board.OK.Let's look at solving this problem.First of all, is it stationary?It is a stationary series because we haveexpressed things recursively.If we shift things in time, we stillhave the same relative relationshipof the axis across different points in time.How about computing the mean?Well the mean we can do just by expectation.We take expectations it's linear,so we have that the expectation of x--this is zero expectation, and thisis theta times 0 expectation, so that's equal to 0.How about the rest of it?Well I'm going to simplify things a bitby letting epsilon t be sigma zt.And then I'm going to divide through by sigma.I'm going to keep calling my variable--I'll call it little x, and then at the endwe can switch variables and we can multiply everythingthrough by sigma if we'd like.So I'm going to have the defining equationthat xt is now going to be zt plus thetatimes z of t minus 2.And we've seen that the expectation of xt is 0.The variance is xt squared, and that's justthe expectation of zt plus theta zt minus 2 quantity squared.Obviously what's going to happen as we expand this out,the cross term will have vanishing expectationbecause zt and zt minus 2 are necessarily two time stepsapart.So that's going to vanish, and the final termwe're going to be left with is goingto be expectation of zt squared plus theta squared expectationof zt minus 2 quantity squared, or in other words1 plus theta squared.And if we multiply through by sigma squared,we'll get the answer to our original questionin terms of big X. Is that what you got?All right, now let's take a look at the autocorrelation functionand things will get interesting.So the autocorrelation function, or ACF is defined--and we're just going to do calculations,so we're just going to use our definitions.So our ACF is going to be obtainedby just computing expectation of xt and xt minus k.Now remember, this is a special case when the means are 0.More generally what we properly should writeis it's the covariance of xt in xt minus k.But it's the same as this expectation in the casewhere the means are 0, and otherwiseas we know we would subtract off the productof the expectations.So what do we do?Let's just substitute in.So we have this is going to be the expectation of ztplus theta zt minus 2--let's change colors here--times z of t minus k plus theta of zt minus k minus 2.Now when we do the expectation, what's going to happen?Well, we know that zt could be paired with--it can't be the same as this one,we're excluding the case where k equals 0.We've already done that, that's the variance.So we know the t and t minus k have to be different.And we know that t minus 2 and t minus 2 minus khave to be different.So the term with no thetas and determined theta squared areboth going to have varnishing expectations of the z's.So we're left with two possible terms.So we're left with theta times the expectation of zt minus 2 times z t minus k plus theta times the expectationof zt with z t minus k minus 2.Now usually, one comment I should makeis that often we do things only for positive kand we think going forward.Formally for stationary series--and it's a property you can checkand you can show from the definition--that if we take k to minus k, that the autocovariancefunctions are the same.We often don't think of them that way because we usuallywant to think about autocovariance and lagvariables because we expect informationto propagate forward in time, not backward in time.So there's no time travel rule in finance.But formally we could have either of these, but whatwe can see is if we look at the two expressions,we can see right away that generally they will vanishexcept if k is equal to 2.If k is equal to 2, then the first expressionwill have expectation 1, and otherwise it will vanish.And in the second term, this one here,this will generally vanish unless k were equal to minus 2,in which case this would give me an expectation of 1and this expectation would vanish.So either way when we put these together,what we're going to get is that this is equal to thetaif k is equal to plus or minus 2, and it's equal to 0otherwise.And of course, if we want to go back and put in our sigmas,we would multiply this through by sigma squared.So the interesting thing about this structureis that it's only a quadratic term, it's very simple algebrathat we've done.And because of the way the variables get paired together,there are only certain combinationsthat have a chance of meeting.So we've reduced something that does involvelag propagation of time, so thereare things that are moving forward two time steps ahead.But when we express things in terms of the z's, weneed the z's to be coincident, or the same time index,and that picks out the terms that are going to be there,and then the result is just what weget by doing a little bit of algebra.

#### Recitation02a-Ex3-en

PROFESSOR: Exercise-- let's let xt be zt plus theta zt minus 2.The z's are IID normalized random variables,means 0 in variance 1.And let's let A be the average of the first fourobservations-- let's say x1, x2, x3, x4.And you can generalize this, and youshould after you've done this.But here, let's try this.Using the results that we did in the previous exercise,let's see what we can say about computing the meanand the variance of A So pause the video now.And A is an average.It doesn't have a time index, but it'sbased on a particular set, not an infinite sumof random variables.So A constitutes a new random variable.What it its mean?What is its variance?Let's compute.Plug in the formulas and take some expectations.So first of all, it should be obvious that the expectationof A is going to be 0, because it's the sum of a bunch of 0mean variables, each of the x's.What about the variance?So we have the expectation of A squared.This is the variance of A with the covarianceof A with itself.Sorry, let me rewrite that.Let's do it a little bit more neatly, as A. And thenlet's just use our definition.This is going to be 1/16 the expectation of x1 plus x2plus x3 plus x4, quantity squared.So what we're going to do, is we're goingto expand out the quadratic.Take expectations, simplify terms,and get our result. So what do we have here?We're going to have two kinds of terms.We're going to have terms in x1 squared plus x2 squaredplus x3 squared plus x4 squared.Let's just write this out.This is going to be 1/16 of--now, we'll have the expectation of let's justcall it x1 squared plus 2 squaredplus 3 squared plus x4 squared.But remember, these are independentand identically distributed.So that whatever the variance is,they all have the same variance.And actually, we know what that variances.This is going to give us 4 times 1 plus theta squared,because we just computed that.Now, what about the cross term?So the cross terms are going to be interesting.So we're going to have 2x 1x2 plus 2x 2x3 and so on.But the only ones that are going to havenon-vanishing expectation are goingto be x1, x3, and x2, x4, because they'reseparated by two time indices.That's the calculation that we just did a moment agoin the previous exercise.So we're going to have this plus-- let me write down2 expectation of x1, x3 plus twicethe expectation of x2, x4.And we'll close our big bracket over here.And we know what those are.This is going to be plus 2 theta,plus 2 more theta over here.So we have our final result--the variance of A is going to be 1/4 of 1plus theta plus theta squared.Again, our principles were take the basic process,expand out the things inside the expectation,write things out algebraically.Expectation of a sum is the sum of the expectations.Reduce things down to z's or to previously known productformulas.And then, get the final numbers in terms of the parametersof the problem.And there we are.I hope that answer matches yours.

#### Recitation02a-Ex4-en

PROFESSOR: Let Rt minus mu be equal to minus lambdatimes Rt minus 1 minus mu plus sigma zt,that's the definition of our AR1 process.Now can you show that this AR1 process can be rewrittenas a moving average process?Let me give you two hints.Number one is to use recursion, and number two is to keepin mind what the goal is, is to express Rt on the left handside, and something that doesn't have any R's on the right handside that only has z's.That's a general rule that we have.They can be of different lags, but there should be onlyz's on the right hand side and no R's.So see if you can do that, come back.Pause the video, see if you can work it out, and then come backand we'll look at it together.So I'm going to simplify notation a little bit for meby removing some of the scaling, let'sget rid of the mu's and the sigmas and boil things downso they're a little bit easier to follow.So I'm going to define a new variableI'll call y sub t to just be Rt minus mu divided by sigma.So you notice that this looks like a standardized randomvariable, but be careful because the sigma is not necessarilythe variance of R. In fact, we know it's not.It's the parameter that multiplies z.So this is just a definition, and in termsof which I can rewrite my AR1 process of the form ytis equal to minus lambda yt plus z sub t.Now what I'm going to do is make a seriesof recursive substitutions.So the first thing I'm going to dois I'm going to leave this zt right here.And what I'm going to do-- oops, sorry.This should be minus 1, very important.So what I'm going to do-- so this is our expression,let's just compare it and check.So what I've done up here is I've divided through by sigma,and then after dividing through by sigma,this is y sub t, which is here.The minus lambda stays, this divided by sigmais y sub t minus 1, and then zt over herecomes from dividing this term by sigma.So that's just our previous expression.What I'm going to do, though, is nowI'm going to take this piece hereand I'm going to take y sub t minus 1and substitute it in this expression.So it'll be a little bit more convenientif I put the z on the left hand side.So let's do it like this.I'm going to write down that yt isequal to zt minus lambda times y t minus 1,but that's the same thing as zt minus lambda times--let's change colors.Now y t minus 1 is just z t minus 1 minus lambda times yof t minus 2.That is, this expression here just corresponds to thisby using this entire definition.That is, if I take t and I replace it by t minus 1,this becomes t minus 1, this becomes t minus 2,and that's what I have here.This is z t minus 1 minus lambda times y of t minus 2.We simplify, and then we do it again.So to simplify, this is going to be zt minus lambda timesz t minus 1.And now I'm going to have plus lambda squared timesy of t minus 2.Let's substitute in for that y of t minus 2.This is going to be equal to zt minus lambda z t minus 1plus lambda squared times z t minus 2 minus lambda of y tminus 3.And we can simplify that.Let's expand that out and you can see the pattern coming.z t minus 1 plus lambda squared z t minus 2 now minus lambdacubed times y of t minus 3.So we're going to keep going, and what's going to happenis we're going to push the y farther and farther offto the side.And there there's one thing that'simportant to keep in mind, which is that lambda, remember, mustbe less than 1 in absolute magnitude, otherwisethis series blows up.So we can imagine that as we push y farther and fartherback--because t minus 3, t minus 4, t minus 5--each time it's being made smaller and smaller,not only can we run this recursion infinitely,assuming we could go infinitely far back,but any residual term that's left overis getting smaller, and smaller, and smaller.So finally, we can write this as an MA series,but the trick is it's of infinite order.So what do we get?We write this out and we can summarize our result.So we continue going down, and finally what we're left withis an expression that y sub t canbe written as the sum from k equals 0to infinity of minus lambda to the kz sub t minus k.So this is our formal result for this expression.We know that in practice we're not reallygoing to be able to do infinite sums,but we expect that it's going to be a good approximation if wetruncate after a reasonable number of termsbecause they're all being suppressed by powers of lambda.So even if this is a formal expression,it encodes one thing that's actually quite important,which is that this is not just an infinite sumin both directions.It's a semi-infinite sum into the past.What that means is that this shows that yt,because it can be expressed as a sum of all of the previousz's--and I've eliminated the previous y's,so we're back to our original variables,remember that this is in fact the same thingas Rt minus mu over sigma.So we can write this for R sub t as just sigma times yt plus mu.What this shows is that it depends onlyon z's of the same time or earlier.So in particular, it means that if wetake two different times--if I were to compute, for example,the expectation of z sub s with y sub t,this is going to be 0 whenever t is earlier than s.So if we pick a point subsequently,this term here, this sum includesfrom our starting point, from lag 0from t, all the way to the past-- t minus 1, t minus 2,t minus 3, if we pick something that happens after that itis necessarily uncorrelated.And that means-- in coming back to our AR1 model--that we have an interesting result that'sactually important in doing other derivations.And now that we've shown it, it shouldbe intuitively reasonable that wheneverwe have crossed terms of this form--whenever we look at the expectation or the covarianceof one of the z's--one of the noise terms with one of the excess return pieces,the Rt minus mu, at a different point in timethis expectation is going to vanish.These have no covariance.So intuitively, it makes sense that the noiseis independent of the general variable,but now here, we can see that as a consequenceof the temporal structure, that we can write the AR1 processin terms of an MA1 process in the semi-infinite pastor in the infinite past.

#### Recitation02a-en

PROFESSOR: We study discrete time stochastic processesin order to develop models that help us make inferencesand predictions about data that's observed over time.We look to the past to understand how data aroseand to try to figure out what the underlying mechanisms wherethey produced it, and we look to the futurein applying models to make predictions and to take action.So time series models are useful in a number of ways.They can summarize data, provide useful descriptive statisticssuch as measures of serial correlation,they can be used for filtering, for detrending,and more generally to differentiatea noisy background from potentially meaningful signalsthat might otherwise be obscured.By quantifying the balance between signal and noisein the context of a model, we canhave some guidance in identifying opportunitiesand managing risk.Most financial market data is noisy.Can we determine whether two sets of datadescribe similar market conditions?Did they come from the same model?Do they have the same underlying data generating process?Did an old model break?Has there been a new regime change?If we need a new model, how do we know when it's needed?How do we know what its connectionshould be with the old one?Time series models help us perform simulations,make predictions, evaluate data adequacy,quantify expected performance, and improve decision making.Now we started with a bunch of stationary models,and in this recitation we'll do a few exercisesand we'll talk about stationarity.So stationarity means that we can shift the model in time.It doesn't have a fixed origin.That means when we write down things, definitions like these,that if we shift the time index--not that the data will be the same,but that the probability distributions are the sameand that the defining equations are the same.And you can see that for each of these,for the generalized random walk model, for this moving averagemodel, and for our old friend the AR1 model.In each of these cases if you wereto replace t by t plus k or t minusl, the equation would take the same form.Now stationarity in reality is much too strong a condition.It would almost never hold.First of all, it would require that the conditionsbe the same forever.And financial markets haven't been around forever,and they might be around forever in the future,but certainly not under identical conditions.So what we really require for applying them--we don't expect it to literally hold in practice,but for the mathematics to be sensibly appliedwe have a couple of things that we need to check.One thing that we want to check isthis thing about long memory.Do we need things infinitely far in the past?So if we can find out and show in our modelsthat the initial conditions do nothave an infinitely long persistence over time,that after some period of time at leastthe behavior of the models doesn't dependon the specific initial conditions,or if it started a finite point in the past, thenat least we have a chance of applying these usefully.Second, we don't want full stationarity.We usually only require somethingcalled weak stationarity, which usesthe first and second moments only.So it says that the first moments, the means,should be time invariant, and the second moments,the variances and two point functionslike the autocovariance functions,should depend only on the difference in time indices,not on the exact location of a particular point in time.And that's a good thing because usuallydon't know what the higher moments are,and we certainly don't know that everything is stationary.So weaker conditions are good for us.So keep in mind that the financial world does change.We don't expect to find universal laws that will alwaysbe applicable, we expect them to hold some period of time.It might be a number of years, itmight be in a high frequency tradingcontext for a number of days, but there'ssome persistence over which we can apply these models to helpunderstand signals and noise.And if we're lucky, a model will be successful for a long time.It'll have a good and stable run,but eventually we want to be on the lookout for whenit will no longer be useful.When it comes to an end it could be through a crash, a crisis,a pandemic, or changes in behavior, changesin institutions, changes in systemsof financial intermediation.But for right now what we want to discussare some practical ways that we canlook at some examples of problemswith stationary time series using our tools of linearityof expectation operators, and now weadd this additional feature that, for a stationary series,we can shift them in time.And that means that we can use translations or recursion,and it can take a number of different forms.

### 04-Testing_the_Random_Walk_Optional

#### Recitation02b-RWtest-en

PROFESSOR: In this video will test a random walk.We'll look at the computational and datatables that are needed to do an analysis,perform a variance ratio test, and explore whether assetprices may be predictable, whether the random walkhypothesis holds for a given data set or not.I'm doing this in an R notebook.And R notebooks are text files that contain codebut they also contain discussion around them.So on the left hand side of my screen,you can see the raw contents of the textfile of the R notebook.And you can load that into your own version of RStudio.And on the right hand side is the formatted version in HTMLwhich you can do whatever you'd like with.And when you hit this preview buttonon the top of the screen, it'll regeneratethe preview of the notebook.But right now what we'll be doingis mostly working on the left hand side.And we'll start by loading a few packages.Now packages in R are installed onceand then they're run many times.So to install a package if you've never seen it,you uncomment these lines, it'll grab the packageand run the package to install it on your computer.Subsequently, packages are loaded into a given sessionusing the library command.So for right now I think the only onethat we need here is going to be the tidyquant package thatwill help us with the function to fetch some data directlyinto R so that we don't need to load it from a flat file.That's a perfectly honorable thing to do.So I click here and run this current chunk,and it will run and load the packages of interest.We'll get a few descriptive messages that will go awaythe next time we run it.So those are not essential informationor essential reading.Now let's take a look at some data.Specifically, we'll take a look at stock for Tootsie Rollwhen the longest continuously the companies that'sbeen around publicly traded for a long period of timesince the beginning of the end of the 19th centurybeginning of the 20th century.And we'll get some data for Tootsie Roll.And if we do grab data, there are a numberof issues we normally need to be concerned about, which are,what's the data source?How do they handle corporate actions?What's the format of the file?How are the line breaks handled?What is delimiters and so on?So we could start with the CSV fileor we could grab things directly from Yahoo Finance.So I'll show you the latter here.So what we'll do is we'll use this one function calledtq_get() which is the tidyquant get function that will graba given ticker symbol for a range of dates,and grab data from Yahoo Finance.So we'll do that now.The ticker symbol that will define hereis tr for Tootsie Roll and we'll pick a range of dates.Now one of the things that we're going to do, so hit the Runbutton here and with fingers crossed because we'rerunning this live.Will hope that everything looks.So one of the things that we commonly dois because we usually are more interested in returnsthan in prices, we need to get and we'll alwaysneed extra prices to be able to compute a return series.So we typically want to start retrieving data few daysat least before the first return that we need to compute.So here I've done this for the periodfrom 1988 to the end of 2017.So this is before the Wall Street Bets era.So to check that we've got the data, we can go to our consoleand take a look at a view data, or we can run and take a lookat any of the lines.So we can either say head TR to take a lookat the first few rows, or we can say View with a capital V,to take a look at all of the data.And what we see is that, we've got here from Yahoo Financeis data structure where the first column is the tickersymbol.Then we have the date open high-low close volume.And the last column called adjusted is what we'll use.That's where the prices have beenadjusted for corporate actions.Tootsie roll was an interesting and unusual dividend policywhich we won't go into, we'll justbe working with these adjusted prices.So, what does the data look like?Well, here's what the price chart looks like over time.So I'm going to click here, and Iwanted to show you some code through example.I'm just using the base R plot function,we can make much nicer plots using the GG plot package.But here we're just doing vanilla plots,and we can dress them up later on.So here's the Tootsie Roll adjusted priceover this period.So it's had a bumpy ride.But generally if you are invested in toastie roll,you've done pretty well.OK?Next, now notice that as I update thisas we run chunks of code, that on the right handside of my notebook up here, and as we scroll down,we'll get these graphs will be incorporated.And we can even include formulas by writing things, commands,and LaTeX.So we can get formulas here.So here's what we do.We defined the logarithmic returns,as being the logarithm of the priceratios, the last observed price divided by the previous price,and we see that can be written as a differenceof successive price logarithms.So, in code what we're going to do is extract the prices,get the return series and most of our analysisreally is going to be testing the returns themselves.Because the returns, when we talk about random walk wesometimes in finance because the context is usually clear,we may abuse the language a little bit.What we're talking about is the return seriesfor a random walk being uncorrelated random variablesover time.The price series does have levels that matter,and it's by taking these differences of logarithmsand we get to the series of interest.So there are two things we could do.First, we could just strip off the data and work with that,or we can also store the data as part of our data structure.So there are two ways we can do it.First of all, what I can do is I candefine a variable p that just pulls out the adjusted priceprocess.I can say r is diff log p.That implements the formula that wesee behind me you just move that up the screen a little bit.There we go.So for that formula right here.Sorry, trying to highlight it, there we go.A little awkwardly, sorry about that.So anyway this formula here is the formula that we want.We get that in code by saying diff log R,you could write a for loop if you like justto take successive differences, and then we'lladd and be the length of the series.Then what we can also do, let me just run this chunkas we're speaking.What we can also do is we can add a new column to our datastructure.And when I do that, if I look at tr,we'll see that now there's a new column here R. At the end,I don't think I want things sorted by R, sorry about that.But here we've got this new column.So let's just see what we did in the code.What we did was we set a new column here for our TR.We added a column r, and we had to include a leadingNA for the simple reason that we're alwaysgoing to have one less return than we do prices.So if we want things to line up, the return correspondingto our very first price is not availablebecause we don't know the price before that.But all the others will line up with their corresponding dates,and then that first date of interest we'll toss it out,so that everything is lined up starting on the first tradingday of 1988 in this example.Now we can take the returns and thenwe can plot those, and see what those look like.And if we do that, we get a graphthat you can see over here on the side,where we see the daily return series.Now, the daily return series is noisy.And the mean return is not really visible on this scale.And this is typical of a lot of financial return data,that on very short time scales like a day or less,it's almost impossible to see the mean return.But you certainly can see the risk.You certainly can see the fluctuations in value.So we'll use some statistics to getat the heart of what's going on to both characterize,to describe the data, and then lookat what we can say about the relationship across timeand about any predictability that mightbe present in the data series.So let's just compare this picturewith what it would look like if it were a pure white noiseseries.So what I'm going to do here, is I'mgoing to generate using the rnorm function.A set of random variables drawn from a normal distributionthat are scaled to have 0 mean and the same standard deviationas the Tootsie Roll data does.So we can see at a glance this is hardly a statistical test,but we can see that they don't exactly look the same.That is the white noise process is noisy,but it's much more uniform over time.Whereas the Tootsie Roll process has not only some pretty bigspikes that come along, but thereare periods of intense fluctuationand some periods of quiet.So what this might suggest is that volatilityitself can vary over time.And then when we talk about the volatility of a process,maybe that's something that we would eventuallyneed to generalize.OK?So that's just in pictures for looking at our data.We can get some summary statistics for the data.So we can use the summary command in Rto give us a look at our data set.And it tells us for each of our data fieldsopen, high-low, close, and the return.What's the mean?What's the max?What's mean?What's the median, interquartile range, and so on.So we've got 7,500 observations which isn't bad,and we can see a range of the numbers.Now these numbers in particular, if we look at the returnsare pretty small because their daily numbers.So the convention is that we annualize numberswhen we're looking at return and risk data.And that means that for our annualization conventions,that when it comes to returns, we'regoing to multiply by the number of time periods.And when it comes two standard deviations,we're going to multiply by the square rootof the number of time periods.And this is just a convention for scalingour descriptive statistics.It would be natural if, in fact, wehave random walks, because we know that the variance scaleswith the square that with time linearly,and the standard deviation with its square root.We don't know how this data behaves,but by convention when we report descriptive statistics,we typically use these conventions.Why 252?It's the typical number of trading days in the US equitymarkets.Now, if we look at what that would correspond to, let'srun this, and let's take a look at howwe would get the numbers.So if we take the mean return and multiply by 252,and we take the standard deviationand we multiplied by the square root of 252,we find that we get a return, annualized return of about 8.3%with a volatility of about 24%, whichis not unusual for US stock.Now let's take a look at the histogram of the returns,and see what their distribution looks like.Now the histogram is very sharply peaked in the middle.So it doesn't look Gaussian, it's not rounded over the top.It's kind of squished in the middle, which is interesting.But it is single peaked and if you remember,our discussion of the attributes of a random walk, and of timeseries models generally use primarily the momentof the distribution not the full distribution.So when we're interested in the sum of the random variables,whether the individual random variables aredrawn from a Gaussian or a log normal distribution,or whether there binomial coin flipsdoesn't make a difference in terms of the large time scaleproperties when we add together a large numberof random variables, and we ask about the mean and varianceof the sum.But it's always a good idea to look at your data.So Lo and MacKinlay asked about whether the varianceof a sample of returns, in fact, grows linearlyas a function of the observation interval?So the difference is, what they didis instead of letting the time and just addingmore and more days where the market conditions mighthave changed, they ask about taking a fixed number of daysand looking at different course screening.So we can look at daily observations,then we can go to two day periods.We can go to four day periods.We can go to one week, one month, and so on.So they did powers of 2.Here we'll just run a for loop and do different numbersof days from two days through 100 days,and let's take a look at it.What we're doing here is, we're lookingat the variance, of the difference, of the logarithms,of the price.And the price what we're doing in ourwe're looking at taking steps but of size n.Now that's going to leave in the eventwhere n does not evenly divide 7,561 or 7562 observationsthat we have.That will leave a few points left over at the end.So this is just to give us a rough idea.It's not as precise as making sure that we divide things,but we can see at a glance that we've got a generallylinear behavior.And now we could ask, so does that settle the matter.Does that say a yes, the variancegrows linearly with time.Well, we don't know what the slopeis, we don't know it's exactly linear,and after all, there is some scatter aroundand the scatter gets worse as we go further out.Now that could be because we havea breakdown of the hypothesis as we get to larger values.And then, on the other hand, it could justbe that as our observation windows get larger,there are fewer of them and we'regoing to have less statistical significancein our observations, and we would think that thingswould be somewhat noisier.So let's take a look at some of these metrics.Now this is the code.And let me move this over here.So you can see the code.So this is the code that's in the Lo and MacKinlay paper,and that I discussed in lecture where we can constructa variety of different flavors of variants,where we might have overlapping windows,we have some scale adjustments, some removal of bias factors.But the basic idea is that what we're going to dois construct an adjusted variance for our data,get all the scaling and all the pre factorsright on our Lo and MacKinlay.And then, we're going to compute the sampling statisticfor the variance ratio.So remember that in the ideal case,the variance ratio where we take the variancedivide by n or q times the, if q is the number of daysthat we're aggregating, that if we take the varianceand take the ratio to the day variance,and we include a factor of q to scale outthe obvious overall dependence, that variance ratio shouldbe equal to 1 if there's a random walk.But the question is not do we get.One, we're going to get somethingin the neighborhood of one this would be what we'd expect.But how significant are the deviations from one.And to do that, we have the Z statistic.And the Z statistic is constructedso that it is sampled from an n zero 1 distribution.That is it should be Gaussian distributed with 0 meanand unit variance itself.So a Z that falls in the range of between plus or minus 2or maybe even plus or minus 3, couldbe consistent with a hypothesis being true.Large values of the Z, outside of plus or minus 2would be considered a significant departure.And if we were to do different testswe'd expect the Z's to be uncorrelated with each other.So let's take a look.So we can run this now that we've got our data,and we have our return series.We define this function variance.c for a functionand we'll run it on our data set.OK, so let's run this chunk.And let's take a look at some of the results that we get.Now again if I want to update things on the right hand side,I click the Preview button just above my window.And now things will be update on the right hand side as well.And here's a bar plot of the results of our variance ratiotest.So what we can see is that all of the valueshave the same sign.These are all negative.Of course, each of these windows these are not independentdata samples were doing different levelsof aggregation, but what we see is that a lot of the valuesare greatly in excess of minus 2.In fact, almost all of these are.So that means that in our Tootsie Roll dataset that we can reject the random walkhypothesis for this range of values,and for this time period within the data set.OK?So what you can do is certainly you can go back and takea look at rerunning this or you should run it first yourself,but you can go back and change pretty much everything.You can pick a different stock, and you can pick the same stockin a different range, or you can change all of this,rerun and take a look and see what you get.I'd encourage you to take a look at itfor a couple of stocks of interest to you,and also to take a look at stock indices.We might expect stocks and stock indicesto behave differently after all stock index has values thatare generated by a weighted sum of a bunchof different companies, which may havelow correlation to each other.So some of the noise may average out.So I would encourage you to take this code, or even betterto write your own, and to run the testson some data of your own.So just one final thing to take a lookat a, what this means in terms of volatilityis, if we were to go back and construct the returnsand scale them.So if we take the variance and we now multiply timessquare root of q or square root of nto the appropriate numerator denominator.So that we get things normalized.If we take a look here what I've definedis sigma n to be scaled with 1 over square root of ntimes the standard deviation.And instead of looking at is the plot linear,let's take out that expected dependenceand ask if our results are constant.After all, that's what we're looking at in our Z statistic.The idea of something that is a random walkby the variance ratio test is, that no matter what aggregationscale we look at, we should alwaysget the same value for the variance.So if we do that, we find that weget kind of a bumpy ride for different values,but we wouldn't expect it to be exactly flat.And the values are all in the 20 to 30%range, which are reasonable for a stock.If we want to get a rough idea without the precise statisticalanalysis, then what we could do iswe might want to compare that again to simulated data,and run a Monte Carlo to generatedata that could have come from a white noise random walkprocess.And we could ask what we would expectto see for its variance just due to sampling error.So this is just a visualization to help give us an intuitivesense of the statistical test on the one hand,and we have an intuitive pictorial sense,and I think both that reasoning might be helpful.So in this case you've got some codethat implements a variance ratio test,you've got some code that will go grab data from YahooFinance, or if you can put it in yourself manually from any datasource that you like.You can run the test and take a lookat the behavior of the variance as yourun through the different aggregations.And you can take a look at the detailed statistical analysisfor Lo and MacKinlay carefully normalized Z statistic,and see for your data set whether you can rejectthe random walk hypothesis.

#### TS07_S01_v2-en

PROFESSOR: The random walk model, like many models,can and should be tested when it's applied against real worlddata.So let's do that.The random walk model has a long history in finance.It actually began back over a century in 1900with Bachelier, whose mathematics thesisstudied the movements of stock prices on the Paris Bourse.It was not much appreciated by his dissertation committee.And the work was forgotten for a long time.And we'll talk in more modern terms.By the 1960s, random walks had reappeared in finance,had been rediscovered, including Bachelier's work.And the idea was that not only might randomwalks provide a good model for the way stock prices seemto behave in the market.It would explain why there's so much randomness and noiseand why not everybody can get rich trading stocks.But at a deeper level, it might bea key to understanding how markets should behaveand how markets serve not only asplaces where value is exchanged but whereinformation is exchanged.And the idea is very simple.The idea is that if people had access to informationin the markets, then if everyone knewwhat something should be worth, thenthe price should be at that value.If you knew that something was going to be worth twice asmuch tomorrow, why would you sell it today for anythingless?So in a-- if we take that one step further,we have this notion that if marketswere efficient in the sense that investors are takinginto account the available information,then the only reason prices should changeis the arrival of new informationthat hadn't been anticipated.That's sort of the definition of news.And in such a world, prices would behave randomly.So somewhat paradoxically, randomness of priceswould be a sign of markets operating efficiently.That is, a good market, a well functioning market,is one where things look chaotic.So this was promoted by a number of celebrated economists,including these papers that I am showing you here.One by Eugene Fama, who said specificallythat we can model stock prices as random walks.And Paul Samuelson, who looked at exactly how and why itwas that this paradox might work mathematically.And he has one of the most wonderful titlesin the paper, the Proof that Properly Anticipated PricesFluctuate Randomly, which captures this paradox.But we're not interested just in the theoretical side.We want to see the empirical side.So what I'd like to do is show you how this can be tested.And we'll follow another set of economistswho did celebrated work a couple of decades after this.And you have the advantage of coming to this a couple decadesafter them.And you can check data now and see if they were right.And who you agree with.So what I'd like to do is review these results,show you the computational approach,give you some of the computational tools,and then let you loose on the data.OK?So this is a great starting pointfor doing empirical analysis and for seeinghow we might test different ideasover different periods of time.So the basic questions, though, thatmotivate this are this question as to how stock prices--I'll talk about stocks for concreteness.But this could apply to any asset thatis investable and its tradable.We do want to think about this primarily as being somethingthat we're going to apply to either exchange tradedinstruments or things in a very active public market.So that the data is observable.It is essential that people be able to observe the dataand what goes on.And possibly for different versionsof the efficient markets hypothesishave access to other amounts of information.But our examples will be with stocksand the generalizations that are most easilyaccessible with these computational toolsare those that come from publishedprices on exchange traded assets of different kinds.So we want to ask two things.One of them is that we have the question about howstock prices do behave.That's an empirical question.And then behind that is how stock prices should behave.And as a background idea, let's thinkof this idea of Fama and Samuelson and back to Bachelierthat possibly our null hypothesis shouldbe that stocks behave randomly.Which sounds kind of crazy and radical when you first hearit, but let's assume that that's the case,let's follow this logic.That it's the sign of a well functioning market.And let's see how the behavior actually works.So many people, depending on your background,you might come to this with different ideas.You might think that asset prices should be deterministic.That's certainly true if you buy a bondor you put money in a savings account.You know how much money you should get outif the bond is risk free and guaranteed.And we've seen that in other financial instrumentsand financial settings.But when it comes to things like stocks,there's a lot of uncertainty.So it could be that there are general trendsthat we could now and discern but there's some noise.So maybe it's deterministic but for a little bit of noise.Or maybe things are fundamentally randomand there's nothing deterministic at all.So behind this, these are the questions again motivating it.Are markets efficient?And for many financial applications, really what thiscomes down to is if they're not efficient in the economistsense, we can ask a very practical questionthat every investor has in mind.Are asset prices predictable?So the random walk model would saythat they're not except in a certain kind of trivial way.And deviations from the random walk,if we were to reject a random walk model, thatopens the door to the question to some of these questions likeare asset prices predictable?What might be alternative models that we have?So let's take a look at the data.

#### TS07_S02_v2-en

PROFESSOR: The random walk model that we've seen thus faris a two-parameter model, as thisis our generalized random walk.We have two parameters, mu and sigma, which are constant.And that tells us how the returns get generatedin subsequent periods.So one of the things about this modelis if we're to look at data and try to match returnsto this model, obviously, that meansthat if mu and sigma really are the constantsand this really is the model, then it means that if weobserve, measure, and estimate the parameters, mu and sigma,they should be the same in any time period we look at,to within sampling error and statistical estimates.So one way you could think of testing the modelis we could say, well, this is the model.Let's do mu and sigma.Can we estimate them?Do we get constants?Then we're done.Well, that's a little bit too specific.And it doesn't generalize quite as nicely.So what we're going to do is we wantto look at quantifying how big the variations are, so we canget an idea as to how significant departures might beif there are any, and to give us some insight as to whatother directions might be availableand what might be driving the results.So what we're going to do is we'regoing to look at some properties of the random walk--in particular, the way that the variance scales,with time, which we've already seen for the pure random walkmodel.And we're going to apply that to databy looking at aggregating data over different observationfrequencies.And let's do that concretely with particular stock.And the stock that I like to use for this exampleis Tootsie Roll.The Tootsie Roll company makes wonderful candiesthat will stick to your teeth, and make your dentist veryhappy, probably over time.And you'll enjoy eating them.But a couple of reasons why I picked Tootsie Roll-- but youcan and should pick your own company to do the same thing.First of all, the company is founded in 1896,and has one of the longest track recordsfor any publicly-traded company.So most companies, even the most venerable ones eventuallyend up either going out of business,acquiring or being acquired by somebody else.And it's unusual to find extremely long time series.There are only handful of companiesthat go back to the beginning of the 20th century.And data providers usually don't go back before 1926.But Tootsie Roll is one of them, so that's one good reason.It also recently found popularitywith the wallstreetbets crowd on Reddit.So if you want to look at some real challengesto the random walk model, you should take a lookat the data from 2020.So we're going to cut off a bit before that.Because certainly, the madness of crowdsis a subject for a whole other coursethat we can take a look at.But if you want to test the null hypothesis,I'll leave that data out of sample.And you can try it out on more recent data.And finally, one of the reasons I like Tootsie Roll is theyran a famous add back in my childhood agesago, with an owl and animals in the forest.But the owl was the wise one who wasable to answer the question-- how many licksdoes it take to get to the center of a Tootsie Pop.And you should go look at that video on YouTubeor on Tootsie Roll's corporate website if you can find it.It's a great example of empirical science at work.So the approach we're going to take, as I mentioned before,is falling to other economists--Andrew Lo and Craig MacKinlay, who tested the randomwalk model on a variety of data in the late 1980s.And their approach was to look at some general propertiesthat we would expect to find if the random walk model held,scaling behavior and by looking at the variance.And they were able to analyze dataand came up with some really interesting results.So I want to show you what they did.Give you some code to show you how you can do it yourself--and we'll take a look at the results for one example,for the case of Tootsie Roll stock.Lo and MacKinlay applied this for individual stocks.They looked across stock indices.They looked at equal weighted, market cap weighted indices.And I strongly recommend taking a look at their original paper,after or before or alongside going through this.So what were the elements?They were looking at what's called a variance ratiotest, that we'll define in a moment, whichlets us get at the behavior of a random walkin the following way-- we have a problemif we were to apply the data.The version that we saw, where wesaw that the variance of a random walkgrew linearly with time, is great.If you look at longer and longer time periods.But if we think about doing that with financial data,we immediately see that there's a problem, whichis something might have changed in the market.It's not the same data if this weregenerated from a random number generator and a Monte Carlo.Sure that would work.But we have a lot of different potential thingsthat might come into play if we look at 1896 to 2000.And then the next 20 years and the next 50 years and so on,a lot of economic things change.And perhaps we don't need to assumethat over the entire period that everything was random.There might be over some period.So the idea that Lo and MacKinlay appliedwas to look at the variance over random walksof different lengths taken not by extending the time period,but by increasing the observation frequency.That is they subdivided into smaller and smaller chunksso they could look at one month returns, one week returns, oneday returns, and so on.In the case of Lo and MacKinlay, they did weeks.Conversely, we could aggregate up.So we could think of a base observation frequency.I'll use daily frequencies.Lo and MacKinlay used weekly.And we could say what happens if I computeusing one day, if I compute using two days, four days,15-day periods, and so on.And in each case, if the observation periodgets longer and is more coarse grained,that there will be fewer returns in the sum.So that will give us some behavior,and let's just do the arithmetic and we'll see.And then we'll compare it with the data.So what we'll do is we'll construct a test that nicelyeliminates a lot of things that we don't reallywant to worry about from real world market and the data.And then we'll compare and see what the consequences are.So let's first look at some of the data.So I've gotten this data from Yahoo Finance.in R using the tidyquant package and the tq_get() function.You can pull this data in, or youcan download it and do the same thing in Excel if you want.But let's take a look.Here's an example of recent periodof prices for Tootsie Roll stock, ending through 2017.As I mentioned, we're leaving out the Reddit period.If I compute the log returns from the successive pricedifferences on a daily level and I plot their time series,I get this graph of differences, differencesof the logs over here.And what we can see is a few interesting features--and this is typical of all sorts of stock returns.You should try this out.First of all, it's noisy.There are a lot of ups and downs.Although the first graph on the left looks like Tootsie Rollhad a very successful period in this.And the stock price rose a lot.If we look at it day-by-day level, what we seeis lots of noise.There lots of ups and downs.If we even try to look at what the mean is,if we try to eyeball and draw a line through it,the line you see through it is the origin .It's hard to say that the mean issignificantly different from 0.And that's typically true on a one-day levelat high frequencies, financial data,it's very difficult to discern whatthe mean return is that will aggregate overa long period of time.But then we also notice that there are these spikes.This is really not uniform volatility.It doesn't look like uniform randomness.And to compare that, look behind me at this graph here.This shows a simulated white noise process.White noise just means that we'redrawing from a random, normal distributionwith constant volatility.And you can see that there's a pretty clear envelope functionhere that's at around say, the equivalent of plus or minussay, three standard deviation.So I've normalized this graph on the rightto have the volatility equal to the empirical volatilityof Tootsie Roll.So just kind of intuitively looking at the two,does Tootsie Roll look like the random walk?Those graphs look kind of different.But obviously, that's not enough to make a definitive statement,much less to tell us if a random walk isn't good,what might be a better model for Tootsie Roll.We can look at summary statistics.And I've got a bunch of them here in R,including ranges for the values over time.And we can take a look at the distributionfor the statistics.So we've got numbers overall.For example, over time, the mean annualized return is 8 and 1/2%with the volatility of 24%--kind of typical numbers for a stock.The histogram, we can take a look at--how does it look to you?So we've go, it's a single peak.It's humped.See if we can get that back, I'm sorry.So it has a single peak.It's humped in the middle.Notice it looks kind of narrow and peaky, not niceand rounded like a typical Gaussian distribution.It has fat tails, which don't show up herebecause the tails are really small.But you might have heard of fat tail distribution.A corollary of distributions, since the probability hasto sum to 1, is that if they've got fat tails,then they also have to have thin middles.There's less probability in the middlethan you would otherwise.Notice that it is roughly symmetric.That is upside and downside returns are about the same.And we look at returns, not prices.Why do you think that is?You can try it, and take a look at the price distribution.The reason that we expect that the return distribution,from an investment perspective, is likely to be stationary.That is the price levels are not, or shouldn'tbe important to investors.What matters is the return that you have.So if the initial price is $10 or $100 or $1,000,it shouldn't matter.The price levels will depend on the actual historyof the stock, and where it started out and where it went.Whereas in the case that we're especially interested in herefor, random walk-type behavior, the returnsare always going to be independent of where we start.So prices would just introduce a lot of artifacts of history,whereas the returns tell us what's actually going on.And as I said, they are what's interesting for the investors.

#### TS07_S03_v2-en

PROFESSOR: So there are a few different flavorsof the random walks.We talk about the random walk model,and of course the idealized random walkis a zero parameter model with one step plus or minus one.And that's kind of boring, and not useful for finance.The three versions that we might consider,and that Lo and MacKinlay explored,we'll only be looking at the first one.But we might think about different waysof generalizing things.So the first one is where the returnsare IID, that is, are independent and identicallydistributed.So X, think of as being the logarithm of the price,so that Xt minus 1 is a logarithm of the price ratio.Technically speaking, we can't take logarithms of prices,only of pure numbers.But a ratio of prices is a pure number.So you could think of the Xt as beingthe logarithm of the price divided by a reference price.But here what we have is in each stepthat Xt is the previous value plus muplus some random increment, which here I'mcalling epsilon T to leave it a bit more general.And one of the things that we'll seeis in the analysis of Lo and MacKinlay,they did it in such a way that it doesn't matterwhat the distribution is.So we're going to say that epsilon is required onlyto be IID with mean 0 and variant sigma.So it certainly could be something written in the formsigma Zt that we wrote before.But this allows possibly this notation is commonand we might allow for other kinds of distributions.And we do have the requirement that,in different time periods, that the epsilons be uncorrelated.That's what we mean by independence.So the delta function, delta TT prime, is equal to 1if T is equal to T prime, and 0 otherwise.So this says that epsilons in different time periodsaren't correlated, and that the varianceof the epsilon in the same period, epsilon Tsquared, as expectation sigma squared.We can also look at the conditional expectations.So this says that the expectation of Xtgiven X zero--so we take the expectation of our series--is going to be Xt plus UT.That's our result, that the mean return grows linearlywith time, and that the variance conditionedon a particular starting point X0,is going to grow linearly with time.Now two generalizations.We have the random walk two, wherewe can have instead of IID we can have them be independent,but not identically distributed.That is, the distribution could change overdifferent periods of time.And there are important models in finance that do this,and an example is a model of time varying volatility, wherewe might have something where the returns are drawnfrom a log normal distribution.They look like a random walk within a day.But then the parameters change from day to day.So that would be a simple case that would notfit under the random walk one.So the returns would be not identical,but they might be varying in some particular waythat we would specify.And then we could have things that are not independent.They could be dependent but maybethey're dependent at a higher order.So it's possible to have series wherewe satisfy that the increments are uncorrelated,but that doesn't mean that they'reindependent random variables.So it just means, remember that the independence impliesthat the returns are uncorrelated,but the returns can be uncorrelatedwithout them being independent.So an example of this that also shows up in volatility models,is one where the epsilons are uncorrelated,but the squares are correlated.And that would be another generalization.So for this purpose for our analysis,we're only going to do the first version.Now variance ratios are constructedin the following way.We start with some base frequency.And in our case, we're going to think about thisas being daily.And as mentioned, in the case of Lo and MacKinlay,they used weekly.Then we're going to aggregate returns.And we're going to do it in a very simple way.So the two day return at time period Tis the return over the two days ending at time T.So compared to the day returns, it'sequal to the period return plus the previous period return.And of course, the logarithm using the propertythat the logarithm of ratio is the differencein the logarithm, logarithm of productis the sum of the logarithms.You can check that this just dropsout the intermediate value P sub T minus 1,and gives us the return over a two day period.So imagine you just looked at the stock prices,you checked your portfolio every other day,or possibly every two days.So in that case, we would construct thisthat I'm calling RT.So ending on time period T, but with this superscriptin parentheses to denote the length of the observationperiod, because it matters.Usually we don't write that down, because we stickto a convention, like daily.But here we're going to be changing that.So q denotes the observation window.T denotes the particular period.And for a given period it's the logarithmic returnover the period.So starting q time steps back, up through the endof the present period.All right.So if the returns were uncorrelated,then we know that the variance computed from each seriesis going to be proportional to its length.That's the basic result we had from our original random walkand generalized random walk model.So if they're uncorrelated-- and that means that in this case,that the variance of the q returns, the q period, or q dayreturns, is q times the variance of the base frequency.So the way we typically set up the testis to see if this q dependence is really there.And one way we can do it is to constructthe ratio of the variance of the q dayperiods divided by q times the variance on the base frequency.And if everything works and the returns are uncorrelated,that should be equal to 1.So for any q I construct this quantity down here.And this quantity should be equal to 1,no matter what q is.So I can do it for q equals 2, 3, 17, any number at all.And the number should be equal to 1.So we have two questions.One of them is, let's put it in the data.Does it work?And when we put in the data, it'snot going to be equal exactly to 1.It never would be, even if the model works perfectly.So how big a departure from 1 is actually significant?So let's grab some data from Yahoo Finance, throw it into R,and let's just compute a bunch of variances,which you can do using the code that I've put here.And what we see is, I've just plottedthe variance computed over N day observations against N.And what do we see?Well, we see this dependence over here,which looks kind of linear.It looks pretty good, right?So we're done.It actually works.There's our random walk hypothesis.Well, maybe we can do a little bit better.First of all, is it exactly linear?No.How close should it be?Can we say something about what the slope should be?What about the variation around the slope?And why does it seem to be getting rougher and more raggedthe farther out we go?Is there a breakdown here, or is that somethingthat we should have expected?So let's get into some details.And these are some formulas taken from Loand MacKinlay's paper, which you can lookat there for the full details.But let's take a look at what the estimates are,how we can compute the variance ratio more precisely,and then we'll take a look at the samplingdistribution for the tests that they actually did.But we're not going to derive all of the statistical results.I'd like to go for what the meaning is, show youhow you can implement it yourself,and then refer you to the original paperif you're interested in the full details.So the first thing is we compute the returns,and we need to match the length of the time series.So we use our usual estimator, that the meanis the arithmetical average.So I take 1 over T times the sum of the returns,and that gives me mu hat.Now in terms of the variance, we can use the usual estimatefor the variance.And we'll see that normally we have a T minus 1.We'll get to some of the exact bias corrections in a moment,but let's just work with this for right now.So what we do is we take the returns relative to the mean,compute their squared difference,take the mean square variation over the period.And we see already that as the sampling frequency getsless frequent as we coarse grain over more and more days,there are going to be fewer terms than the sum,and that could be a contribution to that ragged behavior wesaw for the larger observation windows.There are just fewer things in the sum.And we know that we need at least say, 30 points for thisto be meaningful.And 300 would be better.3 million would be terrific.But it's not going to be uniform as welook over different periods.What we do have in the Lo and MacKinlay approach though,is that we're looking at a given historical period,and by subdividing it at least we're not changing the period.So if we pick 1988 to 2017, that's the same period.If we subdivided, at least we're notlooking at things in different market conditions.So the base frequency, we can lookat this computed with sigma hat a.Sigma hat squared with a B subscriptis defined as relating to the q periodobservations in this way.So in this case, the returns needto be taken relative to the mean for a q period return.And the sampling distribution of thistells us what we should expect.So where should this be drawn from.So it can be shown that we've got a sampling distributionthat these statistics are asymptoticallynormal with a particular mean invariance.We're going to take the square root of Tbe here and scale it out, because weknow that's always there.And we'll take a look for these distributions,and when we get to the actual datawe'll turn things into normalizedso we can look at typical kind of z-scores and T statistics.We can account for overlapping returnsand slightly increase the power of the resultsby looking at returns that are taken over possibly overlappingperiods, rather than looking at discrete windows.And one advantage to doing that, certainly,is that we don't want there to be any arbitrariness in whenwe started our series.But we need to account for multiple counting,because those returns are obviouslynot going to be independent if the windows were overlapping.So the test that we perform is to see if the variance ratio isequal to 1.And when we boil everything down,or when Lo and MacKinlay do, what wefind is we can define a nice value called z over here.So this z number is what we're going to compute,and we're going to compute it because it is normallydistributed with mean 0 and variance 1.Which means that if, under the null hypothesis,if the random walk holds, we shouldexpect z to lie between plus or minus 2, 95% of the time.In between plus or minus 3, 99% of the time.And if we get values that are much larger than that,then that would be evidence for rejecting a random walk.The things that we have here involve the variance ratioitself, in this case computed withthis particular combination.And we'll adjust that again.But a particular-- this is in the spirit that we had before.These are just the computational details.So we take the ratio of the variancedivided by q times the variance over the base period.We subtract 1, and then this pre-factor over hereadjusts for the overlapping periods for the scalingwith the square root of T.And we'll see that there are additional biascorrections that make this a little more accurate.But the idea is, scale everything so that we cancompare it to N(0,1).That's easier than just taking this ratio here, and comparingit to a more complicated distribution.So it's a choice that we can make.So to improve things a little bitwe can tighten up the formulas and write themin this way, where we have the mu.Obviously, we don't need to computethe intermediate returns, because we can justlook at the endpoints.So we can compute the mean return here.We can compute sigma a variance a, in terms of the basefrequency.Sigma B is the one that we had before,which is done with the q period observations.And C is the one done over overlapping periods.And you notice that the pre-factor and the summationare done a little bit differentlyfor the terms that entered.But this one is done using overlapping windows, which canimprove the power for the test.I've put some code here that you can take and runthat implements this.Where we can take some data, computethese different variances at the base frequency,and at any given frequency R.And we can compute then, this function z as a function of qfor our data.And then we can get things out.So we can compute a set of variancesthat we could look at for our data.We can compute these z statistics.The function z of q, which are T stats for the tests,and see if they lie between minus 2 and 2,or minus 3 and 3.And then if we want, we can get p values thatare the probabilities of observingextreme results as extreme, or more extremethan we see from z.And then finally, we can do some plots of this.So the idea of building this particular z with thisparticular function is so that we can compare it to the N(0,1)distribution, which makes it very nice.So remember, it's a normal distribution.And if the random walk holds, we'regoing to see z be somewhere near 0.The variance ratio should be near 1.The z statistic, which measures the significanceof the departures just due to sampling error fromour distribution of a given finite length,is what we want to study to see if a number that's not 1.000 isexactly meaningful or not.And if not, we'll see if there are any other directionsthat we might choose to go.Now there are a whole bunch of other technical complicationsif we really want to sharpen this,but I think that we can actually get a good idea justby doing the variance ratio test on the simple datathat we did before.But if you want to do it right, thereare additional formulas to get this very precise zwith these additional factors just to normalize everythingexactly right.When Lo and MacKinlay did this theylooked for individual stocks, and theylooked at different periods, and different frequencies.And what they found was that nothing obeyed the random walk.So to pick a particular example, if welook where they looked at both equally weighted and valueweighted indices, the numbers that they report here,and here, and here, none of these numbers is equal to 1.In fact, they're actually all bigger than 1.If these were due to sampling errorwe might expect some to be high, some to be low.These are the different frequenciesthat they looked at two, four, eight, 16.So they looked at evenly divisible series.That's not necessarily required, but it is convenient.And then below the numbers they show the T statistics,or the magnitude of the z of q.And you'll see that these are all very large numbers.So not only are the numbers 1.3, 1.64, not equal to 1,they're significantly different from 1.So let's take a look at it with our Tootsie Roll data.So what we can do is, we can look at our data.We can get a rough idea of what'sgoing on by computing the variance or the volatilityat using different sampling frequencies,and just see if we're in the ballpark.So if we do that-- you can try this,running the code I have before--you get the result that we see hereon this graph, where the volatility isdone over the entire period, but using different scalingresults.So is it exactly the same over every sampling window?Absolutely not.But it's roughly constant.So you can see why we need these statistical tests.Is that close enough?So roughly speaking, it looks like itmight be like a random walk.It has that general attribute.This is just another rescaled versionof what we saw earlier on the linear plot.But how well does this actually hold?If we want to get a very quick and dirty idea just to eyeballit and say, are those variations reasonable before werun any statistical tests, what we can dois we can do a Monte Carlo.So let's compute simulated price data thathas the same mean and volatility as the Tootsie Roll stock does.And then on that simulated data-- pretendingthat we didn't know it's simulated--do the same calculation.That is, let's compute volatilityover different time periods.And here we see the same general qualitative behavioron this plot as we saw in the previous one.So it's possible that what we're looking atcould just be statistical error, or it's possiblethat there could be systematic departures from the random walkwhen we do the detailed analysis.

### 05-Problem_Set_2_11_Questions

#### Recitation02c-Multivariate-compact-en

PROFESSOR: Let's talk briefly about multivariate time serieswhen there's more than one variable.We didn't do that in lecture this week.But there is a question on the P set.So I'd like to make sure everyone's ready to tackle it.Now, when there are many variablesand they're interconnected, there are pretty muchthree things that could happen.One of them is you can solve it with the same techniques.You can do things recursively.And you certainly can do that with this problem.And maybe by brute force, you're fiddling around.You might see some interesting symmetries or simplifications.The second category of things that can't be solved at all.They're just complicated.And there's no special insight for them.And some phase like that, like the GARCH model,which I mentioned earlier, don't have simple solutions in termsof elementary functions.But the other category is when there are symmetries.And there are multiple variables to come in on an equal footing.And in that, there are some ways that wecan reframe the equations that not only help us solve it,the numbers we got will be the sameas with any other valid technique.But they give us a little bit of insight as to what's going on.So let me just remind you for the structure,I think we've got a problem here from this week.Let me just grab that.And let's expand it a bit--shall we?So we have two equations.We've got xt is lambda y.Oops, I'm sorry.We should have t minus 1--minus 1.And this should be minus 1.So we've got xt is lambda times t minus 1 plus sigma z.And then we have the same thing basicallywith x and y reversed.And we've given z and w.They're all independent of each other.But we've given them different letters.So we have x is related to a past y.Y is related to a past x.And certainly, we could substitute thatand look at it recursively.But what's really going on in the dynamics?What's really going on is these equationssay that x and y are jointly influencedby their past histories.Whatever happened in the past in x influences.Y, whatever happened in the past of y influences x.And, of course, then they cross over in the next time step,they go back and forth.So what it's saying is these two variablesare really jointly working together.And they're processing information togetheras they go forward in time.So it's fine.And the z's and the w's are independent.They're just noise terms that show upnew in each period of time.But what often happens when we have linear equations like thiswhether they're linear time series models like this one,whether they're linear differential equations,whether they're statistics for joint distributionsof random variables in certain case,like jointly normal distributions,it turns out that we can analyze thisto identify certain linear combinationsof our basic variables in terms of which the model,the dynamics all simplify.And it reduces to a bunch of uncoupled equation.That is to say if we start with N equations of this type--and maybe they're more complicatedon the right-hand side.But the basic point is suppose we have N variables, not justtwo, x and y.So we've got x1, x2, x3.We've got a whole bunch of variables.And we have a linear structure wherewe have the x's at time t are related to the previous valueplus some noise term.And maybe we could generalize fromthis autoregressive structure whichis known as a VAR or vector autoregressivemodel to a more general ARMA type model or ARIMA model.But it's a linear structure that's of interest to us.So when we have this linear structure,one of the things we might look foris, is there a way to reduce N coupled equationsdown to N independent univariate equationswith only one variable where that variable isa well-chosen linear combination of the starting variables.And then we are down to a problemthat we've already solved.We solve it, and we transform the variables back.Now, this case is particularly easy.And I don't want to give away the answer.You can do it either by inspection and playing with itor by taking a look.But let me show you the general way that we can analyze this.So the first step is we'll define vector variablein terms of the old variable.And then at the end, we'll invert.we'll turn them back.Or you will.I'll just show you the general structure here today.So let's take a vector, xt, yt.And let's give it a new name.Instead of primes or other things,let me try some Greek letters.Let's just call it xi sub t.And I will sometimes put arrows.But often, I'll drop my arrows.So I hope-- that's one reason I wentto pick different letters that from the contextis clear which are vectors.And let's combine our noise terms zt and wt.And let's put them in a vector that we're going to call eta t.So in terms of these, what is our equation look like?Well, our structure of our equationis going to be such that we have xi_t,the vector, is going to be some matrix M times t,t minus 1 plus sigma times eta t.And what is the matrix M?Well, in this particular example, M is going to be a 2by 2 matrix, which has the form 0 lambda, lambda 0.When this matrix M here acts on this vector,you can see that it interchanges the x and y.It gives lambda-- excuse me-- x goes down.Y goes up.And then we have our basic equation.Here, this gives us the right-hand sideof our original equation.So in terms of this structure, all we've doneis we've used linear algebra notation.To rewrite it, we haven't done anything at all yet.We notice that M does have a particularly nice and symmetricform.But our task when we want to decouple thingswhen we want to separate them and see whatthe real independent drivers are isto diagonalize or orthogonalize that.So diagonalize we can do in generalby doing an eigenvalue decomposition.And in the case of a symmetric matrix,the eigenvectors that we find will be orthogonal.And what are these eigenvectors before we get there?What we're looking for is the eigenvectorsare going to be particular combinations of x and y--our original x and y in terms of which the equations simplifyand actually can be written as twoindependent one-variable equation.So we can do this if we had six variables,if we had 16 variables.We could take it and reduce it to that same numberof independent linear equations.So let me just remind you of what those features are.So in general, we can diagonalize a matrix.We can diagonalize M, writing it in the form of v.And normally, I would call it lambda.But I've already used lambda.So let me call it gamma for our matrixof eigenvalues v minus 1.So v is a matrix whose columns are eigenvectors.And gamma is a diagonal matrix--eigenvalues.Now, take a moment--just look at the matrix M for a moment that we have right hereand see if you can figure out what the eigenvaluesand eigenvectors are.And then I'll write them down, and we can compare notes.So pause the video here, go take a look, and then come back.So the eigenvectors are 1, 1, and 1 minus 1.And they have eigenvalues lambda and minus lambda respectively.So to formalize that, what we do is we put them into a matrix.And we will normalize because they're orthogonal.We will normalize them with a Euclidean metric.Let's write that we have v is going to be the matrix1 over square root of 2 times 1 minus 1, 1, 1.It's inverse.It's an orthogonal matrix.It's just equal to the transpose.V minus 1 is going to be 1 over square root of 2.And that's just in this example.In general, it might be so much more complicatedand by a matrix.1, 1.So this is just a nice 2 by 2 example.And gamma is going to be the matrix, the diagonal matrix,lambda 0--0 minus lambda.So this matrix V encodes each of the columnsis an eigenvector of M. And you can check that.If you multiply M times that, you'll get lambda.If you take the M times the first column,you'll get lambda times the first column.If you take M times the first column,you'll get lambda times the first column.If you take M times the second column,you get minus lambda times the second column.So this is exactly what we need.And how do we use it?Well, let's just substitute it into our equation.So well, so here's our equation.And what we're going to do is we're going to write this M.We're going to substitute this eigenvalue decomposition-- vgamma v minus 1.So let's do that.And we will write that xi_t vector is going to be v gamma vminus 1 times t minus 1 plus sigma eta_t .And now, let's multiply the equation through by v minus 1.So we write v inverse xi_t on the left.And that's going to be equal to v inverse times v is justthe identity matrix.So this is going to be gamma, whichis a diagonal matrix times v minus 1,xi_t minus 1 plus sigma times v inverse times eta of t.So this is actually all we need.So now we're basically done.So we have two equations--the first and second components of this thing.Let's call-- let's give it a name.If we define-- now, I will use a prime.Let's call it xi_t prime to be v inverse times xi_t.Then we have two equations.We have the first component is goingto be xi prime 1t is going to be lambda timesxi prime 1 at t minus 1 plus sigma times etaprime 1, the first component.And our second component is goingto be xi 2 prime at time t is goingto be minus lambda, xi 2 at time t minus 1plus sigma times eta 2.So if you take the equations for v and you solve itand you plug it in, you can find that you can decouplethese equations or other ones.And you can solve them that way.So this is a more general approach.Now, just so a recap and one further comment.So the first thing is that what we did is we looked for a waywhen the variables enter in such a waythat the dynamics, the multiple equations-- but they'rereally doing is they're all the same kind of equation.They all have the same general structure.In this case, this vector autoregressive modelis component by component.Each line is a AR type model.And the multiple equations just reshuffle the variable.So what we're going to do is unshuffle them,solve the equations, and then reshuffle the combinations backto get our final answers.So very straightforward.That way, we don't need any new or magical tricks.One thing that did make this particularly easy,however, was in addition to the wayin which the variables entered and the coefficients were allvery simple in this case, again, more generally,we'd have a general matrix, general eigenvaluedecomposition.But also, it was full rank.And therefore, the M was invertable.So that was important.And also, the noise terms all enteredwith the single coefficient.So their coefficient was basically a diagonal matrix.And everything went through.When we look at other settings wherewe look at linear models in finance,for example, factor models of covariance in portfoliomanagement and risk management-- wehave two things that differ quite significantly.The first one is that the matrices we use in a factormodel may be of lower rank.In fact, that's the entire benefit of factor models.What we want to do in that setting,unlike this particular setting, iswe want to eliminate degrees of freedom.We want to describe the important riskdrivers of a set of financial instrumentsin terms of common factors, which mightbe an overall market factor.It might be industry exposure.It might be other economic or financial variables.But the idea is to simplify to saythat we have some common factors affecting many assets.Let's simplify the description.So we would expect to have matrices thatare of less than full rank.On the other hand, the noise termsdo need to have a matrix, which is full rank,because the noise terms are idiosyncratic.They are independent.So we may have these two differences,which is we may see that the matrices have different ranks.And we may see, in fact, that a lot of the way and the factormodel setting and some of the structure that wesee in the covariance matrix reallyis driven more by the noise termsthan by the nonnoise terms.Here, they come in more or less on an equal footingand in this example where one matrix wasthe coefficient of the noise terms must diagonal.It made it rather simple to take a look at.So I hope this was helpful.And however you solve the problem,I hope you're always on the lookoutfor new ways and multiple ways to solve a problem not only sothat you have multiple techniques, because generally,each new technique brings some different insights into what'sgoing on with the underlying functions, data,and random processes.

## 06-Week_3-Time_Series_Models

### 01-Overview

### 02-Lecture_3

#### TS06_S01_v1-en

PROFESSOR: Models we study for applications in financeare not just mathematical constructs,they're tools that we use as approximations to realityand that we use for interpreting data and understandingthe world around us.Now in finance, the problem we haveis quite different from that we have in the physical sciences,even though some of the mathematical toolsare quite similar.Rutherford once said that if your experiment needsstatistics, you should have done a better experiment.But in finance, we're really quite different from laboratorysciences.Most of our data is noisy.We need statistics, we need toolsto get to the bottom of it.Furthermore, we can't repeat an experiment,not in a true laboratory sense.Actually, we have an interesting dichotomy.We've got on the one hand, that we oftendeal with market data and historical market data.And that is almost by definition reproducible.If we plug-in the same numbers, weshould get exactly the same answer no matterwho does the calculation.That's a good reason why it's interesting exerciseto pick up previously published papersand work and reproduce their results.Unlike a laboratory result, you shouldbe able to get exactly the same thing if youcan get your hands on the same historical marketdata on which some empirical studies were based.On the other hand, markets change.We can't go back in time.And all of our results are going to generally be provisional.So this leads to a different perspective on modeling,and often to the difficulty in settling questions.And one that we'll take a look atis going to be the role of the random walkmodel and the so-called random walk hypothesis.What does it say and can we test it?More generally when we're looking at models,we have a bunch of questions that we want to ask.And I'll talk about a few of them nowand will develop more of them over the course of this lectureand beyond.We'd really like to know would be,what's the model that generates the data thatdetermines how prices move, how variables evolve and so on.But nobody tells us that there is such a thing.There might not be such a thing.If there is, it might change and we can't look it up in a bookexactly.What we're typically faced with when it comes to real worldproblems is data, and maybe a whole bunch of different modelsand some candidate models.So the questions we ask includes these, and notnecessarily in this order.What's the model that best fits the data?If we have a choice of models.If the models have adjustable parameters,how should we find the best values for those parameters?How do we decide among the better of two models?It might have a different number of adjustable parameters.Do the models of a stationarity?That is, do they describe the evolutionof our variables of interest in a waythat the models themselves don't change over time?That is the probability distributionsare stationary over time, the so-called time's translationinvariance.How should we be estimating our parameters?How can we take a look at what's going on with data?Before we build models and test them,we might want to take a look at the dataand see if there's some general attributes thatsuggest the kind of models that might or might notbe appropriate.So we often do some initial exploration.And sometimes we do this with the same statistical toolsthat show up in other settings as well.We often want to test hypotheses.Is this model correct or is it not?That's our simplest version.Or if we have a bunch of models, which of the modelsis the best?And finally, we'll take a look whenwe look at structured models of information propagationin time series models as to how we can decide about whatthe appropriate correlation links are,what the distances are, what the order and classof an appropriate model is.There's not always an easy answer.So let's review for a moment, just a couple of the basics.

#### TS06_S02_v1-en

PROFESSOR: You know from statisticsthat a statistic is a function of the data.It's a formula into which we can plug numbers and get outanother number.And the classic examples in two of the most useful onesin finance are the mean and the variance.So the mean, we take a bunch of numbers,compute their arithmetical average.That's a function.We could have taken other functions.We could have taken their sum.We could have taken different weighted averages.This is a particular statistic that gives us a summary numbergiven a time series-- or a collection, actually,not necessarily ordered--values R sub t.Same thing for the variance.We can compute this.Now, descriptive statistics don't require a model.And one thing they do is they reducea large number of values down to a small number of values.So these two numbers mu and sigmacan characterize a set of r's of arbitrary size.So that obviously means that we'rethrowing away information.We're going from a large number of values down to two.For these to be useful, we should in some sensecapture values that matter to us for what we'redoing in the sense that if we had two different collectionsof r's, two different samples that were takenand they had the same summary statistics,we've got a good collection of summary statisticsif we feel about the same.In this case, we often think of mu and sigmaas being the mean return and risk associatedwith an investment or an asset.And two assets that had similar mu and similar sigma might bethings that we would feel similarly about,whereas if one had twice the return of the other for a givenlevel of risk we would differentiate them withoutneeding to dive into the details of the r's.So that's a sign of well-chosen and well-behaved statistics.But this is purely descriptive, and itdoesn't require any kind of model or anything further.An estimator is a random variable.And the formulas for estimators look quite familiar,these formulas here.For an estimate for the mean and for the variancetake a form that is mathematicallyidentical to what we saw on the previous page.However, we think about them differently.In this case, we don't yet have the data.We think about them being a functionof future observations.So they're random variables in the sensethat given a particular set of realizations,particular set of draws from a distribution,we'll get different values.So mu hat and sigma squared hat may take different values basedon different observations.So as a random variable, an estimatorhas a distribution that's known as the sampling distribution.And the first and second moments are easy to compute and derive.And because of the central limit theorem,if we've got well-behaved estimators,then we run into the situation that wemight expect where the distribution,the sampling distribution can approacha Gaussian as the number of observations gets very large.So that's one of the reasons we like large statistical samples.We have good statistics, it gives usnot just the narrow distribution,but it also gives us one that has a well-known shapeand approaches the Gaussian.An estimate is a number that we get from the same formulasby applying it to a particular set of realizations.

#### TS06_S03_v1-en

PROFESSOR: We use these to estimate parameters.So for example.In the random walk model that we wrote down,we had two parameters.The generalized random walk, we had two parameters--mu and sigma.When we did Monte Carlo simulation,we picked values of mu and sigma and generateda bunch of concrete numbers on the computer.But suppose we start from data and we'd like to know.What should we use for mu sigma if the datawere generated from, say, the random walk model.What would be the right mu and sigmathat would correspondent that would have generated the data?And the answer to that, we can find from usual statistics.For maximum likelihood estimation, and in this case,we find the mu from the average and the variancefrom computing the sample varianceof our set of observations.Now a quick aside on some things about doing financial returnsin particular, because that's the dominant case where we'reinterested in finance where we're looking at time seriesanalysis.The usual things that we would see in investment reportingare going to involve simple returns--simple returns, monthly returns, annual returns.And variances or volatilities may be computedusing the simple returns.But often, mathematically, it's betterto work with logarithmic returns,continuously compounded returns, rather than simple returns.Now it's easy-- they're one-to-oneconnected because the simple return isjust so I can exponentiate the logarithmic returnand subtract 1 and get the value that I need there.And for a lot of applications, numerically, the valuesare really, really close.For example, if I'm looking at the equity marketsand I'm looking at returns over a one day time scale,the numbers, the typical size of the returns, is very small.And mathematically, these will be quite similar.But if we want to do things right,we need to use the correct formula.These have exactly the same information.And we can compute the expectationsby changing variables in whichever form ismore natural for us to compute.To show you the point I made just a moment ago,if we look at a Taylor expansion of big R in termsof little r, of simple returns, in terms of log returns,or if we turn it around the other way,we can see that the leading order, big R and little r,they're the same.However, there are two things we want to keep in mind.One of them is, deviations can be economically significant.So if we take a look at things like a typical 10% returnwith 30% volatility on an annualized basis,if we look at the formulas, we cansee that there are deviations dependingon which of the formulas we use to compute them.The other thing to keep in mind is,this is great when the values are small, whichthey are most of the time.But when they're not, they're not.So when we have a day like the stock market crash in Octoberof 1987 where the market fell by a quarter in a single day,whether you're using logarithmic returns or simple returnsmakes a big deal, and the higher order termsin the Taylor series matter.So it's always better to do it right.In practice, we can sometimes get awayby not taking a look at the differencedepending on what the applications are.When we're thinking about volatility, though,and we'll see this when we get to the Black-Scholes equationwhen we think about option pricing,one of the important parameters in the modelis the volatility of the underlying.And that is something that we need to estimate from data.So what should we use for our estimator?Our idea is that we ultimately need to have a good model.So there are a lot of different possible ways of estimating.And what we really want the real testis whether the procedure that we useproduces good applications of the model that ultimatelyfit the data in the markets properly.The typical approach, though, is to use logarithmic returns, notsimple returns, because they're consistent with the formulationof the model.That is, within the option pricing models, as we'll see,there's an assumption that the returns are lognormally distributed, or, in other words,that the log returns are normally distributed.If we start from the parameters of the price process,that if we think of the price as beingthe price from the previous day times the exponentialof some logarithmic return, and then wethink about iterating that, that'sconsistent with our random walk model here.Now the drift coefficient cancels outof the definition of the variance.But it is required for our estimation of the volatility.Remember that computing the volatility or computingvariance requires looking at the deviations around the mean.And the only mean that we have, we'regoing to need to estimate from the data.There are in the literature lots of alternative estimatesthat have different benefits.They have improved efficiency and they take into accountsome things we might not see simply from lookingat close-to-close returns.And a couple of them, like the Parkinson and Garman-Klassestimators, take into account additional information thatsort of interpolates between the discrete observations that areusually made for computing returns from the close of onemarket day to the next, including, did the price--where did it achieve a high or a low during the day, intraday,and do we take into account the open, close, high,and low during the day.And that additional information can be helpful.So ultimately, these are modeling choiceswe need to see, but the starting point usuallyis the traditional estimator that we looked at before.Now when we look at hypothesis testing,the simplest case is taking a model, like the random walkmodel, and asking whether it's right or wrong.So hypothesis testing is the simplest case.We start with two hypotheses, a null hypothesisand a alternate, and we define a test statisticto see if we can reject the null hypothesis.This test statistic is a random variable.So we often do this probabilistically.In classical statistical inference,we think about a p-value or we look at a z-statistic.And we say if the null hypothesis were true,what's the likelihood that we would observe a teststatistic like this or that's this extreme or more.That is, we look to see how small the p-value isfor evidence to reject the null.And we compare it to some significance levelthat we've hopefully agreed at in advance.Because the test statistic is a random variable,it's drawn from a probability distribution.And if we have a lot of observations to make,we can re-scale things so that itlooks close to a normal distribution or a relateddistribution.Just to keep in mind, a simple examplebefore we turn to the random walk--imagine that we're flipping a cointo see if it's a fair coin.So we take a coin, we flip it 10 times,and we observe a bunch of heads.And we ask, is the coin fair or biased.If we don't know in advance whether it's fair or biased,we might imagine that there's a particular probabilityof observing heads.And we could ask, what's the value of pand what's the best estimate for p.And if we do have an estimate for the bias,how precise is it, how much confidence do we have.But simple hypothesis testing starts with two hypotheses--H0, the null hypothesis that the coin is fair,that the probability is 1/2, the alternate hypothesis that it'sanything other than 1/2.Question to think about in any of these cases--what are the appropriate test statisticsthat we might choose from.

#### TS08_S01_v1-en

PROFESSOR: Let's look at alternativesto the random walk.If we analyze market data for example for stock pricesin the style of Lo and McKinley doing a variance ratio test,one of the ways that we can see that the random walk model isnot a good fit for the data is the presenceof serial correlation in returns.That is, we see that the returns are not in fact independent.If they were independent, the scaling behavioras we add together more and more terms would grow.The variance would grow linearly with time.And if we observed departures from that,that doesn't just mean that we reject the random walk.It gives us a clue as to what we mightwant to use to replace it.So if we're constructing aggregating returns,say q terms at a time, if they're not independent,then when we compute the variance the cross terms don'tvanish when we take expectations.And that's telling us something important.That's telling us that information is propagatingfrom one step to the next.So we want to think about autocovarianceand autocorrelations, which measure the relationshipof the time series with itself.That's what the auto means.And we just shift in time by k time steps.So we want to do this in two ways.One of them is an expectation for lookingat unrealized, unobserved variables in the future.And the other is we'd like to lookat estimators for these properties based on past data.And, of course, we'd expect these to be related.So the definitions that we have are going to be--and our notation will be gamma k for the covariance between twor's of different lags.When we have a stationary process,the key thing is it should only depend on the differencebetween the time indices.So t minus t minus k is k.And that's why I put the label over here.Notice the gamma k doesn't depend on t.It only depends on the time differenceon the number of steps between the two arguments,in this case rt and rt minus k.Gamma 0 is when I said k equals 0.And that's the covariance of rt with itself.And rho sub k is just a normalized versiondivided by the variance.In the same way that we usually compute the correlation of tworandom variables by dividing by the square root of the productof the variances, if it's the same variable,if it's an autocovariance and we wantto get the autocorrelation, we divideby the square root of the variance twice, variance timesvariance, of the same series.The series is stationary.That's equivalent to just gamma k divided by gamma 0.And this will be normalized.This will be a pure number, whereas gammahas units of r squared if r has dimensions.So for instance, if we think about a sum of twoone-day returns, the variance, if they were uncorrelated,would be twice the variance of the one day returns.But if they are correlated there's an extra term.So the variance of a two-day return, which is--see if I can get my pointer back--well, if not we'll use our pen.The variance of a two-day return,which is just the variance of two consecutive days,is going to be twice the variance.It's going to be the variance of rtplus the variance of rt minus 1-- it's stationary,so those are identical-- plus twicethe cross term in expectation.And that's going to be the covariance r1 and r2.So we can write that is twice the variance times 1plus rho 1, where row 1 is the lag 1 autocorrelation function.That is, it's the correlation of rt with rt minus 1.So this is going to be bigger or smaller than twice the varianceof a single period return dependingon whether the autocorrelation is positive or negative,depending on whether the return in one periodis more likely to have the same sign or the opposite signof the return in the previous period.So in order to estimate and compute,we use our usual formulas for computing covariancesof statistical data and for computing correlationsand statistical data with one caveat.Normally, we take two time series of equal length.And to compute their covariance, we subtract offthe mean of each one.We compute their products and each time period,and we sum over the time periods.We have a little bit of an issue whenwe look at finite length observationsfrom actual historical data.And that suppose we have a series of 100 days.If we shift by 1, they'll only have 99% days in common.That will be one off the front and one off the back.So we need to adjust.And as we increase the lag s for a given dataset,we're going to have shorter and shorter lengths in common.So we need to be careful of that that we don't run out of dataand that we look at the common period.Usually we make sure that we have a series thatare long enough that the end points won't matter,that they'll just be small deviations.But we do need to check that.Alternatively, we can require that wehave data of a certain minimum lengthby saying that we need to have a certain numberof common points.And then we can account for the overhang for the lag.So if we want to go up to lag 20, which we would rarely need,we'd want to make sure that we have enough for 20 pointsoverhanging at the beginning and enough points in the middleafter we chop off those points.So the formula we have really is just a--very much like the formula for computing the covariance of tworandom variables.Subtract the mean, subtract the estimate of the mean.These should be the same, but we usuallywant to compute them appropriately for the lengthof the series it enters.So that because we're not using exactly the same dataseries because of the offset because some points aremissing, we want to use the mean for each series.So it's removed-- we subtract offthe sample mean for the dataset that's there and we compute.Now, we expect in general to see convergencedepending on the details.So as t goes to infinity, or as we take a very large numberof points, this estimate should converge to the true gamma k.And the sampling distributions we can see convergencein square root of t by choosing to resample thingslike-- excuse me, to rescale things.So that if we want we can think of the errors or the deviationsappropriately scaled by powers of tso that they are drawn from a standard and 0, 1 distribution,if we'd like to apply that in a hypothesis testing case,and we want to take a look at usual confidence,or significant levels like plus or minus 2.Now, when we observe autocovariancewhat we're looking for is the directionand the magnitude of departures from a random walk.And we'd like to know how large the correlation isfrom one period to the next.So serial correlation is a typical analytic and statisticthat we'll run when we get a time series of returns.It's an important attribute.After we've computed the mean and the variance,one of the next things we'll almost always wantto take a look at to characterize what's going onis the autocorrelation or autocovariance functions.So in our example of two time steps for lag 1,we compute this.We have this expression.And what we can do is we can compute a variance ratio wherewe can compare our variance over two times stepsto what we would have expected had it been a random walk.This would be 1 under the hypothesisthat it is a random walk.And deviations from 1 means we have deviationsfrom random walk behavior.If it's greater than 1 we have positive serial correlation.If it's less than 1 we have negative serial correlation.And we can generalize this to higher steps,and we can get an expression we canshow with a little bit of algebrathat we can express things as a sum, weighted sumof the different autocorrelation functions at differentlags all the way up to value q, if we're looking at aggregatingq steps at a time.So we'll typically look at all lags.Usually the first one is the one most of interest.But in principle we can look at any lag at any separation.

#### TS08_S02_v2-en

PROFESSOR: So what are some alternatives?Well, we've seen a couple of them already.If we have deviations, we might thinkabout adding extra terms to generalize or extendthe random walk model.And the class in which we can look at ARMA models or evenARIMA models.But ARMA models include a combinationof autoregressive terms that dependon previous lagged observations of the random variable,and moving average term that depend on the previouslagged shocks or innovations whichare not related to the actual direct observations themselves.So in our language, we can add r's.Lagged on the right-hand side, or we can add z's.And of course, they're not entirely independentif we want to trade them off at the possible cost of doingan infinite recursion.So some models that we've seen--random walk model with no extra terms,AR1 with a constant term, a z term, and then one lag,a generalized ARMA pq model wherewe've got p lags of the r variable,q lags of the z variable.And in each case, we have our increments,our z's written here, are normalized IIDrandom variables, which makes it easy for computingour expectations.Coming back to our old friend, the AR1 model,we can write it in sort of standard form.And we can look at its structure.And now we want to think about what this is telling usrelative to the random walk.So we look at the mean return.The mean return is 0.And remember, lambda equals 0 is a special case wherewe get the random walk.The variance, we compute by putting in the equation.We substitute here for the definition.We put in our equation as a reminder.And we take expectations and we solve algebraically.And we find that we have the variance is sigma squaredover 1 minus lambda squared.We get the higher order values by recursion.And we know that the values as a function of k are decreasing.Each extra k, each extra lag in the AR1 modelbrings the power of lambda.Since lambda says less than 1, that'ssuppressing the magnitude of the fluctuations.So what it's telling us is in this model where there'smean reversion, that influence on a given day,above or below the mean, propagates in timebut is damped out exponentially.That would be the end of the storyif there were no sources of randomness.But because we can get new kicks every day,this exponential decay may not beas easily visible in the data.So we want to be able to estimate things from dataand we want to be able to determinewhich is an appropriate model to use from that large class.Is it AR1 or is it an ARMA32 model?How can we tell?How do we pick the appropriate order of a model?And within each model, how do we determine its parameters?So when we look at estimation, we want our estimatorsto be consistent.That is, in probability, they shouldconverge to the true value.If I take t to infinity, if I look at enough points,then the probability of deviating from the true valueshould vanish.This is equivalent to our law of large numbers.We want them to be unbiased.Unbiased simply means that the expectation of the estimatorshould be the true parameter value.We want them to be asymptotically normal--and we expect them to be asymptotically normal--so that we can apply our tests.And this can be shown for the estimatorsthat I've written down so far.Typically, we need to think about the sampling distributionand we'll choose scaling variablesso that we can relate things to a standard normal distributionfor significance testing.And if we have estimators to do all of the above,and we have more than one choice,we'd like to find the best estimator, possiblyone with minimum variance.And we can talk about efficiency of estimatorsthat give us the best estimate within a given class.So how do we do parameter estimation in AR1?Well, R1, we have a structure.We have three parameters.We have mu, lambda, and sigma.And what we want to recognize is it reallyhas a structure of a typical linear regression model.And we can find its parameters using ordinary least squares.In fact, the only thing that's specialis that we have an r on the left and an rt minus 1 on the right.Now when we computed the autocovariance,I emphasized that those are really the same series.It's a stationary series, so their expectationsare the same.And we can think of them as being the same.When it comes to estimating the parameters,I want to take the opposite tack.Let's think of them temporarily as being completely different.So remember, if we have a model that looks like this,we'd like to do a linear fit.We have a typical regression model.And we add an error term if we don't have points lying exactlyon a straight line.And we'd like to find a line of best fitwhere the errors are minimized for the bestvalues of alpha and beta.We can get exactly that same structure from our AR1 modeljust by doing a little algebra and shifting terms around.So I move the r minus mu and I move the muto the right-hand side, I can write thisas rt is a constant plus something timesrt minus 1, plus an error term.So that looks exactly like the aboveif I make the substitutions for alpha--that's equivalent.The intercept is equivalent to mu times 1 plus lambda.The slope is minus lambda.The y variable, the dependent variable, is r sub t.And the independent variable is r of t minus 1.So given data, we can just apply ordinary least squaresto get the values of the coefficients.So we can do that ourselves using ordinary least squaresin a spreadsheet program or in R using the LM function.R also has some nice special functionsfor computing AR and for ARMA models,but we'll get that directly.But the basic idea is that we already know how to do this.It's just ordinary statistics.Now, we can do exactly the same thing for an ARP model.We just have a bunch more terms.So we use our maximum likelihood estimators.We can throw it into a spreadsheet,we can throw it into R.We have a multivariate regression.We turn the crank, we get our usual estimates.How do we determine the order though?Suppose we're not sure what p to use.Suppose I don't know if it should beAR1 or AR3 or something else.So the tool for doing order determinationfor autoregressive models is through what'scalled the PACF function, or the partial autocorrelationfunction.And the idea is really straightforward.What we do is we set up a sequence of models,and we do an AR1 model, and we do an AR2 model,and we do an AR3 model, up to an ARN model.And I've written these down here.So for each of these models, we do an estimate.So I do my line of best fit for the first model,I do my line of best fit.So given the same set of observations in R,so the same time series data for R. In each case,I do my line of best fit.And the PACF is defined to be the coefficient of the last lagterm.So in this case, it's C11.In the first one and the second one,it's C22, and the last one at CNN.And what we want to do is we wantto identify how far we go when we no longer needto add new terms.That is, when the last coefficient is negligible,then we drop it.So the PACF function is very convenient for capturingall of this at once.We compute all these regressions in parallel,and then we can take a look.And what we want to do is we're saying,there could be more terms as we generallydo when deciding how many variables to choose.We want to have an economical parsimoniousdescription of the data.We're going to pick the smallest number of variablesto give us a meaningful description of the data.And we're going to toss out extra terms thatare not needed where their coefficients are notsignificant.So let's look at this for a couple examples.I'll generate some Monte Carlo data.And here's my Monte Carlo data for an AR2.So you can see that here, these are my parameter choices.And here is my AR2.So I've made a bunch of parameter choicesfor c0, c1, and c2.I'm going to look at 1,000 time steps.I'm going to compute a single path here,but you can certainly compute more.I'm putting this in a column vector.If I had had more paths, two in parallel,I could easily do that.I'm going to run a recursion starting at step 3,because I need some initial observations, whichI'm going to set equal to 0.And I'm going to run my recursion.So rt, this is just my defining equation for an AR2.And then I'm going to plot a path.So here's my path.And then I'm going to look at the ACF and at the PACF.And rather than computing that by hand or doing them in Excel,we'll do it in R, because this will give us all the resultsin one fell swoop.So here's an example of what my sample path looks like.You should run the code.Your sample path is obviously going to look different.And here is the AR2 sample autocorrelation function.So remember, that autocorrelation functions,unlike autocovariances, are normalized.They're pure numbers.So they're normalized.The lag 0 should be equal to 1.And we see that here.We see that we've got things showing up at lag 1and lag 2, which is not surprising,given the structure of our model.And then we take a look at the partial autocorrelationfunction.And we see that we have non negligible terms for lag 1and for lag 2.And everything else is not statistically significant.So this is an example of how we can determinethe order of a model when we havepotentially different numbers of terms,how we can estimate the parameters for a givenmodel of a particular order usingordinary least squares, or maximum likelihoodestimation more generally.And how we can extend the random walk model to a range of modelsthat have positive or negative serial correlation.And they potentially allow us to describe interesting waysin which information can propagate from one periodto the next.Now when we add more terms and more parameters,we can improve things by getting a better fit,or it may lead to overfitting.So typically, this is an old story in statistics.We want to expand the likelihood function with a penaltyfor additional parameters.Because we like to say that if youcan have the same quality of fit with different numbers of termsor different parameters, we'd rather have fewer.So we penalize extra parameters in the likelihood function.And there are a couple of ways common ways of doing it.The AIC and BIC, they give slightly different penaltyweights.But the general idea is that we can inmodeling we can favor simpler models with fewer terms.Sometimes, as in the previous example, it will jump out at usand we'll be able to see where to truncate the series.Sometimes, the data unfortunatelywill not be as clear.

#### TS09_S01_v1-en

PROFESSOR: Forecasts with time series modelsare predictions about future observations,future realizations of our random variablesthat are conditioned on information that's knownat the time of the forecast.Now, what is a forecast?Well, the output could be one of a number of different things.It could be a point forecast, for example,the price of Tesla's stock in 30 days, the specific number.It could be a probability forecast.Probability of rain this weekend is 30%.It could be a full distribution, thatis we might say the probability of stock XYZ,its return distribution over the next yearis log normally distributed with a mu of 10% and a sigma of 30%.So any of those could be the outputof a forecasting process.And, of course, we'll want to evaluatethe quality of forecasts.And in many ways it's less dramatic or mysteriousthan it might seem.One of the attributes of a forecastis that it has a horizon or it may have multiple horizons.That is, a forecast is framed in termsof two points, the point at which we make the forecast--and that we need to know so that weknow what information is availableon which to base the forecast--and the future date when the realization will be known.Clearly, we can't judge the quality of a forecastuntil that date passes.And then we can compare our predictionswith the subsequent observations.So we usually think of a horizon.And as time progresses between now and the horizon,unless the horizon is five minutes from nowor the next day, if there are multiple steps in which wecould update our horizons based on new information evolving,the forecast could change.We may have rolling forecasts.We may have forecast where we move both the current timeand the deadline, or very commonly, wehave forecasts for a particular date, an earnings release date,and end of the fiscal year, or picnic weather for this Sunday.Where as time evolves we may be interested in the same terminaldate which may be fixed on the calendar,but we have new information that arisesand we can update our forecasts.So if I said that our chance of rain for Sunday is 30%,perhaps yesterday I made a forecastbased on what I knew at the time and I said it was 0,it wasn't going to rain.And tomorrow my forecast might change again.Perhaps it goes to 50% as new information comes along.In time series models we want to know what's available,what's the information set.And now we're going to use the same machinery that wedid in solving models in closed form unconditionally,but now we're going to condition on informationthat's available at a particular point in time.And here's where the lag structureof models such AR and MA models, and RM models moregenerally come in.So let's take a look at an example.Let's look at AR1 model.So here for convenience, I've simplified our usual AR1 modelby defining a new variable y which isRt minus mu divided by sigma.So I've taken our usual defining equationand I just divided it through by sigma.Now, this looks like a normalized random variable.But, remember, that's not necessarily the case.Sigma is not the standard deviation of R,it's just the coefficient we put in front of Z in our model.So this is scaled to be dimensionless.It certainly looks like it might have 0 mean and some unit 1size variance, but that's somethingthat we would need to compute.We can't just infer that from here.The reason I defined it this way wasto clean up and reduce some of the parametersso that we really only have one parameter leftin our model, lambda.And we can put the others back by re-substituting for yusing this expression.So in terms of these variables, the AR1 modeltakes a simple form.Y sub t is a new random term.Z sub t which would be all we'd have if it were random walk.And if it's autoregressive of order 1,we have a coefficient which here iscalled minus lambda times the previous observationY of t minus 1.If we're forecasting, it's helpful to shift our thinkingfrom looking backward to looking forward.So let's just add 1 to t and write itin this way, which is more a little bit more suggestiveif not more informative.Let's say that Yt plus 1, the next observation we'regoing to have is the next realizationof the random variable Z minus lambda timesthe last known observation Y sub t.Now, suppose we were to compute the conditional expectationbased on the information set availableat time t, which I'm going to denotejust I sub t for the information set.In this case, it only consists of the past realizations of Y,because those are the only variables in our problem.But it might exist of a bunch of auxiliary financial or othereconometric variables.So, in this case, what I wanted to dois take an expected value assumingthat I know all of the realizations up through time tso that Y sub t no longer a random variable.But everything, Yt plus 1, Yt plus 2, Yt plus 3,and so on into the future, those have not yet been observedand they are random variables.So exactly how I denote this is a matter of convention,but and these are my conventions.So hopefully the idea is clear.Let's take a look at what the consequences are.When I take expectations of both sides of the equation,on the left-hand side I have the expectation of Y,condition on the information set I sub t.On the right-hand side the expectation of Zis 0 because it's the standardized random variable.Its value, its expectation is always 0.And this term now is a constant because it's alreadybeen observed.So it's expectation is just equal to itself.So it's minus lambda times Y sub t.How do we find the forecast or an expectation two stepsin the future?We iterate.So Y sub t plus 2 from the defining equationfor AR1 process, I can just take the previous equationand write t--the same way I replace by t plus 1, I'll replace t plus 1by t plus 2.So I have this defining equation Y of t plus 2 is Zt plus 2minus lambda Yt plus 1.Now, I'm going to substitute my previous equationfor Yt plus 1.And I can-- just by substitution I can now express Yt plus 2as Z of t plus 2 which is in the future, minus lambda of Ztplus 1 which is also in the future,plus lambda squared times Yt, which is a known quantity.And now I'll stop.Take expectations of both sides.The first two terms vanish because they're Z's.They have mean 0.And the expectation for two steps ahead in our processconditioned on the information available at time tis equals a lambda squared Y sub t.

#### TS09_S02_v1-en

PROFESSOR: When we look at forecasting,there are a number of different elements that come into play.And I would just like to lay them out for you.But we're only going to take a look at a small subset of them.Forecasting is a very big subject.We're just going to touch on it in the context of time seriesmodeling applications, so that wecan see how we take the structure of our time seriesmodel and construct specific forecasts basedon given information sets.So what are the elements of forecasting generally?Well first, we'd like to know the nature of the process.Is it something deterministic?If it's given by a known curve, a sine wave or parabola,we can predict exactly where something is going to be.We can tell exactly when the next eclipse of the sunis going to be.We know exactly when the next eclipse of the moonis going to be.We can even send spaceships to land very precisely,or send them through the solar system,because we have deterministic processes that we can solve.If we have random processes, we don't expectto get that kind of precision.We're going to have necessarily probabilistic forecasts.The processes could be stationary,they could be non-stationary.We're going to have very different tools for predictingthem in those cases.And are they laws of nature or are they human behavior?They're laws of nature, at least weknow that the process itself doesn't dependon circumstances around it--human behavior could change at any time.How much do we know about the process?Do we know the process, or do we not knowwhat the underlying process is?Perhaps we know the process.We know what it is, let's say, an AR(1) process,or an ARMA(1,2) process, but we don't know what the parametersare.So in one case, we have to figure outwhat model to work with.In the other case, we may have uncertain estimatesof the parameters which we'd like to apply.And that will be an additional sourceof uncertainty in our forecasts compared to the case wherewe know the parameters.And is this a theoretical model that'sbased on some financial or economic ideas?Or is it an empirical model that's just fit to the data,and it seems to work.Or is it a theoretical model that should work?We have the sort of normative and positive views of things.And although the approach is goingto be the same, in the way in which we'llthink about evaluating the model quality will be different,because to the extent that we observe deviations,it will tell us something about our assumptionsand what we would need to revisit,and how we would then refine things.If it's an empirical model, we mayneed to get more data or a better data set,or we might need to find a better model to fit it.If we have a mismatch with a theoretical model,perhaps we need new ideas.Perhaps the ideas that we thought controlledthe processes to produce the variableswere just wrong or in need of some extensionand generalization.How complex is the model?The examples we're doing are mostlygoing to be univariate models or bivariate models.So we could have a very large number of variables.And they could be coupled.Typically, when we think about multivariate models,we look for ways that we can simplify them and reduce themto previous cases.So it's often possible by taking linear combinations,to take a multivariate process, particularly if it'sa linear model, and reduce it to a seriesof uncoupled separate linear models that then we can solve.But the techniques will depend.And linear is usually a fairly straightforward categorywith some reliable tools that we can regularly deploy.Non-linear is kind of an open category where there'sno guarantee of success, and there's not necessarilya general approach.Those are not the most common modelsthat we'll see in finance.And those will not be among the thingswe'll be looking at in our future discussionsor in any of the problems and applications.We do want to think about what the horizon is.Do we need one step ahead?Do we need multiple steps ahead?That is, would we like to produceat every possible future horizon?Does it go off to infinity?Do we need asymptotic results as t goes to infinity?Or perhaps, as many financial applications,we have a finite date.We have the maturity date for a bond.We have the ending period for a loan.We have the expiration date for an option.And in those cases, we might be interested in forecastsover only a multiple steps, but maybe onlyover a particular horizon, which decreases as time evolves.What are the forecast criteria?Are we actually forecasting observable variables or not?That might seem strange.You might think, of course we forecast observable variables.But keep in mind, that one of the things we've already seenis models where we introduce volatility as a parameter.We have sigma.And if we take a model of time varying volatility,we need to keep in mind that volatility--while it can be a parameter in a model--is not an observable quantity.We can ask what the price of an asset is.We can't ask what it's instantaneous volatility is.To know it's volatility, we need to observe itover a period of time.We measure the random fluctuations.And that quantifies what the volatility is.But if we have a model of dynamic volatility,where the volatility changes over time--there are many such models, they'revery important in finance--but we can't directly observe the volatility.So we need to do some extra work to beable to connect the predictions of the model with thingsthat we can observe so that we can compare predictionsto outcomes, so that we can compare forecaststo observations.We'll want to think about measures of forecast accuracy.How close is close enough?If we insist on a point forecast being exactly right,most of our predictions are going to be exactly wrong.But usually, we'd like to have some measure.And one of the important things to keep in mind in financecompared to other areas where we use statistical methods,and we make predictions, and we make forecasts,is that we often have a very real cost associatedwith error.So the usual things in literature,like mean squared forecast error,are convenient mathematically.They're somewhat intuitive.But in finance, we often have other numbers in mind,like the loss in a particular scenario--the financial loss, which might not be the same easyto use mathematical expression.But we do want to keep track of the fact that the economic costof an error, or a deviation, or the benefit--if it's deviations on the upside--is something that we can directlymeasure and is directly related to issues of valuation.So we'll often want to think about forecast accuracy--weighting things by their financial importance,not just taking an equal weighted averageacross all possible kinds of errors.We might want to weight more heavily the kinds of errorsthat we're most interested in avoiding.Models don't stay the same.Models change.Models need to be replaced.So we want to think about what kind of model evolutionwe might expect.We can have static parameters that stay fixed,or we might think about having adjustable parametersthat maybe we change over time.We might think about models where, when we see errors,we update our parameters, so that wecan make gradual changes to our model as our dataset increases.As we make more observations, we can improveour estimates of parameters.And we may need to think also about identifying situationswhere we would declare our model to be broken.There's some fundamental change in the market,sometimes called a regime shift or a breakin time series, that's telling us,hey, that model is not working.There's something new generating the data.Someone swapped out one roulette wheel for us,and they put in another one.So those are kind of things we want to be aware of.There's a question, is the model completely static?Is it somewhat dynamic where the parameters get updated?And if so, how and when?And then, when is it time to go shopping for a new model?How do we set up forecasts?Well, typically we start with observations upto some particular time t.Now, we can't really go for the infinite past.And hopefully, none of our resultswould depend on the series existing in the infinite past.But what we usually think about for forecastingis there is some amount of historyup to a particular point.And maybe we have some set of observations x0, x1, x2, x3,up to the time xt.And my convention for forecastingwill be t will be the time at which we'remaking our forecast about future values for tplus 1, t plus 2, all the way up through t plus h, whereh stands for the horizon.And we assume, that we have the information setavailable of everything that happened before and possiblyincluding the current observation.And we want to know what happens next.The probabilities that we're interested in computingare going to be conditional probabilities.But it's really the same thing we've already seen.We're taking expectations.The only difference is, we need to look at the time indexand not apply stationarity directly.We can apply stationarity for thingsthat are random variables.That is, we can say that the probabilitydistributions of future realizations are the same.But that does not mean the past draws from the distributionare the same.Even though a head and a tail are equally likely,or one of the six sides of a die are equally likely,on our next five random occurrences,the last five are fixed, because they are what they are.So that's our distinction between past and future.We can look at making point forecasts,and we can think about whether we can have enough informationto generate a full probability distribution for future events,or perhaps somewhere in between.Not just a number, but perhaps momentsof the future distribution.What's the mean?What's the variance?And that could tell us something about what our confidence isand what a confidence interval is arounda forecast for future values.We can sometimes include subjective informationas well in a Bayesian approach, wherewe take information about what our prior beliefs areas a starting point.And then, we iteratively update our forecastsas new information becomes available.And we do it in a way that's consistent with the lawsof probability.The optimal forecast we can thinkof from a result of Granger as simplybeing the forecast at horizon, h,is the conditional mean of the forecast.That's our best forecast, provided that the cost functionis symmetric and convex.So this says that the forecast for a future variableis, we take its expectation based on what we know now.We can also compute other moments around it.But for the point forecast, this is the best forecastthat we can do in terms of minimizing different errorcriteria.So for a given model, we can use the optimal forecast.And for a given set of data, we'retasked with finding what the optimal model is.If we think of a typical kind of random walk-- in this case,an arithmetic random walk--where I have a price, and each timeis the previous price plus some new innovation, some new eventthat comes along, something with stepsize sigma where z is a normalized random variable.Sigma is the scale of the volatility.And we ask, what's my forecast h stepsahead for the value of the price that follows this forecast?What I do is, I iterate this out to solve for p t plus hin terms of the previous t's.I take expectations.And because all I'm going to do is add togethermore z's, and those all have 0 mean,the expectation of p of t plus h-- giventhe information I have available--is the current price.That is, the forecast for the price h steps in the futureis the current price.Now, for a symmetric random walk, that makes sense.We're equally likely to have disease go up or down.They will in general diffuse.They will move around.They're very unlikely to be exactly back wherewe started at p.Nevertheless, that is the optimal forecast.

#### TS09_S03_v1-en

PROFESSOR: So we want to think about waysof measuring deviations from forecastsbecause our forecast is unlikely to be exactly realized.And therefore we define forecast errorto be simply the difference between our forecastand what happened, between the outcome and the prediction.If we said the price was going to be 100and it turned out to be 200 or it turned out to be 50,the difference between the forecast and the outcomeis the error.And a good forecast is not one that gives you the highestprice, it's the one where the prediction comesclosest to the final outcome.So if we define our forecast errorwith E to be the outcome in the future minus the forecast thatwas made at an earlier time t-- so this is the forecast madeat time t with horizon h.And what we want to compare it tonaturally is the observation at time t plus h.We can't do that until we've reached time t plus h beyond.But at that point we can evaluate the forecastand the forecast error.So we can take this difference.Now, we want to then define the error.Error function, the cost functionis something that we like to minimizeif we have good forecasts, and somethingthat we can use to quantify or comparedifferent kinds of forecasts.We'd like to say that one forecasting methodology isbetter than another if it produces smaller forecasterrors.The most popular metric is the mean squared forecast error.So let's just take a look at the squared forecasterror for a moment.If we take this quadratic form wherewe take that error, this error term, and we squareit and we might multiply it times some scalecoefficient of positive number c for our cost.This gives us a couple of properties.First, it's 0 when the forecast is spot on.And it's symmetric.It treats whether we're too high or too lowas both being errors.Now, a lot of times financially wedon't feel equally the same about lossesas we do about gains.If we expected to make $1 millionon a particular investment and we make $2 million,most people wouldn't count that as being an error.But we should.And the reason that we should is because itbears on our ability to make betterpredictions in the future.If we ignore the errors that are on the upside,we're missing a chance to improve.However, if we have some control over the distribution--if we have observations in data or controlover the distribution of our errors,we certainly can say that we'd liketo have a forecasting methodology thatminimizes downside errors more than upside errors.And, in that case, we might want to costfunction which is not symmetric, whichdoesn't have this simple form.So this is here for convenience, notbecause it's a universal answer to different kindsof applications.There's another problem with squared forecasterrors as a criterion for choosing or evaluating models.And we can see that by doing the same calculationin two different ways.Here's an example.Consider the AR1 process.So if we think of demeaning our variable,we could write this as xt is minus x--minus lambda xt minus 1 plus sigma 0 here.I've just written it as epsilon t.Now, I could also write, just by subtracting xt minus 1from both sides of the equation, Icould write an expression for delta xt,and I could forecast that.That is, instead of thinking about a forecast for x,I could forecast how much x changes from one periodto the next.Obviously, those are exactly the same thing.So let's take a look at whether we have a process describedby levels or by differences.So add one step ahead, the forecasts differ.So we just compute by taking expectations.So let's let f represent the forecast of our usual modeland our usual expectation of x of t plus 1 at time tgiven the information set time t is minus lambda xt--the previous value that we had, the last value that wasobserved.And for our delta, we get minus 1 times 1 plus lambda xt.But that's not surprising.They're different variables.We would expect the forecast quantities to differ.And I've denoted the delta 1 with a prime.So f prime for the differences, f is for the levels themselves.Now, what about the forecast errors?Well, the mean forecast errors in this caseare identical, which tells us that at this levelit doesn't matter which one we're using.The errors would be the same.And if I minimize the errors forecasting techniqueor parameter estimation, I'm goingto get the same result in either case.So in the first case I apply my definitionfor the forecast error.Observation minus forecast, once it's known,this would be the forecast error.But we're going to ask about it in expectation,before it's yet known.So we'd like to minimize our future errors.Once they're past errors, it's too lateto do anything about them.So here's what we do.We construct this object, x minus f.We take its square, and we compute its expectation,and we do the calculation.And we find its sigma squared.We do the same thing with f prime and its future value,delta in this case of xt plus 1 the valuethat we're trying to forecast, we find we get the same valueBut if two steps ahead, things are different.At two steps ahead we can do the calculation againin terms of both variables.In terms of xt the algebra is a little bit longer,but it's straightforward.It's the same rules that we apply.We have xt plus 2.By doubly recursing and doing a double substitutionto get an expression in terms of xt which is knownand two random variables for time t plus 1 and t plus 2,we compute the forecast two time steps ahead.We get lambda xt--lambda squared xt, and we computethe mean squared forecast error for the twostep ahead forecast.We find it's equal to lambda squared1 plus lambda squared-- sigma squaredtimes 1 plus lambda squared.And you should check and re-derive this yourself.Now, in terms of the difference variablewe get a different result. So if wedo the same thing for f prime at two steps aheadand we do the substitutions, we have this expressionfor our expectation and we computethe difference between the forecast and the outcome.And we take its square and we compute its expectation.That's our mean squared forecast errorfor the expectation of the squared forecast erroror a forecast system built using differences.And we do the algebra.And when the dust clears, we findthat for general lambda, except for one special value of lambdahappens to be equal to minus 1/2,this expression differs from the one we found here.That says that the forecast criterion is differentdepending on which way we describe things.But that's not all.If we don't know our parameters, and usuallywe don't know the exact parameters.Usually we need to estimate parameters from data.So if we're making forecasts using estimated parameterswe have an additional source of error.One of them is the underlying randomnessthat's part of the nature of our process.But the other source of error is the factthat our parameters might not be right.And we can see that by putting in lambda hat for our estimateof the parameter.And, of course, lambda hat is not the true lambda.The process evolves according to the true lambda,but our forecast is made using our best estimate of lambda,which is lambda hat.So the forecast error in this casehas a new term that depends on lambda minus lambda hat.It vanishes in the event that we have estimated the parametercorrectly.But otherwise, we have an extra term.We go through, we turn the crank, and you can check this.And what we find is that now there'sa new term in the two step ahead forecasterror, which depends on the difference between lambdaand lambda hat.So this extra term is an additional contributionto error when our parameters might deviate.And in terms of the difference variable,we get something else, which is even more complicated,which has even more terms.But one of the things we can check in both casesto make sure at least we haven't madea terrible mistake in our algebrais to check that it vanishes in the case where lambdais equal to lambda squared.So we see that the mean squared forecast errors differ.They depend on the value of the parameter.They depend on the value of the estimate that'sused in the forecast.And when we are comparing forecasts we should make surefirst that we do things that are invariant,that don't depend on the way we choseto label our variables to describeexactly the same thing.More importantly, we should think in financial terms.We should think about assigning error functions or costfunctions based on the scenarios of interest.So, again, we might not want to treat asymmetrically gainsand losses the same way.Sometimes we might if we want symmetric precision,but it really depends on the setting and it's somethingthat you should keep in mind.And it's a choice of the modeler.There isn't a single right way to do things.

#### TS10_S01_v1-en

PROFESSOR: Let's look at another setting for random walks--the binomial tree model that's used in option pricing.In the binomial model, in each discrete time stepa stock price, let's say an asset price,can move only up or down to a particular fixed value.This sounds crazy, far away from reality.Stock prices can move anything, up or down in very smallincrements.But in this model, we say there's only one thingit can do going up or down.In typically in the model, we allow the movementsto be by the same percentage increase,to have the same return in each time step,so it's a stationary series.So here's the structure of the model-- time goes to the right.And in each column, so I start from this point hereand I've labeled all these nodes and I go eitherto node 1 or node 2.And then from each of these other nodes,I have two choices as time evolves.Here, I can go to either 4 or 5.I can go up or down.If I'm from 5, I can go to 8 or 9.If I end up a terminal node 8, though, thereare a lot of ways I could have gotten there.I could have gone 0, 1, 4, 8.I could have gone 0, 2, 5, 8.I could go 0, 2, 4, 8.So if I want to know what the likelihood is to end upat a terminal node of a particular value,I can just add up all the possible waysto get there, multiply times the probability of seeingthat particular path realized.And that turns out to be essential for doing optionpricing and for managing risk.But in terms of the basic model, werecognize right away that's a random walk.After all, we're taking steps, discrete steps,in each time period.And we're looking at the aggregate behaviorof those steps.And we know that some of the large time propertiesare related to the statistical distributionof the sum of random steps.So we do this in two steps, no pun intended.We build the tree, we have a structurefor what the up and down moves represent.Usually, we have a fixed return associated with up and down.And that gives us a recombining tree,where you notice there are two different ways to get, say,to node 4.Going up and down is the same as going down and up.There are trees that don't necessarily recombine,but in this case we'll keep the recombining tree.And there are trees also that have multiple branches.There are trinomial trees and multinomial trees.But we'll do a look in the binomial tree.So first we have the tree structure.We assign to each branch a magnitudeby which the return changes, if we go up or if we go down,and a probability of that happening.Once we set up the tree structure,we're ready to do some analytics and to price derivativeson this tree, and also to take a look at in this structuresome very interesting possibilitiesfor exotic options and for different boundary conditions.So the random walk process is the basisof one approach to option pricing.And it's obviously an extreme simplification of the dynamics.But in the limit we actually end upgetting exactly the same result that wedo through continuous time approaches.So in each time step the underlyingcan either go up or down and we have uncertain payoffs.Usually in this model, we think of having two assets--one risky asset and a risk-free asset whose returndoesn't depend on where we are on the tree.But one of the things we also needto do to match this to reality istake our abstract random walk and put some parameters on it.We need to find out what the appropriate scales are.And so we need to set the scales.We need to decide on the returns.We need to decide on the probabilities.And that's going to tell us how this can map overinto the real world.So here's an example of how we set up the structure.We have a recursive behavior for a random walk where we say,at each time step the new price, one step ahead,is going to be the previous price, either times a numberI'll call u for an up move with probability p,or a down move with probability 1 minus p.That's one reason why I sometimes useS instead of p for probability.S we'll think of as stock price.So the structure has this tree structurehere where, as I build things up,I started this node with price S0.With probability p I can go up and realize the price S0u.If I go up again, the probability of going up and upis p squared is my cumulative probabilityto get to this point.If I do so, the asset price with probability p squaredis going to be S0u squared.Now I could end up if I have an up and down move,I have two different ways of doing that.Each of those ways has probability p times 1 minus p,and I get this value, and similarlyfor the downside of the tree.And I can go at an arbitrary number of steps.So what's the structure we expect?Well, it's a binomial tree.No surprise-- we find a binomial distribution.The probability of observing a particular stock priceis equal to the probability of our binomial distributionof the corresponding set of up and down moves.So in this case if I have t time stepsand I need there to be k up moves,I have t choose k ways of doing it.They have probability p to the k, 1 minus p to the t minus k.It's our old friend the binomial distribution.Let's look at a concrete example.Suppose u is equal to 2.This is rather extreme.Suppose in each time step the value of the stock doubles.Suppose if I go down the value of the stock is cut in half.Suppose the probability of an up move is 1/3,the probability of a down move is 1/3.Excuse me, probability of up is 2/3, probability of down moveis 1/3.And let's suppose we have a starting price of 16.So the tree looks like this.16 with probability 2/3 doubles at time 1 to value 32.And it can double again to value 64.The probability of getting there at the end of two times stepsis 4/9.The other terminal values at t equals 2 are 64, 16, and 4.And that's it, it can't be anything else.All right, so this is a very rigid modelof how stock prices could evolve and whattheir terminal values are.We can do some of the usual analytics.For example, we could ask about the distributionof stock prices at time t.And here we have it.So these are probability 4/9 to get a 64, probability 4/9to get a 16.Probability 1/9 to get a 4.And that's it.Now where it really gets interestingis when we apply this to option pricing.Now option pricing-- options are kind of a derivative.And a derivative is a security whose valuedepends on another security.So you may be familiar with stock options,and in particular call options that give you the right--but not the obligation--to buy security at a fixed price k for a call option,but you would only exercise that if the market price is above k.So if I tell you you have the right to buy a stock at $10,you would not exercise that if the stock were $3.You'd only exercise it if the price were more.And then you could realize an immediate profit.So if you have an option to buy a stock at a strike pricek equals $10, and at the time when the option isabout to expire if the stock price is $64, that meansyou could buy it for 10 sell it for 64,and have a profit of $54.So no arbitrage tells us that if youcould make that $54 by doing that transaction,then the value of the option should be $54.So put options work similarly.They give you the right but not the obligationto sell at a fixed price.You're not going to sell if you could get more money by sellingat the market price.So put options are valuable if the price goes down.Call options are valuable if the price goes up.But in both cases, their value dependsquite asymmetrically on the value of the underlying,on the value of the stock.So a common structure that we seein binomial trees as part of our approach to option pricingis that first we set up the binomial random walks thatcorrespond to the stock price movement.And then we look on the terminal nodesout here in this example at t equals 2,and assuming my option expires at t equals 2.I look at the terminal nodes and Isay, what are the values of the options on the terminal nodes.And they're determined by the value of the stockon the terminal nodes.So if the stock has value 64, 16, and 4,then the value of a call option C at that point in timecould be 54 in the upper position with probability 4/9.It could be 6 with probability 4/9,because there are two ways of reaching it.Or it could be 0, because we're notgoing to buy a stock for $10 if we could buy itby exercising our option--if we could just throw away the option, it's valueless,and we were to buy the stock on the market for $4.Put options work in a complementary way.And there's a property called put-call parity, whichyou can see here in action.Where when the risk-free rate is 0,the value of a call minus the value of a putis the value of the security minus the strike price.So here we have the put is worthlessup here, because the stock is worth more than $10.Here it's worthless stock is worth more than $10.And down here it's worth $6, because wecould sell for $10 something that we could buy for $4.The tree becomes useful for more general kinds of problems,and especially if we have different kindsof boundary conditions.So typically we're thinking for a vanillaoption that only expires at a particular point in time.We go out and we look at the terminal nodes in the tree.But we might have dividends that occurat some intermediate point.We might want to know at intermediate pointson interior nodes of the tree should we exercise the option.Is it advantageous to do so?There might be exotic options that if wehit a particular node, if we go down toofar before we're going up, the option might become valueless.Those are known as knock-out options.And there are knock-in options that start valueless.But if we hit a particular node, then they come to life.And that splits.It differentiates among the different paths.We don't just group them togetherand count the total number of combinatorics.We need to separate those that might pass for a particularnode from those that don't.So usual, it reduces to problems that we've alreadyseen in probability where we needto classify different kinds of trajectories,compute the probability of each, and then sum upthe ones that are of interest for the particular application.Now to be able to connect with our previous model, whatwe need to do is calibrate the tree.We need to be able to connect parameterson the tree with parameters of real-world stock prices.So if we think of our stock priceas having a random walk with a logarithmic returnvariable that takes binomial steps, in this notation,if we think of r as being definedas a logarithmic return, then in the binomial modelr would take two values, either the logarithm of uso that e to the r multiplies St minus 1 by u,or logarithm of D. So that's straightforward.If we want to know how to implement our modeland we have a given u and D, this is how we do itAnd we can also do it in terms of a typical Bernoulli-typevariable.If we let x be 1 or 0, we can construct a variable.Because it only has two states, it doesn't reallymatter how we do it.We can rewrite things for linear transformationsas long as there are two different states.Here, if I have a 1 and a 0, I can multiply somethingand add something else.And I can relate it to the log u and log D formulation.So we can use different kinds of formulation.The basic point is, it's a two-state model at each node.So to connect this to real world asset valuesand their returns and their volatilities,we calibrate the model by taking expectations.So we would calibrate mu to be the expectationof r from the formulas that we had before.And we compute sigma squared as the varianceby applying the definition and usingour usual results for things thatare constructed out of basic z.So we put in the distribution of our binomial variables.We have some extra parameters.We compute.And then what we're going to do is we have expressions nowfor mu and sigma squared, which are things that we can estimateand think about in terms of real-world assetprices, their mean and their variance,and we can connect them to model parametersin the random walk, things that are the step size a and b,the coefficients of the step formulationin the Bernoulli form I just showed you and pthe probability.So we can solve for a, p, and b in termsof the up and down factors, for example.And we can do that this over here to have a and bin terms of those with mu and sigma.And then we can express log u and log Dalso in terms of mu and sigma so that if wehave particular real world values of mu and sigma, thatcan tell us what u and D we can use on the model thatwill give us something that will bea discrete representation of the real-world drift and volatilitythat we want.Notice that the specification actually matchesdifferent numbers and parameters, that in this casewe have two real world parameters, mu and sigma,in terms of three model parameters, three unknowns.

#### TS10_S02_v2-en

PROFESSOR: There's a problem in the classical probabilityliterature known as Gambler's Ruin that'sa discrete time stochastic process that'ssolved in a different way.And it would be interesting for us to take a look at it.So here's the idea.The idea is, suppose that you and I are gambling.And we begin with the total amount of wealth,total amount of assets.Let's call it a.And in this example on the right hand side,imagine that there's $10 that we have between us.And we start with you have $5 and I have $5.And the idea is, we play a sequence of games.At each step, if you win, you get $1-- if I win,I get $1, the total amount of wealth is conserved.And we play until one of us is ruined--that is, until either your capital goes to 0 or mine does.So from your perspective, either you get all the wealth,or your wealth goes to 0, at which point it stops.Now, I've shown on the right a picturethat illustrates some possible ways this game might come outwith these starting conditions.And each color represents a different path.You'll notice that of the five paths that are shown here,three of them finish with the player winning--that is, capturing all $10 that are available.One of them finishes with ruin--that is at $0.And then, it stays there.Once you're ruined, you're not allowed to make any more bets.And in the green path, one of themhas not yet hit either end.It hasn't yet hit 0 or $10.And we might even wonder if it could justkeep going indefinitely.So in this kind of game, we have a repeated set of gambles.And to keep it general, we're goingto allow the probability of success or failure--our Bernoulli trials-- be asymmetric.So let's let p represent the probability of success.q is 1 minus p is the probability of failure.You start with some initial capital, x greater than 0.And we have these two classic stopping points,which are either when you're capital x is equal to 0,or x is equal to a.Now, there are two kinds of things that this typifies--two classes of problems, known as stoppingproblems and boundary problems.The boundary case is pretty obvious.We have these two cases where our wealth either hits 0or it hits a, at which point we stop.So we can ask, unlike us unlike our previous case wherewe looked at time series and just said,you give initial conditions.What happens in the future?Here, we have boundary conditionsthat specify something specific that occursif and when we hit them.And of course, there are obvious financial applications.These are things that represent bankruptcy, that'sthe classic definition of ruin.But they might be other events.For example, hitting a capital reserve requirement,hitting a credit default trigger, hitting your stop losslimit.And we could think of things on the upper limit as well.We might have a strategy where we terminate an investmentonce we reach a desired goal.The stopping problems are a little bit different.Those are cases where we want to know,does a given process stop?Does it ever reach the condition?And if it does reach the condition, whatwould be an expected time or whatwould be the distribution of stopping times?We might also think about this strategically.We could have a question where weask, what would be the optimal way to say, run a business,if we wanted to minimize its default probabilityor its bankruptcy probability.So let's look at the math and see how we can do this.What we'll see is, we have a recursion relation.But this recursion is not in time.This recursion is in money.So here's what we do.Let's let q sub x denote the probability of ruin--that is, the probability that we'll eventually hit 0before x equals a, starting from an initial capital level x.Now, the interesting thing here isit does have a Markov structure, because it doesn't matterwhat's happened in the past.All the matters for our probability of survivingis how much capital we have at the present time.Probability is obviously conserved.So the probability of ruin now wecan relate to what happens after our next game.After the next game, we could winwith probability p, in which caseour capital would be x plus 1.And that would give us p times qx plus 1.Or we could lose and end up with capitalx minus 1, in which case, this wouldbe our probability of ruin.And adding together these two mutuallyexclusive possibilities gives us our original probability.Now, you can see that this is a recursion relationship in x.This kind of difference equation wherewe have a relation between x minus 1, x, and x plus 1is similar to differential equationsthat are second order.This is a second order difference equation.Like the differential equation case,there are two independent solutions.And we fix the boundary conditionsby imposing-- we fix the final solution by imposing boundaryconditions on the general linear combination of the twosolutions.So there's a special case when the probabilities are equal.Let's do the general case.In the general case, where p is not equal to q,you can check by substitution that theseare two different solutions.One of them is the trivial solution,that q sub x equals 1.And that's not an interesting solution to our problem,saying the probability of ruin is equal to 1,because we start out not being ruined.But mathematically, leaving aside the boundary conditions,it does solve this equation, because p plus q is equal to 1.The other one is this form here, q over p to the x.And remember, q is equal to 1 minus p.And if you substitute this into the equation,you can check that it works.Now therefore, the most general solutionis a linear combination of these two special solutions.So we have two constants.Let's call them a and b.So our general solution is of the formconstant plus another constant, times q over p to the x power.And we fix a and b by imposing boundary conditions--two obvious boundary conditions.When x equals 0, we are ruined.If we have no money, the probability of ruinis 1, because we're already ruined.And similarly, if we have all the money,if our capital is equal to a, our probability of ruinis 0, because the game is already ended.So if we impose these, we can solve for a and b,and we get this result for the probability of ruin--this expression in the box down here.This tells us, as a function of a, x, and pwhat our probability of ruin is starting from any givenlevel of capital x.Now, we can ask a variety of questionsabout what happens under these absorbing boundary conditions.For example, we could ask, can the sequencecontinue without terminating?That is, does the probability of reaching neither x equals aor x equals 0 in an arbitrary amount of time,is that some positive number?Is it equal to 0, which would meanthat we do hit one of the other two boundaries.We could ask with the expected time is to hit.If we allowed ourselves to stop differently,what kind of strategy might we employ, and could wedo something better?How do we take advantage of unequal odds?For the case where the odds are equal,we can do it in one of two ways.We can either check that 1 and x over aare special solutions to the equation.Or we can take the limit, where q approaches p,using L'Hopital's rule and just taking our general solution.What do we see about actual numerical valuesto get some intuition about what's going on?Well, one interesting fact about this,is that if we start very close to taking all the money,we have a good chance of winning.Which isn't surprising.For example, suppose that there's $100 between us,and we start with $99, and we're playing the house.And suppose the odds are equal, thenyou can check by the previous formula,we have a 99% chance of winning one more dollarbefore we lose all 99% that we have.Not surprising.We're close to owning all of the money.But what's less obvious, is that if the odds are against us,we still have a very good chance of winning all the moneybefore we lose what we have.That is, even when the odds are stacked against us,if we have sufficient capital reserves, the oddsof attaining a finite goal--and in this case, a relatively modest goal--can look very attractive even when the odds are against us.So the odds are against us, we typicallythink it's a game that we shouldn't play.The expected value's negative, stay away.We want to look for opportunitieswhere we have positive expected value in a gamble.And furthermore, where we give adequate compensation for risk.If the expected return is negative,normally we would say, let's leave it alone,provided there are some other better opportunities available.But all that changes when we limit our objective,and we say, suppose I only want a fixed amount of money,and I'm not going to play the game indefinitely.In fact, we can go a bit further.Not only does this sometimes give usa positive chance for achieving a goal before we get ruined,but it says, that when the odds are against us, sometimeswe should take even more risk.What if we change the stakes?Suppose we increase the bet size from 1 to b,and let's suppose that b evenly divides a and x,just for simplicity.So if we change our bet size, then we update our recursion.The problem has the same structure,it's just the individual steps are chunkier.When we substitute in--we play the same game as before.We solve for our formula, we get a new result. And what we findis, that when the stakes are increased, that if the odds areagainst us, we have a lower ruin probability-- thatis, a greater chance of winning all the moneyand hitting the upper boundary, than we did before.So if the odds are against you itcan be advantageous to swing for the fences, so to speak.That is, you can think of this intuitivelyas being kind of a complement to the law of large numbers.In a game where we play indefinitely,we know that our expected return is going to be negative.We of course need to worry about the fluctuations.But this says, that if there's a definite stopping point,the fluctuations can be to our advantageif we stop when we get a fluctuation that'ssufficient for us to hit our upper boundary.That is, the longer we play, the more likelywe are to grind down and end up ruined.But if we take larger bets, we'remore likely to have an instance wherewe hit our upper boundary.So lower ruin probability means greater overall chanceof success.What if our appetite for risk is unbounded.That is, suppose that a is infinite,and we want to keep playing, and justsee how much money we could get.Well, it's pretty clear that if the odds are unfavorable,that we're never going to get all the money.We've set ourselves an impossible task.And in fact, our probability of ruin goes to 1.In the case where the odds are in our favor,we can compute what the ruin probability isand get something potentially that's less than 1.How long does the game last?Well, we could ask about its expected durationin the same way.But now, things are slightly different,because now we have a generalizationof our previous equation.But now we have an inhomogeneous equation.So let d be the duration of the game.Then d of x plus 1 is the duration of the game,starting from x plus $1.And d x minus 1 is the duration of the game startingfrom x minus $1.And we need to find out d of x is,that is, what's the expected return as a function of x.So in our recursion, before we equated this to what'son the left hand side.But now, we know that these are relatedto one more play of the game, so we add 1on the right hand side.So instead of the previous homogeneous equationwhere every term involved the d, here we have this plus 1,where you can check that this givesa solution to the equation.Here it's a slightly more complicated formula for pnot equal to q, for p equals q.This simplifies it to a nice quadratic form.a x minus x squared for p equals q.So that tells us, that for example,in a fair game, if you and I each start with $100--$200 total, the expected duration of the gameis 10,000--100 times 100.And it grows as the square when the stakes are equal.So let's summarize.Gambler's Ruin is a problem whichhas a recursive structure.It's a discrete time process in money rather than in time.And it's subject to boundary conditions.The boundary conditions tell us when the process terminates.It's got applications to gambling, obviously,to insurance where the ruin problem in the insuranceliterature is finding the probability that you haveadequate capital to never get ruinedby random processes which representthe arrival of insurable claims or losses.It has applications to thinking about bankruptcy likelihood,credit default, and to bet sizing in investment strategiesor in gambling strategies.The stopping problems that we considerare things that could be defined by economic conditions,such as a company in distress, beatinga particular term in a covenant, or a bank loan being calledsubject to certain terms.We can think about optimal stopping problems, wherewe might have different kinds of objective functionsrather than maximizing expected return,rather than thinking of maximizing Sharpe ratio,we might think of a business venturewhere what we'd like to do as business owners, and investors,and entrepreneurs is, sure, we mightlike to maximize our profit.But maybe what we'd really like to dowould be to maximize the lifetime of our businessor minimize the probability that we go bankrupt.And those will not be exactly the same calculation.

### 03-Recitation_3

#### Rec03_S01_v1-en

PROFESSOR: Let's talk about forecasting.We saw in lecture that forecastingis an application of conditional probability to time seriesmodels.So we think of the time series as generating the data.And we ask at a given point in time,given all the observations that exist upthrough that point in time, what can we say about the future?We might want to know what happens one time step ahead,two time steps ahead, or in limitas the number of times that goes to infinity,but the key thing is the break between past and future.So we take the present time to be just after we'vemade our final observation.And we're first forecast period is one step ahead.And, as I said, the key tool is in addition toour previous ones with expectations,linearity, algebraic substitution, recursion.We had a new one, which is conditional probability.In this setting, conditional probability simplymeans that for any variable that wasa random variable in the past that has been realized,it's no longer a random variable.Now it's a scalar.Now it's a number.So those things that show up in the recursionthat we previously thought of as random variables,in this setting, when we take conditional expectationsof our defining equations or equations of evolution,then they take a different character,because they're already known.They're no longer random variables.So we looked at an example in lecture.Let's just do a couple of examples together.It's the same structure.They're just one or two things it might be worthpaying attention to as you look at the blind forecastof your own.Some of the things that might have look special for the caseof the AR 1 are quite general.So let's take a look at a model.Let's look at, say, an AR MA 1, model, AR MA 1,1, which is this form.Let's say that Xt is equal to a constant C0 plus C1 Xthe previous 1 plus a bunch of Z's.So I'm going to keep the notation sigmaZt for our shock for innovation in the period.You could give it another name for its coefficient.Remember that sigma, in this case,is not the standard deviation of x.It's just a scaling parameter for the random shock z.And then we'll call this phi 1 Zt minus 1.So the first thing we'd like to dois compute the mean value for x and simplify our expression.So we use our usual trick.Mu is the name will give the expectation of Xt.And then we take expectations on the right hand sideand apply linearity.So we have this is going to be C0 plus C1 expectation of Xt minus 1, but we know that that is justthe same thing as C1 times mu.And then we're going to have plus 0 plus 0,because the Z's have 0 expectation.So we have the result that mu is going to be equalto C0 over 1 minus C1.And you should recognize that expression from our AR 1 model.It's exactly the same expression.And therefore, we can substitute and rewrite our equationas a bunch of things that are grouped together in such a waythat they all have 0 mean.That is to say, if I substitute for C0and say it's equal to mu times 1 minus C1,then I can write this as Xt--let's keep our colors consistent here--Xt minus mu--I can put this on either side of the equation,depending on what I'd like to do--but just for looking at the structure of the model,I'll right this is Xt minus 1 minus muplus sigma Zt plus phi 1 Z of t minus 1.Now the next thing we want to do is put thingsin forecasting form.So what I'm going to do is I'm going to shift t to t plus 1.Everywhere where I see a t, I'm going to write t plus 1.And that puts the future values on the leftand the present and past values or the knownvalues on the right hand side.So for one-time step ahead, this makes exactly the splitthat we want to have.So what I'll do is-- let me just write this as Xt plus 1.Here I can put the mu on the right hand side if I like.And this is going to be C1 of Xt minus 2 plus sigma Zt plus 1plus phi 1 and Z.So notice that in our original description,in our terms of our original coefficientC1 was a reminder that it matched the lag 1x variable.And phi 1 was a reminder that it matched lag 1 Z variable.If we had C2, C3, and phi 2, phi 3, phi 4,those would have matched the corresponding lags of the Z's,but what really matters are the relative amounts.So when I add 1 to everything, there's no surpriseor there shouldn't be the C1 now getsmultiplied by Xt without a lag and similarly with phi 1.So that's here.So what's our forecast?So our definition for our forecastis going to be the conditional probability.So our first forecast is going to be f of t comma 1.That is the forecast made at time t for one-time stepahead in the future.And there are different notations for this.So what you really should rely on is not the notation,but reduce everything to expectations.So this is the expectation of t plus 1 given everythingup through that point, which includes Xt, Zt,and any previous failures, but thosedon't show up in this equation on the right-hand side.So let's compute the expectation.And what we noticed is that the only random variableon the right hand side is this one.That's the only thing that's random.So this value here is known.This value here is known.There's only one random variable.And we take expectations, the expectation of t plus 1is going to vanish.So what do we get?We're going to get that the forecast is equal to--we'll leave this here--is going to be mu plus C1 times Xt minus mu plus phi 1.So we just do the calculation.It's exactly the same as the expressionabove, except for this term, this random termthat dropped out, because it has zero expectation.So let's take a look at the forecast error.So the first forecast error for one-time stepahead is going to be, e is going to be f,or actually it's going to be the outcome, excuse me,but we're going to square it.So it won't matter.The error is going to be X t plus 1 minus f t comma 1.That is the forecast error as definedas the difference between what we predictedand what actually happened.What we'd like to do and the way in whichwe have this definition for the forecast being optimalis we're going to minimize the mean squared forecast error.That is going to minimize the square of ein expectation of all possible things that would happen.Now we could use other kinds of loss functions.Those will depend on the settings,depending on the economic values.So it's just a question of doing and minimization,but in this case, we have this basic resultthat this will be our expectation,but let's compute the forecast error.So the idea is that what we really want, in general, if youwant to drive this and check, what we really wantis we want a predictor for f, that some function of allthe previous observations, in this case, just Xt and Zt,we'd like to be a linear function.And when we find the linear function thatminimizes the mean squared error,we find that it's this conditional expectation.So let's compute this quantity.And we'll see that there's a really nice structure thatshows up.Xt plus 1 minus the forecast, younotice that most of the terms are common.So Xt plus 1 involves this term and this term.Xt plus 1 involves-- this is the only term thatdoesn't appear in ft 1.So when I take this quantity and I subtract this quantity givendown here, I've got a very simple result.This is just equal to sigma z plus 1.And therefore, the mean squared forecast erroris Et plus 1 squared is equal to the expectation of sigmaZt plus 1 quantity squared.And that's just equal to sigma squared.Now what about looking at multiple forecasts?So we'd like to go for future horizons.One-step was easy.So the general rule is that when wewant to do it two-step ahead forecast,we're going to shift everything.We're going to add one more.So we write an expression for X of tplus 2, but now on the right hand side,I've got 2 plus 1, which isn't known yet.So here's the general procedure.Keep doing the recursion.Keep substituting in back until all of the X's on the righthand side of the equation have a time index of t or earlier.The Z's can be later.That's OK, because we're going to take their expectations,and they're going to vanish.So we might have some possibly unknown Z's.But the basic idea is once we go beyond one-time step,how do you know what to do?It's easy.You're doing Xt plus h for horizon hon the left hand side.And on the right hand side, you do probably h or hminus 1 recursive substitutions of the defining equationuntil we can express Xt plus h in terms of X, Xtminus 1, and so on.Those are all known quantities.Then we take conditional expectations.We have our forecast.We compute the forecast errors.We take expectations of their squares.That's easy as well, because it's just the same quantities.Now we have the known and the unknown onesclearly delineated.And we get our results for our mean squared forecast error.And there are two really important propertiesto keep in mind for our solution.One of them is the forecast error has zero expectation.And the forecast error is orthogonalto the other variables, to the other random variables--excuse me, to the other predictor variables.So let's take a look for another exampleLet's take a look at an AR MA 2, 2 model, shall we?So now when you're given numbers for the forecastsor particular horizons, you can either plug them in right awayor you can leave the parameters general.That generally makes it easier to check your mathand find any sign errors that might be there,but either way, whether you substitute indefinite numbersfor the parameters before or after shouldn'tmake any difference.When you're doing forecast, you do want to pay attention thoughto the initial conditions if you have to bootstrap your process,because if you're asked for a forecast one or threeor seven steps ahead, you'll need enough data to getthe process started before you can generate the recursion.The recursive techniques that we havethat I'm writing down here for the forecastare technically appropriate for the case, where we goinfinitely far into the past.Even if the series did exist an infinitely long time,we wouldn't have an infinite amount of data.So we do need to make sure we have the initial conditions setto get numerical answers, but the basic rules are computeconditional expectations after writing our definingequations with variable to be forecast on the left hand sideand only known observations on the right hand side.So let's do this for AR MA 2, 2.So it just has--it's little bit more complicated at least initially.So it looks like C0 plus C1 Xt minus 1 plus C2 Xt minus 2plus our old friend sigma Zt.And now let's add some phi terms plus phi 1, Z of t minus 1plus phi 2, Z of t minus 2.And you can see how it would go for a general ARMA PQ.I'm going to write it in concrete formso we don't have summations running around.And when we shift, it gets a little messykeeping track of the indices, but you can do it.And you can take a look at the literature as well for that.So what's our expectation in this case?So mu is the expectation of Xt.And now that's going to be C0 plus C1 mu plus C2 mu.And that tells us that mu is actuallyequal to C0 divided by 1 minus 1 minus 2.And you can guess how this generalizesfor the general ARMA PQ model, weget the generalization of this expression.And then we can write our equationas Xt is equal to C1 of Xt minus 1 minus muplus C2 Xt minus 2 minus mu.And we start to recognize some patterns.And we get the hang of it, plus phi 1 Ct minus 1plus phi 2 Ct minus 2.And let's not forget our sigma, Zt, which we can put over here,let's do some forecasting, shall we?Oh, excuse me, this should also have on the left hand side,this should be Xt minus mu.You should notice that each of the terms that I'vewritten down is a way that it has 0 mean.That just makes it a bit easier to see what's going on,to see what the dynamics are, and to do some calculations.You can also, if you want to clean it up,you can find a new variable y to be Xt minus mu and shift thingsback.So you can do any rescaling things you like.The end results are going to be the same if they're justredefinitions of the parameters and rescalingsof the variables.So let's take a look for time T plus 1.So for time T plus 1 minus mu, we'regoing to C1 of Xt minus mu plus C2 of Xt minus 1 minus muplus sigma Zt plus 1 plus phi 1 Zt plus phi 2 Zt minus 1.So that one is pretty easy.It looks like the expression that we justdid before for the AR MA 1, 1.That is everything on the right hand side has an index of--all of the X's are taken at time T or T minus 1.And the Z's are mostly in the past.We have these two with coefficientsof phi's both in the past.And this is the only one that's still a random variable,but at time 2, things change.So let's look one more time step ahead.Let's contrast a little bit.So if we write this as Xt plus 2 minus mu,we see that we have C1 Xt plus 1 minus mu.And that is going to be somethingwe're going to need to replace.And then plus the other terms are notgoing to give us any major problems.And this is going to be Ct times Xt minus mu plus sigmaplus T plus 2 plus phi 1 Zt plus 1 plus phi 2 Zt.So all I've done is I shifted T to T plus 1 again.And the terms that are in orange are the things that--well, let me put the other one in orange-- so a littlemore consistent.So let's put in orange things that pertain to the future.So I have two of the terms on the right hand sideinvolve the present or the past.And that's OK.Those are known quantities, but I have these other expressions.So I can't just directly compute the expectationon the left hand side.Now I could take the previous work I did beforeand substitute that would be fine.But if I want to see the general approach for doing itat a particular time step, what I'm going to sayis that the expressions here and here, I can leave alone,because those are both fine.These just involves Z's.And I know their expectations, but Idon't want the recursive structure for Xtplus 1, because remember this is saying that the value twodays from now depends on the value tomorrow, whichI haven't yet observed.So the value today, the value yesterday, those are all known,but rather than expressing it this way,I'd like to do my recursions, get it out.And then I can take clean ordinary simple expectationsand get an answer.So let's do that.And we just need to substitute one more time and put that in.So which term are we going to substitute--we're going to substitute in?We'll have Xt plus 2 minus mu is goingto be C1 times this entire expression above.So let's just write that out.This is going to times C1 Xt minus mu plus C2.Xt minus 1 minus mu and so on.Sigma Zt plus 1 plus phi 1 Zt plus phi 2 Zt minus 1.And then plus the other terms, plus C2 Xt minus 2plus sigma Zt plus 2 plus phi 1 Zt plus 1 plus phi 2 Zt.So what have we got?We finally have an expression, where--and actually, let's do one more thing.Let's just kick mu to the other side of the equation.So I now have an expression for X of tplus 2, where on the right hand side,everything depends on known quantities.So we put it in.We turn the crank.We compute the expectation two-time steps ahead.That will give us our forecast today for two-time steps ahead.When tomorrow is realized, that forecastfor what will then be one more day ahead is going to change.And how will it change?It will be updated by the new observation.So if today is Monday and I'd liketo know about Wednesday's weather,I would make a forecast today.Tomorrow I'll have a new forecast for Wednesday.And that will change.It will change by my knowledge of what happened on Tuesday.But from a mathematical point of view,we separated things into the form that we want.We can first take the expectationwith the appropriate conditions.And second, we can compute forecast error in advance.And we can compute the mean squared forecasttwo steps ahead.And so that's looking ahead for whatour expected forecast error.The reason that that's important isthat we want to think not only about distributions.What's the exact value?Because that exact value probably won't be realized.It gives us characteristics of the full distributionof the actual outcome.And it lets us have a sense as to how weshould evaluate our forecasts.So that's an expectation.Once Wednesday is realized, then we'd like to go back.And then our Xt plus 2 will be a known quantity.We can compare it with our forecast.And, of course, this will differ by some amount,but if we'd like to improve our forecasting techniques,our forecasting methodology, and our forecasting quality,what we do is we look over time.We take a large collection of forecasts and outcomes.And we study the statistics of the forecast errors.So we use forecast errors both in expectation going forwardand to assess forecast quality and lookfor improvements going backward once we'vecollected the relevant data.

#### Rec03_S02_v1-en

PROFESSOR: Estimating the parameters of modelis pretty easy and relatively straightforwardwhen we're given this data set.Finding the right model or choosing among a set of modelscan be much harder.And there might not even be a right answer.So let's take a look at a few examples.We're going to start with the Monte Carlo example.And the reason is that it helps to know that your data actuallycomes from a model.So we'll start from a case that has a known answer.That way, we'll have some confidence when we startlooking at other data sets.It's tough.And there may not always be a clear decisionthat you can make.And it requires judgment-- not only in selecting the model,but in understanding what the practical consequences areof having the wrong model.Is it just a good approximation?Or is it missing some essential componentsof the dynamics of the system and data generatingprocess that you want to study?There's no easy way to know.And you need to constantly be on guardfor things that might go wrong, and keepgoing back and refining your techniques.So let's start with an AR(2) example.Now remember that autoregressive modelshave the property that they do havecorrelations-- autocorrelations-- across time.And typically those autocorrelation functionsdrop off over time, but they exist at all lags.This is in contrast with MA modelsthat are also defined recursively.But they're defined recursively in terms of the innovationsthat are localized in time.So at a sufficient separation in any given MA(q) model,the autocorrelation will go to zero.So that already helps us differentiate between the two.So let's look at our example.I'll generate some data here.You can download the notebook-- in fact,pause the video and do this now if you'd like--so you can follow along and tweak the parametersand try your own examples.Obviously the random numbers you generate will be different.But if you'd like to see the same random numbers, actually,why don't we set this up so that wecan look at the same random numbers together.I'm going to add a command in our notebookwhich will make sure that we get the same random numbersby setting the seed 2021.Now, your computers may come up with a different setof random numbers.What this guarantees is, within a given setting,you will get on each one the same random numbers.So obviously in actual applications,this is the last thing you want to do.Because you want the random numbers to be random.Not just a single draw of random numbers to be reused.But for debugging purposes you might find it helpful.So you can put this in, comment it out or delete it afterwards.So here are the parameters of the model.We've got c_0 is 0.001.So it's a small intercept.It's close to zero.C_1, the first autoregressive parameterthat is the coefficient of the lag 1 observation,is going to be minus 0.1.And c_2 is going to be larger and opposite sign.0.4.So let's take 1,000 times steps.We'll organize them in a column vectorand set this up so that it generalizesfor the case where you want to do an ensemble of pathstogether.But we'll run this forward.Now, one thing we need to be careful of whenwe start with time series models that are simulated--they obviously can't go infinitely far in the past.So we usually bootstrap them by setting the initial values offinto zero.And we do need to make sure that our results don'tdepend on that.Those need to be a good approximationfor larger values.So that's why I've initialized my variable rto be full of zeros, and I've startedmy recursion at time step 3.Because it needs to go back to previous time steps.So if we run this-- so we can seethat I've defined a set of space placeholder for my variables.And I could set that to be plus 1 if I were doing market data.So I have a time 0, but here it's all simulated.It doesn't matter.I pick a bunch of random numbers.Which, in this case, I'm choosingfrom a N (0,1) distribution.These are normally distributed.And then I have a for loop where this isthe basic line of my recursion.So notice I do need to iterate it forward.I can't do this with some clever algebraic tricksbecause I need to know what the values are at time tto know what they are for the next time step at t equals 1.So let's run this chunk of code, plot the resultsand see what we get.So the first graph that we have is goingto be the AR(2) sample path.So it wanders.It looks random.Can you tell that it's autoregressive from lookingat it?I can't.Let's look at the autocorrelation function.Well, here we see we're getting out whatwe expected when we put it in.That is, the first coefficient is nothing to do with c_0.That's normalized to equal to 1.That's the correlation of the series with itself.At lag 1 we have a negative number.And at lag 2 we have a positive number.And all the others look like they'reat the limits of statistical significance.So that's about what we would have expected.Here's the partial ACF.Now remember what the partial ACF does.What it does is, it fits-- for each lag--it fits an autoregressive model of that number of terms.And the partial autocorrelation coefficientis the coefficient of the highest lag term.So what we would expect is that we'regoing to get non-zero results for each coefficientup to the order of our model.In an AR(p) model for the first p terms, in an AR(2) modelfor the first two terms.And everything above that should be close to zero.And that's exactly what we see here.So this would give us confidence that what we're looking atis an AR(2) model if we didn't know what the data was.Now let's go and remove this seed parameter and rerun it.Let's do a new set of random numbers.So I will run this chunk again.And let's take a look.This is a different process.We'll move over here, click on the second box.Here are its autocorrelation coefficients.You notice that the third and fourth are still showing up.But we do see the expected alternating signs and decay.And when we look at the partial ACF,we, again, see the lag 1 and 2 coefficients looking large,and all the others being small.And, of course, this plot out 30.And for 30 things to within 5% significance,we might expect a couple to be up.So these are things to do iteratively.If you see something suspicious, go dig in and investigatea little bit further.How do we estimate?So suppose we've decided, great, that data set isgenerated from an AR(2) model.It's looking good.Let's find the parameters of the AR(2) model.So once we settle on a model, really what we're doingis applying standard estimation techniques.There's nothing very special.In R there are some functions that help streamline it.But the basic idea is that we can do linear regressiontechniques.The only difference is that the variableson the right-hand side that normally wouldbe independent variables are justlag versions of the variables on the left-hand side.So we can use ordinary least squares, maximum likelihoodestimation, usual ways.And we can do that if we take the seriesand create lagged versions of it.Or R happens to provide-- and other languages do, too--packages that have some of these functions already built in.So let's take a look.In this case, let's define.Let's first write it--we'll do it in two methods.First we'll write it as an ordinary least squares.And then we'll do it using an special caseof the built-in ARIMA function, wherewe'll look at the AR(2) as a special case of that.So the first thing is, I can define my variables.y is an independent variable in x1 and x2.Excuse me, y is a dependent variable.x1 and x2 is independent variables.But, of course, there are all from the timeseries of r, which we generated synthetically.Notice the time offset.Because we're looking at the correlation series with itselfas the lags move, I'm going to end upwith some non-matching points-- either at the beginningor at the end.And I need to trim those off so that I havedata series of equal length.If the number of points you trim is significant,then your data series is too short.Or you're looking at--this is not a good model for what you want to be doing,if it's too sensitive.So the two ways we can look at itare we can run in R the lm function.Builds a linear model.It just runs linear regression.And you can do this in any language.You can do it in Excel.Alternatively, we can run the ARIMA function in Rand fit this to a series where the order isgiven by the first parameter is the autoregressive part.The second is an integration level.And the third one is moving average part.So let's take a look and see what we get.So if we fit this by ordinarily least squares,we get the usual results in r.So we have an intercept.We have an x1 and an x2.We see that the intercept is close to zero.It's 0.034 with the standard error of 0.032.So that's close to zero.We didn't exactly pick out our carefully set c_0.But the x1 and x2 values are within the standard errors.So for that given the data series.That is, we have minus 0.07.And there's an approximation to minus 0.1.And we have, for the second coefficient,we've got plus 0.41, 0.42, no, 0.41.It's an approximation 0.4.So we got out what we expected going in.And we can take a look at the significanceof the different values.Now, if we run this second method, this ARIMA function,we also get the coefficients here.It's laid out a little bit differently,but these are the same numbers.And it's just to show you that this is dressed up.It's really just doing an ordinary regression.So that's where we have the order correct.And we fit the parameters.So we decide what the model is.In this case, we generated the data, then we set that aside.We ran the data, we identified the order.We said that looks like it's order 2.We ran a fit to AR(2) model.We have estimates for the coefficients.They're noisy estimates because we have some noisy data,but then we can proceed with that estimated modelwith that set of parameters.Now, what if we got the order incorrect?That is, what if we thought--suppose there had been a spike, just a random jump, at order 5.And we said, ah, we've got an AR(5) model.Well, let's try running that.And in that case we find a set of coefficients here.And we can, again, take a look at what the estimates are.And we see that the standard errors show usthat the errors are much larger than the coefficientsthemselves for the higher order terms.For AR(4) and AR(5).And even the third term is not statistically significant.So if we go too far, we can pull backand refit the model and retune for what we're doing.Try it yourself on some other data.See how well the quality of the estimatesdepends on the length of the series.That we can then turn around and thinkabout how much data is required to get a goodhandle on the models.Let's take a look at this for an MA(2) model.So here is a model, which is MA(2).So it's got two lagged parameters.But those lag parameters this time arethe z's on the right-hand side, not the r's.Not our random variable that we'reobserving, but the innovations.The shocks that occur in each time period.So I need to bootstrap this a little bit.Because at the beginning, again, we'renot going infinitely far back in the past.So we're going to do this with our first two innovations.And then from time 3 forward to the end of the serieswe'll run this recursively.So our recursive definition is terrific for programmability.And let's run this model with a set of parameters.So if we take a look at what we get.Here's an MA(2) sample path.Does it look different from an AR(2) sample path?I can't say so.It looks like a noisy bunch of data to me.We did pick a very large value for sigmain relative terms for financial applications.But that's OK.Finance things are noisy.And you can try scaling these to different sizesto see how they look.How about our ACF and PACF functions?Well, here remember for the MA(2),we expect the ACF function to tell us when to stop.That is, the autocorrelation functions are only goingto exist through the value q.And we see that here.We see that we've got autocorrelation functionsand autocovariances, non-varnishing, for lags 1and 2.And then everything drops off.So that as we would expect.If we look at the PACF, the partial autocorrelationfunction, that's not much help here.So if this isn't showing us much,the reason is not that we've applied it incorrectly.It's because it's not the right toolfor doing this identification.So when we pick our tools, you can throw everythingat every dime series you have and you mightsee some interesting stuff.But think about the question you want to answerand specifically what it is we're looking for.Suppose we now want to estimate the parameters.Let's do that this time.We can run in R. You can repeat the ordinary least squares.Or we'll do it this way, using this notation.So (0,0,2) means it's only a moving average model.And as we run this, we get our coefficients.And we see our intercept is consistent with zero.And our MA(1) and MA(2) are lag 1 and lag 2.Coefficients for the phi's in the right-hand sideare given by the results here.And again, try it out for longer datasets, for shorter data sets.And then for some real-world data.Speaking of real-world data.It's much harder.First of all, it typically doesn'tfit any particular model.So if we're going to pick a modelwe'd like to estimate something thatcaptures the important features of the data.And we don't even know what those necessarily are.So let's take a look at a data set.In this case, we'll grab some datafrom Yahoo Finance using the tidyquant package.And we'll get it for Tootsie Roll stock.So if you haven't used tidyquant before,you can uncomment this line and install it.We load it with the library command.And we'll define a ticker, a start, and an end date.And then this tq_get function grabs data from Yahoo Finance.Or you can just load it from a flat file yourself.So what does the data look like over time?Let's take a look at a chart.So that looks pretty noisy, too.This is more data points than we had before.There's an upward drift, which is definitely significant.Notice I set the drift term close to zeroin both of our previous two examples.But here's the data.Now let's take a look at the time series of returnsby taking the difference of the logarithmsof the successive prices.And here's the return series.Now, when we get data for a stock or an asset,usually what we do-- in fact, what I almost always do--is I'll take the price data.I will turn it into returns like this.I'll use adjusted prices so I account for corporate actionsand splits and dividends and so on.I'll take the adjusted series.And what I want to know is, what are the basic descriptivestatistics for it?Which we can do on any data set.What is the mean?What is the standard deviation?Or, in financial terms, if we annualize numbers,what's the return and what's the risk?What are the parameters?Now, one of the things-- so we can do thatanyways for anything.Those are just descriptive statistics for a set of data.They don't have anything to do with models.But if, in addition, we think about the generalized randomwalk model and we wanted to fit the data to that,well, mu and sigma are given by the same formulasthat we have for the descriptive statistics--the mean and the standard deviation.So we would be in great shape.So we could ask.Is the generalized random walk a good fit for this data?Well, the answer is no.But what do you think?What do you think the reason is?So one of the things that I look at is the feature--there are a couple of features thatare important-- of the random walk model.One of them is the lack of serial correlation.So we ought to immediately take a look at a plot of the ACF.Because if it's a random walk, there'sno information propagating from one time period to the next.But before that, even at the levelof the descriptive statistics, even before we compute them,we can see visually here that this does notlook like a stationary process.So remember that stationarity meansthat we have time independent probability distributions.And it can be a very difficult thing to nail down, exactly.But certainly in the case of the random walk model,one of the things that we know is that in a stationary model,if the probability distributions are the same,then that necessarily means that if we estimate parametersfrom different subsets of the data,we ought to get the same values.At least, to within sampling errors.That means that there ought to be a given mean and a givenstandard deviation that we could sample over time.Now, a model that looks like this, if I run a Monte Carlo tosimulate data that has matching statistics of the Tootsie Rolldata, it looks like this.This is a white noise process that has a constant mean--zero, in this case--and a standard deviation that is constant over time.So we see that the data is time varying.But the probability distribution is not.On the other hand, the data that we see here for Tootsie Rolljust, without running any fancy statistics,we can see that it's very, very unlikelyto come from a generalized random walkmodel because of the presence of extreme spikes and outliers.So depending on what assumptions wewould make for the distribution, thisis unlikely to come from a single modelwith fixed parameters of the typeof the generalized random walk over the entire period.The model that might fit much betteris something that combines many of the elements we have here,but I'm not going to go into in this video.Something that's a model, for example, that has a timevarying volatility parameter thatwould explain the difference between this and this.So this data, you can take.And I encourage you to try it and fit itto each of the models and answer these questions.Which of the models is the best fit?If you're looking for a model of autoregressivemoving average or ARIMA type model, which is the best one?And what would be the parameters in those case?And what's the significance of the parameters?And do you think that the time series is stationary?

#### Rec03_S03_v1-en

PROFESSOR: We saw in lecture how to use Monte Carlotechniques to simulate price paths,for example, for asset prices.For example, behind me I have some sample pricesfor a stock that might follow a log-normal process.That is, its logarithmic returns are normally distributed.And the parameters over here are that I have 252 time steps.I have 10,000 simulations of whichI have plotted the first 10.I have an initial price of $100.I have a mu of 0.6.And I've got a sigma of 0.42.So this shows a particular set of realizations.But there's more than we can do than justlook at pretty pictures.Monte Carlo methods give us a powerful approximation tool.And they give us some direct computation tools whenit comes to derivative pricing.So how are they a powerful computation tool?Well, if we know the exact probability distribution,then if we want to compute some expectations of operators,we end up doing some intervals.So even for something as simple as the Gaussian distribution,we might be interested in some transforms, some exponentials,some other complex functions.We'd have to do a bunch of Gaussian integrals, whichis fine if you like integrals.But there's another way to do it,which is we can simulate price paths on the computer,and then we replace the exact expectation operator,the mathematical operator, where wetake a probability weighted average of our functionor variable of interest.And we replace it by an average, just an ordinary arithmeticaverage, of the quantities that areobserved within our ensemble.What makes this work is the fact that all of our pathsare equally likely.So we don't need to write down the explicit probabilitymeasure.What we do is we generate the pathsbecause each one is as likely to be drawn as any other.The weights will come up, and they willsample the probability measure.And they'll sample the space with appropriate weightsand appropriate frequencies.So this is a very good approximation techniquefor problems where it might be difficult to dothe integrals in closed form, or we might not evenhave an explicit expression for the probability measure.There are two things to keep in mind regarding the accuracy,and you should try out these examples.So there are things on problem sets.But you should go beyond that.Try changing the parameters.In particular, two things to take a look at tosee how they affect the accuracy--one of them is the number of simulations.I typically use 10,000 pounds to startwith because in general, the accuracy of the resultgoes like 1 over the square root of the number of paths.So if I have 10,000 paths, that should give me thingsthat are accurate to around 1%.What's more important-- the number might be different,but the scaling is important.If I want to get it 10 times better,I need to do 100 times more simulations.If I do only 1/100 of the number of simulations,my answers are going to degrade by a factor of 10.The other thing that you might want to experiment with,though, is the size of the time step.How does dt make a difference?Does it matter?For example, if we're looking at approximatinga log-normal price process by breaking it upusing a binomial random walk, by usingsteps that are plus or minus 1 scaled appropriatelyto the mean and volatility of the processthat we're interested in, how does that affect the answer?So a useful thing to do is to startwith a known example, something that youcould do in closed form, where you could look upthe answer, where you could compute the integral.And you can do the interval for this set of parametersif you'd like and then compare with whatyou get in Monte CarloNow, keep in mind when doing problem sets,because the numbers are randomly generated,your answer might not exactly match.It's going to be within some range.And in fact, as you rerun your Monte Carlo,you'll see the answers change.So what you might want to do is takean average of your own answers.In fact, what you might want to dois not only run an ensemble of 10,000 paths,compute the approximate analytics using the rulesthat I mentioned before--we approximate an expectation by taking an averageover the results--but you could go further and run those 10,000 paths maybe100 times and take the average of those,or at least look at what their distribution is.That tells you something about the confidence intervalwithin which your estimate lies.Now, that's true in general for doing statistical analytics.What about financial applications?So one of the interesting things that we can dois, when we've got these stock price paths,is think about the behavior of financial derivatives.Derivatives are securities like stock optionswhose value depends on the value of another security.And one of the important constructionsin applications and quantitative financeand in derivative pricing is to compute expected values thatare functions of stock prices.So the value of an option is a functionof the value of the stock underlying the option.And in a Monte Carlo setting, we can compute plotsof functions of our variable.So here's how we plot our paths initially.And if we wanted to plot a function, say, s squared,we can go into the code and change s to s squaredand take a look.So if I had a derivative whose valueis equal to the square of the stock price,these are simulations of what its value would beNow, we're often interested in the terminal values,especially for derivatives like options that expire.So what we sometimes want to do is compute the terminalor the final value of the stock priceand then the final value of a derivative.So if we do that, I've plotted hereor I've computed S.terminal to be the final row of S.And if I look at a histogram of S.terminal,we can see what the distribution is.If we want to take a look at the distributionof our s squared values, because it follows the value allthe way along, we could just compute the histogramof this quantity squared, but typically we'dlike to know of the entire lifetime of the option.Now, let's take a look at an interesting exampleis to take a look at a call or a put option.And in those cases, the derivativehas a value along the entire trajectory of the option,but the valuation techniques that we often look atinvolve separate considerations for the interiorprior to expiration and at expiration.So if we consider a European-type option,which has nothing to do with Europe--it's just the name of the option--it's something that can only be exercised at expiration,at no time prior.If it can be exercised early, it's typicallyknown as an American option.So if we consider a European call optionon a stock with strike price K, and we'dlike to know what its distribution of terminal valuesis, that would be an interesting question.So for example, suppose we go back to our--let's go back and look at our previous graph--our original graph right here.And suppose we have an option--a stock option that gives us the right but not the obligationto buy the stock if the price exceeds, say, $150.So it starts at 100.And we want to know a year later,is it going to be in excess of $150 or not?If yes, we will make money on our option.If not, we would not exercise the option.So one of the interesting questions we might askis, how likely is it that the value of the stockwill exceed a particular threshold?And that's something we can answer with Monte Carlo.Let's take a look at that.So let's define a strike price K. Let's let it be 150.And now let's define the value of our call option.And we'll define it at all pointsin time relative to the value of our stock price.So let's say C is S minus K. Now, that's partly true.That's good for all the points where S is greater than Kbut not where it's less than K.So what we'll do-- this is an r-specific construct.You can do the same kind of thingin different ways in other languages.But I'm going to multiply this timesthe expression S greater than K, which is a Boolean expression.So it's equal to 1 if S is greater than K,0 if S is equal to or less than K.And it multiplies these point by point.So this expression for C should give methe value of the option when it'sin the money, when the stock price exceeds the strike price.And it'll give me 0 otherwise.So let's take a look at what some of those paths look like.And I'm going to go back to my plotting function.And I'm going to change S to C, and let's plot those.Now, we notice the value never goes below zero, which is good.So the options-- you cannot lose money apart from the premiumthat you paid for the option.So all the places where the paths hit 0 or don't evenshow up, those are cases where the value was below the strikeprice, and the other ones are above.Now, we could ask-- this is just for the first 10 paths.We could look at what happens over 100 paths.But if we do that, we're still not getting the whole flavor.Because we don't know what fraction of pathsare ending up above versus the number that wedon't see that are below.So let's take a look.We can look at the histogram of the terminal values, which isgoing to be C of 252 comma 0--excuse me-- 252 comma.So we get all of the columns in our simulation.And what we see is that of our 10,000 simulations,6,000 of them ended up at 0.So what we saw was the distributionof the values above the strike price, but most of the valuesare below the strike price.So we have a very asymmetric distribution.60% of the paths are worthless.They finish below the strike price.Of those that are above some of them go to quite large values.In fact, that highest point that we can see in the pixel range--600 is above the strike price of 150.So that would be a very fortunate outcome.Unfortunately, it's quite unlikely to happen.So when we are working with derivatives,we often create a sample of paths for the underlying.We then compute functions of the underlying thatare appropriate to the value of the derivative,and then we look at the analytics of interest.One of the analytics of interest isgoing to be the distribution of terminal valuesand maybe some moments of its distribution,such as the mean and the variance.In this case, because the distributionis so skewed and so unusual, we mightwant to ask conditionally, for example,conditioned on having a positive value, what is the mean?And in other cases, such as options,and it might have early exercise opportunitieswhere early exercise could be optimalor where there may be barrier options whose value couldgo to 0, say if it hits a particular valueduring its lifetime prior to expiration, in those cases,we want to work not just by averaging overthe entire ensemble of paths.We might look path by path at which pathsmeet certain conditions either at different points in timein the case of early exercise or at different points in spaceand in stock price in the case of barrier options.

### 04-Problem_Set_3_21_Questions

## 07-Week_4-Introduction_to_Continuous-Time_Stochastic_Processes

### 01-Overview

### 02-Lecture_4

#### CT01_S01_v1-en

The real world exists in continuous time,and we need models that evolve in continuous time as well.We've looked at discrete-time processesand discrete-time models, and they're great for what they do.If we think about making discrete observationsor approximating time as being a series of discrete intervals,then we can have a structure where we write downmodels that show how information and other econometric variablespropagate forward in time.We can do a lot of calculations, wecan solve some of those models in closed form,and we can extend and generalize them in a variety of ways.But time is continuous.So while we might think of approximating timeas, say, each individual day is a separate point in time,decisions are made in continuous time,and we want some variables that do so as well.Now, we want to distinguish between timebeing continuous or discrete versus variablesbeing continuous or discrete.We could have variables like pricing variablesthat are continuous or near continuousin both discrete time and in continuous time.We'll see that although the world evolvesin continuous time, the mathematicshas some interesting twists, and it's more complex.So many times we might want to use a simpler settingas an approximation of discrete time.When we want to put things on a computer,we'll see the computers don't handle continuous variablesat all, and we'll need to discretize time.So in a certain sense, we'll going back where we started,but we'll pick up some new tools and intuition along the way.So what we're going to do is we'regoing to scale our random walk.So we talked about our basic random walkas being a series of steps of a stochastic process that evolvesin time where, with each new step,the time window over which our walk has existedgets longer and longer and longer.What we're going to do now is keep the overall length fixed,but let the time steps get smaller and smaller.So rather than going farther and farther into the future,we're going to be taking smaller and smaller steps.We'll take advantage of linearity, our basic tool,and expectations, one of our basic toolsfor analyzing discrete processes.But now we're going to take a limit wherewe'll assign an interval delta t to the width of timebetween two steps.And we'll see that by scaling delta t and possibly the stepsize, we come up with a new notion knownas Brownian motion that will be the basis for Ito processesin finance in continuous time.So let's begin with a standardized random variable zwith the usual properties, that its expectation is 0 and thatits variance is equal to , and that the covariance of any twoz's taken at different times is 0 unless they're at the samepoint.That is, zt and zs are independent unless tis equal to s.So we're going to construct a sum of z's and the originof time is not going to be important.So if I let it be, say, t0, I can construct a set of steps,and what I'm going to do is I'm goingto write this now as B because eventually it'sgoing to turn into Brownian motion,so B will be for Brownian.1 represents the size of the time step,and big T represents the overall length of the path.So if I'm taking unit steps on my path, then I take t steps,so this should be t0 plus 1, t0 plus 2, t0 plus three.So t0 is an arbitrary origin.We could let it equal 0.But it's important that things onlydepend on time differences.So what's the expectation?Well, normally we would say that the expectation is equal to 0,but we need to be careful about whenwe're taking the expectation.If we take an expectation after some of the stepshave been realized, then it's only the future stepsthat have expected value 0, as we've seen.So in the event that we take an expectation priorto the start of our path, which I will designate in this way,as E with a subscript t, meaning that's the time at whichthe expectation is taken, provided that t is prior to t0,then the expectation is 0.It's just that the expectation of each of the z's is0, 0 plus 0 plus 0 plus 0 is 0, and that's it.Similarly, the variance is equal to big T.But if I start computing varianceswhen I'm in the middle of the process, thatis, some time between the initial pointand the final point, then the only thingsthat contribute to the variance are things that are aheadof my observation point.Those are the points that have not yet been observed.So the variance is equal to T minus the amount of timethat's already been elapsed.So it's shortened by the amount of time elapsed.The variance depends on the amountof time remaining in the walk.So whenever we take any limiting process,whenever we do any limit, we should alwaysask a few basic questions.First, does the limit converge?Second, if it does converge, in what sensedoes the result that we obtain represent the thing that weare starting with?That is, how is the result representativeof the same dynamics that we started with?And is it unique?Might there be more than limit dependingon the way in which we take limits, particularlyin cases that might have multiple variablesor parameters?Could there be different limits thatare obtained by taking limits in different ways?Could we get different kinds of results?So let's take a look at our random walk.And I'd like to consider a few different cases,show you a few different ways that we mightthink about taking the limit.So the first thing that we would dois, let's just start with the most obvious.Let delta t go to 0.So what's delta t?Well, let's let there be n steps.We're going to hold big T fixed.Big T is the overall length of time that we're interested in.We're going to let there be n steps,and we're going to let each step be of length delta t.It's going to be t divided by n, the number of steps.So if I want to let delta t go to 0, I can hold t fixedand let n go to infinity.Those will be equivalent.Now, let's construct a B path, but now as I told you before,instead of B1, T, I have the first argument here is delta t.This is going to consist of a path of steps that representinterval delta t in time, and thereare going to be n of them to get to my horizon.So I'm going to let t go from to n,and I'm going to take these z's.What's the expectation of that sum?0.The expectation of each term is 0, and the sum of the 0's is 0.What's the variance?Well, they're going to be as usualbecause these are independent.The variance of the sum is going to ben times the variance of an individual z.So n times the variance of the z, the z's are standardized,is going to give me n.So what happens as n goes to infinity?The variance becomes infinite.Not too useful.Let's try again.Suppose we rescale the time step in the step size,because it's easy to see what went wrong before.We took an infinite number of steps, each of which was size ,so of course the variance blew up.So we should think about it, and instead of just varyingthe time interval, we should, as welet delta t get smaller and smaller,we should also let the step size approach 0.So let's see if we can do that.Let's let delta t equal T/n as before,and let's define epsilon to be our variable for our step size,and let's let it be lambda times our unit variableso that we can, instead of changing our beloved z's,this way we can let lambda go to 0 to let the step size go to 0.So what do we have?Well, we construct a sum of n variables.But this time, the n variables are the epsilons.Each epsilon is lambda times z, so the lambdaspull out in front of the sum.So what do we have for the variance?Well, the expectation is 0, as before.The variance is going to be n times the varianceof the single step.The variance of a constant times a variableis the constant squared times the variance of the variable.So we have n lambda squared times the variance of z,and that gives us n lambda squaredfor the variance of this process.Now, we want the step size to go to 0,so suppose lambda goes as 1/n, the same waythat delta t goes as 1/n.Then we let n go to infinity.What do we get?Well, now we get that the variance of our processis going to be n lambda squared.That's going to be n over n squared.That's going to vanish.That is, as we let n go to 0 [CORRECTION: infinity],it takes delta t to 0 and it takes the step size to 0in such a way that the variance also goes to 0.Variance 0 means it's deterministic.There's no randomness at all.And that would be nice, but it's notgoing to be too useful for formulatingcontinuous-time finance.So the problem here was the relative rateof change of the time step and the step size, that is,the spacing in the size of the step that we takeand how we interpret them as evolving in time.Take a moment and see where you think we might go next.

#### CT02_S01_v1-en

PROFESSOR: Let's try exercising a little bit more controlover the way in which delta t goes to zeroand the step size goes to zero so that we canget a limit which has a finite variance instead of one that'sinfinite or zero.So consider the following.Let's let delta t be T/n as before.This time, let's take our step sizeto go as square root of delta t.That is, let's let lambda, which is the stepsize that we're going to have in our process,be square root of T/n.The important part isn't the T. It's the square root of 1/nthat we have here.So as before, we construct our series B delta t,T as consisting of a number of stepsto represent the entire time horizon of length big T.That's our overall duration in macroscopic time.And we're going to have n infinitesimal steps epsilon t.Those steps are going to have this scaling.They're going to be square root of delta t times zt.And what about the variance?Well, the expectation is zero as always,but now the variance is n times the varianceof the epsilon variables of our scaled step sizes.That means that the variance is n deltat times the variance of z.This variance is just equal to one,and this here is equal to big T because n deltat is being held fixed.We saw that up here.So what we get is the variance is equal to T, which is finite.So by scaling our steps in a particular way,by letting the step size go to zero as 1over square root of n, or as the square root of delta t,we can achieve a continuous limitwhere delta t goes to zero and we stillend up with finite variance, not zero and not infinite.This defines Brownian motion.So Brownian motion is a process whereit's the limit we obtain by lettingdelta t go to zero where we find that, relative to our startingpoint, the endpoint is a Gaussian randomly distributedvariable with zero mean and a varianceequal to the length of time elapsed,no matter what that time is.Now, there are a lot of interesting propertiesof Brownian motion, and we're notgoing to derive all of them.We're just going to work with the processesto see the things that are most useful for finance.The paths that we get that we obtain by taking this limitare fractal in nature.They're continuous paths, but they're nowhere differentiable,so we're going to need to modify our rules for takingderivatives to deal with these new paths.Instead of looking at our usual definitionsfor taking derivatives for doing calculus,we're going to have to think about things probabilisticallyand replace our usual limits by a kind of convergencefor probability distributions.Now, we could have defined this abstractly from the beginning,but it's useful for a lot of practical and conceptualreasons to think about taking the limit in this way.One of the interesting things is that this limit reallyis universal.We could have started with steps, remember,that are drawn from any IID distribution that satisfiesthe properties that we have for just our general thingsfor a standardized random variable.So we're going to end up with something which has a Gaussiandistribution, regardless of where we started,due to the central limit theorem.Interestingly, we'll see that whenwe want to do numerical approximations,we want to do Monte Carlo option pricing, for example,we're going to re-discretize, and it'lllook like we've come full circle,and then we're going back to where we started.Now, there is more than one limit possible,and there's a literature on this, whichwe're not going to go into.I want to point out that the essential ingredientfor finance is that we have non-anticipating processes.That is, we're taking a limit as t evolveswhere we don't know what's in the future.It's possible to take things that are symmetric,that are agnostic between past and future,or even things that go the other way and that anticipatethe future.So there are some mathematical subtletiesin those different limits.I'll point out what the rules are for the limitthat we're interested in, which is defined in just the waythat we went through right now.So what are some of the properties of Brownian paths?Well, we started by taking a finite path,we broke it into infinitesimals, and we came upwith some properties that are trueof the finite macroscopic path.So one of them is that the properties of the pathdepend only on the time differences.So if we think of X of t1 and t2 as being Brownian motion thatgoes between time t1 and t2, we can think of itas the difference between the endpoints, all right?So the initial point doesn't matter.The results that we have are a functiononly of the elapsed time between the two.It doesn't matter what the origin of time is.So if we shift time forward or backward by any constant,the properties that we have are the same.The distribution is the same.The variance only depends on the elapsed timebetween the endpoints.But that being said, the endpointsdon't need to be separated by a finite amount of time.We could bring them back to where big T gets smallerand smaller and smaller and to the point wherewe get a new infinitesimal.So we started by taking a finite path,we chopped it into infinitesimals,we got properties of that finite path,and now I'm going to shrink the length of that path backto delta t.So this might seem as though we've done nothingand we're going full circle, but I remind youthat our initial discrete process for any finite sizedelta t could have had non-Gaussian distribution,and the Brownian paths are Gaussian at all scales.So if I look at a small chunk, a small pieceof infinitesimal time evolution in Brownian motionfor a Brownian path, and I'll callthat interval dB sub t just to remind youof the time dependence.Little subscript t is notation you'll see sometimes.It's not particularly meaningful.It's just a reminder of the time dependence.This is going to be normally distributedwith mean zero, of course, and variance equal to the timeinterval, which is delta t.So if we'd started with somethingthat, for example, was a discrete random variable, maybewith plus or minus one, we wouldn'thave had this property at all.At small scales our granular thingwould have recovered the building blocks that we had.So here we do have this universal behaviorfor Brownian paths, that they're Gaussian at all time scales,big and small.They also are independent.So if I look at the covariance takenat two different times for two different infinitesimal timeintervals, I find that they're equal to zero if the times aredifferent, or the variance of the processis dt if t and t prime are equal.We can also talk about integrating the processto go from an infinitesimal back to the finite values.And sometimes we'll write this in integral formas saying that BT minus B0, or I canput the B0 on the right-hand side,is the integral from time zero to timebig T of our infinitesimal.

#### CT02_S02_v1-en

PROFESSOR: So we have integral formulasand we have differential formulas.What are we going to do?What are we going to use?The answer is we're going to use them both.Most of the time we're going to be working in differential formand constructing what are known as stochastic differentialequations that involve things like that infinitesimal dBthat I showed you on the previous slide.That's the small time limit of our finite Brownian motionpath.And we'll see these stochastic differentialsinvolve these Gaussian random variables.And under certain circumstances, wecan reduce them to partial differential equations,familiar from calculus, that don't have any randomness.And then we can apply normal techniquesthat we have from the theory of partial differential equations.However, we also sometimes use the integral form,where we want to take a differential versionand integrate it up.That's something that we need to thinkabout a little bit differently from doing integralsin ordinary single or multiple-variable calculusbecause the thing that we're integratingis a random variable, and its randomnessdepends on where it is in time.So we can't just do a straightforward integration.We need to think about the results of the integrationas themselves representing a probability distribution.But an important example of wherewe think about things, these integral formsfor finite values, is in doing option pricing,and a discrete approximation to that on a computerthat we'll be seeing where we do Monte Carlo simulations.So we might like to--it turns out that we can define the price of an optionas an expectation over a bunch of Brownian pathsthat are integrated over a finite time period.And for that, we'll want to have our integral representationof what the paths are and what their probabilitydistribution is.Finally, let's do a quick versionof our generalized random walk because just pure Brownianmotion is a bit boring.It's like a standardized random variable.There's not a whole lot that we cando with it if it only depends on timeand it doesn't have any parameters.We'd like to include something thatcould represent our old friends, return and risk.So remember what we did with our basic random walkto get to the generalized random walk.We introduced parameters.So we started with a return variablefor our log-normal process where wetook our variable z, our standardized random variable,we multiplied it times a constant,sigma, to represent the step size,and we possibly added another constant mu thatrepresented the drift.So I've written this as mu 0 and sigma 0because I don't exactly know right now whatscale I want to use.And let's think of those as being the bare parametersfor constructing a process where the time interval was fixed.So when delta t was equal to 1, this was how we set things up.We said that if I had bare parameters mu 0 and sigma 0,then the random variable constructed in this way, r subt, was normally distributed with mean mu and variancesigma squared.Then, if I added a whole bunch of themtogether to get some finite-length pathof multiple steps, I could go from 0to a value of, let's say, big T, letting big T be an integernumber, by aggregating a bunch of individual time steps,mostly T of them.And because the logarithm of a productis the sum of the logarithms and because the variances addand all our usual rules, we see that by adding together big Tvariables, I could get a process that was normally distributedwith parameter mu 0 t, variance sigma 0squared T relative to the bare parameters.Well, now we'd like to let delta t go to 0.So how are we going to do it?What we'd like to do is find a waythat we can pick a scaling for our parameterssuch that we get finite values that wecan interpret financially when we get our Brownian motionlimit.So we'd like to think about getting the same kind of value,a finite path, logarithm of ST over S0, sameas we had up here, by taking the limit as delta t goes to 0.How are we going to do that?Well, we're going to have our path consistof a bunch of steps, but now we'regoing to let our parameters scale in the following way.We're going to let the drift term go as mu delta tand we're going to let the step sizeterm go as sigma square root of delta t.And with that particular scaling, when we take n steps,where n is t over delta t, as we saw before,we'll get a finite result. So it's the same thingthat we saw.The part that's random is the square root of delta t.The part that's deterministic, a 1/n result is just fine.So if we do these sums, I've got n terms here, mu delta t times,each term is going to be identical,times t over delta t.That's going to give me mu times t.Over here, I can scale out in front a sigma square rootof delta t times the sum of the z's.But the square root of delta t groupedwith the z, if I only pull the sigma out in front,then I have exactly my definition of my Brownian path.So with this scaling, by introducing mu and sigmain precisely this way where the drift and the volatilityof a process as we let delta t go to 0,we get the finite result that we canhave stock price evolution, let's say,represented by a random path thathas mean mu times the length of time.And sigma integral dB is going to give ussomething which is finite--for finite times, is a random variablethat's drawn from mu of--excuse me, from N of mu, t sigma squared t.That is, it is going to have a mean thatgrows with time linearly and a variance thatgrows with time linearly and a volatility that growswith the square root of time.More generally, we don't need to let mu and sigma be constant.If they depend on time, if they're deterministic functionsof time, then we could think about lettingthem change slowly in time.If they're smooth functions of time,or actually just integrable functions of time,we can have this general result, but provided that they're notrandom variables.So the typical case is mu and sigma are constant,but we'll see shortly that we can generalize evenfurther when we introduce Ito processes.

#### CT03_S01_v1-en

PROFESSOR: An Ito process is like a generalized random walk,and Ito's lemma will give us a formula for doing calculuswith Ito processes.So an Ito process is defined to be a differential that'sa linear combination of dB, our Gaussian Brownianrandom variable, plus possibly times a scale factor little b,plus some deterministic part I'll call a dt.If the second term were absent, thiswould just be an ordinary differential,and we could look about ordinary ways of integrating it.But dB is going to be random, and that's goingto give us something different.In particular, because the Brownian pathitself is not differentiable, X won't be differentiable,and we can't take derivatives in the usual way.If we had a function of X and t where X were a normal variable,the usual chain rule would say that we computethe differential of our function F of t and Xas partial of F with respect to t timesdt plus partial with respect to X dX,and that would be it for our ordinary chain rule.But we're going to see that there's an extra term thatgets added when we're dealing with Ito processes,and that comes about because we can't use this rule because wecan't differentiate directly for Brownian paths.So the idea behind the proof is we'regoing to try to rewrite our familiar ideas from calculusin a way that makes sense probabilistically.Let me tell you up front that, number one,I'm going to sketch out the proofand it's not going to be rigorous.This is going to be a somewhat heuristic proof.And number two, the results actuallymatter more than the proof.So I'll be upfront about this.I want you to see where it comes from.I'd like you to see where the probability arises and the Itoterm in the modified chain rule, but thisis an area where even if you don't rememberhow to derive it, if you start with Ito's lemma, the rulethat we're going to have, you can apply it successfullywithout really needing to come back to the derivation.So with a little bit of chagrin, I will admit that.But I hope it gives you confidence that you can--if you don't follow every detail in what we're doing,it's not going to make any difference for the result.So the idea is we'd like to capture the expression up herein a case where we're dealing with probabilities.So you can think of this as we constructthe object on the right by taking finite changesdx, where I've written it here as delta x.I construct this ratio F of x plus deltax minus F of x over delta x, and then I take a limit.And that defines the object that's on the left-hand sidethat we typically call the derivative of F,or in this case, F prime.So what I'd like to do is I'd liketo say in probability, because the resulton the right-hand side is going to be different every time Icompute it, because x is a random variable,F is going to be random.I'm not going to get a concrete, definite result for F.The sense in which I'm going to define itis to say that I have found a sensible definition for F primeif the probability that this function deviatesfrom the right-hand side goes to 0 as delta x goes to 0.So I can write this in the following two ways.I can write it either as saying that the probabilityof a deviation-- so I've written thisas being the difference between the left and right-hand sidesabove me, quantity squared, so that it's alwaysa positive quantity.The probability that that's greater than 0goes to 0 as delta x goes to 0.In other words, they're equal.So if a construct, F prime of x, satisfies this,I would say I've found the derivatives.You notice that's the same flavor,same result in the non-probabilistic caseas the traditional formula.I can also state it in terms of expectations.I can say that the expectation that the squared differencewill be non-zero goes to 0.So what are we going to do?Well, we're going to start by writing things out,a differential for a Taylor series,including lots of higher-order terms,and then we're going to only keepterms that are of order dt.Anything that vanishes as dt or delta tgoes to 0 faster than dt, we're going to toss out.But what we'll need to do is keep a couple extra termsbecause a few things that we might have thoughtwould vanish actually, it turns out, stick around.So we're going to start with our definition of our Ito processand just plug it in.So I start by writing out an ordinary Taylor expansionfor a differential in terms of allthese higher-order derivatives.There will be cross terms, partialof F with respect to X and t, dX/dt, term in dt squared,terms in dX cubed, dX squared, dt, and so on.And what I'm going to do for each of theseis I can substitute in my expression here for dX, herefor dX squared, and so on.And then what I'd like to do is thinkabout taking expectations of the left sideand the right-hand side and see whichterms survive as we think of dt as being an infinitesimal.So to do that, we want to look at our basic building block.Remember that dB is a Gaussian random variable.So it has mean 0, it has no skewness for its third moment,its square.We know its variance is dt, the length of the time interval,which is infinitesimal.And if we want the fourth power, weget-- whereas a normal random variable, the fourth moment isequal to 3, that's the reason we subtract off3 for our excess kurtosis, in the case of infinitesimals,when you put it in the dt's, I get the resultfor the fourth power.This is the same as the usual 3 timesdt squared, which we get just on dimensional grounds.So if I take those building blocks for dBand I apply them to Ito processesand ask about expectation and mean and variance and so on,do the usual thing.I apply linearity.So dX is just a dt plus b dB.Apply linearity, so it's the expectation of a sumis the sum of the expectations.a dt is deterministic.It's like a constant.So I get a dt out here.The mean of dB is 0, so all I getfor the mean of my Ito process isa dt, which is deterministic.What about the square?Well, for the square, I put in the square,take the second power, expand it out, do the exponentials usingthe formulas on the top of the screen,and I get a squared dt plus b squared dt.When I compute the variance, rememberingthat the variance is always the expectationof the square minus the square of the expectation,I find that the variance of dt is just little b squared dt,and so on.And I can compute higher moments as well.So let's go back to our formula for dF,and remember that we're going to be interested in termsthat are of order dt.The key thing to keep in mind that'sgoing to drive our results is that because the expectationof dB squared is dt and the varianceor the expectation of dX squared has a dt in itfor the variance, that we can think of dB as beinglike a square root of dt.And remember, as dt goes to 0, the square root of dtis going to be bigger than dt.But let's just put in the terms, we'll group things together,and then we'll take the limit and see what vanishes.So first I've got my expression for dF.Next we're going to substitute in for dX, for dX squared,and so on, where we're thinking about expectations.And the higher-order terms are going to be non-stochastic.We can group things together, where I can nowgroup together coefficients of dt.Notice that I have a dt over here, a dt here, and a dt here.Let me take the first and last terms and groupthem together here, and I'll take the middle term,and let's just keep it in this form for the moment,bring it down here, partial of F with respect to X times dX.Alternatively, instead of writing thingsas a function of dt and dX, I can write themas a function of dt and dB simplyby using the definition of dX.So either way, in either this form or in the bottom form,I have an expression for dF that I can work with.So either of these two forms, depending on our applications,will be useful.The point about looking at the last oneis look at its structure.You notice that it's of the form something times dtplus something else times dB.That's just an Ito process.So the differential of F when F is a function of an Ito processis also an Ito process, and that's why these are useful,because they're closed when we take differentials.We get more Ito processes.Here's the heuristic.It's the easy way to keep track of thingswithout doing a lot of Taylor expansions.If every time you see a dB squared,you think of it as being a dt and every time yousee a dX squared, you think of it-- remember,this is the pure, standardized random variable.This is with a scale factor in it.If every time you see a dX squared, you replace itby little b squared dt, you'll basicallyget the right answers.So the differential that we have has one extra termbeyond the usual chain rule, OK?So this is our result from the previous page.When we take a look at this expression here,we see that this term dt--this term-- get my pointer working.This term dt and this term dX are the usual chain rule,but this one here is something new.So writing it in standard form, we have Ito's lemma in the box,and I'll circle it again in red.So this is worth getting to know very, very well.It says that the differential of a function of X,where X is an Ito process, is partial of F with respectto t dt, plus partial of F with respect to X dXplus a new term that involves the second partial derivativewith respect to X squared, but it's multiplied by dt.So we've seen that the differentialof a function of an Ito process is itself an Ito process.And this formula is Ito's lemma.

#### CT04_S01_v1-en

PROFESSOR: Let's look at a few examples of Ito processes.Our first example is going to be a Brownian motion with drift.Could this be a possible model for stock prices?Let's take a look.We'll define dS to be mu dt plus sigma dB,where mu and sigma are both constants.This is easy to integrate.So suppose we start with this expression,and now, let's just integrate each term, keeping in mindthat mu and sigma are constant.So this will be from t equals 0 to big T.And if we integrate on the left-hand side,we just get St minus S at time 0 is equal to mu timesT plus sigma times BT, or, to be precise,if we might have had some non-zero constant,we could have this here.So that's-- we've integrated an Ito process, and there we go.We see that it has a linear growth with timefrom the first term, and the second termrepresents-- this term here represents a random variable,so that the final destination of ST is unknown,but BT, as we know, is drawn-- or this differenceis drawn from a Gaussian distribution.Now, this model has been consideredand generally rejected for purposes of stock prices.It was the first model considered by Bachelier in 1900for a theory for option pricing.But the biggest complaint about it,generally, is that it allows pricesto go negative with positive probability, somethingthat stocks can't do since stocks have limited liability.So this is generally the preferred model.And this geometric Brownian motion,this continuous-time version of our log-normal process,is the standard model for stock prices.That doesn't mean it's right.It means that it's the reference model.Whether it's right or not, how well it works,remains to be seen by looking at dataand by looking at applications.But let's take a look at this nowas an application of Ito's lemma.So we begin with this form, wherethis looks similar to what we had before, but noticeI've multiplied through--on the right-hand side, each of these terms has an extra S.So my coefficient function a, little a and little b,is mu S over here and sigma S over here.So let's take a look at this as an application of Ito's lemma.So here's our expression where I'vedivided through by S. In this form,we can see that what's a--Brownian motion generalized is the quantity dS over S.But notice we can't integrate that immediately because it'snot an exact differential.It's a differential divided by S. If it were d of something,then we'd be done, and that's our goal.So I got this by taking dS is mu S dt plus sigma SdB, which is of the form, of course,a dt plus sigma, excuse me, plus b dB.So we have that a, in this case, is mu S and b is sigma S.And now we'd like to apply Ito's lemma.So it would be convenient to have that.Luckily, it's right up here.Let's bring it down.So here's Ito's lemma, and let's take a lookat how we can apply it to this situation.Notice that the B squared here isgoing to be replaced by this value here, by sigma S squared.So I've written this in terms of S down here instead of x,and what should we use for F?The f that we're going to be interested inis the logarithm of the stock price for the same reasonsthat we've talked about earlier and when we lookedat discrete-time processes.So let's go.We have that F is equal to log S. Therefore,the partial of F with respect to t is 0.That was easy.Partial of F with respect to S is 1/S.And the second partial of F with respect to S squared is minus 1over S squared.What does Ito's lemma say?It says that dF, d of log S, is going to be, well, let's see.Partial of F-- partial of F with respect to t is zero,so I'm not going to have an immediate dt term.I'm going to have a term which will be partial of Fwith respect to S dS.But that's going to be--well, here, let's write it out in two steps.This is going to be dF dS dS, plus our Ito term, whichis going to be little b squared, whichis sigma S over 2, second partial of F with respectto S squared, times dt.Now, let's substitute.This is going to be 1/S dS plus sigma Squantity squared over 2 times minus 1over s squared times dt.Now, remember that this first term right hereis dS/S, which is what we started with.I think we have it way back here, dS/S. There it is,right here.So let's take this value for dS/S,which is mu dt plus sigma B, and substitute itin right over here, shall we?So this is equal to mu dt plus sigma dB.That's from this first term.And now we have this second term whereI'm going to have an S squared and a minus 1 over S squared.So that's going to give me minus sigma squared over 2 times dt.So let's combine these and clean this all up.This tells us that d of log S is equal to muminus sigma squared over 2.Oops, changed our colors.dt plus sigma dB.So what have we done?What we've accomplished right hereis that we've taken our original Ito processand we've rewritten it.Where we had dS/S, which was not an exact differential,we've now been able to take the function log S and showthat it's an exact differential.And on the right-hand side, we have somethingwhich we can integrate.So what we have is, if we do the integration, we have log ST/S0.Since a difference of logs is the log of the ratio,this is going to be mu minus sigma squaredover 2 times t plus sigma times BT minus B0,just as we had before, if we want to integrate it.So if we compare with our notes, wesee that we've taken this format hereand we've shown that log S is an exact differential.It looks like a Brownian motion, so that the logarithm of Sbehaves as a Brownian motion with the same volatility.Notice that sigma is unchanged here, but we have sigma dB.And over here, compared to our previous exampleof an ordinary arithmetic Brownian motion with drift,the sigma dB term is the same, and theleft-- on the first term, rather,on the deterministic term, we have mushifted by sigma squared over 2.So this piece here, mu minus sigma squared over 2--we'll be seeing a bunch of minus sigma squared over 2's runningaround in some other formulas.This is where it comes from.It comes from the Ito term in doing this change of variables.Then finally, if we want to integrate things upin finite form, we just exponentiatethe last expression that I wrote down.This model has the virtue that it excludes negative prices.So because the logarithm goes from minus infinity to infinityand we're exponentiating the result,we never get negative numbers.The exponential is always positive.This is potentially-- it has the opposite problem.We don't get negative prices, but also,prices that obey this can never reach 0,and unfortunately, real companies sometimes dohave stock prices that go to 0.So that's something that we should think about,whether it's a good approximation or a good modelto apply to real-world prices.The thing that we see in our original model,we can actually see that without solving it.How do we see that?We noticed that because these coefficient functionshave an S on the right-hand side, that as S approaches 0,the coefficients of dt and dB are going to 0.That means that there's not a lot of motioneither deterministically or randomly.As the stock price goes to 0, everything quiets down,and that's partly how it avoids the origin.Another common model is the Ornstein-Uhlenbeck process,which is a continuous-time analog of the mean reversionprocess that we saw in discrete time thatlooks like the AR 1 process.Now, here's a case where we can learna lot about the solution to the equationwithout actually solving anything.Let's take a look.First thing we notice is that if the lambda term were 0,we would just have an ordinary random walk.So the stochastic term is very, very simple.What about the deterministic term?Well, this is a restoring force.So I've suggestively called the constant here lambda timesS bar.And here's an S. This is our dynamic random variable,the same one that appears in the left-hand side.So how can we think about this equation?This says that the change in S, dS, has a random component.This is the shock here, which is unconnected with anything.But if S is below S bar and lambda is positive,then this will be a positive value.And if S is above S bar, then this will be a negative value.So depending on the sign of lambda, if it's positive,we basically have the mean-reverting dynamicsthat we saw before, that we move toward the mean value,and we would expect that the long-term mean value isgoing to be S bar.Now, can we use this as a model for stock prices?Well, on the one hand, it's got a random component thatallows drift, and there's no boundedness on S,so S could get to be infinitely large.It could get to be negative.On the other hand, the first term acts as a restoring force.It keeps things relatively tight near S bar.So depending on the magnitude of lambda comparedto the magnitude of sigma, it mightbe OK for certain periods of time as a good approximation,but it does allow the possibility,with finite probability, that prices could go negative.It's not strictly forbidden.So this is a model that's commonlyused for many processes.Most notably, we'll take a look whenwe think about models for interest rates.Another model used for interest ratesis the Cox-Ingersoll-Ross process,which looks a lot more complicated,but really it's just one small modificationto the previous one, to the Ornstein-Uhlenbeck process.So if I take a look here, I see this is the mean reversionterm.But now, notice that the volatility termis modified by this square root of rho that's here.So think of rho as being a rate, an interest rate type variable.And what does the square root of rho do here?Well, I have a restoring force near rho bar,but this does say that if rho approaches 0from above, that the volatility term gets very small.So maybe we have a chance of avoiding the origin.Notice that we absolutely can't have negative values of rhoin this model.The first term doesn't have a problem,but taking square roots of negative numbersnow gives us not just a financial problem because it'sa mathematical one too because we're notgoing to find or want to find solutionsin the complex numbers.So we can sometimes break this down by a little bit furthermanipulation, and here's one more applicationof Ito's lemma.We can transform things to simplify the stochastic termand move all of the complexity into the deterministic term.The stochastic terms are the onesthat are genuinely new for what we're doing.They're the ones we might want to Monte Carlo model.The coefficients of dt, as complicated as they might be,follow the domain of usual kinds of differentialsthat we would look at and standard analytic functions wemight consider.So let's just see what happens if we have this transformation.So we compute the necessary derivatives.If F is equal to the square root of rho,the partial of F with respect to t vanishes.The first partial of F with respect to rhois 1 over 2 square root of rho.The next partial derivative is minus 1/4 rho to the minus 3/2.We substitute that into Ito's lemma,and we find that we can write the result in this form.dF has this expression, this coefficient function for dt,plus now a newly simplified coefficient function for dB.So now if we want to see about avoiding behavioron the origin, we just need to studythe behavior of this term.The stochastic term is constant.So we have mean reversion dynamicsfor an appropriate range of parameters.We do avoid the origin.And this model is one that's usedfor taking a look at interest rates and at term structure.

#### CT05_S01_v1-en

PROFESSOR: We have all the tools we need nowto derive the Black-Scholes equation for option pricingand for derivative pricing generally.And the method in this case is justas interesting as the result. We'regoing to use the tools that we have with Ito's lemma,and we're going to take stochastic differentialequations and reduce them to partial differential equations.And the technique that we use is,instead of trying to solve for the randomness,we're going to eliminate it completely.Let's see how that works.Suppose we've got a function V, which,think of V as standing for the value of a derivative function.So let's let the underlying-- so for concreteness,we can think of a stock option, say a standard callor a put option.So let V be the value of the option,let S the value of the stock, genericallycalled the underlying, and a derivative issomething whose value depends on the value of something else.So S is the stock price value, V is the value of our derivative,t is our old friend time, and let's supposethat the stock price follows geometric Brownianmotion, which we just solved.So dS/S over S is mu dt plus sigma dB,or if I multiply through by S, I have this expression here.What about V?Well let's write d--So that's dS.Let's write dV using Ito's lemma,where we think of V as being a function of S,and then S is this function of time and of randomness.So applying Ito's lemma, we have dV is something times dt.Now, I've grouped the Ito term here as a coefficient of dt,so I have partial of V with respectto t plus this term here, this sigma S, quantitysquared over 2.That comes because of this sigma S,so that shows up in the coefficient in the Ito term,divided by 2, second partial of V with respect to S,all of that times dt, plus partial of V with respect to S,dS.So that's just Ito's lemma applied to a generic functionV.Now, let's combine the two in a portfolio.So specifically, let's imagine that we're looking at the valuewhere we buy one option, and maybe we'regoing to go short a certain number of shares.Let's give that number a name.Let's call it delta.So the value of the portfolio is goingto be V, the value of the option,plus the quantity of shares times the value of the shares.Our quantity is going to be a negative quantity, sominus delta, times the value of the shares.So my portfolio value, which I'll designate by pi,is V minus delta S. Now, I'm goingto start shifting around my portfolio a bit,and the thing I'm going to changeis the amount of stock I own.It's a lot easier to trade stock and a lot cheaperand the market is much more liquid.So I'm going to imagine I'm going to hold V fixed.I'm going to hold the single option fixed.If we had a different number, we could multiply thisall by some overall constant.But I have one option which I'm long,and I'm going to be short delta shares.And therefore, the value of the portfoliois going to be V minus delta S.Let's look at this in differential form.What happens as the stock price changes?Well, the change in value of the portfolio, d pi,is going to be dV minus delta dS.So what do we know about dV and dS?Well, for dV, we take this expressionthat we have up here, and let's write it down below.Notice that I have my dt term come straight down.And then I have this extra term, partial of V with respectto S times dS.That comes over here.And then I have this other term, which is much simplerbecause it's stock itself.It doesn't need any other partials.So I have minus delta times dS.So I've written the change in portfolio valueas an Ito process with something times dt plus something timesdS.I don't need-- I could expand this dS out in terms of dBif I wanted to, but it's actuallygoing to be a bit more convenient to leave itright here.So notice that the first term is deterministic.The second term is stochastic because of the dS.And gee, wouldn't it be nice if we could make that go away?Well, we can.Suppose that instead of dS vanishing, whichwe can't do because it does obey this stochastic differentialequation, suppose we just multiply at time 0.That is, suppose we choose delta to match dV/dS in such a waythat the coefficient is 0.The stochastic term vanishes if we choose delta equals dV/dS.That is-- that says that if we knewthe sensitivity of the price of the optionas the stock price changed, that would tell usthe number of shares to own.So the right-hand side, in general, varies with time,and so is going to be delta.So there's no risk that's left over.We've canceled out all of the risk,but at the cost of having to keepreadjusting the number of shares that we have.So as the market price changes, the exact number of sharesdelta that we need changes.And this is a strategy that's known as dynamic hedging.So dynamic hedging means that we holda number of shares in relation to our option that's specifiedin a very, very specific way.Given all the values, I will know exactly how many sharesI need to trade.But when things change, I will need to update those.Having done that, though, there'sno risk in the portfolio because this term here vanishesand d pi is just something times dt.If there's no risk in the portfolio,then the portfolio should earn the risk-free rate,under penalty of arbitrage.So it should be the case, then, that d pi shouldgrow at a rate r dt times pi.So it's proportional to the valueof the portfolio times the risk-free rate times dt.Well, let's see what that gives us.So this is r dt times pi, but after all, piis the portfolio value, V minus delta S.So I have that d pi should be r times v minus delta S dt,and that's equal to what we had on the previous screen,which is rV minus our expression for delta.So that's going to be minus r, this r here.So I have minus, I have the r in front,I have delta is this partial of V with respect to S,times S, dt.So now if I want to equate the coefficients of dton the left-hand side and the right-hand side,or I should say, on this screen and the previous one,so here I have one expression for d pi,and I have this other expression for d pi that just consistsof the first term here.The second term we've arranged carefully have vanished.So let's say that this expression for d pihas to be equal to this expression for d pi,and let's drop the dt's because all of the coefficientsare the same.And then we have this expression,that the partial of V with respect to t plus sigma squaredS squared over 2 d2 V dS squared has to be rV minus rS dV/dS.So notice the right-hand side is proportional to r.The left-hand side doesn't have any r's.Each term has a V or some derivatives of V in it.So let's put everything over on one side of the equationand clean things up.And now we have a partial differential equationwith no randomness left in it.This equation is the Black-Scholes equation.Partial of V with respect to t, the time variationin the derivative, plus rS times partial of V with respect to S,plus sigma squared S squared over 2 d2 V dS squared minus rVis all equal to 0.Notice that we have our two terms here and herethat are proportional to r.And everything contains V, so thisis a homogeneous equation, linear in V,of first and second partial derivatives,plus a term with no derivatives here, this term here.So we're going to talk about solving the equation,but what can we say about the equation before we solve it?Well, we know it's linear in V. Therefore,we know it obeys superposition.That is, if we were to have two or more solutions,we could add them together and get another solution.So any linear combination of solutions is also a solution.For equations of this from, we knowthat we find the exact unique solution to our problemfrom the boundary conditions.So we'll need to find some general solutionsto this equation.But then to get the exact ones of interest to us for finance,we'll need to apply boundary conditions.What are the parameters in the model?Well, there's some explicit parameters.We have r and we have sigma.Sigma is the volatility and r is the risk-free rate.But wait a minute.We started with three parameters, didn't we?We introduced r at the end because we had a risk-free ratebecause we'd eliminated risk by canceling outthe stochastic term.We have the volatility that we would expectbecause of the randomness.Notice the special cases gets rather trivialif we set sigma equal to 0.But we had a third parameter mu.Where did that go?And there are some parameters herethat are implicit that come from the boundary conditions.So if we're thinking about an option,we need to give an expiration date,we need to give a strike price, weneed to say whether it's a call or a put,and all of those things are not part of the equation.They're not part of the general solutions.They will be part of the boundary conditionsand determine the specific solution that we have.

### 03-Recitation_4

#### Rec04_S01_v1-en

PROFESSOR: Let's take a look at Ito processes and Ito's lemma.Let's do a few examples.So an Ito process has two parts.It has a deterministic part and a random part.And of course, random part is the onethat we're particularly interested in.This is directly analogous to what we did whenwe looked at discrete time.If we think about our old friend the generalized random walk,we had a term r, which representedthe change, the difference in variables,in this case, logarithms and prices,over a particular interval.That's going to be one way you can think about dx.The next term, mu, was just a constant.It was something by which in every period r would increase.The same kind of thing with the term adt.We think of it as being a deterministic term.And in fact, if a were a constant mu,and we were to integrate this over a time interval of length1, we would see that we'd get the same result.We would just get a constant.And then the last term has two parts, a little b and a big B.The big dB plays the role of our standardized random variableZ. That is, it has zero mean instead of unit variance.Because it's an infinitesimal, it has the next best thing.It has variance dt.And the coefficient function in front of it, little b,plays the same role as sigma.The difference is that our coefficient functions a and b,might just be that.They might be functions.So a and b can be functions of t and of x itself, all right?So we do have that a can be a function in general of t and x.And b could be a function of t and x as well.But certainly, the special cases where little a and little bare constant, are going to be interesting.Now the question that we ask in applyingIto's lemma is, suppose I'm given an Ito process dx,and I have some function of x.What's its differential?If it were an ordinary function, an ordinary deterministicfunction, then the answer would be given by the chain rule.And if you don't remember the chain rule,now would be an excellent time to go brush upbecause we're going to be using it a lot.And what I want you to focus on are the differencesbetween the ordinary chain rule and the Ito rule.So the first two terms tell us for a function of t and xhow differentials behave.They depend on the evolution with respectto time, the partial derivative with respectto time times dt plus the partial with respect to x timesdx.And this piece over here is genuinely new.And that's going to be the sourceof a lot of the interesting thingsthat we'll see when we look at continuous time finance.Our strategy is going to be the samethough, that we saw in looking at time series models,namely, to build complex models and interesting phenomenonrelationships out of very simple building blocks.So our simple building block here, is going to be dB.That's it.So we want to know the properties of dB,either in differential or integral form.And we're going to be combining those in different waysand solving some interesting financial problems.So the idea is that economic variables of interest,like a stock price, like an interest rate,like a yield or a wide variety of other variables,will be described by stochastic processes that can be built outof Brownian motion, who is in infinitesimal form, our dB.Then we're going to apply our usual tools, which we linearityexpectations plus a new tool, Ito's lemma,for evaluating functions for looking at changes in variableto get interesting results.Now in general, our goal is goingto be to apply Ito's lemma to functions of the form F of tand x, and--sorry, let's scrawl that up slightly.So we're going to apply Ito's lemmato things that are of the form function of tand a function of x.In the classic case, and one will be thinking most about--it's going to be the case of pricing derivative securities.So a derivative security is a securitywhose value depends on, is derived from,the value of something else.So the classic example would be a stock option,where x would be the stock price or possiblythe logarithm of the stock price,but x is related to the value of the underlying,t is ordinary time, and F is the valueof the derivative security.And what Ito's lemma tells us is,how changes in the value of the underlyingtranslate into changes in the valueof the derivative security.We'll look at this as we do oftenin differential equations, by takingwhat happened that infinitesimal time,and then solving for what happens in the general caseas we apply boundary conditions.So, what I'd like to do now is give a few examples,where we can just use some of the basic calculusand get used to computing Ito differentials.And there are a few things I'd like you to pay attention to.The first one is to look at the structure.So the basic structure of an Ito processis that, in an Ito process, it's alwaysof the form for an Ito process that we have--an Ito process is something times dtplus something else times dB.And we might need to massage thingsor move some terms around, or regroup or rewrite things.But if we can do that, then we'll be all set.That means that it's an Ito process.And the reason that Ito processesare interesting as a class is that, Ito's lemma tells usthat the differential of an Ito processis itself an Ito process.So that's what's going to be helpful.So what we want to do is, we want to look at the structurethat we have, in terms of the different differentials.We want to keep in mind which pieces are stochasticand which pieces are deterministic,which pieces are functions of time only,so they can evolve in time but in a non-random way.We want to see which things depend on what.Are there functions that are constant?Do they depend on t?Do they depend on B?Do they depend on both?If I'm computing differentials, noticethat in the formula for dF, that I have b, appears here,but a doesn't appear at all.So does that mean the dF is independent of a?Well certainly not independent of b.So when I've written little a and little b, remember,those are just the coefficients of these things.So we'll use different variables,I'll take different forms.I might even re-use letters a and b from time to time.But in this formula, in Ito's formula,this b squared means the coefficientof whatever is in the defining formula for dx,which is the variable with respect to which we'redifferentiating.So does this mean that dF is independent of a?Well, it looks like it in this form,but not really, because remember,this expression, which is a standard form Ito's lemma,contains a dx.So then this term is a dt, this term is a dt.We could group them together.The reason it's often written like this is so that we cansay, chain rule plus new guy.But in addition to that, we do have dx,which I could substitute in.It has a dt and a dB.And that of course, contains a.So even though the a isn't explicitly visible,we might think of it as being there.And you'll want to keep an eye on thesebecause they'll show up in interesting waysin different applications, whether things are explicitlyvisible or implicit in the language,or whether they're gone entirely.

#### Rec04_S02_v1-en

PROFESSOR: Here's our first exercise.Suppose I have a function, which is just a function of t and Bexplicitly.And it's t cubed plus B cubed.Can you find dF?So please pause the video, take a minuteto see what you can do.And then come back if you need a hint.And then I'll give you another chanceto solve the problem, with or without the hint.OK, just a hint in case you're stuck on thingsbecause this looks a little bit different,but it's actually a trivial special case.We wrote down Ito's lemma in terms of x,but this is just a special case.So we have here--this is really just a special case, where dx is equal to dB.And that means, in terms of our general expression,if I write this as adt plus bdB, thatimplies that a is equal to 0 and little b is equal to 1.So I find it sometimes helpful to write the assumptions outexplicitly.And that means that we can write Ito's lemma in this form.We can say that Ito's lemma is dF, is going to be partial of Fwith respect to t dt plus partial of F--now normally I would have written with partial of Fwith respect to x.But in this case, because d--sorry-- dx and dB are the same thing,we can write this just in terms of dB.So let's write this as partial dB plus the Ito term, whichis normally little b squared.But again, because we have that b is equal to 1,we can simplify this.And we can write this as 1/2 second partial of Fwith respect to B squared times dt.And now let's combine the first and last terms to get ussomething that we can use easily.So this is going to be partial of Fwith respect to t plus 1/2 second partial of Fwith respect to B squared.It doesn't matter whether you do thisbefore or after, of course, because additionis commutative.This is times dt plus partial of F with respect to B dB.So take a moment now, and see if youcan compute dF for our function F, whichis t cubed plus B cubed.OK, let's take a look.We have that F is t cubed, plus B cubed.So let's just compute the partial derivatives.Partial of F with respect to t is 3t squared.Partial of F with respect to B is 3B squared.In the second partial derivative of F with respect to Bsquared is going to be 6B.So let's take those results, plug them into our formulas.And we're going to have here-- thisis going to be 3t squared plus 1/2of the second partial derivative.That's going to be 6B divided by 2.That's going to give us plus 3B, all times dt,plus our last term just has a single partial, partial of Fwith respect to B, which is 3B squared times dB.So that's our answer.So we have a big 3 out in front, and wecould write this as 3 times t squaredplus B dt plus B squared dB.Question?Is this an Ito process?Answer.What do you think?If it is an Ito process, write down little a and little b.If it's not an Ito process, why not?Well it is an Ito process because we havesomething dt plus something dB.And in this case, let me call it a--maybe we'll call it a sub F. It'sgoing to be 3t squared plus 3B.So notice that's of the form function of t and B.And similarly, b F is going to be 3B squared.So that's our answer for this exercise.

#### Rec04_S03_v1-en

PROFESSOR: Now here's an exercise.Let F be the function of t and B,where B is a standard Brownian motion,be e to the minus rt times the sine of theta B.So r and theta are both constants.And what we'd like to do are two things.First, find the differential dF using Ito's lemma.Second, looking at the result that you have, considerthe parameter values, r and theta,and ask if there are choices of r and theta in terms of which,dF becomes particularly simple, whereit becomes only, either a function of dtor a function of dB.So pause the video.Take a few minutes to work on it.And then we'll go through the solution together.Now we'll use the simplified form of Ito's lemmabecause we have it in terms of B,not in a more complicated generalized Ito process.So let's take a look.We have that dx is just dB.So in our version of Ito's lemma,where we take differentials with respectto x, we can just replace them by B.And where we have the Ito term with little b squared--remember that in our usual notation, this is a equals 0and little b equals 1.So that simplifies.The next thing we do is we computethe partial derivatives, the three partial derivatives thatshow up in Ito's formula, of F. So we need partialof F with respect to time.That's easy.That's e to the minus rt times minus r times sine of theta B.So we can rewrite that as, minus r times F itself,if we'd like to.We can use either of those forms.We have the second partial derivativein the first partial derivative with respectto B. So partial of F with respect to Bis just equal to theta times e to the minus rttimes cosine of theta B.And the second partial derivativeis going to be second partial of F with respect to B squaredis going to be minus theta squared e to the minus rttimes sine of theta B. And that is the same thingas minus theta squared times F. Minus thetasquared times F because the e to the minus rtjust comes along for the ride.So let's just substitute with our results.So we have that dF is the partial of F with respectto t times to dt.That's going to give us a minus reto the minus rt sine theta B, all timesdt plus first partial with respect to B times dB.That's going to give us theta e the minus rt cosine theta Btimes dB plus the Ito term, whichis going to be 1/2 second partial with respect to bsquared of F times dt.So that's going to give us minus theta squarede to the minus rt divided by 2 times sine theta B dt.If we group the terms together we see,first of all, that everything--the common e to the minus rt out in front.That's good to keep in mind.And then the first term we're goingto have is going to be give us a minus rplus theta squared over 2 times sine theta B dt.Let's see.We wanted to have a big thing for our exponential outsideof everything.And we've got our second term.It's going to be the dB term.It's going to be plus theta e to the minus rt cosine theta B dB.And there we go.So this expression gives us our result or dF.So that's our expression.So it's an Ito process because it'ssomething times dt plus something times dB, OK?So if we want to write down these coefficient functions,we could say that we have a F is going to be minuse to the minus rt times r plus theta squared over 2 sine thetaB. And that's definitely a function of t and B.And B is going to be e to the minus rt times thetacosine of theta B. And that's definitelya function of time and B. Sorry, it's behind my head.So let's take a look at the expressionand see if we can answer the second question,are there values of r and theta, in which thiswould simplify to only be a function of dt or dB?Well it can't possibly be a function only of dB.Remember, the dB is our source of randomness.And we can't make the randomness go away just by changingvariables in a simple way.We're not going to turn somethingthat was random into something that's non-random that easily.We'll see some other ways to do that.But what about the first term?Well the first term is e to the minus rt,but now notice the coefficient function.It involves r plus theta squared over 2.So if I chose r to be minus theta squared over 2,then the first term would vanish.Usually, when we have r in our expressions,we think of r as being the risk-free interest rate.And normally the risk-free interest rateneeds to be a positive number.But keep in mind that, there certainlyare negative interest rates that actually do nowhappen in the real world, even though we normallywould think of r as being typically positive.And here in this example, this is notmeant to be a financial example.These are just arbitrary parameter choices.So we certainly could pick a special valueof r, in terms of which the coefficient function of twould vanish.And then we'd be left with just the term in dB.So, a simple case where we took a basic function,not additive but multiplicative, a function of r times--excuse me, a function of time, times a function of B,applied Ito's lemma, turn the crank and we get our answer.That's all there is to it.

#### Rec04_S04_v1-en

PROFESSOR: Exercise-- let F be the natural logarithm of B.Find dF by using Ito's lemma.Pause the video, take a moment to do it on your own,then come back, and we'll do it together.This case is especially simple.So we have that dX is dB.So we only need to worry about taking partial derivativeswith respect to B. There's no dt term in our underlying Itoprocess.And F depends on B only, not on time.So we have that the partial of F with respect to timeis equal to 0.The first partial of F with respect to B is 1 over B.And the second partial derivativeof F with respect to B squared is minus 1 over B squared.So let's compute dF.Well, dF is partial of F with respect to t dt.That doesn't exist.Then, we're going to have partial of Fwith respect to B times dB.Plus, we have the Ito term, which,because we've got this specially simple form for our Itoprocess, is going to involve just 1/2 timesthe second partial derivative minus 1 over B squaredtimes dt.So we're done.This is dB over B minus 1 over 2B squared dt.

#### Rec04_S05_v1-en

PROFESSOR: Suppose x is a stochastic processthat's defined by the expression dxover x equals mu dt plus sigma dB,where mu and sigma are both constants,and we'd like to find a function Fin terms of which dF is an Ito processwith constant coefficients.So take a moment to think about it.Think about how you'd approach it,if you can set it up, and then let's take a look at ittogether.I'd like to do this systematically.So you might have gotten it by inspectionor had a clever guess, or maybe you've seen it before.But let's see how we can work through this systematically.What we'd like to do is use the different waysthat we can write dF to solve systematicallyfor such a function.And we're going to do it by deriving some equations that Fhas to satisfy in order that the coefficients aF and BF wouldbe constant.So two things we want to do-- first of all,let's just identify our-- the parts of our function,our function dx, by writing dx isequal to mu x times dt plus sigma x time dB.So in our usual notation for an Ito process,we have a is the function mu x.B is the function sigma x.So that all just comes from here.That's direct.Now, let's apply Ito to dF using the expressionsthat we have worked out earlier.So let's say that dF is equal to something times dt.Well, what's the coefficient of dt?We have the partial of F with respectto t plus we have the Ito term, B squared over 2,which, in our case, is sigma x squared over 2 timesthe second partial of F dx squared plus we have a terma dF dx.So this is going to be mu x times partial of Fwith respect to x.And this whole thing times dt plus another term,which is going to be a little bit simpler--this is going to be sigma x, whichis little b, partial of F with respect to x, times dB.So this is the form of Ito's lemmawhere we combine terms into something timesdt for something times dB rather than something times dtplus something times dx.So in this term, what we'd like iswe'd like the things in these brackets.Let me make these red brackets now.This should be a constant, and so should this.Now, the second one has only one term.The first one has three.So why don't we work in the easy one first?So we need a function F so that this expression hereis a constant.That is, we need F t and x such that sigmax partial of F with respect to x is a constant.Well, I can easily move the-- we can divide both sidesof this equation by sigma.Divide that by sigma over here.And in the left, we'll do division by erasure.So I have this expression.That's just another constant.The sigma is a nonzero constant.So this says, what is the functionsuch that x-- partial of F with respect to x is a constant?Well, if F were a function of x only, that would be easy.So suppose if t and x is just F of x.Then we would have x partial of F with respectto x is some constant.Let's call it c.It's our old constant, which was unspecified, divided by sigma.In this equation, we can integrate.This just says that dF is equal to cdx over x, which tells us that F is equal to c times log x.So let's check this expression and seethat it satisfies at least giving a constant coefficientof our second term.We notice that if we come back up over here,we have x partial of F with respect to x, in this case,is going to be x times d over x.And it's equal to c, which is, indeed, a constant.And that's the term that went here.So, in fact, we would find that thiswould have coefficient sigma c, where cis our constant of integration.What about our term above?Well, let's continue with this form of x.So if F of x-- let me move out of the way--is the expression that we had here.And, in fact-- so it's something times the logarithm of x.The first partial derivative here is going to vanish.The second partial derivative is goingto give minus c over x squared.The x squared will cancel this x squared.And this will be a constant.There won't be any more x's.And over here, similarly, partial of F with respect to xgives me c over x.And the x multiplies this x.And those cancel out.And I'm left with a constant.So what we find is--so we find that the specific choice F of xequals c log x gives dF.It's going to be equal to c sigmasquared over 2 with a minus sign in frontfrom the second derivative term plus cmu, all times dt plus c sigma dB.And now let's let c equals 1.It's a little bit simpler.Since these are constants, anyways,we'll come back to our old friend.So this is equal to--let's just write this as C in front times u minus sigmasquared over 2 dt plus sigma dB.And this is the differential of F.So in the lecture, I wrote down the choiceof a function that was the logarithm of a stock price.And we derived this equation as a result--that we said that this equation for the logarithm of F was,in fact, integrable because both the left-hand sides--left- and right-hand sides were differentials.Now we see that we come to the same expressionif we ask a different question.That's how we got it to be differentiablein the first place.If we said, what functions are theresuch that the expressions we get are goingto be integrable with constant coefficients,the answer to that equation is the functionwe need is the logarithm.

#### Rec04_S06_v1-en

PROFESSOR: When we derived the Black-Scholes equationin lecture, it had two parts.An expression for the stock dynamics is an Ito processand then an expression for the derivative theused Ito's lemma.And then we combine the two in a portfolio, canceled the risk,and found a partial differential equation, whichhad no risk in it, and then we can solve thatby ordinary techniques.Now one thing that we might ask is,what if stocks don't follow random walks?What if stocks don't follow geometric Brownian motion?How important is that?Does the whole option-pricing relationship fall apart?Quite the opposite.So let's take a look.Suppose we have a general Ito process, where we have dS,is given by any function, a timesdt plus any other function b of t and S times dB,times the random part.Let's see what happens in our derivation.Which parts go through and which parts change.So remember when we did it before, we had previously,this was dS was equal to uSdt plus sigma S dB.So these were very special forms of coefficient functions. aand b in particular, they're time independent,they're linear in S. And that's it.So those were quite special, but let's leave a and bcompletely general.So that was one part.The other part we're going to leave identical.So let's let V is going to be a general function of t and S, isthe value of the derivative securityon the underlying security whose price is given by S.And you notice some places, I've had little subscripts, t,on my variables.From now on, generally, I'm goingto assume that we know that our capital letters arerandom variables, they're stochastic processes,and that they're time dependent.In our coefficient functions, a and b and F and V,our value functions, are going to be ordinary functionsbut they're functions of random variables.So sometimes it was convenient to put a little subscript, t,down here and over here, to remind us that theseare the random variables.But by now it should be clear in context that S or x or Vare always going to be functions, possiblyexplicitly of time, but they're going to be random variables.And those random variables are time dependent.OK.So what did we have for dV?Well, dV was given because it's a derivative,it doesn't have any choice.It depends on S. And what it depends on also is Ito's lemmaand that's just math.So it's given by--excuse me, we're working in v instead of f.Just a different part of the alphabet for a change.And it's conventional in literature,when we're talking about derivatives,that you can pick your favorite letter.So this is going to be partial of v with respect to tdt.Partial of v with respect to SdS.And then, plus the Ito term, whichwill be b squared over 2, second partial of F with respect to Ssquared dt.OK.So this b over here is the same one as this coefficient there.So all I've done is I've just left us in more general form.Let's follow the same steps.So this is, just to mark this up a little bit,this defines dynamics of the underlying.This is just Ito's lemma.We'll call it Ito's formula for V.And now we'd like to build a portfolio.In our portfolio, pi will consistof being long one derivative and minus a quantity, q,that I'll give the name delta, in this case.Think of them as shares of stock.So I have delta shares of stock with value S.So this is the value of the portfolio,and then we'd like to ask about its change of value,its differential.So we have d pi, is going to be dV minus delta dS.And when we combined terms, we sawthat this was terms with a dt times partial of Vwith respect to t.That comes from up here.| have my Ito term, it's going to be plus b squared over 2.Second partial of V with respect to S squared.And then I'm going to have a term, whichis going to be plus dS, and it's going to have partial of Vwith respect to S from right here.And it's going to have a delta termfrom here, which is delta dS.And because it's written in that form I reallydon't want to go to the trouble of expanding out this dS,writing it in terms of its original defining parts, do I?Because I can cancel it out right there where it sits.So our strategy was let's let delta equal partialof V with respect to S. That makesthe risky term on the right, on the second termof the right hand side, vanish.And then we can have an expressionfor a risk free portfolio.So if we set delta equal to partial of V with respect to S.If we do this, then two things happen.That risky term in dS vanishes.So that's one.And two, we would say that pi earns the risk free rate.Rate of interest.Because otherwise it would be arbitrage.So in that case, we have the d pi is going to be equal,on the one hand, dt times the first term and that's it.The second one will drop out.And this has to be equal to the riskfree rate of growth, which will be r pi dt infinitesimally.And that's our basic expression.Now, I'm going to do a little bit more elaboration on it.But up to here, what depended on the particular choiceof stock dynamics?So the answer is almost nothing.But the only thing that shows up, it depends on the formthat we began with up here.It does not depend on the sigma S.The sigma S does mean that when we get expressions like thishere, this would be sigma squared S squared over 2in the Black-Scholes equation.Here it's general.It's b squared over 2.What about the a term?The a term goes away.Nothing depends on it.It's dropped out completely.Well it's not completely dropped out.In a sense, the a term is part of dS,but we canceled the dS term.So whatever relationship there is between thea function in the stock, and the subsequent behaviorof the derivative, it's already been taken care ofor it's already been canceled out of the equation.It no longer matters when we have a portfolio thatbalances exactly the right amountof the derivative security in the right amountof the underlying.So we still have a b, which we haven't specified.So the only difference at this point,from our Black-Scholes equation, is that instead of b squared,we would have had sigma squared S squared.And then we expanded out and we have the same thingthat we had before.We simply write this as r times V minus delta S times dt.And now we notice that on the left hand, right hand sides,I have everything in dt.Moving everything to the same sideor if you'd like, dividing by dt,because there are no more stochastic differentials,we can put in our dt times partial of V with respect to tplus b squared over 2.d2 of V squared plus r partial of V with respect to S--should be rS--minus rV.And this whole thing is equal to zero.And therefore the coefficient, the thing in the brackets,has to be equal to zero.The thing that is the coefficient of dt.So that's it.That's our generalization.So given an Ito process, a general Itoprocess up here, in terms of anythingwith any coefficient a and any coefficientb, we've got the Black-Scholes equation, with the only thingthat we need to do is to substitutein the appropriate b.So here's your chance to try it out.

#### Rec04_S07_v1-en

PROFESSOR: An asset follows the Ornstein-Uhlenbeck process,which is a continuous time, mean reverting process if it'sgiven by the expression, dS equalslambda, which is a constant, times Sbar, another constant, nimus S dt plus sigma dB.This is in the continuous time analog of an AR1 process.This is the standardized Brownian motion, sigma dB,where sigma is a scale factor for the randomness.Over here, we see I've got mean reversion, whereif lambda's a positive constant, thistells me that if S is below S bar, this is positive.If this S is above S bar, this is negative.So this gives me a mean reversion force,and this gives me a random shock as time has evolved.So, just given this description, whichis quite different from the log normal, geometric Brownianmotion that was part of the original Black-Scholes-Mertonderivation, this is a different process.What PDE is satisfied by derivatives of this asset?Take a moment, and then we'll check together.What did you find?Did you rederive using Ito's Lemma?We don't even need to work that hard, we can justplug into our last result. We knowit looks exactly like the Black-Scholes equation,with exactly one change.We identify, in terms of our standard form,if we want to write dS of the form a dt plus b dB.That implies that we have a is equal to lambda, S barminus S, which doesn't appear in the differential equationwe want.And we have b is equal to sigma.In the Black-Scholes equation, itwould have been sigma times S.So the equation we want is partial of V with respectto t plus sigma squared over 2 second partial of Vwith respect to S squared plus rS partial of Vwith respect to S minus rV equals 0 and we're done.That's it.So the only difference between this and Black-Scholesis that-- the coefficient function here in frontwould have had an S squared in Black-Scholes.Here, it only has a sigma.The a function, which was mu S in the case of Black-Scholes.And here, it's something linear and S.It could have been cubic.It could have been any polynomial function or a morecomplicated function in S.It wouldn't make any difference.It wouldn't show up as part of the differential equation.It might show up elsewhere.And it certainly shows up if we wantto understand the dynamics of the underlying itself.But if we want to know about the derivatives,given the behavior of the underlying,our expression is easy to derive.And all we needed to do was, in our derivation,once we canceled the risk, the only part thatretained an explicit memory of the Ito process,was the Ito term, which had the coefficient B squared,the coefficient of the randomness in the original wedefined process.

### 04-Problem_Set_4_11_Questions

## 08-Week_5-It_Calculus

### 01-Overview

### 02-Lecture_5

#### CT06_S01_v1-en

PROFESSOR: Now, the Black-Scholes equationthat we just derived is one of the most important equationsin modern finance, and the derivation only took ustwo slides.But I pulled a fast one.Can you tell where?The derivation, remember, assumedthat the number of shares was constant, right?But then we found that the number of shares that we neededfor delta in order to do our hedgewas partial to V with respect to S.But when we solve the equation, wefind out that V depends on S and on time,and therefore, delta is going to depend on S and time.And therefore, delta actually isn't constant at all.So this contradicts something thatwas an essential assumption of our derivation.Now, we're going to do a little bit of a digressionhere, and let me give you the short versionso that you know our result is OK.The derivation was a little shaky.So we're going to go through it more carefully,and we'll be much more solid ground,but the end result is the same.So the derivation I showed you was very quick,it was very slick, but it a cheat.It was wrong.The intuition was right, and you can apply similar intuitionin other cases.But there's some deeper mechanisms going onthat we should take a look at, and actually, it'spretty nice too.So what was the problem?The problem was that when we had a differential that we shouldhave taken, the differential of delta S,we just said, oh, that's delta dS.That is, we treated the delta as being constant.What we should have said is, hm, maybe weneed a generalized chain rule to apply to cases wherewe have a product rule, where we havea product of two processes or two random variables.So at a minimum, we should have been cautiousand at least written the differential of delta Sis delta dS plus Sd delta plus maybe a higher orderterm, d delta dS.And then we'd have to figure out what each of those thingsmeans.So to do this right, we're going to bring in oneextra financial instrument.We started with an underlying, the stock,and we had options, or our general derivative V,and now we're going to include cashbecause if you think about it, I said things are growingat the risk-free rate, and we're dynamicallyrebalancing our portfolio, but we're doing it with what money?We need some cash to be able to buy and sell sharesto execute our delta hedge.So our dynamic trading strategy that we're going to look atis as follows.We're going to buy and hold our derivative.We're going to rebalance our stock position,but it's going to be self-financing,so we're going to start out with no money, but a lot of credit.We're going to assume that we could lend and borrowat the risk-free rate, an arbitrary amount,and that the stock purchases and sales are funded directlyfrom that account.So if I'm going to short sell shares worth $10,000,I take in $10,000 to the cash account,and I've sold short the shares.If I need to buy long $20,000 worth of stock, I buy it,and my account balance in the cash accountgoes down by $20,000.And if I'm earning interest at the risk-free rate,that accrues to the cash account.And if I'm borrowing money, if the balance in my cash accountis negative, then I need to pay interest.But interest, either way, regardless of the sign,it's always going to be the risk-free rate timesdt times the quantity in the cash account.Now, I've made a bunch of assumptions,so let's be explicit about what they are.These are all idealizations for the real world.First, I assume I have unlimited credit,so I can lend or borrow as much as I want.I'm assuming that I lend and borrow at the same rate,at the risk-free rate.In reality, it costs a little more to borrow,and you earn a little bit less when you lend.I'm assuming that the stock can be tradedin fractional quantities, so I'm notgoing to restrict delta to be an integer.On the other hand, so is that a bad assumption?Sure, because we can't really trade fractional shares easily,but in an institutional setting, we'renot buying a single option.In fact, a single option contract in the United Statesis on 100 shares of stock, and we might buy many contracts.So we can be concerned about rounding errors,but generally, this won't be an issue because we're notdoing this for a single option.We're assuming that we have full useof the proceeds of short sales, somethingthat is actually limited because we have to keep collateral.We're assuming that there are no dividends for this,no transaction costs, no delays, no market impact.So a whole bunch of frictionless trading assumptions, justfor purposes of our derivation.

#### CT06_S02_v1-en

PROFESSOR: Now, I'd like you to give you a pictureand have you keep this picture in mind, because it'sa discrete picture, and then we'regoing to let delta t go to 0 again.But in many ways, a discrete pictureis important and gives us some insightinto what's going on in the Black-Scholes world.So what I'd like to do is think of each of these segmentsas being related to a given trading period.And we'll think of this as being a trading day.And in fact, this is how many option traders and marketmakers do trade.They think of re-hedging, let's say, once per periodor that might be once per day.So what I want to do is I want to thinkabout opening an initial position here at the beginning.And then there's intraday period and then the end of the daycomes and we observe the closing prices at the end of the day.I'm going to assume that very close to the end,let's say a minute 30 seconds before the equity marketsclose, that there's a lot of activity and liquidityin the markets and that without waiting for the sharesto close, they're not going to move very muchbut that I can buy or sell sharesto set a new delta position to have for the following day.So here's what I assume.At the end of each day, I'm goingto observe the price of the underlying,but I'm also going to use that information to constructa new hedge position.And then I'll wait for the next trading dayand at the end of that day, I'll repeat the process.So I've broken this set of steps into two parts.One of them is that when the market is open,the quantities that we have are held fixed,but the prices change as the market moves.So prices change, but we're not doing any tradingduring the day.At the end of the day, the prices no longer move.I'm assuming they move very, very little during the timeit takes us to do this.At the end of the day, as I rebalance,the prices are held fixed, but the quantities change.So from an accounting perspective,the rebalancing is just exchangingone asset for another.We're exchanging cash for stock of equal value.OK.So we've got two things.We've got the end of day rebalancing and fixed priceand we have the intraday market evolution dynamic stock priceevolution, dynamic option price evolution while we're holdingthe quantities constant.And when we look at the real world prices,we see this is an example, a screenshot taken from Bloombergwhere we can see the price in Spotifyover several intraday periods.You can see that on some days, the movements are jaggedand look stochastic.And I've left out the overnight period.And the next day begins more or lesswhere the other one started.But that's not always the case.Sometimes we do observe jumps and there are very big changesfrom the close on one day to the beginning of the next day.And we're either going to be excluding thator it won't really matter because we'regoing to be jumping from one end of day closeto the next end of day close.So whether this dropped immediately on the openor at some point during the day, the main driver for our resultsis going to be where it ends up on the following day.SoLet's leave the derivatives out of it for a momentand look at a rebalancing conditionfor this self-financing portfolio.So let's let x be a portfolio that initially has value 0.But again, I've got a lot of credit.So it can have stocks and bonds.And I'm going to just call our interest bearing instrumentscash.Instead of money market, instead of a bond,I'll refer to it as cash.So let's assume that I have a portfolio x.X is the value of the portfolio.And I can have stock in quantity qand I can have cash in quantity C. S is the value of the stock.M is the value of money, which willgrow with the risk free rate.So when I initially set up my portfolio,I started with no money.I'm going to end up with no money.So my initial setup doesn't require any money.And subsequent rebalancing never changes the portfolio value.That is, if I want to be long stock at a positive price,I'm going to need to have a negative cashbalance to finance it.If I'm going to be short stock and this is negative,I'll have positive cash.And the amount of cash is determinedas C is going to equal minus qS over M, the value of money.So it's as simple as that.When we look at rebalancing at the end of a day, soat the end of a day, the prices aren't changing.And I look at the value from post re-hedgingcompared to pre re-hedging where I changedthe quantities of stock.What do I get?Well, simple arithmetic.So I've got S times the change in quantityfor the trade I do for re-hedging plus M timesthe change in quantity in cash.That's the change in value of the portfolio.But because everything-- none of the prices are changing,we're just shifting one asset into another.That value is equal to 0.Now, let me just rewrite that.Because what I'd like to do is I'dlike to shift the end points a little bit.So instead of ST and MT here, I'dreally like to have ST minus 1 and MT minus 1.Because these represent a change in valuein the future from T minus 1 to T. And I'd like this to be--I like to think of this as being a random variable,and I want this to be non-anticipating.So I'd like this to be at the beginning of my end pointrather than at the end of the end point over here.So I can do that at the cost of adding two new terms justto cancel the stuff I added.And that gives me these terms down below.And this is just arithmetic.This is an exact equality.Now if we think about turning this into infinitesimalsin continuous time and we recognizethat this whole thing is 0, we have the following equationthat represents self-financing.Sdq, which is up here, plus MdC plus dSdq plus dMdCnow is equal to 0.So this equation here holds when our rebalancingis self-financing, when there's no new money coming in or goingout.

#### CT06_S03_v1-en

PROFESSOR: Now we're almost ready to do Black-Scholes.Let's consider our portfolio.But now we're going to augment pi by including cash.So before I wrote down that pi was V minus delta S.And that was partly to lure you toward the answer.Let's be much more open minded about what the number of sharesis, and just leave it as a generic q,and yet put in a plus sign here for Q.So we're going to have to solve for everything.So my general rule for the portfoliois, I have the value of 1 option plus the number of sharestimes the value per share plus the amount of cashtimes the value of the cash, and that'sthe value of a portfolio.So what happens to this portfolio as we rebalance?Well, we think of our picture.And we've got the rebalancing.And we have the dynamics between two different periods.So the rebalancing, we know that the value doesn'tchange by accounting rules.We're just changing one asset for another.So what happens between two rebalancings,that is, over the time scale of one market day?Well, we're holding-- remember our picture,over the market day, we're holding our quantities fixed,and the prices are changing.So the change in value in the portfoliois a change in value of the optionplus this quantity is held fixed, the stock changes value,the cash balance is held fixed, and possiblythe money changes value where we're earning interest.If we go to the continuous time limit, and go to differentials,we see that we can write that as d pi, as dVplus d of qS plus CM.That is, I'm just taking the differential of my top line.Now, let's expand it out.This is dV plus--and let's keep everything from our product rule.I have qdS plus Sdq, which I've put out here.I have C plus dqdS.I have CdM plus MdC plus dCdM.And I've grouped these this way for a reason.These four terms are just a self-financing conditionthat we saw previously.So these four terms together are allpresent on the right-hand side, but collectively they equal 0.So our expression gets a lot simpler.d pi is dV plus qdS plus CdM.Now we recognize that dM, the change in the value of money,is just our rMdt.That's the risk-free rate.Finally, we can take CM--which, we don't really want to see moneyin our equation anyways.Come back up here, and we can replace CMby pi minus V minus qS, which I've done right here.So now I have an expression for d pi.dV plus qdS plus r times this quantity times dt.Now we want to look for a dynamic trading strategywhere the number of shares that we have, q, not onlyis we're not going to assume it's constant.We expect it to be changing.In fact, that's going to give us to rule for howwe can execute these hedges.That's going to give us the rule for how we can actuallyeliminate risk.So the reason we can do this, and wewould expect this to work, is there'sonly one stochastic driver in the entire problem,and that's the stock.So we have that dS term.And we know that the stock moves,but the value of the derivative is random, the value of Vrandom through its dependence on S. So we've got one driver.We have two, possibly three instruments.Maybe we can cancel it out in a dynamic way.So let's take a look.I'm going to take my previous expression.And all I'm going to do is, in place of dV,I'm going to use Ito's lemma.So I'm going to have this set of terms, dt plus partial of Vwith respect to S times dS.And this term over here comes alongfrom the ride from the previous slide.Notice that, if I group my dS terms together--OK, I have this is a dt term, this is a dt term,I've got my dS terms here.Can I make this coefficient go away?Yes, we can.If we define q to be minus partial of V with respect to S.And that corresponds to what we called minus delta before.But now, notice that we're not assumingthat anything is constant.In fact, we're requiring that we trade such that q alwaysis equal to partial of V with respect to Sso that the risk is always balanced.We can do that instantaneously.When the prices change, we might need to retrade.So this dynamic rehedging lets us eliminate riskat the cost of possibly doing a lot of tradingover very small intervals.Finally, with this choice, we can go through and simplify.And we'll find that we get the same Black-Scholes.Equation again.This term here goes away.Everything else we group together, has a dt in it.We look for the coefficient of dt and setthat equal to 0 because we've said d pi is not changing.And we finally have-- because rememberd pi is not changing now because pi includes the cash.And the interest is all incorporatedas part of our portfolio.So we started with a portfolio with initial value 0.It's self-financing.There's no money coming in or out.There's no risk.So it began with value 0.It stays 0.The rate of change is 0.And that tells us that this big expression in parentheseshas to be 0 for all time and for all values of Swhere the option is alive.That's prior to expiration.And that gives us the Black-Scholes.Partial differential equation once again,this time without cheating.So the lesson to take away from this, apartfrom two different derivations for getting Black-Scholes.Equation is this notion of, number one,that we have a self-financing portfolio, that thisis a self-contained closed world where we're able to rebalance.And because we have these multiple instruments and onlyone source of risk, we're able to cancel out the risk.By looking at the rebalancing, though,even though we're back continuous time,by having broken it into two parts--the rebalancing where we hold prices fixed and changequantities and the evolution periodwhere we hold the quantities fixedand the prices can change--that becomes hard to distinguish if we do everythingimmediately in continuous time.But it is important that we do things in a nonparticipatingway.So these are discrete.That is, we need to observe, and then trade, observe,and then trade, no matter how small the time intervals.We can't do it in the opposite order.If we could see the future prices and then trade on them,that would be a terrific source of riches.Unfortunately, real markets don't work that way.And our mathematics needs to respect that.

#### CT07_S01_v1-en

PROFESSOR: Let's summarize a few key formulas.Ito processes are our generalized random walks,our generalized processes that have the form a dt plus b dBwhere little a and little b are, in general, functionsof x and t.x, in our example of stock prices, is s- is price--but it may take different values.Ito's formula tells us, for stochastic processes of the Itotype, Ito's formula from Ito's lemmatells us how to compute differentials.And they have an extra term relative to the ordinary chainrule.We have first partial with respect to t,first partial with respect to x, and then wehave a second partial with respect to x but timesdt instead of dx squared.We remember the heuristic-- that every time we seea d b squared, it's worth a dt.Every time we would have seen a dx squared,it's worth a b squared dt, where little b is the sameas the coefficient up here.Our most common and most popular Ito processis the standard stock price formulathat's written as dS over S is mu dt plus sigma db,or multiply thing through by S so that we can correctlyidentify the coefficients a and b,we can write this is dS is mu S dt plus sigma S db.We saw-- and you should check and be familiar with this--that if we apply Ito's lemma to the function f equals log S,we derive, on the right-hand side,that the differential of log S-- thisis an exact differential on the left-hand side,and on the right-hand side is an Ito processwith constant coefficients.The sigma parameter now doesn't have an S in here,and the mu is shifted by an amountminus sigma squared over 2.To derive the Black-Scholes equation,we combine this stock price evolutionwith a hedging algorithm where wepick a number of shares delta that'salways equal to partial of V with respect to Sto hold short.We assume that our portfolio grows at the risk-free rate.And we're able to eliminate risk by dynamically hedging.And that tells us what the value of a derivativemust be in order to avoid arbitrage.It's given by solutions to this equation.What I want to do is just show a coupleof tweaks that we can make to the equation.And then we're going to turn to lookingat how to solve the equation.The way we're going to do it is, we'regoing to simplify the equation.This is pretty complicated to solve, and along the way,we're going to turn it into a much simpler differentialequation.We'll take a look at that equation for a while.It's called the diffusion equation.And then we'll recover it back in our original Black-Scholesvariables.First, some of the overall properties.The equation is linear.And that means that the sum of two solutions,or any linear combination of solutions,is always a solution.Now, in boundary value in partial differential equations,we sometimes look at initial values.We sometimes look at boundary values on the sides.But what's special about our application for finance--it's a little bit different from what you wouldsee in a typical PDE textbook.Is, instead of initial conditions,we're going to specify a terminal condition.That is, when we think about options,we know what they're worth when they expire.We want to know what they're worth before expiration.The payoff is contractually determined at a future date,and we're going to have to work backwards in time.Luckily, we'll see that the signs in our equationwork out just right for that.Now, there are a whole bunch of other assumptionsthat go into this.In particular, we're looking at a special stock price model--namely, geometric Brownian motion.But a lot of what we said could go throughfor other kinds of processes.We can change the process to some of the examplesI showed you earlier.And we might ask about generalizing furtherwhere some of the things that we've held constantperhaps become, themselves, dynamic over time.What happens if volatility changesover time, which seems to be a real-world phenomenonin financial markets?What if there are limits on the allowed prices?There are lots of generalizations we could make.Let's take a look at a few easy ones.One of them is that I neglected dividends.And if you've studied options before,you know that discrete dividends are a big deal.There's a theorem about early exercise.Now, the dividends I'm going to discuss hereare not discrete dividends, which we usually wouldhandle with different tools.But I want to think about a continuous dividendyield, which is one way that we typicallymodel indices or portfolios.We think that if there are a bunch of stocks thatget dividends at different times,we'll just kind of average this out smoothly.The important thing is that, if dividends arrive at a rate D,we might think that the dividends arekind of offsetting the interest rate.But there are two reasons--there are two places where the interest rate entersthe equation, and only one place where the dividends show up.So it's not just a shift in the risk-free rate.The holder of the stock gets dividends,but the holder of the option does not get the dividends.That's the whole thing behind the timing of early exercise.The Black-Scholes equation is modified,but it's not just a straight substitution of r.It's a substitution in this term,because the stock is earning dividends.We could think of currency options,which are on foreign currency.And we don't just trade suitcases full of cash.We trade interest-bearing instruments.On currency options, we receive a foreign interest rate, whichis equivalent to a cash inflow.Again, we've got to change to our cash.And again, it's not just a straight-out substitutionof the interest rates.Here, we've got to change to r in this place.This r stays the same.We have another adjustment we can make in commodity options,where we have a cost of carry.It doesn't cost anything to store a stock option.It does cost something if you have oiland you have options on oil.Having an oil option doesn't cost anything, but having oildoes cost something.Having gold does cost something-- to store it,to have security for it, possibly to transport it.So when we look at physical commodities,we typically include a cost of carry for the durationof the contract at a rate q.And guess what?That shows up in this term.And once again, the other interest rate termis unchanged.Options on futures are an interesting case,and we can get an equation calledthe Black equation, which Fischer Black did on his own,without Scholes.And we do this by changing the valuefrom the spot to the forward price.Keep in mind that there is discounting.We can think about present values.And in fact, we'll see that one reason there'sa lot of complexity in the Black-Scholes equationis because we didn't build discountinginto it to begin with.You can see that the equation simplifiesa lot if we were to set the interest rate equal to 0.But there are two things we might potentially discount.One of them is S. The other one is V.Let's take a look.If we change variables so that wedo things in terms of the forward price insteadof the spot price, I can introduce this script F,which I've done because we used Fbefore for a general function.Here, I'd like this F to representthe forward price that's related to the spotprice in the usual way.And we substitute in-- use the ordinary chainrule, because there's nothing special about this pre-factor.F and s are both stochastic, but e to the r t minus t is not.And we get a simpler equation.One of our terms from our original Black-Scholes equationdropped out.And that's telling us, what that equation really was doingwas accounting for the fact that weshould think about the present value rather than the spotvalue.In those terms, my Black-Scholes equation nowhas only a term with a time derivative,and with a second derivative with respect to the under line,the first derivative term went away.And I still have the constant term that's left over.Now, what I would like to do is, Iwould like to compare this with another well-known equationcalled the diffusion equation, which I've writtendown here at the bottom.The diffusion equation-- you'll notice both of these equationshave a term partial of V with respect to t.The next term-- they both have a 1/2.They both have a second derivative with respectto another variable over here.This has a pre-factor.This one doesn't.This has a plus sign.This one has a minus sign.And of course, there's this extra leftover term right here.But the first two terms are intriguing.And we're going to go a bit further and seeif we can get the original Black-Scholesequation to be related to a diffusion equation.

#### CT10_S01_v1-en

PROFESSOR: Now let's look at using the Ito calculusand the tools of continuous time finance in settingof fixed-income modeling.So far, we've looked mostly at the classic examples of stockas a random continuous time process,looking at the evolution of the stock price,and we've looked at derivative pricing in termsof an option on the stock.When we go to the world of bonds,we'll find a bunch of interesting things.First of all, interest rates are dynamic.Now, when we saw interest rates in looking at stock optionsand deriving the Black-Scholes equation,there was a single variable r, whichwas held to be a constant, the risk-free rate.In fact, interest rates change over time,and interest rates change over time unpredictably.So they're in fact random variables, not just parameters.Interest rates aren't tradable.So although we'll have a random driver that, in many ways,will have the same properties and same kind of Itodescription as we had for stock prices,our hedging arguments won't necessarilygo through the same way, because we can't tradeinterest rates themselves.Interest rates are the term structure.That is, there are different interest rates associatedwith different maturities of bonds and, of course,different levels of creditworthiness.So even if we're looking at risk-free bonds thathave no default risk, they may still have risk in the sensethat market rates, interest rates can vary.There's a term structure.So we don't find the same interest rateon a one-year bond, a two-year bond, and a 30-year bond.These term structures themselves change over time.And they're a very important subject for modeling.And they not only change over time,but they do so in ways that are unpredictable.So it's natural to model the entire curve not justa single point or a single interest rateas being stochastic.The bond prices are determined in relationto these interest rates.But there may be a lot of bonds associated with a single rateor with a particular set of rates.So there are many interrelationshipsamong the different interest ratesand across the entire yield curve.And interest rate derivatives on futures, bond options, interestrate swaps--a whole variety of other derivative contractsdepend on all of these features.So here's a snapshot just taken from Bloombergof a bunch of US securities.And we see that there are securities that trade.They have different interest rates.They're quoted in price.They're quoted in yield terms.They're quoted with different expirations.And we can find this across various sovereign debt markets.And of course, the corporate market is even larger.Here's an example of what I meant by the yield curve.We're looking at the interest rate, the yield to maturity,for US bonds.And this curve shows us the interest ratein percent on the y-axis against the termor tenor on the x-axis.So we see a characteristic shape wherethings are rising over time.We get higher interest rates if we go farther out.But also notice, there's some curvage area here.We're convex here, and we become concave.There's a point of inflection.If I look at a different point in time--for example, I look at a point one year prioror a month prior, I might see a different shapeand a different level.So this curve up here, notice, is downward-sloping.It's an inverted curve at the beginning, and then it rises.So all of these rates are higher than the ones down below.So the curve is moved up.But it's also changed in shape, and it's changed in direction.So what are some features that areconsistent with basic principles of finance?What are the mathematical tools we have to describe them?And then, what kinds of predictions can we make?That's a subject of fixed-income modeling.And we can pick different kinds of variables,which may be closely associated, but mayhave different interpretations.Now, suppose we want to take a look at how to price bondsin the same way that we looked at howto price stock options already.Now, the pricing of bonds has a few twists.First of all, which interest rate should we use?What should they depend on?There's not a single risk-free ratethat showed up in our calculationsbefore that we could use for discountingor for risk-neutral pricing.Now, risk-free bonds of different maturitiesall could lay an equal claim to being the risk-free rate.It's tempting to take a look at the short rate, the shortestmaturity bonds, but--because they seem to be special because they'reat one end of the curve rather than some arbitrarypoint in the middle.But really, between any two points in the curve,we can ask what a view that represents for how ratesmight evolve in the future.And they all contribute to our notionof what we should think about as beingthe relevant risk-free rate, especially when wehave multi-period problems or multiple time horizons.We can't just content ourselves with pickinga short overnight rate saying that's it;let's be done with it.So interest rates aren't constant in time.They're not deterministic.We do need to model them as random variables.But we also need to keep in mind that whatgets traded are bonds, are generally bonds, or derivativeson bonds or on interest rates, but not the interest ratesthemselves.Those can't be traded.So the bonds come in-- and I'll talk mostly about bonds.But bonds come in a variety of maturities.And because we have multiple instruments all trading basedon the same kind of principles, wemight expect there to be some no-arbitrage constraintson the relative prices of bond.So here's an idea.What we'd like to do is look for a way to price all bonds,or all bonds from a particular class,of all maturities in a way that avoids arbitrage and thatminimizes or leads to a fixed number of stochastic factors.We could try to model each bond independently,but that would not be a great description of realitybecause they do have commonalities.But also, we really want to be able to take advantagein thinking about portfolios and thinking about possibilitiesfor arbitrage and how no arbitragecan inform pricing relationships, about howthe bonds that are connected to common rates,they have relationships among them.So let's take a look at the simplest example.We're going to imagine that we have bonds that do dependon a single, random variable.And that random variable, we'll saywill be what we call the short rate, whichis a-- think of not just as being an overnight rate,but as being an instantaneous spot interestrate, the rate we can get right now for infinitesimal duration.So this isn't tradable.You can't buy it.You can't buy a bond for that.You can't invest in it.But it's kind of clear that it might be approximatelyequal to what we would see for very short-term, say,overnight rates.So let's think that that might beone of the variables of interest in describing our yield curveand describing bonds, certainly, whatthey're worth a very short period of timewould inform arbitrages.So let's imagine that we have a variablethat we'll call y for the short term--this short instantaneous rate.So let's think that we want to have a pricing formula wherewe have the price of a bond; let's call it V.It depends on time.It depends on the current time.It depends on big T--I'll let it be the maturity of the bond.So let's think of that as being a fixed time in the future.It's a parameter of the bond; it's not a variable.And y, little y where I've written a subscript tto remind us that it's time dependent-- to beour random variable.And let's let y be described by an Ito process.So dy is something of the form a dt plus bdB.So in this structure, what we're doing iswe're imagining that the short rate, y,which is an observable, is neverthelessdescribed by an Ito process, and the valueof bonds of all maturities depend on that variable.It might depend on other things too.But let's start with the one-factor picture.And let's see where that leads us.

#### CT10_S02_v1-en

PROFESSOR: So how can we generalizethe work we've done so far to this new setting?How do we find a partial differential equation thatdescribes the prices of bonds?Remember that in the case of stock options,we had a definite underlying that was tradable,and we built a portfolio of the stock with the derivative.But here we have a whole bunch of bonds,they're all on an equal footing, and none of themis actually the random variable of interest.So the thing that we know that's described by an Ito processis the short rate, and the prices depend on that.So how can we generalize things?How can we set up a relationship that could lead to a PDE?What kind of instruments can we use for hedging?Now what we'd like to do is first,let's count our stochastic degrees of freedom.We've got one.We have a single short rate.And of course, this generalizes for more sophisticated models,but let's just start with that.It's not tradable, but we have a whole bunchof bonds, all of which depend on that rate.Since there are multiple bonds, they allhave a dependence on that single factor,if we put them together in a portfolioand we think about dynamically rebalancing the portfolio,it should be possible to cancel out the riskand determine a PDE that gives us the relative relationshipamong bonds.How many bonds?Why don't we start with two?That would let us cancel the common source of riskto both of them.Which two?Take your pick.So let's see what we can do.We're going to start with the one-factor model,and we're going to assume that all the bondprices depend on this single stochastic variable,the short rate.So what we'll do is we'll take two zero-coupon bondsof different maturities.We'll think of them as being T1 and T2 and the valuesas being the V1 and V2.And we'll create a dynamic portfoliothat's going to be risk-free.Where do we start?With Ito's lemma.So for each bond, Ito's formula tells usthat the DV, the differential for the value of the bond,is given by partial of V with respectto t times dt plus partial of V with respectto y dy plus the Ito term, which here I'vegrouped with the coefficient of dt that'sgiven by the usual form, b squared over 2 second partialof V with respect to y.So keep in mind now that this is analogous to whatwe saw for stocks where s is replaced by y,and the b squared is going to depend on the particular modelthat we have for the short interest rate.But our portfolio doesn't consist of any y's ,it's only going to consist of v's.Let's see how that goes.So we're going to do is let's builda portfolio with q1 bonds of value 1 and q2 bonds value 2,and we'll call this value oi, and we'dlike to eliminate risk.Well, we can do that in exactly the same waythat we did before, by choosing an appropriate ratio of q1and q2.Now keep in mind, when we looked at the stock option case,we thought of keeping a single option in a variable numberof shares of stock, but there wasno reason we had to do that except partly,historical interest, and partly, the realities of tradingin the market, which is that stock ismuch more liquid than options.But we could have held one share of stockin our hedging argument.It would've gone through exactly the same wayif we'd varied the number of options that we had.And in fact, the overall scale doesn't matter.What matters is the ratio of the numberof shares of one instrument relative to another.So the same thing holds here.But this time it's actually a little bit clearer,because v1 and v2 are on equal footing.So if I build a portfolio with q1 units of bond 1,q2 units of bond 2 that have maturities t1 and t2,and I choose these ratios in this particular way--that are given by the ratios thatlook like what we previously called the delta in the caseof the stock option--then, and if I apply Ito's formula to this portfolio,I can cancel the risky terms.I can cancel the coefficients of dyand be left only with something in dt, the same waythat we eliminated risk in deriving the Black-Scholesequation.So what do we get?By combining the portfolio in this waywith the specially chosen ratio of q1 to q2,we can see that our portfolio pi earns the risk-free rate.So instead of r times pi dt, now because it'searning over an infinitesimal period of timeand y is the short-term interest rate,I have the d pi, because it's risk-free,is going to earn y dt times the value of that portfolio, pi.So it's earning a risk-free rate at rate y.If I expand the differentials and Itake account of the cancellation from q1 and q2,the terms that don't cancel give me this expression.I've got a sum over 1 and 2 for q sub i of dV dtplus b squared over 2 second partial of Vwith respect to y squared, all times dt.So this left-hand side is all somethingthat's proportional to dt.It's got a bunch of partial derivatives,a bunch of quantities in front, and it's somethingthat's deterministic.On the right-hand side, I also have something proportionalto dt.It's y times the value of the portfolio itself.So notice now the structure that we've got.The last time we did this for deriving Black-Scholes,we had a whole bunch of terms thatwere all coefficients of dt.We said the only way that that could holdis if the coefficients of dt were themselves equal.So that is, this summation here shouldbe equal to y times q1 v1 plus q2 v2.Now notice that we've got a bunch of 1s and a bunch of 2s,and they're separate.So we have a bunch of terms that sum with q1 and v1,and a bunch of other terms with q2 and v2.And one of the standard techniquesfor solving and organizing differential equationsis to separate variables.So let's choose, not just the ratio of q1 over q2,let's set the scale, let's pick a particular value.So here's a convenient one.If we take q1 to be 1 over--let's see if I can get my pointer back.If I can take q1 to be 1 over partial of V with respect to y,assuming that's non-zero, and q2 to beminus the similar kind of thing, younotice these two choices will satisfy this ratio.That's all I need.And when I go back to my expression for Ito,you see that that will be sufficientwhen I multiply q1 times this term with v1 and q2with that term to v2, that will cancel out the dy terms.So this particular choice not onlycancels out the dy terms that's already given by this ratio,but it lets us separate the v1 and the v2 terms completely.So here's what we get.Let's equate the coefficients of dt.Let's group the terms together.Let's put all the v1's on the left,let's put all the v2's on the right.And because that minus sign in front of q2,we have the following nice symmetrical expression.We have one equation in terms of two unknown prices, v1 and v2.So I have this expression in v1 is equal to this expressionhere in v2.And let's look at the structure for a moment.In the numerator, we see that most of these terms, theseare three of the four terms that showed upin the Black-Scholes equation, partial of V with respect to t.I've got a b squared over 2 second partial with respectto y minus v1.And then I've divided by partial of v1 with respect to y1.That's my q.And over here, I've got the same thing,but just with all the subscripts 1 replaced by subscripts 2.So it's different from Black-Scholes.Before, I had an expression for a single variable v,and I set it equal to 0.In this case, I have two expressions, one of them in v1,one of them in v2, and I set them equal to each other.Neither of them is equal to 0.So it doesn't look like we made a lot of progress.Again, one equation for two unknowns, v1 and v2.But let's think about the structure for a moment.Because all the v1's and v2's are isolated--and remember that the v1's and v2'scorrespond to the prices of bonds of different maturities--that really tells us something.Because the expression on the left depends on T1,the second expression depends on T2.But these two expressions are equal to each other.And the one on the left doesn't have any T2's, the oneon the right doesn't have T1's.How could that be?The only way that this expression can hold,that we can have these two thingsequal to each other, that this can be equal to this,is if neither of them depends on T1 or T2.That is, this entire ratio as well as this oneneed to be constant.They need to be independent of the particular bond.They can't depend on the bond's maturity.They can't depend on anything else for the bond.They need to be something that depends onlyon time and on the short rate, whichare the two things that they have in common.Anything that's bonds specific can't appear.So it's in the individual terms, the v1and its partial derivatives are there,but that particular grouping of partial derivativesand all those different terms in the numeratorsneed to be such that all of the explicit things thatare bond-dependent cancel out.So because each side needs to be independentand they're both equal to each other,we can give that thing that they're equal to a name.And we'll call it f.We'll call it f, and we'll say it can depend on t,and it can depend on y.So it's some unknown function.It's not 0, but it is something that doesn'tdepend on the individual bonds.And in fact, this is not only true for bond 1 and bond 2,which are arbitrary.It has to be true for all of the bonds,no matter what their maturities are.So here's what we found.Now we have a differential equation for the bond pricing.We've got the equation for any bond with any subscript i,we have this Black-Scholes-like equation,partial of V with respect to t plus second derivative,this our diffusion term, with b squared over 2--b comes from the Ito process defining y--minus yV.Remember, this looks like our minus rV term in Black-Scholes.But now instead of r, it's replacedby y, which is dynamic.It's not the constant risk-free rate.It's the dynamical random variable.And then I have this other term, f of y--which is a function that we don't know, it's unspecified--times the partial of V with respect to y,that we get just by multiplying through and clearingdenominators.And that whole thing is equal to 0.And what do we have for a boundary condition?These are zero coupon bonds that are typicallynormalized by saying that at maturity, theypay off $1 or one unit.We can pick a different normalization if we'd like.So they have the normalization, then at maturity,they're equal to 1.But at times prior, their value'sdetermined by this differential equation,and the maturity is one of the defining featuresof the particular bond.

#### CT10_S03_v1-en

PROFESSOR: Is there a financial interpretation to the mysteryfunction f of t and y?Well, here's one.We can think of it in terms of the risk premium on the bond.So the bond's Ito process can be written as usual.From Ito's Lemma is dV something times dt plus somethingtimes dy.And let's put it in standard form.We will rewrite it as something times dt plus something timesdB.So the coefficient of dB is what we usually think ofis being the volatility.And it's associated with the randomness.If that coefficient were to go to 0,the equation would be deterministic.It would only depend.It would have time evolution determined by dt.But there wouldn't be any randomness associated with it.So we can think of the deterministic pieceas telling us about the growth rate in the absence of riskand this piece being associated with the risk.So if we ask about the amount of excessrisk there is and the amount of--excuse me-- the amount of risk thereis relative to the amount of excess returnabove the risk-free rate, we can takethe value, the return on the bond, dV in a given period,relative to what it would earn if it were risk free.So if it were risk free, this would be equal to 0.And then we divide it by the riskto get the ratio of excess return per unit of risk.And we have this expression.And the coefficient of dt, in this case, in terms of a and b,the coefficients from the Ito process,and f, our unknown function, that particular combinationa plus f over b is given a name.And it's called the market price of risk.Now, we give it a symbol.We'll call it eta.So we can track it through some further manipulationsif we'd like.But what are its properties?Well, first of all, it doesn't depend on which bondwe look at.It's going to be the same thing for all of the bonds.And it represents the extra returnthat we get per unit of randomness,per extra coefficient of dB.Unfortunately, it's not observable.And it ends up being a fudge factor in lots of models.This happens whenever the stochastic driver is notsomething that's directly tradable.That's where this uncertainty comes from.In the case of our stock and our stock option,the stock price was directly observable.And we didn't have any ambiguity.So common approaches are either to figure outsomething that seems like it ought to bea reasonable functional form.We'd make or look for something that can be solved analyticallyor to try to make empirical fits to market data.

#### CT10_S04_v1-en

PROFESSOR: What kinds of Ito processesmight we use for looking at the short rate?So we've seen how given an Ito process for the short rate,we can get a differential equation,a partial differential equation for bond pricesin terms of this unknown market price at risk.But we do have a whole bunch of relationshipsthat hold in order to avoid arbitrage among the bonds,and it gives some hope of seeing a structure for the yieldcurve.So there's a huge literature on different kindsof models for the spot rate, and here are a few examples.So just to take a look at a few of them,the Ho and Lee model starts with an arbitrary function of dtplus a constant Brownian term.So there's a time-dependent, deterministic first termthat corresponds to the drift part,to the return part of an Ito process,and a random part fixed volatility.So we can determine new arbitrage prices.And then by picking different functional forms of psi,we can try to fit observed market prices if we thinkthat the markets are efficient in our pricingand taking into account these relationships correctly.So one way that we might do that isto take a look at observed market pricesand then try to fit a curve through this,take some derivatives of this in such a waythat we can determine a psi of t that yields prices--no pun intended-- that yields pricesthat hopefully, fit the yield curve reasonably well.So that's a way to kind of match existing market data.The Vasicek model is a single-factor modelthat has mean reversion built into it.And you'll recognize this as being the Ornstein-Uhlenbeckprocess that we looked at in the continuous timeanalog of an autoregressive time series model.So in this model, there's also a constant term,but there's a definite specific form for the coefficient of dt.It's not some arbitrary function psi.It's a particular form, and it says that interest ratesare mean reverting.The Hull and White model kind of triesto combine the best of both of the above.So it has a mean reversion term plus an arbitrary function,and it lets us model the yield curveand have some structure for volatility.The CIR model, the Cox-Ingersoll-Ross model,takes a different twist by modifying the dB termand taking a look at how the effective volatility maydepend on the levels of interest rates.So how do we proceed?You pick your model, you pick your Ito process,and then you solve your bond pricing equation.You look at the market.You see what you like.If you don't like it, you come back here,you pick another one, and you start again.And if you don't like any of these models,you can start with your own.So the methodology goes this way.We're connecting a particular postulate for an Ito processthat drives one of the random factors--in this case, these are single-factor models--and then we solve for prices consistent with principlesof no arbitrage.So for example, if the spot rate follows an OU process,and the market price of risk is assumedto be constant or linear--so this eta function, I'm just putting an arbitrary, c0 or c1,you can set one or the other of them to 0 if you'd like.We can do a little bit of arithmetic with the functionf in terms of the a and b parameters for the structureof our Ito process from our bond-pricing equation,and we can see what kind of equation that we get.We can look at estimating the model parameterseither from looking at dynamics of the short rateor by taking a look at observed bond prices.So here, I've introduced the a prime and a y primejust to be rescaled parameters basedon some estimates we might do.The details aren't that important.It's just to show you that the overall structure that I getcan have a form that's of the same overall form, somethingthat's linear in the spot rate, which is the same structurethat we have up here in our original process.So the reason we do this as opposed to something simpler,like Brownian motion or geometric Brownian motion,is that interest rates, unlike stock prices, don't diffuse.They don't go all over the place.In fact, they don't vary that much at all.So mean reversion is an interesting starting place.The idea is the rates might change,but maybe they stay in a given neighborhood for a while.Certainly, over the last long period of time,the rates have been pretty close to 0.But the idea is that instead of having a strict bound--say, a zero bound for interest rates or an upper boundbeyond which they can't go--we see that the diffusion model isn't a good model.But by having a mean reversion factor, like the Vasicek model,it's the dynamics that keep it from going.There's something always pulling the interest rates back.Now, that does mean that we need an estimate for whatthe parameters are for this mean to which they're reverting.Is there some long-term average that we should use?Is there a different way we can think about it?So those are part of the estimationquestion for this model.And we can ask if we're thinking about what things shouldbe long-term, or if we're thinking about empirically,what works best in terms of the set of optionprices and the yield curve that the model produces.But suppose we do take this structure,and we just want to do the mathematicsand see what we can get by applying the Itocalculus to this setting.So let's take a look.So we've got this general structure.So we have that dy is some constant times y bar minus y--that's our mean reversion term--plus sigma dB.Now, one of the things that we can do that's convenientis to transform the variables.So let's use Ito's lemma to change from variable yto variable z where we'll put in an exponential dependence.And we're not surprised by that, because we would thinkthat if the model were purely deterministic,we would have a long-term average interest rate,and we might expect to see exponential behavior.So if we just plug that in and turn the crank,we see that we get this expression for dy.We make this substitution for y and z.And then we see that we can write dzin terms of an exponential prefactorout in front, times something that looks like a random walkwith constant coefficients.So this is not a random walk.But in terms of the z variable, we'veturned it into something that looks like ithas some similar properties.And the advantage of this is not that we'regoing to get diffusion where we didn't have any before.The point here is that by having this be an exact differentialand this have constant coefficients,we have a chance of integrating the last integral.So if we integrate that SDE, whatdo we find for the behavior?We find that z can be written-- the evolution of zfrom an initial starting point that'san arbitrary constant, z0, can be written in this form wherewe can now study what happens as t goes to 0and as t goes to infinity for a long time.So what we see is when we turn things, we solve for z,we do the integral in terms of z.And then we substitute back to get y.And what do we see?We see one term, initially y0, and this termdecreases exponentially with time.This term here, as time goes on, the e to the minusat goes to 0, and this approaches y bar.And now we see that by combining these two terms,that if sigma were equal to 0, wewould have something that would begin at any y0,and it would relax over time to reachy bar as t goes to infinity, whichis what we would expect for our mean reversion processin the absence of volatility.There is volatility, though.And we have this term in dB, which isa sequence of random variables.And therefore, writing it out in this way,it looks like it's in closed form.But, of course, that interval over dBis itself a random variable.It says that dB's need to be weightedby the exponential prefactor at different steps along the way.So this is an expression for y.We can ask about the moments of its distribution.That's the full y.We know it's related to a Gaussian,because the infinitesimal dB's are Gaussian,but we have this time-weighted average of dB's.But we certainly can compute the mean and varianceof that expression.So if we take the mean for the long-term value,we see that because the expectation is linear,the dB term goes away, and we're just left with this expressionthat I mentioned before for how the long-term average behavesand how it starts at y0, and it relaxes as t goes to infinity,to reach y bar.In terms of the variance, we apply our definition.The variance is the expectation of y minus its own expectation,quantity squared.We multiply it out.We end up with double integrals of our products of dB.We use our Ito rule, which says that dBat time s and dB at time s prime are uncorrelatedwith each other, unless their times coincide,in which case, their variance is dt.So we can do the integrals, and wefind a time-dependent variance.And t goes to infinity, we're left with the constant resultin terms of the initial parameters of the model,sigma squared-- remember, sigma was the coefficientof our Brownian term--sigma squared over 2 alpha.

#### CT10_S05_v1-en

PROFESSOR: So let's put it togetherand see what we can say about bond pricesand about yield curves.So the bond pricing equation we have now,under the set of assumptions we have,takes this general form, where wehave some unknown parameters, alpha and y bar, that wemight fit from the data.Let's assume that we've got this particular form.And to solve this equation, we lookat separation of variables.And we're going to try Ansatz, whichmeans that we're just going to takewe're going to guess a particular formas a starting point and then see if we can refine whatthose choices are.The formal pick is inspired by the general ideathat bonds, if there were no randomnessand things were constant, should seean exponential behavior in time and a linear dependencein the exponent on the risk-free rate.So let's assume that the functiony is in the form e to the f of t that depends only on tand a term that's linear and y.So we have a time-dependent function,which is independent of y, minus y times another functionthat's also independent of y.And what we're going to do is apply the boundary conditions.So the question we can ask is, inthis simple one-factor model, what kind of prices do we get?What kind of term structures do we get?Do we only get a rigid term structure?Do we have different parameters wherewe can have things that are upward sloping,inverted curves, oscillating?So what's possible?What's not allowed?That would be especially interesting.And do we have enough degrees of freedom in our parameterchoices and in our model specificationto fit the market?Well, in this particular example,we can take a look at fit for some particular numericalexamples.And depending on how we tune the parameters,we can get a variety of behaviors.We can get a curve which is upward sloping.We can also generate a curve which is downward sloping.And we can even generate a curve which is inverted,which begins by being convex, rising,and then becomes downward sloping.So there are a variety of behaviors we can have.This is the simplest model.And it's a bit too simple for applying to the real world.But this shows you how we can apply these techniques to matchdifferent kinds of assumptions about processesto observable bond prices and their yields in the marketplaceand then use what we observe in the marketplace in turnto go back and try to find what might be appropriate notonly Ito process for the short ratebut how many other factors might be requiredor advisable to include in our modeling.

#### CT11_S01_v1-en

PROFESSOR: In order to solve the Black-Scholes equation, whichis a pretty complicated differential equation,what we're going to do is make some changes of variablesto turn Black-Scholes into a related equation that'sa lot easier to work with and easier to understand.We'll take a look at some of its features,and then we'll transform back and we'llget our final answer in terms of the original Black-Scholesvariables.So let's just preview some of the key resultsand what our key approach is going to be,how we're going to go about doing this.So the first thing is what equation are we talking about?The Black-Scholes PDE is closely relatedto the diffusion equation, a well-known partial differentialequation, which is written in this wayas the partial of a function we'll call p0 with respect to tis equal to 1/2 the second derivative.So I have the first derivative on the left hand side.I have second derivative on the right hand side,and these both have the same sign.If I put them on the same side of the equation,there's going to be a minus sign relative to the two.What's the solution to this equation?Well, there are a lot of them.But there's one that's very, very special.That solution is a Gaussian, and that's one I've called p0.So right now you should take a momentto check that this expression satisfies this differentialequation.You'd like to practice your partial derivatives,there's no better time to do it right now.You can see it's a little bit complicatedbecause this Gaussian where we've done Gaussiansbefore, it's easy to differentiatewith respect to z.There's z squared up here.But the t's appear in two different places.They appear down here and they appear over here.And the effect of t's appearing inthat way is that as t plays the role of sigma squared,it's related to the width of the distribution.As t gets larger, the Gaussian gets wider and wider.And I've illustrated this here, that the peak gets lower,the distribution gets larger.One of the really interesting featuresis that t approaches 0, the opposite happens.The Gaussian gets steeper and steeperand gets peaked near the origin.So the first thing is simple differential equation.Very interesting Gaussian, our old friend the Gaussian.Special solution to that differential equation.And we're going to use that special solutionto generate other solutions.So the way in which we do that is goingto be a kernel type approach.And I'll show you some examples in a momentand you'll have a chance to do some yourself.But the basic idea is that we find a function p.It has a special form, and in this case, it's a Gaussian.And if we want to find any particular solution thathas special boundary conditions, what we dois we take our function p.We're going to integrate it times something representingthe boundary conditions to get the thing that we want.So in the case of stock options, what we're thinking aboutis this expression here is going to be the replacement for p0.This is going to be some complicated expression,but it's going to be the moral and variable transformedequivalent of p0.This expression here is going to definethe payoff of the derivative at expiration.Usually when we look at partial differential equations,we think of initial conditions or of boundary conditions.And if we have initial conditions,we think about what happened subsequently.In the case of financial derivativesthat have a definite expiration date, we work time backwards.We know what they're worth in the future at expiration,but we need to figure out what they're worth at times prior.What this expression does is it letsus convert from one to the other and lookat the structure of it, because we'll be seeing this again.The integration variable is with respectto this St over all possible future terminalvalues of the stock price.But this function here, p, depends not onlyon St and big T on the values at termination.It also depends on the current stockprice and the current time.And because these are variables outside but they'reconstants under the integral, this p functionis going to give us a bridge between the two,between the terminal values and the present values.And we're also going to see that the same equation,the diffusion equation, describesa bunch of other things, includingthe evolution of probability distributions for random walks.It helps us solve problems for the presence of barriersfor things like exotic options, knock in,knock out options, and so on.We'll get some good intuition about how those behave.

#### CT11_S02_v1-en

PROFESSOR: Now, to get from Black-Scholes to the diffusionequation, we make a few changes of variables,which are not obvious at all.And I'm going to show them to you,and you're free to check them outor you can take my word for them.I'll explain where each of them comes from.The first change of variables that we haveis to replace V by a present value factor in frontand to change the value.That is, instead of writing things for the derivative,we can express things in terms of its forward or future value.So we know that there's discountingshould take place, at least for people who've taken 15415.You know how that works, how we look at present value.And one of the ways that we can simplify our equationby combining terms is simply to putin a discount factor in terms of the derivative itself.And if we do that, we eliminate the oneterm in the Black-Scholes equationthey didn't have any derivatives, the minus rV term,and we can have this expression here in terms of U.The next thing we can do is substitute for timeand for the stock price.In terms of the stock price, what we're going to dois we're going to introduce a logarithmic variable.And we've already seen that in many ways rather than price,the logarithm of price or the differences of logarithmsof price are much more natural variables.Because what matters from an investment point of view,from an informational point of viewis how stock prices change, not with the absolute levels are.And the natural variable for capturingthose in a continuous time settingis a logarithm of the price.But this is just a change of variables.So we'll call S. We'll replace it by E to the xior we'll let xi equal the logarithm of S.And that will help simplify the equation.The tip off that we might see that whenwe look at the structure of our differential equationis to notice the structure of these terms here.Where this is an S d by dS and thishas an S squared with a second partial with respect to Ssquared.Because this has an S and a derivative with respect to S,this is two S's and two derivatives, those behavelike logarithmic derivatives.So the logarithmic derivatives simplify things,and they'll transform this so that insteadof having this pre-factor S and this pre-factor S squared,we won't have anything.We'll just get an equation with constant coefficients.The other change we'd like to make at the same timeis in our time variable.And instead of measuring time forward,we're going to measure time backwardscounting back from potentially an option expiration.And the tip off for that is the relative signthat we have between the time derivativeand the second derivative with respectto the independent variable with respect to the underlying.Now, notice that if I change S to minus S,not only to negative prices not make sense financially,but this equation, this part wouldn't change.But there's a single time derivative here.So changing the direction of time matters a lot.Now, this actually works out fantastically well for us.Normally for partial differential equations,we look at how things evolve forwardand the relative sign that we would wantwould be a minus sign.Here there's a plus sign, which wouldmake it much more difficult to interpret and to solve.But it turns out that the conditions we wantare the backward conditions.We know the terminal values.We want to find out what happens before.So let's make this substitution.We'll let tau equal t minus big T some fixed constant minus t.Because this is a constant and we're making derivatives,the big T isn't going to matter.It's not going to show up.And in fact, big T really will onlyreappear when we impose boundary conditions on our equations.So if we make those changes to variables,we find that we get this expression.We now have a derivative with respectto a timelike variable, a relative minus sign,a second derivative term with constant coefficients,and then this piece over here with our interesting minussigma squared over 2 that we've seenbefore times the first derivative piece.And we can make that part go away as well.So let's clean it up.Finally, with one more change thatwill absorb a single derivative term in our change of variable,and let's introduce this variable x.You'll notice that this logarithm, this log of Splus this other piece in tau, if we were to exponentiate it,if we were to exponentiate this whole expression,you'll notice this should look familiar from the formthat we saw for the geometric Brownian motion.And we looked at the integral of the stochastic differentialequation.We had an expression just like that.So it's not that the natural variableis log S. Really the natural variable lookslike logarithm of S, E to the R tau minus sigmasquared tau over 2.So either way, whether you like cleaning up the mathematicsor whether you're inspired by the form of the SDEthat we saw earlier, if we make that change a variable,we're left with this expression nowwhich looks exactly like our diffusion equationwith a diffusion constant.This is standard in literature sometimesto have the constant sigma squaredthat's here known as the diffusion constant.We can make that go away as well by absorbing it into tau sothat the combination that always will appear would be sigmasquared tau.And by redefining that, we could make it go away.So there would be no extra coefficients at all.We can check that this particular formdoes satisfy that equation.So let's take a look at this special solution.This is like the p0 that I showed you before.Again, it's an exercise in differentiation.If you didn't do the earlier one,you can follow along with this one.So here's my definition of U. The only differenceis the sigma squared that shows up, and as I said,always in this combination, sigma squared tau.So we take one partial derivativeand we see it brings down a pre-factor with respectto U, because it's exponential.The second partial derivative with respectto x, partial derivative with respect to tau,and then we can equate these expressions.So we see that the partial with respect to tauis sigma squared over 2 times the second partial with respectto x.That's our diffusion equation.

#### CT11_S03_v1-en

PROFESSOR: Now here is an integral formulathat tells us how to use the special functionp0 to get a general solution to the differential equation thatsatisfies arbitrary initial conditions.So imagine that at time t equals 0, we want our function p of zand t that satisfies the diffusionequation to have some particular functional form f of z.It could be something like f of z equals z squared.It could be a cosine.So you pick a function f of z, and the questionis, can we find a time dependent function thatsatisfies the diffusion equation such that when t is equal to 0,it takes the particular form that we want.If we can do that, getting the solutionto the Black-Scholes equation is going to be a piece of cake.And here's how it works.We put in our function p0 where we takea difference of the variable.That is, we're going to have an integration variable.We're going to integrate over all possible zprimes of our special function for our initial conditionsf of z prime.And then we're going to multiply that against a kernel functionagainst what's known as a Green's functionour special p0 where we're substitutingfor z the difference between z and zprime where z is the outside variableand z prime is the variable of integration.So if we were to differentiate this with respect to z,the only z appears here, and it's not integrated over.So we can bring a derivative inside the equation.Similarly, if we want to integrate with respect to time,this integral is not over time.z prime is a dummy variable for integration.If we want to differentiate this with respect to time,this is the only place where time appears.So let's take a look at a couple examples,and you can check that this actually works.If we substitute in our particular expression for p0,here's our rule.We've got 1 over square root of 2 pi t, whichI put in front because it doesn't dependon z prime, exponential of minus z minus zprime quantity squared over 2t times f of z prime dz prime.

#### CT11_S04_v1-en

PROFESSOR: So let's try a few examplesto check that this trick really looks like it should work.And then we'll be all set to take a look both athow and why it works, and how we can apply it to solvingthe Black-Scholes equation.Let's try a couple of examples.If we take a look f of z equal to z squared,then what our rule says is we should have p of ztshould be the integral of 1 over square root 2 pi te to the minus z minus z prime squared, z prime--oops.Let's leave it in red.z prime squared dz prime.And if we do that Gaussian integral we find the result.This is equal to z squared plus t.And let's check that.Well, p of z at t equals 0 is z squared.So that part works.This part matches this part.That's good.Does it satisfy the differential equation?What does the differential equation say?The differential equation says that partialof p with respect to t minus 1/2 second partial of pwith respect to z squared should be equal to 0.Is it?Well, partial of-- here's our expression.The partial with respect to t is 1 minus 1/2 timesthe second partial with respect to z.First partial is 2z, the second partial is 2,and it's equal to 0.Shall we do another one?Let's try f of z equals cosine of lambdaz, where lambda is a constant.So then we do the integral.We find the p of z, t by doing the Gaussian integral.And you can do this by looking it up in a table book,you can use Mathematica, or you canbreak the cosine into complex exponentialsand complete the squared.There are a variety of techniques for doing this.When you do the integral, we find that thisis equal to-- let's see.We have-- this is the integral of p0 of z minus z prime t.That's our old friend, the Gaussian.Times cosine of lambda z.Of course, my integrals, unless specified otherwise,go from minus infinity to infinity.That's a z prime.dz prime.And this integral, when we do it,is equal to e to the minus lambda squared t, or 2 timescosine lambda z.So let's take a look at this expression and see,does it satisfy the differential equation?Does it satisfy the initial conditions?p of z, t as t goes to 0 equal to cosine lambda z.So that checks.And how about the derivatives?Well, the partial of p with respectto t minus 1/2 partial of p with respect to z squared.Partial of this expression with respect to tgives us from this exponential, e is here.When we differentiate with respect to t,we're going to get a minus lambda squared over 2,going to get--it's going to be minus lambda squared over 2 timesthe function itself, times p of z, t, and minus 1/2times the second partial with respect to z.Well, the derivative, the first derivativeof that function with respect to zis e to the minus lambda squared t/2 times lambda minus sine.And the second one is going to bring down another lambda,and the sine will turn into a cosine,and we'll be left with minus 1/2 times minus lambda squaredtimes the function itself, p of z, t, all of whichis equal to 0.So those are two instances that we'vechecked so far in which doing our integral formulagenerates something which is a completely reasonable function.It has the desired properties that wewanted when t is equal to 0, and it'sgot some time dependence for t greater than 0 for whatgoes on.Finally, let's look at one more examplethat's actually relevant for option pricing, that'sa closer example.So let's take a look now at what happens if we have f of zis equal to what we'll call the step function, theta zminus kappa, where theta z is defined to be 1 for zgreater than zero and z for z less than zero.It's a step function.It goes long for 0, and then it goes up,and then it's equal to 1.So it's 0 for negative numbers, it's 1 for positive numbers.That's what we'd like to have as t goes to 0.And in this case then, that meansthat our integration, our integrand,is going to be our Gaussian times the function 1,but the integral's going to be cut off.So this says that p of z, t whichis going to be the integral, remember, of p0 of z minus zprime t times f of z prime dz prime,is going to be equal to 1 over square root of 2 pit times the integral of e the minus z minus z prime squaredover 2t times dz prime.And what about our limits of integration?Well, this is only going to be nonzero for,and this is the part I wanted to have in yellow,starting from kappa to infinity, not from minus infinityto infinity.So we can rewrite this in terms of a variable.Let's define a new variable.Let's let u equal z minus z prime over square root of t.So du is going to be minus dz prime over square root of t.Remember that inside the integral, z and tare both constant.So now I can write this integral as the integral is going to beequal to 1 over square root of 2 pi, which is a constant,from minus infinity to a value we'll call u*,of e to the minus u squared over 2 du.Now, this expression is the cumulative distributionfunction, or the Gauss integral.That is, instead of integrating from minus infinityto infinity, where we get 1, we'reintegrating from minus infinity up to some particular value.And this function, this definite integralwhich doesn't go to infinity, has a name.And well call it, we'll give it a notationthat we'll be calling this phi.So we will define this to be phi of u*.And when we substitute back to our original variables,we find that this is going to be equal to phi z minus kappaover square root of t.So phi is this incomplete integral.It's the thing which when we differentiate it,we get the probability density, because wedifferentiate with respect to the upper limitof the integral.And in this case, what we get is an integral that'scut off at the lower bound where we have the cutoff in our stepfunction, our initial function here.Our function-- excuse me, forgot my pointer--our initial function right here.So our initial function says that we'vegot theta is 1 where z in excess of kappaand it's 0 below kappa.So that's the solution when t equals 0,and the solution for arbitrary times is given here.Now, this one we need to be careful.Because in the limit where t goes to 0,we need to be quite careful about how this behaves.Because the function is a smooth function,but it's going to approach a step function.So what happens is this function is going to behavemore or less like this--if we can draw this.Then we're going to go from minus 1 to 1for the phi function.But as t goes to 0, this functionis going to become steeper and steeper,and eventually approach a step function, whichhas a discontinuity that we put in at the beginning.But for larger values of t, it's a completely reasonablefunction and a very smooth function.So we've done three examples of our basic rulefrom our equation, which says that wecan use our special Gaussian solution to generate arbitrarysolutions.And how are we going to apply thatfor option pricing given the kernel that we have,given this function p0?And we'll find the correct version of itfor the Black-Scholes equation.It says if you want a price not just a call option,but a put option or a straddle or somethingwith some exotic pay-off, all you need to dois take the same integrand, changethe function-- the payoff function-- do the integral,and then you're done.And this will generate all possible solutionsto the differential equation for the valuesof option prices, derivative prices thatare consistent with these financial principles.

### 03-Recitation_5

#### Rec05_S01_v1-en

PROFESSOR: Let's talk more about ito processes and Ito's lemma.So we know that an ito process is a stochastic process thatcan be described in differential formby an expression of the type dx is adt plus bdB.And we think of this as somethingthat tells us what happens between a time interval dt.That's why we think of the dt part as being deterministic.The coefficient functions a and bare evaluated at the starting point,or evaluated at a time, t, for value x.And that we assume is known.What we want to know is what happensduring the next interval dt.What's the new increment to x, dx that gets added on?So in that sense, the a and b are coefficient functionsand the randomness is all in dB.And we know the nice properties of dB,of our Brownian increment.We know that this is a normal random variable with mean 0and variance dt.Now Ito's lemma tells us how we can take these functions of x,where x is generally not differentiable,but F is a differentiable function of t and x,and how we can find out how it behaves, how it evolved.And I've shown you two ways of framing it.And I'd like to sort of add a third hybrid way thatcan also be useful.It doesn't really add anything new,but it's another thing to keep in mind because it'san extra approach for solving different kinds of problems.So remember that we saw that we can write thingsin differential form.And in certain cases, we can also integrate explicitly.In particular, when the left and right hand sidedo total differentials, we can write things outin explicit form.So let's take a look at an exampleand just go through the different waysthat we can write dF.So this is one of them.So this is one of them where I writethings in terms of dt and dx.And as we've seen in our derivations of Ito's lemma,this is particularly convenient when the dx's aregoing to cancel each other out.So in this case, we think of writing the two functionsin square brackets that begin with F. They alldepend on derivatives of F. F is a function of tand x, so we think of the square bracketsand writing them out as functions of t And x.And that's just fine.So from this point of view, the one other waywe might choose to write it is to take our expression for dxand simplify, or expand dependingon how you look at it, by substituting in this valuehere for dx, in which case, we haveour alternate expression where we can write this as dF equalspartial of F with respect to t plus b squared over 2,our ito term, d2F dx squared.And now we'll replace our dx by its definition.So we'll include another term, thisplus a partial of F with respect to x times dtplus b partial of F with respect to x plus dB.So all I did was I expanded this term by substitutingwhat we had here, OK?So in the top form, it's useful when we want to cancel the x's.In the bottom form, it's useful whenwe want to look at an ito process on its own.And it's helpful to break things down to its lowest componentsbecause dB is normally standardized.Dx, that we have on the line above,isn't necessarily standardized.So depending on what we'd like to do,we have different applications that might be useful.The third thing I wanted to add, though,is that sometimes, we'd like to expressthe coefficient functions in the square brackets,not in terms of t and x, but in terms of t and F.That is, we'd like to have a complete replacement,a complete transformation of the variable from x into F.And in certain cases, that will be possible.In some other cases, it won't.So let's take a look at an examplethat we can write in three different ways.Exercise.Let's let dx evolve according to ux dt plus sigma x dB.So our coefficient functions a and b in this caseare replaced by the definite valuesthat we've seen in this familiar form.Little a is equal to mu times x.Little b is equal to sigma times x.And let's suppose that we have a function F which is equal to eto the minus rt where r is a constant--think of it as being a risk free rate--times x squared.So here's the exercise.Write out df in three different ways.Write it first as a function of something dt plus something dx.Then write it is something dt plus something dB.And then, finally, write it again as something dt plussomething dB, but this time, without any explicit x's.See if you can write it strictly in terms of F. And if you can,what kind of interpretation does it have?Take a moment to look at that, to work it out, and thencome back and we'll solve it together.All right, let's begin by taking partial derivatives, shall we?So we know that equal to e to the minus rt times x squared.So partial of F with respect to t is going to be minus re to the minus rt times x squared partial of Fwith respect to x.It's going to be e to the minus rt times 2x.And the second partial derivativeof F with respect to x squared isgoing to be simply twice e to the minus rt.So let's take these results and put theminto our formula for Ito's lemma.So we have the df in our first expressionis going to be partial of F with respect to t.That's going to give us a minus r e to the minus rt x squaredplus b squared over 2, which is goingto be sigma x quantity squared over 2 timesthe second partial derivative with respectto x squared, which is going to be times 2 e to the minus rt.This is the expression that multiplies dt.Plus, the coefficient for dB is simplerbecause it's just the first partial with respect to x.So it's e to the minus RT times 2x dx.So if we simplify terms a little bit,we notice that everything gets multiplied by an eto the minus rt, so we could take that out in frontif we like.Each of the terms will have an e to the minus rt.Now we know this it's going to have an x squared timesminus r plus sigma squared dt.That is, we notice there's an x squared hereand there's an x squared here that came from our ito term.And there's no x over there.So I have an x squared and an x squared.We're minus r from taking the derivative.And sigma squared over 2 multiplied by 2,which just gives me sigma squared.In the second term, it's going to be just as easy.So it's going to be plus e to the minus rt times 2x dx.Now at this point, we can make an interesting observationfor that third form that we had.Notice that the first line in our result righthere is a combination e to the minus rt and x squared.But that's just the same as F.So let's go ahead and rewrite this as F times sigma squaredminus r dt.That's our first term.And what about the second term?Well, this is not equal to F. But supposethat we multiply and divide by x.In that case, we could write this as plus 2 F times dxover x.So what I've done is I've multiplied and divided.In this line, I've multiplied this by x,and I've divided this by x.Now you notice I have F times something dt plus Ftimes dx over x.And here, I can substitute back my original definition.So let's keep going.So this is going to be F times sigma squaredminus r dt plus 2F times dx over x,which was mu dt plus sigma dB.Let's combine these.And this is our dt term is going to beF times sigma squared minus r plus 2mu dt plus 2F sigma dB.In other words, we could write this as dF over Fis equal to 2mu plus sigma squared minus r dt plus 2 sigmadB.So you notice that this form here for the ito process justinvolves F. There are no explicit x's.The way the x's entered was exactly in the right way thatwe could group them together to make them into F's.Now that worked because of the particular formwe chose for our ito process, but that'sa very common process, and it's a very useful form.So in this case, I have an expression for dF writtenin terms of dt plus dB, so we can see it's an ito process,but there are no explicit x's.We've changed variables completely,so everything instead of depending on t and x,now it depends on t and F. And, of course, our middleform we can get just by doing our usual substitutionby writing out dx here and expanding the rest of the way.And the values, we would have dF is going to be--keeping everything in terms of the x'sand the partial derivatives that we had--e to the minus rt x squared times minus rplus sigma squared plus 2mu dt.Let's see.I think I need another parenthesis here somewhere.Let's try putting one there.OK, plus 2 sigma e to the minus rt x squared dB.So just to make that clear, this issomething dt plus something dB.And in this case, the coefficient functions of dtand dB are just in terms of x's.So if I were combining multiple thingsand I had different versions of x,this might be more convenient form.If I wanted to study f on its own and ask how does f behave,the line above, this one in the box,might be easier to integrate.So all of these are valid forms.And in each case, all we need to dois apply the rules for Ito's lemma, take the derivatives,and substitute them in.Which way we regroup them together and what's usefulis going to depend on the application that you have.Just as one final extension of this,if we wanted to go all the way and integrate the process F,we could do the game that we did before wherenow the expression in the box looks exactlylike the kind of expression that we had for geometric Brownianmotion.DF over F is some constant times dtplus some other constant times dB.We'd look for the differential of log F. We know that that'sgoing to take this form, and we'regoing to shift by the square of 2 sigma in the drift termand get another expression.And that would be integral.There's another shorthand way that we could do it,too, which is to use our definition of Finside the differential.So if we were to ask for d of log F,we could use Ito's lemma on that process dF over F. Or are wecould say, well, this is just d of logarithm of eto the minus rt times x squared.And that's an ordinary function.We could do that logarithm that says that this is d of minus rtplus twice log X. And that tells us that this is minus r dtplus twice d of log X. And we know what d of log X is.And if we substitute in, we find the same result. OK,we find that this is going to be equal to 2mu minussigma squared minus r dt plus 2 sigma dB.Two ways of getting the same answer.

#### Rec05_S02_v1-en

PROFESSOR: Let's look at more expectations involvingour stochastic processes.We know that db is a Gaussian random variablewith a mean 0 and variance dt.We also know that if we integratedb from, say, 0 to time t--And for convenience, I can write this as bt minus b0.Let's agree that b0 is going to be 0.It will simplify our notation.So this I'll just write is bt.And we know that this is distributed as n 0t, thatis, it has variance t.So since that is the case, we have an easy waythat we can write things.We know that the expectation of d is going to be 0.We know that its variance is going to be t.So let's just replace the random variable bt, or really,bt minus b0, by square root of t timesz, where z doesn't have any time dependence.z is just n 01.So that's just simplifying things and putting everythingin an even more standard form.But it also makes explicit the time dependent.And it's the scaling with time that'sgoing to be important for a lot of financial applications,and for risk management.So, what that means is that any timewhere we see a bt, or a bt minus b0,we can replace it by that function.So if we want to compute the expectation of some functionof bt minus b0, we can just writethat the expectation of square root of t timesz, our function of square root of t and z, and compute that.OK.And remember these are our Gaussian intervals.So we just need to do an integral.That's all it is.So this is equal to 1 over square root of 2 pi integralfrom minus infinity to infinity of eto the minus z squared over 2 timesf of square root of t times z.Easy.So for example, suppose we wantedto compute the fourth power.The expectation of the fourth power.So suppose that we had f of x is the function x to the fourth.So we'd like to compute.This is an example.So we'd like to compute f of et minus e0.That's going to be the expectation of bt minus b0is to the fourth power.That's the same thing as expectationof square root of tz raised to the fourth power.We can pull out square root of t,which is nonstochastic to get t squaredtimes the expectation of z to the 4th, whichis a well-known Gaussian integal that we use in the kurtosis.It's just equal to 3.3t squared.All right.So this way of standardizing things and writing thingsin terms of z when we work in the integral form,when we integrate our processes, is very convenient.Let's do an example, and I want to reviewa very useful trick with you.So let's take a look.So, for example, suppose we do another example.Suppose we wanted to compute the expectation of e to the 6xwhere dx, let's just say it's ordinary Brownian motion, udtplus sigma db.So because it's in this form, we canintegrate x, like xt minus x0.OK, it's going to be mu times t plus square root of t times z.So if we go to compute the expectation of e to the 6 timesut plus square root of tz.We could also-- you might see it sometimes in the formbefore it's been replaced.It's just e to the 6 times mu t plus b.Either way, we'd like to do an integral.Looking at the first form, obviously e to the six mu tis just a factor.It's a scalar, so we can write that-- we can pull that outin front.6 mu t times the expectation of e to the 6square root of t times z.Now in this case, this is a form that we'll see a lot.I'd like to give you a useful general formula.That if we'd like to take the expectation of eto the something, linear and z.And in fact, we already know what this is.Because we already did, in our first lecture,the characteristic function.And it's also related to the moment generating function,e to the something times z.But let me just connect it with the Gaussian intervalsand remind you of where we got that.And let's get a useful formula.So, a useful formula.Suppose that we have e to the, let's say, alphaz plus b, plus beta.So, some linear function.So, I would like to compute the expectation of some exponentialof a linear function of z.And this shows up a lot in particular in assetpricing formulas.So this is clearly equal to e to the beta,because that's just a pre factor.Times e to the alpha z.And this we do by doing the Gaussian integral,with the trick of completing the square in the exponent.So this is 1 over 2 pi e to the minus z squared over 2 timese to the alpha z dz.That's just our definition for the expectation operator.And of course I had the e to the beta in front,so let's not lose that.So inside the integral, what I cando in the integrand is I can write this as,let's keep our prefactory e to the betaover square root of 2 pi.And I can write this as e to the minus z minus alphato the quantity squared over 2.Now you notice if we expand this, I'll get minus esquared over 2.I'll get minus minus alpha z times 2over 2, which is exactly the coefficient with the weightingthat I need over here.But then there's an extra piece.There's an alpha squared over 2.So let's correct for that.Let's put in our integral, and let's write this as plus alphasquared over 2 times dz.But this expression is e to the beta plus alpha squared over2 times 1 over square root of 2 pi integrale to the minus z minus alpha quantity squared over 2 dz.And because the integral goes from minus infinityto infinity, the difference in the exponential between zand z minus alpha makes no difference at all.If you'd like, you can shift the variable of integration.The integral inside the square bracketswith 1 over square root of 2 pi in front is equal to 1.So our final result, our final useful formula,is that the expectation of e to the alpha z plus beta,for any alpha and beta that are constant,is going to be e to the alpha squared over 2 plus beta.Now, let's apply that to our example.We had-- this is our useful formula.And our example was the exponential of eto the 6x was expectation of e to the 6 mu tplus 6 square root of t times z.So applying our formula, this is goingto give me e to the 6 mu t plus the squareof the coefficient of z.That's going to be 6 times square root of t divided by 2.So 6 squared over 2.6 squared Is 36, over 2 is 18.And square root of t squared is t.And there's my answer for my expectation.Yes, except we left out one coefficient,which was the sigma squared.So, this is my mistake.If you didn't catch the sigma squared, I hope you did.Because t should always come in with the sigmasquared in front of it.But let's go back and fix my formulas.There should have been a--we began here with mu t plus sigma, square root of t.There should have been a sigma square root of t there.We have a sigma b here.This should have had a sigma here.And then as we come down here, we needed a sigma here.And then keep in mind that our expressionwas to take this quantity in the red parentheses squareddivided by 2.That's our alpha that we see over here.So I apologize for the typo, but I hopeyou caught it before I did.So this is 6 squared over 2 is 18.Square root of t is t.And sigma squared is sigma squared.So there's our answer for finding this expectation.And this works, generally, for a larger classof functions that show up for different kinds of Itoprocesses.

#### Rec05_S03_v1-en

PROFESSOR: Let's take a closer look at the diffusion equation.So the general diffusion equation is given right here.So we say that we have a function p of z and t,and they need to satisfy this differential equation.The first partial with respect to tminus half the second partial with respect to z equals 0.And we've seen that there's a very special solution, p0,that satisfies that equation, whichwe can find by plugging it in and taking some derivatives.So here's our p0.Now, I claimed that if we construct this integral on top,that this is the solution to the equation.So what I'd like to do is, let's check that,and then let's apply it.So the first thing to do is to check it.And the way we do it is we take derivatives.And what we find is that if we take that integral expression,and we stick it into the differential equation, whatwe'll do is, we'll move the differential operators inside.So for example, the partial derivativewith respect to time of p of z and tis the integral of the partial with respect to--excuse me-- the partial with respectto time of everything inside the integral P0 z minus wt f of w,dw.But where is the t dependence?The t dependence is only in one place.It's in p0.And similarly with the second derivative.So if I take the differential operator, partial with respectto t minus 1/2 second partial with respect to z squared,and I act on p, then that's the same thingas this differential operator partial of t minus 1/2second partial with respect to--let me get our pens right--z squared, times-- what are they going to act on?Well, the only thing that depends on z and t is p0.p0 z and t--excuse me.z minus w t of w, tw.The only potential complication that we'd have to worry aboutis this derivative act here on this t.This is derivatives with respect to z.This is not p0 of z and t, it's z minus w.But because it's just shifted by a constant,the derivatives are exactly the same.So this operator, when I move it inside the integral,acting on this part of the integrand gives 0.And it doesn't matter what f is.The integral is always going to be 0, providedthat the intervals converge.And they will converge whenever t is greater than 0.The limit t goes to 0 is a special case.And we'll have more to say about that.This is the reason why this integral form works.So the reason it works is that, wheneverI act with the differential operator,this piece here is the only thing that's hit,and it vanishes.So this expression necessarily solvesthe differential equation.If in addition, I get something thathas the right initial conditions, then I'm done.I know that it satisfies the initial conditions.I know that it satisfies the differential equation.That's all we need to know.So let's do a couple examples.So exercise.Suppose that f of z is z squared.So this was an example that we did a lecture.So I have the p of z comma 0 is equal to z squared.And I say, find p of zt, or t in general,at least for positive values of t.So take a moment and go do that.Take a look at the internals.And then, we'll come back and we'll do that together.OK.Let's go.Do you have an answer?All right, well you probably have the same answerthat we had in lecture.But let's do the integrals.So what we need to do is, we've got a formula.Let's just plug and chug.So p of zt is going to be equal to the integral of 1over square root of 2 pi, e to the minus zminus w squared over 2t.I should have put in a t down here.Remember, it's a Gaussian where the variance is t.So it's not completely standardized.So there is t dependence in this.And then, what we'd like to do ismultiply this times w squared tw.So that's the integral that we'd like to do.How do we do this integral?Well, let's change variables.So what we'd like to do is, let's simplify the exponentand pick a new variable.So let's let u be equal to w minus z dividedby square root of t.That way, the thing in the exponentialup here is going to be e to the minus u squared over 2.And that'll be a very simple form.Then, because we have this differential form--because we have this form for u, We alsohave the du is going to be dw over square root of t.But that's pretty good, because we have a dw right here,and we have a square root of t down here.So those are going to combine very nicely.So let's make those substitutions.And we'll see that p of z is goingto be equal to 1 over square root of 2pi times the integral of e to the minusu squared over 2 times--we need a w squared.Well, w-- if this is my expression for u,then w is going to be u times square root of t plus z.So let's write that out.This is going to be u times square root of t, plus z.Then we have that quantity squared du.Well, that's pretty easy.Because now we almost have things in standardized formfor a Gaussian interval.And this goes from minus infinity to infinity.So this is going to be 1 over square root of 2 pi integralfrom minus infinity to infinity, eto the minus u squared, times--let's just expand that out.We're going to have u squared times t plus 2u square rootof t times z plus z squared du.Let's look at each of these terms.The first term, right here, is going to be u squared times t.Remember, t is a constant with respectto the variable of integration.So this is going to give us--a first term will be t times 1 over square root of 2pi integral should be over 2, e to the minus 2 squared over 2,u squared du.The second term, right here, is going to vanish.Because it's linear in u, this is an even function in u.We're going from minus infinity to infinity.And even functions-- excuse me, odd functionsare going to have varnishing integrals.It's just a plus sign to the minus signare going to cancel each other out.And then, the last term, z squared that we have righthere, that's just a constant.So we have plus z squared times 1over square root of 2 pi, integral e to the minus usquared over 2 du, without anything else.Well, this expression is equal to 1.And so is this expression.Because this is just the varianceof the standardized Gaussian distribution.So we do the integrals.And what we're left with is z squared plus t.And we can check that it satisfies our differentialequation.If we take the partial of p with respect to t, we get 1.If we take the second partial--1/2 the second partial with respect to z squared, we get 1.And if we subtract the two of them, we get 0.So we're done.So this is the answer.Let's do one more exercise.Slightly different version of the one that we did in lecture.But now, don't refer back to the lecture.Just take a look at what we've done for the integrals.And do this one yourself.So what I'd like to do is introduce the Gaussiancumulative distribution function,which is going to be useful and show up in a few places.I will call this phi of x.It's going to be defined as the integral of e to the minus zsquared over 2 dz, from minus infinity up to x.So I compute the left side of the integralof the bell curve for the Gaussian distributionup to some point x.So in terms of Gaussian probabilities,this is the same thing as the probabilitythat a Gaussian random variable z is lessthan some particular value x.Now, from the fundamental theorem of calculus of course,I know that d by dx phi of x is just e to the minus xsquared over 2.So I can differentiate or I can integrate.I can go back and forth.But this basic idea that it's an incomplete integral.So I integrate from minus infinityup to a particular value x that's defined out here.It's going to be useful, and we'llsee that it shows up in a bunch of places.Here's a really simple example.So exercise.Let's let f of w equal 1 for w less than kappa,and 0 for w greater than kappa.So the question is, find p of zt,where remember that this is p and z a time 0.So at time 0, it's a step function.It's either 0 or 1 depending on the value of its argument.I apologize, this should be a w in that case.So what we'd like to do is, we want to find p of ztfor the general case.So take a moment, see if you can work it outfrom our general definition.Remember that our definition is, we integrate p0against p0 evaluated at z minus w against the function f of w.And we integrate that over w in an explicit expressionin terms of z.Go take a moment to do that.And then, we'll take a look at this together.OK?Let's go.Let's just work from the definition.The reason why this is particularly niceis the integrand is either 1 or 0.So there's an interesting generalizationthat's important for the Black-Scholes case, wherewe might-- instead of 1 or 0, we mightlike to let it be 0 in the lower case, but kappa minus win the upper case.So after you've done this one, I'dsuggest trying that one as an extension.But this one's fairly straightforward.So let's do this one together justto make sure we've got the concepts and our definitionsof the integral.So this is going to be integral of 1 over the square root of 2pi t, e to the minus z minus w quantity squared over 2, dw--now, the integrand is either 0 or 1.So if it were 1, we would be done.But because it's 0 for large values of w, for wgreater than kappa, our integral is onlygoing to go from minus infinity up to kappa.So that's it.So now you can recognize that apartfrom the shift in the exponent-- and sorry,I put my omissions in red.There should be a t here just to match the t that's down here.So now we need to do the Gaussian integral.And as a function of kappa, what are we going to get?So let's do the integral.And the way we can do the integralis, we can make the same change of variables as last time.So let's let u equal w minus z over square root of t.Implies that we have du is going to be dw over square root of t.That's going to work the same as before.In addition, our upper limit of integration is w equals kappa.And that's going to translate into an upper limit of uis going to be kappa minus z over square root of t.So let's call that u star perhaps,for upper limit of integration.So now, we have making that change of variables.p of zt is going to be the integral from minusinfinity up to kappa minus z over square root of t,times 1 over square root of 2 pi, eto the minus u squared over 2, du.Now, there are no more t's in the integrand.Everything in terms of a new variableof integration, a dummy variable u.And this is our definition of our function phi.So this is now equal to phi kappa minus z, dividedby square root of t, which is a very well behaved functionfor positive values of t.And it would be interesting to take a lookand plot this as t goes to 0.But right now, we have the result that we saw it.And we can check this, again, by differentiating and putting itinto the differential equation, and verifying that it satisfiesthe equation, and verifying that itsatisfies the initial conditions a t equals 0.Which as I said, it requires taking a limit,because we can't immediately set t equals 0in this case in the way we did previously.

### 04-Problem_Set_5

## 09-Week_6-Continuous-Time_Finance

### 01-Overview

### 02-Lecture_6

#### CT12_S01_v1-en

PROFESSOR: Ito processes are generalized Brownian motion,and Brownian motion is a continuous time random walk.We've looked at how to describe the evolution of a random walkin differential and in integral form,and now, let's consider an ensemble,a whole set of paths and random walks,like those you can see behind me.We start at a particular point, and each of these pathsis an equally probable realizationof what might happen.These are paths simulated on a computer,where I have taken the expression for an Ito process,discretized it, and in this case,we can see that, from the same data generatingprocess with the same drift rate and volatility,some of our paths go up.Some of them go down.None of them are straight for any period of time.But if we think about this as time evolves, as we go fromleft to right, and we think of considering cross sectionsat a particular point in time, what does the distribution looklike?What is the probability of a random walkappearing at a given distance from the origin?Well, from this picture, we can see a few things.First, we can see that the outcomes are indeed random,that whether we're up or down or wherewe are depends on which paths.So many, many outcomes are possible at any givenpoint in time.We also can see that the width of the distributiongrows over time, and there's no surprise.We know that the variance grows linearly,that the standard deviation growswith the square root of time, and thatmeans that individual random walks tend to diffuse awayfrom the origin.The longer time goes on, the greater chancethey have of reaching a larger distanceand the more improbable it is they're found near the origin,even though the center of the distributionremains the most probable place.So let's think about-- keep this picture in mind,of random walks.We want to think about, for a givenpoint in time, what the distribution of outcomesthat is.What the probability distribution function is?What's the likelihood, at a given point in time,that I end up here versus here versus rightin the thick of things or right down here?And that, of course, is a function of time,but typically, we think, of course,of starting with initial conditionsand letting time evolve forwards.What we're going to see and take advantageof is that, for a given initial condition,we can ask about probabilities of reaching future outcomes.The probability distribution functionswe have, though, will be a functionof the initial starting point, and the factthat it depends on both endpoints of our walk--the initial starting point and the uncertain future outcome--will be helpful for us for solving the Black-Scholesequation.So let's start with basics--give a random variable, mean mu, and variance sigma squared--which we write in this way.We say that x is drawn from a normal distribution of mean muand variant sigma squared.We have the familiar Gaussian probability density function.p of x is a normalization factor, one of our square rootto pi sigma squared.e to the minus x minus mu quantity squared--that tells us that the center of the peakis when the exponential vanishes,when x equals mu, divided by 2 sigma squared,which tells us-- which normalizes the distribution.Sigma is the width of the distribution,and that tells us that we can thinkabout how far we are from the peak in units of sigma.If our distance from the peak in units of sigmais the same, when we change sigma,the probabilities will be identical.So that's for a single random variable.Now, a time dependence stochastic process,x sub t, which we've seen, which we've looked at,saying Ito process with constant coefficients mu and sigma,as a generalized arithmetic Brownian motion,has variants sigma squared t, and its got mean mu t.That is, the mean grows linearly with time.The variance grows also linearly with time.So what does that mean?That means xt, the end point, the distance we'vetraveled from the initial point, is a Gaussian distributedrandom variable.That's true for all time scales t, from dt infinitesimalto macroscopic time scales, and thatmeans we know what the probability distribution isfor the endpoints.We know the probability density function is the same as the onewe had before, but where now, it's a function of t,and we put in t in the appropriate places.Mu gets replaced by mu t, and sigmasquared get replaced by sigma squared t.And you can check that this is still appropriately normalized.But the picture is now quite different.This is what we saw on the previous slide.The peak of this distribution moves at speed t.If mu is a positive number, it moves to the right.If mu is a negative number, it moves to the left,and I've illustrated that up here behind me.So this might be the peak at one point.This is at a point mu t.And as time goes on, the peak moves to the right.These are subsequent time steps, and as the distributionmoves to the right, we also see that, with the peak,sigma squared of t broadens out over time.So this probability distribution describes a time varying bellcurve, the Gaussian shape.It moves to the right for positive mu at speed mu,and it broadens out with time.That also means that if we're to run time backwards, that as tgets smaller and approaches 0, that we would be movingin the opposite direction.That is, that the peaks get narrower--the curves get narrower and narrowerand get more and more concentratedat a central value.So that's our Gaussian distribution.We've just applied it in a new way.We've seen it in many settings, and here's one more.You can check that this probability distributionfunction, p of xt, satisfies a differential equation calledthe Fokker-Planck equation, and I've written it here.Partial derivative with respect to t minus sigmasquared over 2.Second partial with respect to x plus the mudependent term mu, partial of p with respect to x.And you can check that by taking partial derivatives,and in fact, each of the partial derivativesis proportional to p itself becauseof the exponential nature here.And the prefactor doesn't change that, so all of the termscan be written as proportional to p.If you take the appropriate partials,substitute them into the equation,you'll see that this, in fact, isa differential equation for that probability density function.So just to recap--this probability density functionmeasures the distribution.If we do this for a Monte Carlo simulation,the histogram at a given point in timewould be one of these curves, and itwould be an approximation to one of these curves.And as time goes on, the peaks move out,but in particular, the curve broadens.So that was for a random walk that began at the originand went to a point xt.But now, suppose we're specific about startingat a particular point, x0 t0.And in this notation, you can read thisas the probability to be at x big Tat time big T given that we started at x0 at time t0.So it looks a little complicated.There are for arguments, but the first twoare measuring the probability of being observedat this point in time, given that westarted deterministically at point x0 and t0.Now, in this expression, this is just from time and spacetranslation.Everything depends on t minus t0 and x minus x0.So this is the same expression that we wrote downbefore if you take the special case where x0 equals 0and where t0 equals 0.But it's interesting to note that, having written it down,even though big T and t0 have verydifferent interpretations--one is where we observe a random variable.The other is where we begin our random walk.But time t0, we know exactly where we are.The distribution has to be concentrated at x0.Despite the fact that they have very different meanings,as a function, we can evaluate p both as a functionof its first two arguments or as a function of its last twoarguments.And if I think about it as a function of x0and t0 holding xt and big T fixed,then I find that it satisfies a different differentialequation called a backward equation,and it's backward because we're lookingat the wrong point in t.That is, this is asking a slightly different question.It's saying, if I wanted to observe the probabilityat a particular value at a particular ending point,how does that depend on where I start?The probability will change, obviously.The farther away I am, depending on the distancein time or in space, the smaller the probability will be.So it's a fair question to ask how this function dependson the two arguments x0 and t0.Because it's so similar, because everything depends onlyon differences, I can replace partial of pwith respect to t by the negative of the partial pwith respect to t0.And similarly, for the x derivatives, sothis term changes sign.This term changes sign.This one would get 2 sign changesbecause there are two x0.So now, where before, we had two relative plus signs and oneminus sign, all three of these signsare positive in this differential equation.In this equation, we haven't derived from anywhere else.All we're saying is, if we plug in this expression,this Gaussian curve into this differential equation,that the equation is satisfied.

#### CT12_S02_v1-en

PROFESSOR: Now special case, if we let mu equal 0,then that last term drops out.If we let sigma equals 1, the three factor sigmasquared over 2 just becomes 1/2, and weget the diffusion equation that we've already seen.So the diffusion equation in its standardized formis partial of p0, we'll call it.We'll be thinking of a particular thing.But in a general case, partial of p with respect to tis 1/2 second partial of p with respect to z.And there are no other constants herejust because I've set them to particular values.Now this partial differential equationhas a lot of solutions.But there's one that's very, very special,and that's the standardized Gaussian.p0 of z and t is equal to 1 over square root of t e to the minusz squared over 2t.And we'll see that the reason that this is specialis it will let us generate other solutions thatare of particular interest for financeto the diffusion equation and some related equations.But just taking it on its face, firstdoes it satisfy the equation?Yep, it does.It's special case, mu equals 0, sigma equals 1.Take the partials, plug it in, try it out.If you're stuck on the other one, do this one first.It's a little bit easier.There are fewer terms.But this is just a special case.So it satisfies the equation.Second, how do we visualize it?Well, this is a symmetric random walk.The up and down probabilities are equal.Mu is equal to 0, so it stays centered around the origin.And as time goes on, the width still increasesand the curves get--the peak gets lower and lower and the curvesget broader and broader over time.If we run time backwards, as we go from large timeand approach t equals 0 from above, thenwhat we see is the peaks converge on the origin,get narrower and narrower.Because they're probability distributions, of course,the area under the curve is always equal to 1.Do note that this is only a solution to our equationfor positive values of t because we have this square root here,and that would take us into the complex numbers, whichwould be difficult to interpret as a probability.So this is a special equation thatcan be thought of as being concentratedat the origin as t approaches 0 from above as werun the clock backwards.Now, this special solution can be usedto obtain the general solution.I'd like to show you the formula,and then we'll take a look at why it works.So here's the formula.If we've got some initial conditions, so at time 0,we want a function p that at time 0 has some shape,any shape you'd like.Well, it can't be any shape.It needs to be integrable.So it needs to be somewhat reasonable, not grow too fast,not have too many [? angularities ?]or discontinuities.But let's call that general function f.So I'd like to have the solution to the diffusion equationthat, in addition, a t equals zero takes on a specified form.And the answer to that, the general solution,is to take our previous expression,our special p0, our special Gaussian,replace z by z minus w, multiply it times f of w,and integrate over w.And that's it.So concretely, it's exactly this expression.It's just a Gaussian integral.You pick an f.You plug it in.You do an integration.You get an expression.And you can check by direct inspectionthat it satisfies the equation.For example, if you take f of z is z squared,and you do this integral, you put in z squared,make some changes of variables, you do the integral,it's an ordinary Gaussian integral, definite integral,from minus infinity to infinity, youget the result because it's a functionthat we integrate over w.But the result is a function of z and t.You get the answer z squared plus t.And when t is equal to 0, we recover--we recover the p of z and t at t equals 0 is z squared.And it satisfies the differential equation,as you can check.How does it work?Well, we need to do two things, checkthat it satisfies the differential equation,check that it satisfies the initial conditions.The way that we check that it intensifies the differentialequation is to differentiate it, that is,we take the differential operator of our diffusionequation-- these operators-- which are linear operators,and when they act on the function p of z,t, we can move-- p of z, t is defined by an integral,but the integral, of course, can be thought of as a sum.It's a linear set of pieces for its arguments.And if the integral is convergent,I can move the differential operatorunder the integral sign, where, because it depends on t and z,it only acts on p0.Everything else depends only on w.And there no double w's in the differential operator.So the differential operator in square brackets acts on p0,and it gives 0.So 0 times f of w is 0.Integrating 0 minus infinity to infinity gives 0 again.It satisfies the differential equation for any f.This expression will work.But does it satisfy the initial conditions?So what we'd like to look at is what'sthe limit as t goes to 0 from aboveof that integral expression that we've seen,that we've written down right here.Well, we take the limit as t goes to 0 of our expression,and we can substitute variables under the integralif we define u to be w minus z over square root of t.Then that takes out the z and the t dependents.This becomes e to the minus u squared over 2.The square root of t that we have here,dw over square root of t, is going to be du.So that's over here.So the square root of t went away.And the argument in f of w now gets shifted--it becomes f of z--plus u times square root of t.If we're away from any singular pointsin the function or discontinuities, thenas t goes to 0, this term vanishes.I'm left with f of z, which is a constant with respect to u.And the remaining integral is equal to 1.It's a Gaussian interval.It's normalized.And I get f of z, which is the appropriate initial condition.

#### CT13_S01_v1-en

PROFESSOR: There are a few functionsthat help summarize some of the results.We won't need these for everything we're doing,but they are convenient to keep in mindand you will see them certainly in the literature.The first thing I'd like you to dois take a look at this picture that typically wesee when representing the payoff for a call optionat expiration.If we have a stock of price S and the strike priceat price K, the price at which the option can be exercised,we only exercise if the price is above, say, K is 100,S is $120, that means that we can buy a stock for $100and sell it for $120 and our profit would be S minus K.Or if S is below the strike price,we wouldn't exercise it at all.That would be a money-losing proposition.And the value is 0.So this is typically shown in a graphlike this, where it's flat for low valuesand then it increases linearly above.We can rewrite that in terms of the absolute value functionin a simple way, which you can check.It's 1/2 of the absolute value of S minus K plus S minus K. Soif S is above K, this doubles.And if S is below K the absolute value flips the sign of thisand we get 0.The reason I wrote it that way is if I'd like to take--consider taking the derivative of this function,it's a lot easier in the absolute value form.And if you look at the picture, you can see what we have.The left for S below K, the slope is 0, the line is flat.For S above K, the slope has line--the line has slope 1.So the first derivative of that function has a name.It's called the theta function, or the heavy side function,or the step function.And its equ-- value is equal to 1 if S is bigger than K.And it's equal to 0 if S is less than K. And the value at 0depends slightly on how we define it,either 0 or sometimes a 1/2.We take it as the limiting case.But in any event away from the point 0,we see that it has this shape.What do you think its derivative is?Well, its derivative is 0.That is the curve is flat on the left and flat on the right.It's flat everywhere except at the origin wherethe slope changes infinitely in an infinitesimal period of timeor in a 0 point of time.And, in fact, this defines--this-- we can represent somethingcalled the Dirac delta function thathas the peculiar property that its 0 everywhere except whenits argument vanishes.There it's equal to infinity.But the area under its curve, whichis infinitely high and of 0 width, is equal to 1.Now, it sounds strange.But, in fact, one way to represent the delta functionis as the limit of our friend, our special solutionto the diffusion equation-- this Gaussian in the limitwhere t goes to 0.Now, we've seen that to get our special solutionand initial conditions that we cantake a limit of an integral-- changevariables inside the integral.But sometimes we might want to take the limit directly.And if we want to do so, this delta function notation--thinking of this as the limit of the Gaussian,it has these properties where its integral is equal to 1--gives us a result sometimes more directly.The properties that the delta functionhas that are worth keeping in mind are the following.We usually don't look at it on its own.In fact, properly speaking, we can only look at itin an integral integrated in--against another function.So one way that we see it is if Itake delta of x against f of x, gives me f of 0.And this is sometimes called a generalized functionor a functional, which is something that takes functionsand maps them to real numbers.So, in this case, this takes the function f of x.And although I've written as an integral,I get the value at a particular point.The point is not always 0.The point is wherever the argument of the delta functionvanishes.So if it's delta of x minus y timesf of x, that gives me f of y.And that is also--gives us a way that you'll sometimessee for summarizing the rule about the initial conditionsfor our integral form of our general solutionto our partial differential equation.If we have inhomogeneous equations wherewe have something that doesn't dependon our variable of interest on the right hand side,then we can use these functions to generate general solutionsas well.Although the results are a little bit more complicated,I've written them down here.And we're not going to be doing that right now,but you will see them in the same discussionsof partial differential equations that we've had.So you can know the functions that we're lookingat, the Green's functions-- this exponential--this special Gaussian exponential form is of generaluse and it lets us generate overall time-dependentsolutions where we might have a differential equation withsome, for example--that doesn't depend on p on the right hand side,but is some function of z and t on the right hand side.And if I ask not what function p sets as equal to 0,but what gives me a solution for an arbitrary h,then these integral expressions, using my special function here,let me generate a solution by doing an integralwhere I have an arbitrary function h.

#### CT14_S01_v1-en

PROFESSOR: We talked about initial conditionsfor the diffusion equation, but more broadlydifferential equations can be formulatedwith boundary conditions that could appearat different points in time.Or they could be conditioned on the spatial variablesthat we have.So I'd like to talk about a few examples of boundary problems.And a couple of tricks that are helpful in their solution.The first trick that we'll take a look atis called the method of images.And the idea is that suppose we wantedto take a look at the probability of gettingfrom point A over here to point B at this end.If we just wanted to get from point A to point B,and we're taking, say random walksor going up and down by 1 unit, we know how to do that.It's just combinatorics.We count all the ways that we can get all the possible stepsto take us there.But suppose I had a condition, and Isay I want you to get from A to B without crossing this line.So here I've got this is 6.I want to get to 8 in a certain number of time steps.But I want to do it without ever crossing this boundary at 5.That makes the counting much more complicated.And in the continuous time case, which we want to get to,makes it impossible.How are we going to count the paths?Well there are two things that wecan do to get away from counting the work in this caseand they generalize nicely to continuous time.The first thing is we'll think about stating thingsrelative to the boundary.We'll think about what it means to hit the boundary.And the second thing we'll do is we'lluse an artificial construction thatwill look at the mirror image of some partsof our path in the boundary.So let's take a look at this first case.Suppose that if I want to get from point Ato point B without hitting C, I imagine that if I hit point C,I'm dead.So I want to know what the probability is to get there.And we'll call that a survival probability.How do I get from one place to anotherwithout hitting an intermediate condition?And it's something we've already talkedabout in the context of Gambler's Ruinwhere we hit a boundary and the game is over.And we've looked at a number of discrete problemswhere if there's a particular draw downin a financial balance, then thataffects the outcome in which probabilitiescontribute to a final answer.So here we've got another version of the same thing.But here's our approach to solving it.What we're going to do is we're goingto say that, first of all, some paths willgo from A to B without ever hitting the boundary.But there are some that do hit the boundary.What we could do is instead of just counting the ones thatdon't hit the boundary, we could count them alland then subtract the ones that hit the boundary.How do we do that?Well, the way we can characterize all the paths thathit the boundary is to notice that if they hit the boundaryone or more than one time, then they definitelyhit it at least once.What I do is look at this blue path behind me.What I do is I take a look at the first place whereit hits the boundary.So I look at this blue path that starts above.It hits the boundary here.Then it goes below and above.It hits it a second time.It bounces around.And finally it arrives at point B. So what I'm going to dois I'm going to focus on this first crossing point.This first place where it touches our barrier.And around this point, I'm going to draw a mirror image.And that's this red line.So you notice that this red line isthis segment of the blue line reflected in the barrier.So if this is one unit above the barrier,this starts one unit below the barrier.Everything after the first passage pointcontinues the same.So these paths are in one to one correspondence.For every path starting at A that gets to Band hits the boundary, there is exactlyone path that starts at an image point below the boundaryand also finishes at B.How many such plans are there?Well that's an easy thing to countbecause those are unrestricted.Because every path where I've donethis reflection trick starts below the barrier.And they all finish above the barrier.They necessarily cross the barrier.So the barrier is no restriction in the counting of these paths.They all cross it if you want for free justby virtue of where they're starting and endpoints are.So if I want to compute the barrier,now I have an easy rule.I compute the probability to get from A to B unrestricted,and I subtract the probability to get from the mirrorpoint, this fictitious point below the boundary, whereI never could be because otherwise Iwould already by definition be out of the game.We would be dead.But to go from this fictitious point up to here.And I subtract that probability, and that gives methe survival probability.Now this generalizes nicely for continuous time processes.And it leads us to an interesting wayto think about boundary values for differential equations.So in terms of our diffusion equation,suppose we have a barrier at z star.We start at some point z0 that has to be above z star.Again, if we're at the barrier or below,and where our survival probabilities is already0 like our Gambler's Ruin problem,the first thing I can do is I can say,let's look at the unrestricted probabilityto get from z0 to anywhere in time t.And while I just measure my distance from z0and z minus z0 in time t.And that's given by p0.I'd like to subtract the mirror image that is the probabilityto get from the mirror point, which is 2z star minus z0.And I want to subtract that probability.Well, that's just the same p0 function.p0 of z minus its origin, its starting point,to z star minus z0, t.And if I combine those two expressions,I get this result right--excuse me.I get this result right here, whichyou will notice is not a probability density.And it shouldn't be.It doesn't normalize to 1 because the longer timegoes on, the more chance there isthat we will have hit the boundary the less chancethere is that we will survive.It certainly should be a positive quantity.And you can check that it is.Here's its most interesting property.It obeys the property that when z is equal to z star,it vanishes.The two terms cancel each other out.That's exactly what should happen.z equals z star at any point t meansthat we're at the boundary where we no longer survive.So we could have started from the beginningand said this is our boundary value on the problem.We are looking for a function ps of zand t that satisfies the diffusion equation suchthat whenever it's evaluated and star any time t,it's equal to 0.That's an example of a boundary where in this casea kind of barrier which we can't cross.Now of course that solution is only a solution for tgreater than 0.And it's only a solution above the barrier for zgreater than z star.You'll notice that this expression here we'vewritten down doesn't exist for negative times.That's OK because the square root.But it does exist for all values of z thatis this expression makes sense.But it doesn't really solve our differential equationbecause if z were below z star, the probability has alreadygone to 0, and we wouldn't want to get something negative.The complete solution to this boundary value problemis that the probability to survive to z and tis given by 1 over the square root of 2 pit times this expression.Minus the Gaussian exponential with the distancemeasured from the image charge.But if z is below is z star or equal, then the value is 0.Now this was for a symmetric random walkwhere there was no drifter.

#### CT14_S02_v1-en

PROFESSOR: If there is a drift term,then things change, and we can't reallyuse our symmetry argument.We can't use the method of images.And in fact, in our discrete case,if our up and down probabilities were different,that argument wouldn't have worked at all.We could count the paths the same way,but the weighting factors would have been different.And we would have needed to adjust the weighting part,even though the combinatorics would have been the same.But we don't need to go that far to tweak our solutionto get a correct value.And we'll do what we did in two ways.The first thing is to notice that our boundary condition isthe same.We want to have that the probabilities shouldvanish whenever it z is equal to z star.That's just the nature of the boundary.So that's OK.We know that if we have a linear combination of twosolutions to the diffusion equation, by linearityit's also a solution.So let's not toss our solutions away.Let's see if maybe instead of just taking the difference,if a different weighted average of the twomight be able to work.So what we're going to do is we're going to make a guess.We'll put in a particular form.We'll see what would be required by that form.And then we'll see if we can come upwith a general solution.So the form I'm going to try is I'mgoing to suppose that all I need to dois multiply by some constant C. And the constant C wouldbe equal to 1 if mu were equal to 0,but I don't know what it is.It's going to be some function of mu thatvanishes when-- or that goes to 1 when mu is equal to 0.So it certainly satisfies the differential equation.That's great.What happens when z equals z star?Well, I want to set it equal to 0.So if I put in that condition, and Irequire that this expression be equal to 0 and z equal z star,I can solve for C. OK.Just by dividing, I have this expressionin parentheses is equal to 0.That means I have the ratio of these two exponentials.And I find that C is equal to e to the minus 2mu z0 minus z star over sigma squared.So if mu is equal to 0, it checks the conditionthat we needed.C is equal to 1.So this satisfies our differential equationbecause it's the difference of solutions,and it satisfies our boundary conditionsbecause, by construction, when z is equal to z star,the function vanishes, the two terms cancel each other out.Now, suppose we want to know our survival probability at a givenpoint in time, that is, not to get to a particular terminalpoint z, but to finish anywhere above the boundary.Well, I have the probability density.ps of z and t dz tells me the probability in time tthat I'll have reached some point between z and z plus dz.Let's integrate it over all z, but only those z's thatare above the boundary.Well, our integrand is going to be a Gaussian type exponentialwith a Gaussian prefactor, and with some cut offon the integral.And that means that we can express everythingin terms of a cumulative distribution functionfrom the Gaussian.And I'm going to note that by the function phi.And it shows up all over the place.Whenever we're dealing with Gaussians,phi is defined to be the definite integral fromminus infinity to x of the Gaussian kernel 1over square root of 2 pi e to the minus x squared over 2.So I'm integrating, but only up to x.It has a nice symmetry property for phi of minus x.And you can get that to change the limits of integration.And the result that we get when we do the integral is Iget two terms, both in phi.I have phi here with this argument.And I have another phi here with a different argument.And I have a little exponential prefactor.So this is my solution.You notice that it depends on time.It depends on my starting point.It depends, in fact, not just on the starting point,but it depends on z0 minus z.That is, it depends on how far away I am from the barrierinitially.If mu is a positive number, then on average--or a negative number, actually, for that matter--then this thing in the numerator is, on average,how far I expect what my expected location is,how far away am I going to be.If mu is big, then this increases over time,and it means I'm getting farther and fartheraway from the barrier.And this denominator square root of sigmasquared t gives me a measure as to how much diffusionI typically would expect in time t.Now, let's think of places where we might apply this.Suppose we want to think about the probability of defaultor a firm.And the default could be that the firm runs out of moneyand that the equity goes to 0, or it could be a trigger point.There could be some particular financial termthat's a covenant in a bond, let's say.But let's keep things simple.Let's picture a firm that's represented by debt and equity.So its resources our D plus E. That's the value of the firm.z, we'll that be the firm value.We'll let z star be the case when the equity goes to 0, whenthe shareholders are wiped out, and we'reon the borderline where the value of the firmmight be less than the outstanding debt that's owned.So that's z star.Certainly, we don't want the valueof our firm to go below z star.What's the probability of that happening?Well, let's start with the current valuez0 to be the firm value, and let's assume that we'vegot some positive equity.Then we know how to solve the problem.That's the survival probability that we just computed.It says, in a given amount of time,what's the probability that you don't default?And that's-- now we can think about what that's a functionof.Well, it depends on the rate of growth of the firm, mu.It depends on the capital reserves, on z0 minus z star.That's how much initial capital we have.So by having a good capital buffer--and you can check this--the larger the capital buffer is,the higher the survival probabilityis, which certainly makes sense.But we could turn this around and think of this as somethingto solve for.If you're raising money for your startup,instead of just seeing how much money you can get,or who's offering you the best terms,or what might be the return that they're demanding,you might ask a very personal question closeto the heart, which is, what are the chances of my businesssurviving?How does it depend on the capital?And if I want to minimize my default probability,if I want to minimize my extinctionprobability for a business, how much capital do I need?That is, we can solve what the capital resources areto achieve a particular probability level for default.We can also think about two different thingsthat both contribute.One of them is how much initial capital we have,and the other is what the rate of growth of the firm is.Obviously, for a slow growth rate,we're going to be mostly dependenton the initial buffer.If it's expected to have a high growth rate,then that might not be as important.This also shows up in a slightly different version in a numberof insurance problems.We have some capital base.We have a possibility of claim premiumsthat, usually, we would model is a jump process,not a diffusion process.But we do need to balance that against the rate of growth,the rate of income through premiumsthat might be needed, ultimately,to offset negative fluctuations that would show up.So we can think about this as representing real eventsfor things that might happen, representedby a boundary, the likelihood of a particular event.And it's not something we can formulate in advance,and saying this happens at a particular time,so this could have happened anywhere.And this helps us answer the question,a somewhat path-dependent question,without getting into the paths.What's the probability to get from A to Bwithout hitting some event, in this case a barrier,along the way?Here's a numerical example of this problem you can findworked out in detail in the book Fixed Income Financeby Wise and Bhansali.And they take the example where mu is 1%, sigma is 25%,and the z0 minus z is a half.And we can see how the survival probability evolves over time.And, as we would expect, the longer we wait,the more it goes down because you have more and more chancesfor something bad to happen.And we can see that we have this initial behavior here,and then it drops off over time.And here we look at the point where it reaches 50%.At the end of 10 years, you can go backand rerun the numbers using that closed form expressionto see how things behave with the different growth rate.How does that change the survival probabilities?How does that compare to changing the initial capitalbuffer?

#### CT15_S01_v1-en

PROFESSOR: In looking at probability densities,we were asking a question about the likelihoodof finding a random walk or possiblythe value of financial asset at some time in the futureunder an uncertain set of probability assumptions.But we don't just need to ask about the value of the stock,or the value of an underlying, or the value of a random walk.We can ask about the value of functionsof any of those things.So we can ask about more general future payoffs.We can ask about general derivatives.How they behave in the future if their functionsay of a random walking stock price.And we can compute not only the distributions,but some expectations.What we're going to see is these expectations satisfieddifferential equations.And the differential equations are going to be quite familiar.So let's go back now to our stock prices.If we remember, our standard modelfor a stock diffusion for geometric Brownian motion,it's given by this EDO process.dS is mu Sdt plus sigma SdB.And we know that by changing to logarithmic variables,that the logarithm of S is a random walk with the driftand a volatility coefficient.And therefore, it has a probability density.It's going to be a little bit more complicatedbecause the logarithms.But it's an example of the logarithm.And S is an example of everythingthat we've looked at in looking at probability densityfunctions that vary with time that solve the diffusionequation.So when there's a drift term, remember we have an extra part.The Fokker Planck equation or the backward equation.And the probability density in logarithmic variables,if we flip them back now to--if we go from log variables wherelog S represents a random walk back to our original S,and we create the analogous probability density,the probability of arriving at ST a time big T giventhat we started at price at this time Tsatisfies a differential equation.And that differential equation has all the plus sides.And it takes this form partial of p with respectto t plus a familiar pre-factor sigma S squared over 2.Second partial of p with respect to Ssquared plus an unfamiliar term with the mu with the driftcoefficient times S partial of p with respect to S.It's familiar in our context of random walk probabilitydensities.But it's not one that we saw whenwe derive the Black-Scholes equation, which you rememberis independent of the value of the drift term mu.So here we have in terms of S variablesthe differential equations satisfied by the probabilitydensity or a stock that follows its standard EDO process.Now we can compute some expectation values.And we do this in the usual way where we take the probabilityweighted average.So suppose I have some function.It's a function of S sub T of the terminal values.And I'd like to compute its expectation at an earlier timet.Well, I compute that by taking my probability density.I multiply it times the function in question.I take the probability weighted average.I integrate over all the values ST. And that's my expectation.The kind of thing that we have in mindis going to be something like the payoff on a call optionwhere big T represents the time when the option expires.So to compute an expectation, we compute this probabilityweighted average.We do the integral and we're done.Notice that inside the integral, the coordinatesfrom the starting point big S and are just S and Tare constants inside the integral.They don't do anything they're not integrated against.So the result is some function of the stock price and time.So the expected value where we'recomputing the expectation of some terminal values at timeT is itself a function of the starting point S and T.And It satisfies the same differential equation as p.The equation that we wrote down on the previous slide.So f satisfies a differential equation.It also has interesting initial conditions.In the limit where little t goes to big T,we think this is arriving at the expected value.We can go through the same argumenteither by looking at the Gaussian formhere, and changing variables in the interval.Or by using the delta function to saythat when the big T goes to little t,the probability density approaches delta function.Either way we do it, we find it satisfiesthe initial conditions that this large value whenlittle t goes to big T takes the expected result.No pun intended.f of S because this will be f of S evaluatedat the terminal point S sub t where it'sno longer random because we're evaluating at time big T whatthe value will be a time big T.Let's take things one step further.Let's think about f and compute its present value.So the present value is the discountingunder the continuous risk free rate.It's e the minus RT of some quantity.That is, we think of the future valuesas being what their value would beif they earned compound interest at a rate r continuouslycompounded for a given period of time.The present value reverses that.It says let's find out the value nowthat would be required to get a given future value.So I'm going to define V to be the present value of Fwhere I'm going to multiply it times the usual factorthat we see in finance.e to the minus r times the amountof time left to expiration, which in this caseis big T minus little t.Now what equation does V satisfy?e to the minus rT times F is juste minus rT minus t times the expectation.But remember we saw that f of St is just the terminalvalue of our function.So we can rewrite this as the present valueof the expectation of V itself evaluatedat the terminal value.That is to say that V anad S sub t at an initial timeis equal to the discounted present valueof the expectation of the terminal value.And this expectation, of course, is computed with probabilitydensity p.

#### CT15_S02_v1-en

PROFESSOR: The quantity V satisfies a differentialequation that's very similar to the Black-Scholes equation.The prefactor we put in front, the e to the minus rt minus t,the discounting factor adds an extra term minus rVwhen we take time partials with respect to it.One partial acts on the prefactor,the other partial acts on the functionV, and we can cancel out an overall prefactorin the equation.So the equation that's satisfied by Vlooks very similar to Black-Scholes,except there's a mu here.And what we ought to have is an r where we see a mu.Now, V would satisfy the Black-Scholes equationif instead it were based on this Ito process.dS equals rSdt plus sigma SdB.That is, if we changed the drift rateand replaced it by the risk-free rate,then the equation would be Black-Scholes.And what that means is that if wewant to solve the Black-Scholes equation, what we can dois take the expression we wrote down for V, everywhere wherewe see mu, cancel it out and replace itby r, and that's going to satisfy this differentialequation.Now, there's a reason for this that we're not driving here,but you'll see it in the finance portion of the MicroMasterscourse.And what you'll see is that this is called risk-neutral pricing.Risk neutral you can think of as meaning that there'sno particular compensation for risk,that all assets under risk-neutral pricingand under risk-neutral probabilitiesgrow at the risk-free rate.So under this assumption that we're using the risk-neutralmeasure, sometimes called Q-measure,and that the Ito process evolves not with a real-world value mu,but with this fictitious drift rate r--under that set of assumptions, then wecan find a solution to the Black-Scholes equation.And we know that the V that we wrote down beforesolves that, provided we make that substitution.And here is the relationship that we havethat V must satisfy.The e to the minus rt times V at S of t at an earlier timeis equal to the expectation of e to the minus r big Tat a later time of the value of the function evaluatedat that later time, where this expectation is takenby averaging over the probabilitiesfor all possible values of ST at future timebig T under the probability density that is notthe real-world one with mu, but the risk-neutral onewhere r has replaced mu.So there are two ways that we can get Black-Scholes equationsdoing this.One of them is we can do the integral.The other way is we can evaluate that expectationthat we wrote down.So the Monte Carlo techniques, whichwe'll see a little bit later, involvetaking that expected value and replacing itby an arithmetical average instead of theoreticallycomputing the weighted average of all possible outcomesfor all possible price evolutions.Under this risk-control measure, we'll compute a set of them,a large number of them, and we'll take an average.The other way is we just plug in and do some integrals.That is, we already have the probability density functions,so let's compute V from the integral formulathat we wrote down.We can think of V as being an expectation over terminalvalues.But in the end, we just have some integrals to do.So let's take a look at an example where, for instance,we think of a call option with strike price K at time big T,and we're at time little t currently.Well, V of St in the present--that should be a big S--is going to be the probability density times the terminalvalue.And when we substitute in our definitionsfor our specific payoff that we want,we get this integral expression here, which we can do.And we can take x and x prime, whichwere logarithmic variables from our original changein variables, and change them back and do the integral.Or to be more explicit, we can writethis formula using our results.So the full risk-neutral probability distributionwhen we change back from logarithmic variablesto s where x was log s and we change back,we have this expression down hereis just the probability density.It looks pretty big and ugly, but that's becauseof our changes of variables.This really is everything that webegan with for the basic probabilitydensity for a set of random walkswith a drift coefficient mu.Now, this is a Gaussian probability density.We're going to do a Gaussian integral.This piece here is the exponential weightingfrom the discounted present value.And then for my payoff function, I'm going to put in S minus K.And it's easier to do the integralif we work in exponential variablesand try to have these logarithms inside the integral.So a change of variables is helpful here.We can go from this exact result.By letting x equal log S, we have this.Recognize this is in a Gaussian form.And let's take a look at three features.The first feature is like in our barrier case,we have a lower limit of integration.If the stock price is below K, there's no value,there's no contribution.The payoff function is 0.If we're above the strike price, there are two.Terms there's S minus K. So we can do two different intervals.The second one is easy.K is just a constant.It comes outside.And this is going to give us something in phi.It's going to give us a cumulative distributionfunction because I have just e to the minus xsquared over 2 in the appropriate units integratedfrom something to infinity.So that's going to give me somethingin phi, where phi, as usual, is defined in this way.And the other term is not much harder.Because this is e to the x prime,I complete the square in the exponent, do the integrals,and I'll get another function phi.So the result of plugging this in and changing backthe variables is we get the Black-Scholes solution, S timesphi evaluated at argument I'll call d plus.In literature, these are often called d1 in d2.I like to write them as d plus and d minus.But I have one term in d plus minus the present valueof the strike price Ke to the minus r T minus t timesphi of d minus.So the definition of d plus and d minus,they really just come from changingvariables in the integral and lookingat the limits of integration.In this case, d plus or minus is this first expressionplus or minus 1/2 sigma squared root of T.And this first expression does havean interesting interpretation.So the logarithms are-- because it'sprice changes and relative returns on stocksthat matter more than price levels, the ratiothat we see here is the ratio of the stock priceS, the current price, to the present valueof the strike price.Or we could turn it around and ask about the forward valueof the stock price relative to the strike price, which wouldbe what we'd see at expiration.So this numerator is a measure of how farwe are in or out of the money.If S is larger than the denominator,the logarithm is going to be the logarithm of a number that'sbigger than 1.And if it's below, it will be the logarithmof a number that's less than 1, whichwill be a negative number.And it'll be 0 if the function-- not if it's not the money,not if S is equal to K, but if it's at the money forwardand if that ratio inside the logarithm should vanish.So that's a measure of how far awaywe are from the at the money forward value.And the denominator, the sigma over square rootof T minus t, that's telling us how far the stockprice, or the log stock price moreprecisely would be expected to diffuse given the volatilitysigma and the time remaining until expiration.

#### CT16_S01_v1-en

PROFESSOR: Now, it's customary and of incredible practicalimportance for risk management to take a look at a coupleof related quantities, having solved the Black-Scholesequation and found the Black-Scholes formula in puts--for calls, which we wrote down in puts,which are very similar.The first thing is the famous delta,which we used as part of our hedging argument.So we know that delta is defined as the partial of Vwith respect to S. Now that we have a closed formexpression for V, we can take the derivatives,and we can compute.And we find these values, that the delta for a callis phi of d plus, where the argument isthe previous one that we wrote down,phi of minus d plus for a put.And there's a relationship between the two deltasfor puts and calls that follows from a relationshipthat you'll see in the foundations of finance,that put-call parity tells us that the valueof a call minus the value of a putis always equal to the stock price minus the present valueof the strike price.So if we differentiate this once with respect to S,we get the delta of the call minus the delta of the putis equal to 1.If we take two derivatives, we find outthe gamma, the second derivative of an option value with respectto stock price, is the same for both puts and calls.And the vega is the value of the option with respect to sigma.And this is a little bit different from the othersbecause sigma isn't a dynamical variable.It's not a variable at all.It's just a parameter.We don't usually think about differentiating with respectto parameters.But it is important in thinking about the solutionbecause it tells us about the sensitivity to changesand levels of volatility.If sigma were non-constant, our derivation for Black-Scholeswould not hold, at least not the way we did it.We'd need to generalize it a bit.But if we are holding options, wemight be interested in what would happen to their valueif, say, there were, I don't know,a global pandemic and everyone's understanding of risk change.And while the volatility is constant,it jumped to a new level, or it moved a small amountto a new level.That would be one reason where itwould be helpful to know what the sensitivity of the valueis with respect to a change in sigma.Now, in addition to puts and calls,that are vanilla options, our approachlets us solve for any payoff at all.Remember, we could put any terminal functionV or any general function f into our equation.We can have any payout we want at time big T,and all we need to do is do an integral to get that equation.So that's why this is much more powerful than just havinga bunch of formulas that we can look up in a book or onlinefor different categories for solutions to Black-Scholes.If you would like to generate a particular payoff,you know how to do it.Write down what you would like the functionto look like at expiration.Do the interval.That will tell you what the value of the option should be.Here's one example that's even easierthan doing a put or a call.It's a binary, or sometimes called the digital option, thatdoesn't pay off proportionally.It's like a bet.Either it pays off or it doesn't.So if the strike price finishes above K, you get $1.If it finishes below, you get nothing.And if we plug that in the integrand is even easier.It's either 1 or 0.The only effect of this is to cut offthe lower limit of integration in S of big Tat the strike price.And we do the integral, and no surprise,we end up with a Gaussian cumulative distributionfunction phi with an appropriate argument.So this is the value.There's only one term, not two.And you notice that it is not multiplied times an S or a Kbecause it doesn't have units of--scale of the stock price.It just pays $1 in that limit.Now, this is directly related to-- because it depends on phi,and we talked about how we can think about d, it's related,as you might expect, to the probabilityof finishing in the money.After all, a fair bet would be--would pay off based on what the probability of winning is.That ought to be what the value is.But that's not quite what's going on herebecause, in fact, the probability distributionthat we're using to compute, the probability distributioninside our integrals is the risk-neutral distribution.So even if we knew the return on our underlying mu,we wouldn't use it.And this is a little bit counterintuitive.So the value of the payoff is notrelated to the probability of finishing in the money.It is related to the probability of finishingin the money under the risk-neutral distribution,but that could be wildly differentin the real-world probability of finishing in the money.Why is that?Well, our normal gambling intuitionsays that we have all these different, uncertain outcomes,and we start by asking what would be fair.And the expected value is their typical definitionof what's fair.But in the case of these options,where the derivatives and the underlying have the samestochastic driver-- they're based on related Itoprocesses--we can eliminate risk, as we've seen.There is no risk at all.So the value needs to be such that it avoids arbitrage.If you know the arbitrage value, and someone comes upwith a different value through other arguments thatdon't take into account the possibility of eliminatingrisk, you've got a great opportunity to make a trade.Here's another example of an exotic option with no strikeprice involved at all, and a different techniquewhere we don't need to do the same kind of integralsbecause we don't have a complicated payoff.The payoff that we have, in fact,is-- we're going to assume that the payoff isas S squared and some appropriate unit.So let's say that we measure S in dollars,and at expiration, you get S squared dollars,whatever that might be.So how are we going to compute that?Well, we want to think about what the evolution isand about what the expectation is,and we want to apply our result that the value of an optionis the discounted present value of the expectationof the terminal value under the risk-neutral measure.So let's take those words and those formulas for expectationsand put them into play.And what we see is, first of all,that log X is just twice as log S.We know that log S is a Brownian motion-- an arithmetic,not a lognormal Brownian motion, because we've taken logarithm.So we know what d of log S is.And d of log X is just twice d of log S.So that means that a time t, where we can let t be zero,it's going to be the initial valueS squared times e to twice mu minus sigmasquared over 2 times t plus--because it's a random walk, because log S is a random walkand log X is some random walk, we'regoing to represent this as plus sigma squaredroot of t times Z.So here's my 2, and going from X--excuse me, going from S to X, thisis what we normally would have gotten by integrating our logS. And because it's a square, we justend up with the factor of 2.Going to the risk-neutral measure means that we take mu,and we just replace it by r.That's our heuristic, and it really works.So we take mu, we replace it by r,and then we need to compute the expectation with respectto the Gaussian probability distribution.Again, what I've called Q-measure means don't use mu.Where you see mu, write r.So we'd like to do some Gaussian integrals of this expression,where we replace u by r.And then we recognize Z as being a Gaussian variable.We do the expectations, and what we'releft with is an expression with r minus sigma squared over2 times T e to the 2 sigma squared T,and then when we take its discounted present valuee to the minus rT, we get this final result,that the value of the option is going to bethe current value squared.And let's let T be the--so we're at time T equals zero right now times eto the rT plus sigma squared T.

#### CT17_S01_v1-en

PROFESSOR: Another example of boundary conditionsin our differential equations is lookingat the exercise conditions.More American options.The European option is an option thatcan only be exercised at its expiration date.An American option is one that canbe exercised at the discretion of the holderof a long position.The option any time up until exercise.So the owner has to choose whether or notto exercise early.And if to exercise when or under what conditions.And we can't apply our previous formulas really heldfor European exercise because thosecovered the entire domain.But once an option holder exercises his or her option,that option is no longer there.And the solution would no longer be valid.So we have a different kind of boundary condition.Now this is actually a fairly complicated subject.We're going to look at one very, very special example.And that's going to be to consideran option that never expires.And we'll consider a put option.So the put option is something that pays offif the value goes down.If value is below the strike price.And the amount that it pays off isequal to the amount by which is below the strike price.Basically, the put option gives you the right, but notthe obligation to sell at price K.So you would never do that if the price were above K.You would sell at the market price.But if the price drops low, then youmight choose to exercise and sell at K.If the price goes to 0, obviously youmight as well exercise it early because that'sthe maximum amount of money you can get.The stock price never can go below 0.The maximum value you can ever get is K.So if the price were to hit 0, you would certainly exercise.But it might be the case and if the pricegets sufficiently low, you would exercise as well.So let's see if that might be the case.The interesting thing about the perpetual optionis because it never expires the value is time independent.So this is a way to get an equation that'ssimpler than the partial differential equations.It's going to be an ordinary differential equation.So the value can only depend on the stock price.It doesn't matter if it's been bouncing around for an houror for a year.The value only depends on what the current stockprice is because the time never ever enters into the problem.So the equation we have is very simplified Black-Scholeswhere V depends only on S. And we drop the time derivative.So this is the equation that we havethat's for any time independent contract that satisfiesthe Black-Scholes equation.Now this equation in order to solve it,we're going to try a particular form.We're going to look for an inspired guess.See if we get lucky.See if it might work.And if it does, what conditions arethere so that we can get any arbitrary parameters exactlyright.So the guess that we're going to try here is to try a power law.And the motivation for that guessis to notice this is homogeneous in its weight in S.This doesn't have any S this is just a V. Thishas an S in the numerator.One in the denominator.This has 2 in the numerator.2 in the denominator.So let's see what happens.If I take V of S as S to some power,if I differentiate it I'm going to get s to the alpha--I'm going to get alpha S to the alpha minus 1.I multiply by S. And now I've got S to the alpha again.If I take two derivatives, I'm goingto end up with something-- or actually specifically alphatimes alpha minus 1.S to the alpha minus 2.I multiply S squared, I'm going to get us to the alpha again.So if I do that, I divide through by S to the alpha.I get an equation or alpha for these coefficientsthat come from these equations.And then it's a quadratic equation in alpha.So I solve the quadratic equation.And I find there are two possible values.a equals 1 or minus 2r over sigma squared.Now a equals 1 would have been easy to guess.a equals 1 says that the value is S.And the stock price itself always satisfiesthe Black-Scholes equation.But we also know that that can't be part of the solutionbecause it grows as S grows to infinity.And the value of a put should be a decreasing functionin the stock price.So that can't be part of the solution.What about the other one?Well, assuming that interest rates are positive,and volatility of course, is positive we'regoing to get S to the minus 2r over sigma squared.So our solution has to be something of this form.There's a overall proportionality constant.But the S dependence has to be power law in S decreasing.And that will satisfy this differential equation.We might choose to exercise the price is sufficiently low.And when we exercise, the value of the optionwill be equal to its exercise price.Because otherwise there would be an arbitrage opportunity valuewhere higher or lower.Though at the exercise point, we havethat whatever it is S hat, that the value of the optionis going to be K minus S hat.And that lets us rewrite our form in terms of we'vejust traded one unknown for another unknown.In this case S hat.Now the way that we can think about the valueis that the person holding the long positionwho has the choice as to whether to exerciseor not might choose to maximize his or her value.The person with the short positionhas to assume that because that's sort of the worst case.If the person who holds the optiondoesn't take advantage of an exploration opportunity,that's good.That's extra value.But that isn't something that you'dwant to count on if you were managing risk,and you were in the business of writing options.So let's assume that the option holder will tryto optimize maximize its value.And we can compute by differentiating with respectto this parameter that's a choice.This S hat.And see what maximizes the value.And then that will pin down what our final value for the optionis.So the first part of this is something thatshowed up on a problem set.This part completes the problem.You can try it out first before you look at these formulas.But otherwise, if you're looking at them now,and you want to see how it goes to finish things up,we see that the first partial setting it to 0gives us the solution for S hat.We can check that this is a maximum and not a minimumby looking at second derivatives.And then if we substitute S hat into the expressionabove, we finally get this result for the valueof the American option in terms of S and K.The parameters sigma and r.And obviously time doesn't appear in the problem.

#### CT18_S01_v1-en

PROFESSOR: Let's look at how to compute option prices via MonteCarlo methods.So here's the rule for applying risk-neutral pricing.The rule is to get the risk-neutral measure,then we take the drift rate mu and we replace it by r.Now, this is beyond the scope of the course,but there's a larger subject about changes of variablesand changes of measures to ensurethat we have risk neutrality, and,under the risk-neutral measure, that we don't have arbitrage.So the origin of this is a no arbitrage argument.The conclusion of that argument isthat all traded assets, in order to avoid arbitrage,have to have discounted price processes thatare martingales that helps us construct the Q-measure.But for our case, for a stock price,it obeys the rule that I just said.Everywhere where you see a mu, replace itby r, use that is your measure.Let's see how we do computations under that rule.Well, we saw earlier that the value of an asset,it's discounted value now, is equal to its expectationunder the Q-measure of the same random variable at expiration.So for a call option that says the value of a call optionnow is a discount factor times the expectationunder the Q-measure, under letting the paths evolveaccording to Ito processes, but where we replace the drift ratemu by the risk-free rate r.And we take the expectation of what?So that's the measure.What's the function?The function is the payoff at expiration,which in the case of a call optionis the larger of S minus k, or 0.So we make a translation to do Monte Carlo pricingbetween exact probability measure averagesto compute exact expectations.And we do numerical approximations.So instead of an exact expectation,we use the sum of our paths.We're going to take an average.We're going to generate an ensemble of paths.They're all going to be equally probable.We'll compute the terminal value for each path realizationof the derivative of a call option,and then we'll just take an average of those values.To get the Q-measure, we use r instead of mu.For V sub T, what we're going to dois we're going to generate paths,and then we're going to read off the value in their final timestep.And then the discounting factor is justgoing to be an e to the minus r times the durationthat we have.It can be generalized for cases where the interest rates mightbe deterministic and time varying,or even where they might be stochastic.And if they were stochastic, theyneed to stay inside the expectation value.I've moved them in and out because I'massuming the case of constant interest rates.So what we do is we generate an ensemble of risk-neutral paths.We use a risk-free rate for the drift.We use a random number generator so that all of these pathsare equally likely.We look at the terminal values.We compute the average of the terminal values,and then we multiply times a discount factor eto the minus rT for the length of time that's there.The paths that we generate are the sameas we did earlier in the class, and weget some ensemble of Monte Carlo paths, maybe 10,as I've drawn--10 or so, as I've drawn here, maybe 1,000, maybe 10,000,maybe 10 million, depending on whatyour patient's computational resources desiredlevels of accuracy are.But here are the kind of results we have.If I pick particular values for S, for K, for mu,for T for the risk-free rate, if Itake a simulation for a certain number of timesteps, a certain value dt, a certain number of paths,I can write my function and see priceas a function of these arguments,including the simulation parameters, numberof timestamps, number of paths.And I'll get some numbers out in this particular casewhere I ran a simulation, 16.9, 7.05.Now I'll do a recitation, where we'lldiscuss this in more detail.But right now, we can compare that single run of a MonteCarlo against the exact values from the Black-Scholes formula.You certainly can take the valuesthat we solved for in terms of the five functions,put it in r, and run a calculation justin terms of the cumulative distribution functions.Or you can take this library RQuantLib,and it has functions already for the Black-Scholesformulas for European options for calls and puts.And here we find values that we get, 16.7, 7.2.So first of all, we see we're generally in the ballpark.It looks like we're doing something right.Second, we see we didn't get the exact answer,so we should ask is that economically significant.How do we improve the accuracy?Do we change the number of paths?Do we change the number of time steps?Do we need to change our formulation of the problemthat we discretized?So one of the questions is, how do you adjust your algorithmin order to improve the accuracy of your Monte Carlo optionpricer?But the pricer itself couldn't be simpler.We generate a bunch of paths, look at their terminal values,just at the terminal values, take an average, discount it,and we're done.Very easy, no differential equations involved.When we think about how these paths behave,of course, the paths themselves are lognormally distributed,but the shape of the distributionis going to depend on the risk-neutral measure, thereforein the risk-free rate.It's going to be the same thing for every stock,with the same volatility, regardless of what mu is.So the option prices would be the same,and the ensemble would be the same,but will generate some set of sample pathslike the ones I showed you.If we look at the--and the derivative, because remember,what we're going to do is not take the underlying,but we're going to take the terminalvalue of the derivative.So if it's a call option, I take the greater of S minus K or 0,and those paths look like this.You notice it's cut off below at 0.For all the paths that we're finishingin positive territory above the strike price,they're all going to be included here.But an awful lot of paths that hit 0, and stay below 0,or finish below 0 are going to be cut off at this pointbecause we don't see anything below 0 for the value of a calloption.If I look at the histogram of the terminal values, whatI see is a giant spike at 0, a large fraction of the pathsnever made it above the strike price, and thena very asymmetric distribution that's decreasingas a function of price.No surprise there.The higher the value that we would gain,the farther away from the strike price we are, the less likelyit is to occur.

#### CT19_S01_v1-en

PROFESSOR: The generalization of Ito's lemmato multiple variables is straightforward.And we won't go through the same derivation here.We'd just like to tell you the resultand show you a couple examples.If we have multiple variables X, then wecan imagine that each of them is an Ito process,with the difference that the coefficient functions coulddepend on any of the other variables.So the generalization is that I leti run from 1 through, say, n.And for each dXi, each of the coefficient functions ai or bican depend on time, plus all of the other X's.Now, this is dt.There's only a single time.But I'm introducing a Brownian motiondBi for each possible process.Now, some applications of this arewhere we might have multiple assets,like a whole bunch of stocks in a portfolio or in an index.We might have a factor model wherewe try to describe the market in termsof a small number of factors.If it were the capital asset pricing model, or CAPM,we might try to describe many stocks in termsof a single stochastic driver.If it were a factor model, we mighttry to describe the covariant structure observedamong multiple stocks with a small number of factorsand have a covariance matrix that'sperhaps of less than full rank.So all those cases would be examples where wewould have multiple variables.And when we have multiple variables,the only thing we need to be concerned aboutis the possibility that they might be correlated.So the first terms in our multidimensional Ito's lemmaare the same that we saw before.We have partial of F with respect to dt.For each of the X's, we have an independent term,partial of F with respect to X times dX,which is its own Ito process for X1, X2, X3.And the diagonal terms here when i is equal to j,row ij, the correlation between i and j is equal to 1.And this gives us our usual Ito term.But there are a whole lot of extra termsthat can arise if the Brownian motions arecorrelated with each other.And there's a simple heuristic whichgeneralizes what we did before.So in the diagonal cases, dB squared,dBi squared, dB1 squared, or dB2 2squared, and so on gets replaced by a dt.In dX1 squared, it's replaced by b1 squared dt, same as wehad before, ordinary Ito.But if b1 and b2 have correlation rho 12,then the product of these two differentialsis going to be, in probability, equivalentto replacing it by row ij dt.So that gives us this full term, wherewhat used to be a single second partial derivative with respectto X is now replaced by a matrix of second partial derivativeswhere they're multiplied times the correlationcoefficients times the b factors for each of those weights.For example, suppose I've got two stochastic variablesand I have F as their product X1 X2.I apply Ito's lemma, and I see that I get X1 dX2 plus X2dX1 plus dX1 times dX2.And I haven't yet said what either of those Ito processesare for X1 or X2, but we already cansimplify by dividing through by F in this case.So if I divide through by X1 X2, I get a very simple form.dF over F is dX1 over X1 plus dX2 over X2 plus their product.Now, suppose we apply that for a specific case.Say we have geometric Brownian motion,so suppose for X1 and X2 that both of them have dXi over Xiis an individual mu dt plus an individualized sigma dB,then I would have the dF over F isgoing to be mu 1 plus mu 2, the sum of the drift rates,plus an Ito term plus two Brownian terms, sigma 1, sigma2.If rho 12 goes to 0, this ends up justbeing the sum the two Ito processes directly.Suppose we take the ratio, so I take X1 over X2.Well, if we go through and apply the same rulesand divide through by F, we find a somewhat more complicatedexpression.Ratios are a little bit harder to differentiate, so that's OK.But let's take a look at this special case,and we'll see a little bit of a paradox that'shere that you can think about.If the coefficient in rho 12 is zero,so the two processes are uncorrelated,then we have this expression.We don't need to worry about the minus sign here.You might be a little bit worriedthat there's a minus sign in front of the drift term,but remember, it depends only on sigma squared,so the minus sign makes no difference.It's not as though there is risk canceling out between these twoin the event where they're uncorrelated.On the other hand, suppose mu 1 equals mu 2,the drift rates are equal.This term is strictly positive.It depends on sigma 1 squared as the asset in the Itoprocess, the stochastic process, in the denominator dividedby X1 squared.So in the event the mu 1 equals mu 2,these terms vanish, the coefficient is positive,and we have a positive drift term.Now, the question is, how could that be the case?Because if I applied this to X1 over X2and I let F measure the growth rate of X1 relative to X2,how can that be positive at the same timethat the growth rate of X2 relative to X1is also positive?

### 03-Recitation_6

#### Rec06_S01_v1-en

PROFESSOR: One common approach to solving partial differentialequations is to make an educated guessas to the form of the correct answer and see where it leads.Now, this is a little bit differentfrom the special example that we had before,where the example appeared full blown out of thin air,we checked that at it worked, it satisfied the equations,and we were done.What do we do when we face other differential equations wherewe're not given an answer completely?Well, what we do is we look for the structure.And this is one trick that works in many cases,but by no means all, but it does come upin some of our recent discussions.So I thought we'd do a couple of examples together.One of the methods is to try a formwhere we might have a simple form wherethe trial function, sometimes called ansatz,factorizes into two forms.So for example, suppose we didn'tknow about that exponential solution.We had this equation, we noticed that it has two terms-- one'sin t, one is in z.The coefficients are constant.So suppose we try a function.Let's try a function of the form p of z and tis f of z g of t, where f and z are unknown functions,but they're each a function of a single variable.So our goal is to see if we can simplify things.This is a much simpler structure.We can get individual equations for f and g, each of whichis an ordinary differential equation, nota partial differential equation.And then we impose boundary conditions,which might give us the answer right away,or it might require taking a superposition of solutionsusing linearity-- that is, to takedifferent solutions of the same general formand adding them together.So let's take a look in this particular example.If I turn the crank, get we computethe partial derivatives.Partial derivative of p with respect to tis f of z is going to be constant times derivative of g.And the second partial derivativeof p with respect to z squared is goingto be f double prime of z--just a second derivative of the function f--times g of z.So now if we plug these into our differential equation,what do we get?Well, we get that f times g primehas to be equal to 1/2 f double prime times g.And let's divide the whole thing through by fg--by p, that is--by fg.If we take this, we can rewrite things in this form.Then we have g prime of t divided by g of t is 1/2f double prime of z divided by f of z.So this follows just from our differential equation.We took the original equation, we substitutedin this specific form, we get this expression,fg prime is 1/2 f double prime g.We divide through by f and g to simplify things.And you notice what happens here in this expression,I have on the left side, I have g prime over g.They're both functions of t only.That's why I did the division.On the right-hand side, those are functions of z only.So how can I have a function of t equals a function of zfor all values of t and z?Can't really work unless they're both constant.So we're going to do is we're going to set them both equalto a constant.And that will give us one differential equation for g,another one for f, and then when we solve them,we can multiply f and g together, and we're done.So let's call this constant, let's say we'll give it a name.Let's call this lambda.And now we have two differential equations.So I've got g prime of t is equal to lambda g of t.That's an easy equation to solve.That's just an exponential.g of t is equal to some constant--let me call c0 e to the minus lambda t.That's our first equation for g, and we're done.What about f?Just as easy.f double prime of z is going to be equal to 2--from the 1/2 in the diffusion equation-- times lambda timesf of z.So I've got 2 lambda instead of lambda,and I have 2 derivatives with respectto z instead of one derivative with respect to t,but the equation is very similar.And its solution is f of z has two possible terms, twoconstants of integration, c1 timese to the square root of 2 lambda tplus c2 times e to the minus square root of 2 lambda t.Now, if lambda were a negative number, thenthis would have been sines and cosines.Now we don't need to worry about the square root.We would have something times sine plus something timescosine with an arbitrary linear combination of the two.So e0, c1, c2, they're constants of integration.Any linear combination of the terms f of z, g of twill satisfy the conditions.So we can take p of z, t can be f of z g of t.And if we have multiple such terms,we can take a sum over them.And that will automatically satisfy the differentialequation, and then we're done.So let's consider an exercise.So let's try a particular form of the solution--in this case, a function not of t times a function of y.But let's try something of this form, where we let v of t and yof the form that it's the exponential of something that'slinear in y, so that we can see that it might recover thisas a special case when t goes to 0.And where f and g are functions of time alone,and all of the y dependence is herein this exponential to the minus y times f and g.So please take a moment now, try it again.Or if that's what you've already got, hang on.And then we'll take a look throughand what happens when we substitute thisinto our equation.OK, have you got it?Well, what we're going to do is let'scompute partial derivatives and then substituteinto the equation and see if we can get simplifiedequations for f and g.Shall we?So computing partial derivatives,we have that partial of V with respectto t in this form is going to be partial--excuse me, it's going to be a regular derivative.It's going to be df dt minus y dg dt acting on V.And the reason for this is becauseof the exponential form.You remember in our diffusion example,we divided through by e.Here it's helpful if we have a form where everything ends upbeing proportional in the different terms.So taking derivatives with respect to time, I have this.What about the space derivatives?Well, I have partial of V with respect to yis going to be minus g times V andthe second partial derivative of V with respect to y squared.Because remember y, we're linear in the exponent.This is going to be g squared of V. Minus g times minus gjust gives us g squared.So now if we take these partial derivativesand we substitute into our original differential equation,what do we get?We get that it's going to have V timesdf dt minus y dg dt plus 1/2 sigmasquared g squared plus alpha yg is equal to 0.Let's rewrite that.Let's notice that we've got terms that are linear in y,like this one and this one, and the others have no explicity's.So let's group them in terms of those that are linear in yand those that are constants.And we can divide by V-- we're assuming that V is non-zero.After all, we've assumed it's in exponential form.So now we would have df dt plus 1/2 sigma squaredg squared plus y times alpha g minus dg dt.And this has to be equal to 0.Well, how can this be equal to 0?It has to be equal to 0 for all t and for all y.So the coefficient of y has to be equal to 0.And then the constant term, this first term in parentheses,has to be equal to 0 separately.So now we have two equations for df dt and for dg dt.Let's do the second one first, because this term has only g's.This one here has a partial of f with respect to t,and it's going to depend on the value of g.We don't know what g is yet.So why don't we solve g by solvingthis equation, plug g in over here,and then we can solve for f?So these equations are pretty easy.Let's take a look.So taking the g equation first, we'regoing to have that dg dt is going to be equal to alpha g.And that tells us that g of t is going to be some constanttimes e to the alpha t.And now remember what our initial conditions were.Our initial conditions said that at time 0,the function should be e to the minus y.That means that g of t should be equal to 1when t is equal to 0, and f of t should be equal to 0when t is equal to 0.So let me just add that up here for discussionand to remind us.This implies f of 0 equals 0, and g of 0has to be equal to 1.So now let's take a look at our special form.And we can see that that's easy.That means that c has to be equal to 1.So this says the g of t is just going to be e to the alpha t.And when t is equal to 0, g is equal to 1.And we're done.Now, let's look at the differential equation for f.Well, we have df dt is going to be equal to minus sigma squaredover 2g squared.But we know what g is, we just solved for it.So this is going to be minus sigma squared over 2 eto the 2 alpha t, so I've just put in the explicit form of gsquared.And if we want to solve that, that's easy also.If the derivative of f is an exponential, then fis an exponential.We just need to get the constant right.So we're going to have a constant of integration.So this tells us that f is going to be equal to minus--excuse me-- minus sigma squared over 4 alpha eto the 2 alpha t plus a constant.And then f of 0 equals 0 gives usour final form, that f of t, that's to be equal to sigmasquared over 4 alpha times 1 minus e to the 2 alpha t.And you can check.When t goes to 0, this exponential goes to 1.1 minus 1 gives 0, and f of t of 0 zero.Now finally, we've got our solutionto the original equation.So therefore, the solution is V of y and-- or I guess part of tand y--either way, we know what it is-- isgoing to be the exponential of sigma squared over4 alpha times 1 minus e to the 2 alpha t minus y timese to the alpha t.And that's it.So it's an exponential with exponentials in the exponent,but it solves our differential equation, as you can check.You can go back to the beginning.It has the desired form that we wanted.And because it satisfies the appropriate boundaryconditions, we know that it's the right answerthat we were looking for.

#### Rec06_S02_v1-en

PROFESSOR: Let's look a bit more about option pricingin the presence of boundaries and barriers.So we've seen that usually in a partial differentialequation where a derivative value is somewhat universal,it really depends on what the underlying isand the relationship between the risk factors and the underlyingand the derivative.But the boundary conditions matter a lot,and they determine what kind of option we have.So we have vanilla options, puts and calls,with our traditional payoffs above or below a strike price.But there are all kinds of other options, usually calledexotic options if they're not vanilla options.And they may depend on other conditions thatcould happen in time, they could depend on the path of s,and they might involve looking at specific events or eventheir lookback options, whose value dependson the entire past trajectory of s.For example, it could depend on the maximum thats during its lifetime, which would notbe known until expiration.So let's take a look at an example here calleda trigger option.So I'd like to assume that s is given by a usual geometricBrownian motion.And this trigger option gives the ownerthe right, but not the obligation,to buy the underlying stock at a strike price Kif the stock value exceeds another value calledthe trigger X at expiration.So the underlying follows the Ito process, dS over sequals mu dt plus sigma dB.What PDE does the option satisfy, and what's its price?So let me give you one hint, whichis what you might want to do is sketch the option payoff.And you could even ask, could thisbe replicated by another series of contracts?So you might consider that we're thinkingabout-- the generic call option would have a payofffunction that looks like this.A function that had a strike price at Xwould have a payoff function that lookslike this if it were a call.But this one is a little bit different.The payoff is the payoff above K,but only if the price exceeds X. Sotake a moment to see if you can map it out and draw a picture.And if you can solve the equation, even better.I'll be back in just a moment.So first, the payoff.The payoff should-- let's draw this in red, I guess.So the payoff is going to be 0 until we get X.Because if we're below X, we don't get anything.And from that point forward, the payoffis the same we would have had here, that we would have hadfor the ordinary call option.So one way to say this is that the payoff isequal to the payoff for ST greater than xis going to be ST minus K, but only for ST greater than x.Well, another way we can write thatis we can say that ST minus K is equal to ST minus X plus Xminus K. So that is to say, the first part,ST minus X would be the payoff if the strike pricewere equal to X. That is, that would be this payoff function.But that would be a little bit too low, right?We have an extra piece that we're missing here.And that distance, because this has slope 1, is X minus K.And that says that if we're below, we get nothing.But if we're above, we get X minus K units.Hmm, that sounds like a digital option or a binary option.So that says that we could replicate.So this can be replicated--the payoff can be replicated with an optionof strike X plus X minus K binary options of strike K.Oops, sorry.I didn't mean to block that out.So the solution is just going to be the sum,and we've computed those in class.So we can write down the Black-Scholes solutionplus the solution to the binary part.So our answer is that the value of our derivative Vis going to be S times phi of T plus minus Xe to the minus RT times phi of d minus plus Xminus K times the solution for a binary option,e to the minus RT phi of d minus.I've taken little t to be equal to 0 for our current time,and big T is the time to maturity.And then you notice there's a small cancellationbetween these two terms.So this is equal to S phi of T plus minus K eto the minus RT phi of t minus--where we need to make sure that weuse a d plus and a d minus that are appropriate for the strikeprice X. So where d plus minus areequal to the log of S over X e to the minus RT dividedby sigma square root of T plus or minus 1/2 sigma squaredof T. And as usual, phi representsthe Gaussian cumulative distribution function.Now, the lesson here is that we lookat what the payoff is, we check the boundary conditions.And wherever possible, we use our existing solutionsto Black-Scholes to combine them in a way--because we know that we can alwaystake a linear combination of solutionsto the partial differential equationto get another solution to the partial differential equation.What we need is to be able to match the boundary conditions.And this equation matches the boundary conditions,which are the specified payoff at expiration.

#### Rec06_S03_v1-en

Here's an exercise for a barrier optionthat involves solving a differential equation usingthe method of images, or reflection,and the notion of trying to make an inspired guess for a trialfunction.Let's see if we can put it all together.So here's the problem.The problem is to find the value the European down-and-out calloption.And this is an example that was given in Robert Martin'soriginal paper on option pricing that came out at the same timeas Black and Scholes, and he gavethis example of this option.So it has a strike price K, it has time to expiration T,it satisfies geometric Brownian motion,so it has an Ito process.dS over S is mu dt plus sigma dB with mu and sigma constant.There's a knock-out barrier at X,which we'll take to be below the strike price.And the idea is that this is an option thatlooks like an ordinary call optionuntil or unless the stock price hits the value of the barrier.If it hits the barrier, it's done, and it becomes worthless.Why do such things exist?Well, they're cheaper than other options.So there might be particular risks that it's tailored to.There might be particular conditions where someone'shedging a risk, and they figure under certain circumstances,they might not need it.But in any event, there's this option.And there's an interesting complementaritywith another option, the knock-in option wherea knock-in option does the opposite.It begins worthless.But if the strike price hits the barrier, the specified barrierin a specified way, then it comes to life,and it becomes just like an ordinary vanilla option.And it doesn't matter subsequentlywhat happens if it hits the barrier again.Once it's alive, it stays alive.So this is our setup.And what can we do?So why don't you take a few minutes to think about it,and then we can work through it together.OK, let's look at it together.So I've taken a risk-free rate equal to 0to simplify the math, because this is a math example,and it'll be a lot easier.The Black-Scholes equation will go from four terms down to two.So this is not a realistic solution that you could trade.Although these days, with interest rates so low,it might not be a bad approximation.However, we're making a mathematical simplificationjust for the purposes of doing our example here.This is not the right financial equation.So we're just setting r equal to 0 to simplify the math, OK?So the idea is we want to think about what we saw in lectureabout how the diffusion and the random walk property of stockprices looks like the behavior that we saw in the diffusionequation where we saw that we could dealwith barriers by a method of images,by looking at reflected points.So we might think, we might have an ideathat we could try to take a look at the ordinary solutionto the Black-Scholes equation.Let's say, so can we relate--let's ask, can we relate the usual solution--let me call it C of S,t to something at an image price--let's call it-- let's say to option valueat the reflected price or the image price.Now, how are we going to find it?Well, let's just try doing the usual thing.We know that S should be thought of as a logarithmic variable.We know that we want the same distance below as above.So we might take a look at, for example,trying an image price of the form--let me call it log S tilde to be 2 log X minus log S. Sothat way, they're equally spaced above or below the barrier.So if C is the value of the option-- that is,it's the function that's a Black-Scholes function that wehave, it looks like we might be able to write things in termsof--so that is, could we have C of S, t minus Cof X squared over S and t?Now you notice what happens.So I've re--exponentiated, and we can see that this satisfiesthe boundary condition.Because if S is equal to X, the two terms cancel.If the first term has an X, is equal to X,the second term has X squared over X,the two terms would cancel.So this is great.It satisfies the boundary condition.The problem is it doesn't quite satisfy the differentialequation.So it's close, but we're not quite there.So what we're going to do is let's try--so unfortunately, not a solution.So let's try something different.Let's not give up too quickly just yet.So let's try the form S over X to some power--let's say, alpha-- times C of X squared over S times t.What's our motivation for this?Well, if we can do it, we can solve it.We know that the Black-Scholes equationis homogeneous in the powers of S.I've written X as a constant.But rather than just writing S to the alpha,I'm writing it as S over X to the alpha.Now it's automatically clear whenS equals X, that pre-factor is equal to 1,and my usual equation goes through.So this is a guess.We're going to try it out and see where it leads.And if we do it well, and we're lucky,we'll have a good answer.If not, it's back to the drawing board.But let's give it a try.So what shall we do?Let's compute some partial derivatives, shall we?So we have-- let's give this a name.Let's call this f of S and t.Obviously, it also depends on X and the other parameters.So let's compute.Partial of f with respect to t isgoing to be S over X to the alpha partial of Cwith respect to t.That was easy, because the pre-factordoesn't have any t's in it.First, partial with respect to us is going to be--I'm going to be able to pull out a factor of thisfrom my final answer.This is going to be alpha over S times C.And that comes from differentiating with respectto the pre-factor.S to the alpha goes as alpha S to the S minus 1-- excuseme, S to the alpha, the derivative,it's alpha S to the alpha minus 1.So I've written that as S to the alpha.And the minus 1 is down here, just so I can pull outthat common pre-factor.And then I differentiate C, and Ineed to worry about the X squared over S in its argument.So I'm going to get another term, whichwill be minus X squared over S squared times C prime dC dS.And now if we compute the second derivative,we get a somewhat messier expression,but all will become clear shortly.S over X raised to the alpha times--now we're taking two derivatives,so we're taking the derivative of the expression above.We're going to get one term is going to be alpha,alpha minus 1 over S squared times C. I'mgoing to get acting on the X squared over S squared.That's going to give me a term, which willbe plus 2 times alpha minus 1.Rather, this is acting on the alpha minus S.This is the cross-term.The middle term is minus X squared over S squared times dCdS plus one more term, finally, minus X squared over S squared,squared, times second partial of C with respect to dS squared.So let's take a look.These are our three partial derivatives.And remember, we're looking for the Black-Scholes equationwhen we set the interest rate equal to 0.And that means that there's no first derivative term.So this term here won't be present.We really just need to worry about this term and this one.Now, notice something interestingabout this final expression.Look at the alpha independence of it.There's something we might guess is a lucky choice for alphaor an inspired choice for alpha.How about alpha equals 1?If alpha equals 1, this part vanishes, this part vanishes,and the coefficient looks very simple.So if we choose alpha equals 1 for our trial solution,then we get the equation partial of f with respectto t plus sigma S squared over 2 second partialof f with respect to squared--is going to be S over X to the alpha, which is equal to 1,times partial of C with respect to t plus sigma S tildesquared over 2.And actually, I should have put in tildes before.Apologies.Tilde.And here for our derivatives, tilde,where we're taking these derivatives and a tilde here.So now we have that our expression for fgives us something in terms of the transformed variable,our expression here.And we know that that's equal to 0,because that satisfies the Black-Scholes equation.So therefore, we have the value of the down-and-out calloption, down-and-out call.That's this form.C of down-and-out S and t is justC of t minus S over X C of S squared over S, t.That is, the derivatives we had above with respect to tildeare derivatives with respect to the first argument of the callfunction.So this is for S greater than or equal to the barrier Xand equal to 0 for S less than or equal to X.And that's our solution.So what we did is we took our notionthat the call option formula solves Black-Scholes equation.We had a barrier.We found that we could satisfy the barrier conditionsby using method of images by looking at a point below.We constructed something that was close,by looking at that argument X squared of S. That'sin logarithmic variables.That's the equivalent to looking above and below the barrierby an equal reflected amount.We saw that we needed another pre-factor, just asin our discussion of the survival probabilities.We put in a guess for it.We solved for our particular parameter,alpha, that was in the coefficient.We get a final result that gives usthe value of the option above the barrierand 0 below the barrier.And in fact, expanding this out, you'llsee that it looks very much like the expressionthat we had for the survival probabilities.And there we go.

#### Rec06_S04_v1-en

PROFESSOR: Lecture, we saw two waysof solving the Black-Scholes equation.One of them was by doing integrals.Where we had a kernel, a probability density function,we could multiply times the desired payoff,do the integral, and get a solution.But I mentioned, then, that there was another waythat we could do it by using directlythe formula for expectations and the factthat certain expected values satisfy differentialequations in general, and in particular,the Black-Scholes equation.So what I'd like to do is just show you a little bit morein detail here.But I'm not going to write the code.I left that for you to do.And the steps are pretty easy, though.What I want to show you, I've written a functionhere, MCprice, and behind me are a set of Monte Carlo pathsthat I generated before you came in.And I did this using code that's very similar to the code we didat the beginning of the class when we firsttalked about Monte Carlos, except that it'sbeen adapted for the specifics of an Ito process.So what do I mean by that?Well, we have-- our idea is goingto be to find the value of a derivative at time tto be the present value in the time remaining to expirationof the expected value of the function at expiration.And we're going to replace this by an approximation.So this is going to be computed as the averageover a bunch of Vs that could have comeunder different realizations.But we said that this was under the Q-measure.So Q is economist speak.Q-measure, or risk-neutral measure,simply means that we're going to picka drift rate r, the risk-free rate,to replace mu in our formulas.Now, what is it we want to do?We wanted to start with an underlying,so we have an underlying price process.And remember, we're going to discretize things.So we want to do an approximationto a continuous time world, but we'regoing to go back to discrete.So remember when we talked about discrete processes,we said that we could define changes recursivelyin terms of return, logarithmic returns,over a given time period.If we rewrite this, of course, thisis the same as saying that rt is the logarithm of Stover St minus 1.And we didn't specify how far apart t and t minus 1 were,and here we'll think of them as beingsome small but finite distance dt, or delta t, if you prefer.And you notice that this is the same thing as logof St minus log of St minus 1.Now, if you're a nitpicker, you wouldsay that you can't take a logarithm of somethingwith units.So we could divide this by $1, let's say,and just have it be--I could divide this by, say, some S star equal to $1just so that those are dimensionless,and that obviously cancels out.But the important point is that, in termsof this dimensionless variable, thisis going to be what we mean by d of log S.So this r over here is just the return over the time step.That's not the risk-free rate.So what we want is, we'd like to build upa series of iterated values.This is S minus 2, e to the rt plus rt minus 1,and so on, so that we can say that Stis going to be equal to some initial S0 times eto the sum r1 plus r2 plus all the way up to rtwhere these rt's are things that themselvesare described by d of log S.So what does d of log S look like?Well, we know that S is an Ito process.So what we need to do is considerthat if dS/S is given by the risk-free descriptionplus sigma dB, this is what we'd like to do to have our MonteCarlo, but not dS/S, but we want to simulatea sequence of random variables d of log S.And you'll write out what this is in terms of dtand what it is in terms of dB.And then those will be in the same format that we had before.But we need to get the coefficients rightto get the right answer.So the idea is that we're going to generatea particular sequence of random variables thatare consistent with the Ito processthat we have, but with the special drift ratewhere the drift rate is given by the risk-free rate,not the actual drift rate on the stock.And then to compute our option values, what we're going to dois at the end we're going to take--well, put in a discount factor in front.That's not too hard.But our main idea is that we're going to,instead of computing this mathematical expectationby doing Gaussian integrals, we'regoing to generate a whole bunch of price paths of Sand then compute V of S and just evaluate it at the endpoints.So finally, it's going to look like e to the minusr T minus t expectation of V evaluated at the final timeT and that final price ST.So let's make that really concrete.Let me just show you what the pieces are,and then you'll put them together.I promise you, it's not more than a page of code.So if we take a look, what I've doneis I've generated a bunch of paths here.And I've got my parameters already on the side.Now, I have these parameters which are associatedwith the stock price.S0 is 100, mu is 5%, and sigma is 30%.I have these parameters associatedwith the option itself.So let's run those.So I have the strike price is $100.You can pick your value.T is equal to 1 year.One thing to watch out in R is R assumes that capital T standsfor true or false.I always redefine it, but be careful.You can pick a different letter if youwant because it's reserved until you overwrite it the way I did.And I'll take a risk-free rate of 10%.And then finally, I have a set of parametersthat are purely related to my simulation, whereI have two choices.I can pick the number of time stepsinto which I'm going to divide my macroscopic period hereof 1 year, and I have the number of paths in my simulation.So I like to start with around 10,000,the typical size of the error is close of the square root of NP.So that's going to give me a startingpoint with a ballpark in the area of around 1% errors.But you should try it and see how things behavewhen you take a look at it.So let's run those parameters.Now, take a look at the sample paths.I've already run this expression on the right-hand side.And you can see behind me a whole bunch of sample paths.Now, these are all drawn from exactly the same distribution.I haven't told you which process I have to generate them,but you could guess.And I haven't told you what random variable I'm using,but I wrote everything out in termsof a standardized random variable Z.One of the questions you should look at when you tryis to ask how much of a difference does it make.For example, if you take Z equals plus or minus 1,or you take Z to be drawn from a normal distribution of mean 0and variance 1, or you pick somethingelse an exponential variable, anything else that'sbeen rescaled, how much of a differencedoes it make in your simulations?And how does it depend, for example,on the number of time steps before, say, the central limittheorem kicks in, as we would expect it to do overa long period of time, over, say, a few hundred steps?It is worth noting that, if you add evenas few as six uniform random variables,that you can get a fairly decent approximation to the Gaussiandistribution.So here I've got a bunch of paths,and you'll notice this gives me the stockprice all the way out.And I've drawn only 10 of them, not 10,000,because the graph would look rather a mess otherwise.OK.So that's what some of the paths look like.What do the option values look like?Well, remember, the value of a call option on a stockis equal to the stock price minus the strike price.So it's equal to the price minus 100provided the price is above 100.But it's equal to 0 below 100.So if I take a look at my expression,now looking at call values where I've computed in that way,here's what they look like.So you notice these price paths never go below 0.They're not as big as the others because I've basicallysubtracted off 100.And a large number of them are reallyinvisible because they all hug the bottom of the curve.But this is what I want.So I went from my underlying S to my derivative V,or in this case, I've called it C.I've got another one called P for doing the put values.And all that's left to do is to takethe average of the terminal values and discount it,and then we're done.But it might be interesting to see what happens,because these are not evenly distributed.So remember that the histogram for, let's say,the terminal values of S--so let's take the last time step, which would be Nt plus 1,in this case 253, and if we look at a histogram of the values,we see that we get something thatlooks like a typical kind of log-normal distribution.If I do the same thing in terms of the call values,though, I'm going to get somethingthat's quite different.Oops, let's try capital C, definitely case sensitive here.And what I see is, I have a huge spike at 0.A lot of my paths finish below the money,and they don't contribute.And then for the ones that do finish above the money,they're actually decreasing more or less monotonically.There are a couple bumps there, but thoseare artifacts of the simulation and some of the biddingin the histogram.And that makes sense.It makes sense because it's less and less likelythat a stock is going to greatly exceed the strikeprice if it started at the strike priceand these are random walks.The more likely thing is it's goingto be closer to the original value,depending on what the drift rate is, in this case,set by the risk-free rate r.So that's part of what the distribution looks like.This also tells us ways that you could make a much better MonteCarlo than the one I've suggested.Since a lot of the paths, a large chunk of them,in this case almost 60% of the paths, finished with a value,with a contribution of 0 to my final sum,then perhaps we could find a way to spend less time simulatingpaths that aren't going to contribute to the final answer.So those are our steps.We needed to first simulate the paths and the underlying.Second, we take those and we computethe value of the derivative over its entire trajectory.The third step is we then take an arithmeticaverage of the terminal values that are out here.I showed you the histogram, but you justneed to compute an average of those values.So they're either S minus K or they're 0.We compute an average.And then we have a discount factor in front.And that's what goes into my function right here, MCprice.So let's run it and see what we get when I run my function.I have a function that gives me put and a call.And I've enhanced this a little bit to give me an estimatefor standard errors as well by analyzing the dispersionof the results that I have.But let's focus on the first two numbers.So I have that for my set of parameters,the call value should be worth $16.65.The put value should be worth $7.35.So that's it, right?Well, maybe.Let's consider two things.One of them is we can check with the exact resultsfrom Black-Scholes.This is an approximation method, after all.So if we compare with the exact results for Black-Scholes,one way that we can do it is with a librarycalled R Quantlab that includes functions.Or you can code them up yourself just from the Black-Scholesformula, very easy to do.And what we find is for the call,the exact value is $16.73 against our value of $16.65.So is that close enough?At least for a ballpark.But one of the things to think aboutis, what is it that would make the answer precise?Or if I told you that you needed the answer to be within $0.10,within $1, within a penny, would you know what to changein the simulation to get it to sufficient accuracy?How about the put value?Well, $7.22.It looks like the exact value is $7.35.So it looks like our call option is a little high.Our put option is a little bit low.So-- excuse me.Our call value is a little bit below the true value.Our put value is a little bit above the true value.And one of the things that you should considerwhen you do this is whether or not,if you're computing different contractson the same underlying, should you re-run the random numbersor not?Should you re-run the same simulations?There are two arguments, and I'll let you think about itand decide for yourself.One of them is that the whole point of thisis the random numbers need to be random.They can't be biased.So of course, every new thing you do,you should do a new draw of random numbers.The other argument says no, there's only one underlying.And although we might be biased in a particular ensembleand a particular set of paths might notbe exactly representative of what could happen in S,it's very important in the marketplacethat we price puts and calls consistently with each otherin order to avoid arbitrage.So what we could do in that case is generate one set of pathsfor the underlying and then use those to priceputs and calls, different options with different strikesand the same maturity.Or if we want different maturities,we could go out to simulate paths outto our longest maturity, but then use that same set of pathsto use a subset of those for things that would expirepotentially sooner.So finally, we might also remember that in additionto comparing to the known true value--and you should do that because now you'vegot a great test case for your code.You can check your code against the actual values.So any numbers your pick, any parameters you want,compare them to a Black-Scholes calculator.And you'll know when you've got the right answer.But remember, it is a random number generator.So if I run my function again, I'mgoing to get some different values.This time I'm high, $16.85.I run it again, $16.80.So there's some scatter in the values I have.You might think that I could computean average of these values.One question I would ask you is, is thereany difference between averaging different runs of my MonteCarlo pricer versus doing a single run with moresimulated paths inside it?In any event, have fun with it.This is your chance to do it and run a Monte Carloand see if you can reproduce the Black-Scholes results this way.And keep in mind that this is not only an easy thingto code and much easier than solving differential equationsor doing Gaussian integrals if you likebeing around a computer at all.You don't need to do it in R. You can do it in Python,you can do it in Java, you can do itin Visual Basic, anything you want.And they've all been done.They're all widely used.But the other thing about the Monte Carlo methodis that it generalizes to cases wherewe don't have closed form analytical solutionsto the partial differential equations.So we might have a different processfor the underlying for which we don't have the closed formanswer, but we could still use this and put iton the computer.So it's always a good idea to take your algorithms,to take your code, test them against knowncases like the pure Black-Scholes model,and then you'll be ready to face more complicated problems thatshow up in the real world.

### 04-Problem_Set_6

## 10-Week_7-Linear_Algebra_of_Asset_Pricing

### 01-Overview

### 02-Lecture_7

#### LA01_S01_v1-en

PROFESSOR: Let's talk about the structure of financial marketsand when markets are complete, incomplete, or overcomplete.We've seen a variety of instrumentsin different settings.We've seen stocks, we've seen bonds,we've seen derivatives such as options.Let's take a look at the kinds of instrumentscan exist within a marketplace, what kinds of relationshipsthere might be among them, and what kinds of openingsthere are for financial innovation.So the tools to do that are goingto be basic linear algebra.And we're going to take a starting exampleto get us warmed up to the subject is a simple modelfor a one-period market.So there's going to be an initial time,we'll call it to equal 0.And there's one step ahead in the future.We're going to look at a small number of securities,and we're going to see what we can sayand how we can characterize the relationships among them.This model, which we're only going to introduce,can be developed into a multi-period model, whichcan lead to things like the binomial tree model,and bring us full circle back to thingslike the models of continuous timefinance that we've been studying earlier.However, with an appreciation about the kindsof relationships that might be availableand that might be required among the different instrumentsin the marketplace.So here's our simple model.Let's take a look.So our first model is going to bea one-period model where there are two times, time 0 and time1.And we're going to have four securities in this market.So let's take a look at what they are, and then we'llsee how we can model this using simple conceptsfrom linear algebra.So the securities that we have aregoing to be a bond, a stock, and two call options,call option with strike 1.5 dollars,and a call option with strike price of $1.There are going to be three states of the world.We're going to imagine the states of the worldas being three possible outcomes.They might be a good economy, a bad economy, and a pandemic,or some terrible economy.So let's just give the names 1, 2, and 3.This could be any number.We're keeping it small to make it so the algebrayou can almost do in your head, and the slidescan fit on one page.This could be any number of discrete states.We're assuming that they are mutually exclusiveand that they cover all the possibilities.So the probability up in each state adds up to 1.So we'll assign a probability 1/2, 1/6, and 1/3.One of the fascinating things that we're about to seeis that these probabilities, the real world probabilitiesof appearing in these different states,don't matter at all for the pricing relationshipsthat we're going to explore.So what about each of the options?Well, we would like to know how much it's worth in the future.We're going to assume that the price now is fixed.We're not going to say yet what it is.We'll get to that in a bit.But we're going to ask what the future value is going to be,and this is known as the payoff.So the payoff for a risk-free bondis going to be defined as $1 in the future.What makes it risk-free is not that it's $1,it's that the outcome doesn't depend on what stateof the world we're in.The stock, on the other hand, is going to be a risky asset.The amount that it's worth depends on which statewe're in.It could be worth $3.It could be worth $2.It could be worth $1.It might even be worth less than the value of the bond.The call option, however, is determinedbased on the value of the stock because it'sa call option on that stock.So, if the strike price is 1 and a half dollarsand the stock price finishes in one period at $3,then it's worth 1 and a half dollarsbecause we could exercise it immediatelyto buy stock for 1 and a half dollars, sell it for 3,and capture a value of 1 and a half.Similarly, if the stock price is $2,we could buy at 1 and a a half, sell at $2,make it a profit of $0.50.But the value is 0 in the lowest state of the worldbecause we're not going to buy a stock for $1.50 if the marketprice is $1.Our second option, the call optionwith a strike price of $1, is worth $2in this state of the world, $1 in this state of the world,and 0, again, if the market price exceedsthe value of the call option.You can extend this with puts, with other optionsof other strikes, and so on.So, what did we leave out?Well, this is very-- first of all,we only have three states of the world.We've left out a lot of possibilitiesthat these values might have.We're assuming that we can buy or sell these freely,and that we can hold any quantity that we'dlike to have.But we're going to start with this idealized marketwhere there are no market frictions.And we're going to see what these relationshipsamong the future payoffs imply about these instruments.So let's group these numbers together the payoffsthat are received for each securityin each state of the world, an object we're goingto call the payoff matrix.So let there be n different securitiesand s states of the world.In our example n is equal to 4, s is equal to 3.And we're going to represent the payoffsfor each security at our fixed time in the futureas being a column vector of length s.And we're going to collect them in the form of a payoff matrix.So the payoff matrix is a mapping from Rn to Rs.So Rn, where we've got four different securities,tells us which securities we have.And for each security, we're goingto see what it's payoffs are.And there are three possibilitiesfor the payoffs, Rs.So in our example where n is 4 and sis 3 and the numbers of the ones Ishowed you on the previous table,this would be the payoff matrix.The first column represents the payoff of the risk-free bond.In states 1, 2, and 3, it receives $1.So how would we represent that as a vectorin our initial space Rn?Well, we could represent that by a vector, say, that is x--I may not be consistent in keeping arrowsover all of my vectors--is 1, 0, 0, 0 because I have one bond in the first position.And that corresponds to my first column.If I take the matrix A acting on the vector x, I get--because this is a unit vector--I get the first column, so I would get 1, 1, 1.If I change my vector, for example,I look at a vector corresponding to a single share of stock,let's call this x2, that would be represented by 0, 1, 0, 0.And A acting on x2 gives 3, 2, 1.What if I have a mixed portfolio with stocks and bonds?Well, suppose I have a vector.Let's call it x.And say that it's equal to qB, qs, 0, 0,where qB is the number of bonds I have and qsis the number of stocks that I have,then the payoff Ax is obviously going to be qB times 1,1, 1, plus qs times 3, 2, 1.That is to say, portfolios form a vector space.So I can write x as being qB times the first basis vectorplus--plus I have a jumpy pen--qs times 0, 1, 0, 0.And remember that this is a linear algebra.So a matrix multiplication appliesto the rules of linearity.So I can say that A times x in this caseis going to be A acting on qB, qs, 0, 0,which is A acting on qB times 1, 0, 0, 0 plus qs times 0, 1, 0,0.And, by our usual rules of linearity,this is going to be qB times A of 1, 0, 0, 0 plus qsof A acting on 0, 1, 0, 0.And then we get the result that I wrote down before.Remember that A acting on the first basis vectorgives us the first column of the matrix.A acting on the second basis vectorgives us the second column and so on.So we're finally left with our valueis going to be qB plus 3 qs in the first state of the world,qB plus 2 qs in the second state of the world,and qB plus qs in the third stateof the world for our portfolio with qB bonds and qs stocks.

#### LA01_S02_v1-en

PROFESSOR: So, in general, we have portfoliosthat are represented as a vector of the quantities heldfor each security.Those are elements in Rn.And, when we act on it with A, wehave a linear payoff for the simple reasonthat three stocks are worth three times more than one.500 bonds are worth 500 times more than a single bond.And the value of a bunch of stocks and bonds in a portfoliois equal to the value of the stocksplus the value of the bonds, perfect setting for linearity.It's really not very complicated.So we have a portfolio to representthe vector of quantities.And the payoff matrix acts to tell us what the payoff is.So, if I have this vector, which represents being short onebond, long two shares of stock, short two calloptions of strike 1 and 1/2, and short one calloption of strike 1, what is the payoff of this portfolio?Well, the payoff of the portfoliois a linear combination of the payoffsof the individual assets.And we get it by doing matrix multiplication.And, if you check, you'll find that the payoffof that particular portfolio vectoris 0 in the first state of the world,1 in the second state of the world,and 1 in the last state of the world.And, if you want, you can either do the matrix multiplication,or, in simple cases, you can noticethat what matrix multiplication really doesis it gives us a linear combinationof the columns in the matrix.That is I'm taking minus 1 times this columnplus 2 times this column minus twicethis column minus this column.And, when I take that linear combination,it's the same thing as A times x, and I get this value.So it's very simple.Given a vector x, you want to know the payoff.You multiply with the matrix A. Do the matrix multiplication,and there's your payoff.What about going the other way around?Would you have been able to answerif I asked you, here's A, here's the payoff I'd like to get--0, 1, 1-- is there a portfolio that produces this payoff?So this is actually, in many ways,a fundamental question of the designof financial instruments, which is, if there'sa demand for a particular kind of payoff,is it possible to construct a portfolio of instruments thatare available in the marketplace that produces a desired payoff?In a complete market, the answer is yes.And, in incomplete market, the answer is no.So, in other words, what we're askingis how to solve a general linear equation.And this is the most basic problem in linear algebra.Suppose we have a payoff, a target, that we wantthat's given by a vector b.And we have a payoff matrix A. And we'dlike to solve the equation Ax equals b.That is we'd like to find x, the portfolio, whose payoff issome given constant that we've prespecified b.So, as you know, in linear algebra,this could be one number of equationsand some other number of variables.We have s equations and n variables in this case.And, depending on whether n is bigger or smaller or the sameas s and depending on some other relationships,we might have a unique answer.We might have multiple answers.Or we might have none.So let's take the simplest case.If A is non-singular and there's a unique-- and n is equal to s,then there's a unique solution.If A is non-singular, we take the inverse.x is equal to A inverse b, and we're done.So what are the conditions required for that?Well, A has to be invertible.So the columns of A need to be independent.The rows do also.That means that the rank of A has to be full rank.In our example, we could be 3 by 3.The securities are not redundant.That is there's no linear relationship among the payoffsand the securities.We can't write one of the columnsas a linear combination of the others.That's what it means for them to be independent.And we need the same number of securitiesas states, obviously, for the matrixto be square so it can be inverted.What if n equals s doesn't hold?Well, if n is less than s, if the number of securitiesis smaller than the number of states in our financial model,then, in general, there's not going to be any solution.So, for an arbitrary b, there may not be a solution.We just have more states than we have securities.There's no way that we can solve the problem in general.We might be able to solve it for some special cases.So there might be some special b's--that is vectors that lie in the imagespace of the linear transformation A--where there is a solution, but not for all possible b's.So we might have, for example, a two-dimensional subspacewhere there are certain payoffs that we could create,but not any possible payoff.On the other hand, what happens if we have more securitiesthan we have states?Well, in that case, there might or might not be a solution.But, in any event, they're probably notunique because, if n is greater than s,then some vectors need to get mapped to 0.The target space is smaller than the initial space.And that space of vectors that can mapped to 0is known as the kernel or the null space.And one of the interesting thingsis, because A acting on an element of this null spaceis equal to 0, we can add--that means that an element of the null space or of the kernelhas zero payoff.That means that we could add it to any portfolioand still have the same payoff.So these are our possibilities.We could have n equal to s, n less than s, or n greaterthan s.What really is going to matter, though, isthe rank of the matrix.So market completeness is defined as follows.A complete market is one in which every possible payoff canbe generated by some portfolio.One way to say that is that the image of Ais the full space of payoffs.Another way to say it is that the rank of A is equal to s.That is that the vectors that canbe reached by acting with A on somethingis equal to the dimension of the target space.And, equivalently, we could say that the linear transformationis onto or surjective.That means it covers the entire target space.And, if the market isn't complete,well, then it's incomplete.So an incomplete market is one in whichthere exists some payoffs that can'tbe generated by any portfolio.So that means that the image of Ais smaller than the entire space of payoffs.So it's a proper subspace within the space of payoffs.In the example I gave before, it wouldbe a space of lower dimensions.Equivalently, the rank of A is less than s,which is the number of independent statesof the world.So, intuitively, we need for a complete marketto have at least as many securitiesas there are states in the world.That might not be enough because, if wehave a lot of securities, but the securities are reallyjust similar to each other, then theymay not generate anything new, but it's certainly necessary.And, if we have fewer securities than states, thanwe necessarily have an incomplete market.

#### LA01_S03_v1-en

PROFESSOR: So the payoff matrix ishow we think about what it's possible to create.And when we think about looking at derivatives markets, whenwe think about many problems, business problems, managingrisks, looking for insurance, covering and hedgingrisky positions, we're often looking for waysto construct a portfolio of financial instrumentsor contracts that will balance certain risks that we havethat are either part of an investment portfoliothat consists of securities, or possibly other businessand financial and corporate risks thatoccur in different states of the world.So this is the problem of risk management.We want to ask, can we find portfoliosof financial instruments that meet desired payoffprofiles that might either satisfy an urge for gamblingin different states of the world,but more commonly in the financial industry context.We're looking for combinations of assetsthat can match certain exposures or risks thatmight occur in different states of the world.

#### LA01_S04_v1-en

PROFESSOR: Now, I mentioned beforethat we might have securities that aren't independent.We might have more securities than thereare states of the world.And we might have securities that actually are notreally needed, that are equivalent to other securities.And, at first glance, we might thinkthat that would be superfluous.But we do it all the time.Just because we have $1 bills in the American economy,$5 bills are superfluous.You can make a 5 out of five 1's.And you can make a 20 out of four 5's.But we do have these different instrumentsbecause they're convenient.Now, there are no arbitrage relationships among them.You would be hard pressed to find someone who'sgoing to trade you at a different rate$5 bills for $10 bills than the expectedratio between their face values.But, when we're talking about instruments that are risky,unlike risk-free instruments like dollar bills,the answer isn't always so obvious.And markets do have a lot of room for extra instruments.And we'll see that these are really valuable.So we have a notion from our studyof options that options in a certain senseare different instruments than stocksbecause they have different payoffs.On the other hand, because they can be dynamically hedgedusing stocks, there's a sense in which the payoff in an optioncan be replicated, albeit dynamically,by a portfolio of stock.So how do we look at this?Well, let's take a look at our world, whichis not very dynamic.It's only got one period.So the structure is going to be a lot simpler.So in complete and incomplete markets,we could have redundant securities.And that occurs when securities or sets of securitieshave payoffs that are linearly dependent.We often say that that means that one or moresecurities have payoffs that can bereplicated by a portfolio of other securities.And really, if one portfolio can replicate another,we usually can turn it around in either direction.Mathematically, that's equivalent of sayingthat the kernel or the null space of A is non-empty,or the dimension of the kernel of A is bigger than 0if you want.That means that there are portfoliosthat have zero payoff because, if we takethat portfolio, a portfolio of zero payoffs,we add it to some portfolio that has a payoff that we want.The resulting portfolio is a different portfoliowith the same payoff.That's what we mean by redundant.Redundant means there are multiple portfolios thathave the same payoff.Now, in this case, we know that the kernel of a linear operatoris itself a vector space.So, obviously, if I add some element of the kernel,I could add some multiple of the kernel as well.If we want to look at this on the blackboard,suppose that we have a portfolio thatis equal to a given target.So x is our portfolio.b is our payoff.A is the payoff matrix.And suppose that z is an element of the kernel of A.Mathematically, that just means--all I'm saying is that A acting on z is equal to 0.And it means I'm always leaving out the trivial case wherez is a non-zero vector.So, if A acting on z is equal to 0,what happens to the portfolio?Suppose I consider the portfolio--let's call at x prime--to be x plus an arbitrary constant times z.Well, the payoff on x prime is A actingon x prime, which is A acting on xplus cz, which, by linearity, is A acting on xplus c times A acting on z.The first term is equal to b.And the second term is equal to 0 because A acting on 0is equal to 0.So we see that, if I have a non-zero z,I have a one-parameter family of solutions,of redundant securities of portfolios, all of whichhave the same payoff.So, if redundant securities exist,then we don't have a unique association between portfolios.The payoff is not one to one.But, for a given portfolio, for a given x, we know what b is.We act with A on x.We get a definite answer by doing matrix multiplication.But, for a given payoff b, there mightbe more than one portfolio that solves the equation.So, just as I showed you on the blackboard,we can take any solution.We can add to it a multiple of any arbitrage portfolio.And it's going to have the same payoff.Now, in an incomplete market, the existence of solutionsdepends on b.So there might be no solutions at all.But, if there is a portfolio that has a solution,then there's going to be an infinite number of solutions.

#### LA01_S05_v1-en

PROFESSOR: Let's take a look at an example.So suppose I have this reduced payoff matrix.Suppose I have a world with three securities, and I have--so I have three securities representedby the first columns.Think of them as being our first threesecurities, a bond in column 1, a stock in column 2,and a call option on stock with strike price 1 and 1/2in column 3, but no fourth security.And I have three states of the world.So now my payoff matrix is 3 by 3.And suppose the payoff I'm interested inis 2, 1, 0, which, incidentally, was the column that welopped off from our matrix.But suppose we asked a question.Can the K equals 1 call option, column b, the vector 2, 1,0, be replicated from the other three securities?So why don't you take a moment to think about that?See if you can come up with a three vectorx such that A acting on x is equal to b.Or can you show that there's no such thing that exists?Well, A is invertible.So let's invert it.If we invert A, we can find it has this form.I did this numerically.Generally, you're not going to wantto invert any matrix larger than 2 by 2 in your head.You should know how to do a 2 by 2 matrix in your head.But, in this case, here's A inverse.So, because A is invertible, we have a unique solution for x.So not only is there a solution for x.It's unique, and the solution is the portfoliominus 1, 1, which is equivalent to beinglong one share of stock and short one bond.And you can see that.Look at the second column here.Subtract the first column.And we get 2, 1, 0.So I take 3 minus 1 and 2 minus 1 and 1 minus 1.And that gives me this column.So you can see it by inspection, and the third columndoesn't matter at all.Therefore, the fourth security in our original payoff matrixis redundant.So, in our original payoff matrixwhere we had four securities and three states of the world,because the fourth column, 2, 1, 0, canbe written as a linear combination,because its payoff is equivalent to be long the stock and shortthe bond, it's a redundant security.We have an overcomplete market.Its payoffs is identical to a portfolio of basis assets.And that tells us that we have more securities than we need,and one of them is redundant.How about this example?Let's reduce things even further.Suppose I remove the call option.Can the K equals 1 call be replicatedfrom two other securities?Well, this is a little bit different.We know that it can, but we also know that the matrix is notinvertible in this case.In fact, the matrix is a 3 by 2 matrix.So it's not invertible because it isn't even square.There's no chance of inverting it.But a solution still exists.So this is what we said that, when we have a 3 by 2 matrix,we're taking two vectors into a three-dimensional space.There's no way that we can hit all possible threevectors and all possible payoffs,but we can hit some of them.And this is one of those lucky payoffs that we can hit.So, in this case, if we pick x to be the same portfolio, shorta bond, long a stock, even though we have only twosecurities, we still can get this payoff,but there are some payoffs that we can't get.Another example, suppose we include in our security worldthe K equals 1 call.And now let's kick out the K equals 1 and 1/2 call and askif it can be replicated from the other three securities.What do you think?Can you find a linear combinationof these three securities that gives b as a payoff?Well, the rank of the matrix is 2.We know it's singular because we knowthe third column is a linear combination of the first two.We've already seen that.So A is not invertible.And, actually, this option can't be replicated.And this market then would be incompletebecause there are payoffs, such as 1.5, 0.5, and 0, that do nothave portfolios to create them.And that's true whether I include the stock and the bond,which are independent securities,or whether I add a redundant security.Obviously, adding the third columndoesn't help me any because the third column justhas the same information and the same possibilitiesas the first two since I'm already free to make portfoliosfrom them.So, in this case, we've got an incomplete market wherehere's an example of a payoff that cannot be replicatedby the other three securities.One of those three securities is linearlydependent on the others.That means that the rank is not full rank,and it's not invertible.If they were independent, if the matrix were invertible,then we'd have a unique solution.A complete market is one in whichwe can get any payout from a portfolio of our basis assets.So, in a complete market, the payoff matrixhas rank equal to the number of states.In our example of a three-dimensional statespace means that the matrix needs to have rank 3.If, in addition, we have three securities, or we have nequals s, then we don't have extra redundant securities.It means that we have a matrix of full rank.So, if n is equal to s--so it's a square matrix--and the rank is equal to the number of rows and columns,then there's an inverse.And then there's a unique solution for any b.And you might think that's the best possible case,but, actually, it's kind of boring because, in finance, weoften like to find ways of constructingnew instruments for which there might be a demand.And, sometimes, they are actually technically redundant,but there's an interesting market use for them.If n is bigger than s, though, and the matrix has rank s--so, if n is bigger than s, of course, the rank of the matrixcan't be bigger than the smaller of the number of rowsand columns.So, whether n is bigger or smaller than s,the rank of a matrix can't be more than the number of rowsor the number of columns, whichever is smaller,but, if n is bigger than s and the matrix has rank s,then we have an overcomplete set of securities.We have a redundant set.What we can do is, to get a complete basis,we can pick any s securities that are linearly independent,have independent payoffs, and we can drop the extra ones.So, in our example before, in the casewhere we had the K equals 1 call option, we could drop that oneand keep the other three, which are linearly independent.If we have more securities and more complicated matrices,we just need a set of vectors that span the space.So they can form a basis, providedthat they span the space and they have rank s.And we can reduce things to a square matrix thatproduces all of the payoffs.So we have these properties for the rank of a matrix, whichyou should review if they're not familiar, that, first of all,that the rank of a matrix is equal to the rankof a transpose.And it's equal to the smaller-- it'sless than or equal to the smallerof the number of the rows or columns that we have.And, if we have a product of two matrices,remember that, when we have linear transformations,we usually read them from right to leftbecause that's the way in which they act on vectors.And, if one transformation reduces the size of the space,then that carries forward the rest of the way.So, in a product, the rank of a productis never going to be greater than the smaller of the rankof the two matrices.And, if I have a product of A times A transpose,that's going to be equal to the rank of A.

#### LA01_S06_v1-en

PROFESSOR: What about security prices?So far, we just talked about payoffs, future payoffsfor securities.What about the prices?And why do we talk about payoffs instead of returnson securities, how we usually think about it?Well, for prices, let's represent them by a vector S.And what's the dimension of the space?Well, it's going to be n.There's going to be one price for each security in our space.And, if we want to compute the market value of a portfolio,we use the standard rule for computing the marketvalue of any portfolio.We take the quantity of securities, xsub i of security of type i.We multiply times the price.And we sum over the portfolio.We can write this in matrix notationas a row vector times a column vector.Or we can flip it around the other way.So think of S is related to the adjoint, which canbe written with a transpose.It can be written with a star sometimes.But this just means that we're taking S, turning itinto a row vector, and multiplyingtimes a column vector x.It's another way of saying we're justtaking the linear sum of each component of Stimes each component of x.The key thing here is, first, we have one price per securityin our portfolio and, second, that the pricingwe can think of as a linear operation on portfolio vectors.And I can write it like this as S acting on the vectorx, which gives us a real number, whichwould be the market value.Now, in setups where we're thinking about applicationsin derivative pricing, we often talk about future payoffs.And, later on, we don't talk about the return on a securitybecause we sometimes are going to talkabout arbitrage portfolios and portfolios thatmight have zero value.And, if they have non-zero payoffs on the future,then they would have infinite returnif we're dividing by something.So we're going to talk about payoffs because thoseare positive numbers that we're going to have in the future.And, generally, they're going to benon-zero values for securities, but we're nothaving any denominators.So we're only going to keep the numerators.So we've seen that we have a vector space of portfolios,so of dimension, in our starting example, of 4.We have a vector space of prices,which is the same dimension, but it's not the same vector space.Remember, in a vector space, you can add vectors,but prices are measured in dollars.The portfolio space, they're measuredin shares or numbers or quantities of bonds.And you can't add $10 per share, the value of S, to 15 shares.You can multiply them and get something,which dollars per share times sharesgives you something in dollars, but youcan't add them together.So these are two quantities, whichare both vectors, S and x.We can multiply them in this way to get a scalar.But, even though they're of the same dimension,we don't add them.They're actually in different vector spaces,which are called dual spaces.One of them is dual to the other if it has the same dimensionand it acts linearly.That's why, in this picture, we canthink of prices as acting on portfolios to give usmarket values.

#### LA02_S01_v2-en

PROFESSOR: Let's talk about arbitrage.And I'm going to talk about two kinds of arbitrage.And we'll call them type I and type II.What's type I arbitrage?So type I arbitrage says you pay nothing now,and you get something later.So type I arbitrage is something for nothing.The idea is that, right now, the value of a portfoliois either 0 or it's negative.Negative value means that, when you buy it,you get a negative amount of money.That means you get paid to own this portfolio.So suppose I have a portfolio.So I have a marketplace where the prices are given.They're given by us.I pick a portfolio x.And suppose that there exists a portfolio such that S actingon x gives a value that's negative, that's less thanor equal to 0.Let's say it's negative, or it's equal to 0.And suppose, later on, that there'sa non-negative-- there are only non-negative payoffs,and at least one payoff is 0.So if it's purely equal-- if it's the zero vector,that would be trivial.But, otherwise, what we want to have is, in the future,some states could have a zero payoff,but there's at least one state in the future that's positive.And none of the future states are negative.So, in this case, this would be terrific.This is no risk.I either pay nothing, or I get paid.And there's no way I can lose in the future.So basic common sense and finance theorysay that this kind of thing shouldn'texist in the marketplace.If it did, people would exploit it,and it would disappear very quickly.Therefore, it's going to serve on a constraint about the kindsof market structures and pricing relationshipsthat we might observe.So the notation here, I do want to point outone thing, which is not standard in linear algebra.Most of what we do will be.But, normally, we don't write vector inequalities like this.So, in this case, here's precisely what I mean.What I mean is that this holds for all the components, OK?So each of the components has this inequality.Some of the components can be 0.None of them can be negative.But I'm also going, when I write this,to require that at least one component is positive.And, since there's no other notation for it,I'm going to steal this one and torture it slightlyfor our purposes.But common sense and our ideas about arbitrageshould tell you what we mean.And the case where everything is 0is certainly going to be a trivial case.So this is type I arbitrage, somethingfor nothing with no risk.Let's try an example.Suppose I have a securities marketwith two securities, a stock and a bond,and there are three states of the world.And the prices are given by the vector S equals 1, 1.And I look at the portfolio that'sshort a bond and long a stock.Then S acting on x, the market value of the portfolio,is 0 because they have equal prices,and I'm long one and short the other.And the payoff matrix acting on x is 2, 1, 0.And that's what we said would constitute an arbitrage.The value of the portfolio is 0 or negative.In this case, it's 0.And the payoffs are non-negative, and at least oneof them is positive.Now, what if we were to change the prices?This is for this particular set of prices.Can we say something about pricesthat would prevent arbitrage from occurring?So consider this.Can arbitrage be avoided in this example?Three choices-- yes if S2 is greater than 1,yes if S1 is less than 0--less than 1, or no, arbitrage can't be avoided at all.

#### LA02_S02_v1-en

PROFESSOR: So the answer in this caseis yes, provided that S2 is bigger than S1.In that case, we'll have a positive pricefor this portfolio.And there's no contradiction.The problem here was that the stock stochasticallydominates the bond we say in technical terms.Or, in common sense, the stock is alwaysbetter than or equal to the bond in each state of the world.No matter what the possible outcome is,the stock is as good or better.It has a payoff equal to or greater than that of the bond.So its price must be higher.That's a very easy case to consider.Type II arbitrage, in contrast to type I arbitrage,is a case where there are redundant assets.And, in this case, that means that thereare non-trivial solutions to the payoff matrix equation,Ax equals 0.That means that A is less than the rank S.And it means that there's a non-trivial kernelto the matrix A.So type II arbitrage says that, if there'sa portfolio with zero payoff, then it has a non-zero price.So our previous example, in type I,we could get something for nothing.And, in this case, you get nothing for something.So all that's required for type II arbitrageis that a portfolio that has zero payoffhas a non-zero price.And we don't even care whether it'sa positive or a negative price because wecould go long or short, whichever sign weneed to make money for free.That is we're going to collect moneyby selling a portfolio that has no payoffs at all.And we can get money in the present.Again, that's the kind of thing that shouldn't reallybe allowed in a well functioning,properly set up security market.So let's take a look at an example.In this case, let's go back to our original payoffmatrix example A. And let's consider this portfolio--1, 2, 1, 5-- so one bond, two sharesof stock, and six call options of the different strikes.And consider-- so that's my pricing vector.And then consider this particular portfolio.Well, A acting on this portfolio,because the last security is a redundant security,this has zero payoff, but it has a non-zero price.That means it permits arbitrage.What we expect to have to avoid arbitrageis that, if the payoff is zero, the price must be zero.Violating that is type II arbitrage.So can we change the prices so that we could avoid arbitragein this market?

#### LA02_S03_v1-en

PROFESSOR: The answer is yes, providedthat the pricing relationships areconsistent with the redundant securities.That is, since the fourth securitycan be thought of as a linear combination of the first two,its price should be consistent with that.So, if the value of the fourth security,the k equals 1 call option, is the priceof the stock minus the price of the bondand it can be replicated by owning one share of the stockand shorting one bond, then S times x,the market value of the portfolio, of any portfolio,is going to be consistent.And the market value of this portfolio is going to be 0.So we have a rule.We have a law.And it's called the law of one price.The law of one price says that different portfoliosthat have the same payoff have to have the same price.That ensures an absence of arbitrage.And it does mean that there are unique prices for securitiesin the market.Prices are linear.So we have a linear combination of assets in a portfolio.And, for valuing the portfolio, the market valueis going to be a linear combination of prices.In mathematical terms and algebraic terms,we would say that, if the payoffs are the same--if I have two portfolios, x1 and x2,the payoffs are the same if A acting on x1 is A acting on x2.That says the two portfolios have the same payoff.Then S acting on x1 and S acting on x2 have be equal.Notice that this equation involves a row vectorS acting on the vector--on the vector x.This is a matrix equation acting.And this needs to hold for both vectors.Now, we can rewrite this.And we can subtract the A x2 from this equation,and we can write this on the leftby saying that A acting on the differencevector between x1 and x2 is 0.Well, A acting on a vector that gives 0says that x1 minus x2 is in the kernel of A.It's a non-zero vector that is taken into 0 by the payoffmatrix.It's an arbitrage portfolio.If x1 equals x2, then this is trivial.So we're always considering the non-trivial case.That means-- again, doing the same trick,subtracting on the second equation, thatmeans that the price of the arbitrage portfolio, x1minus x2, has to be 0.That's the law of one price.We avoid arbitrage by saying that non-zero portfolios thathave zero payoffs must have zero price.And that's required by the absence of type II arbitrage.Now, we can use no-arbitrage pricing among the basis assetsto price any other asset with any portfolio.And there are two ways that we might think about pricing.We might think about relative and absolute pricing.And, in this picture, like our derivative pricing modelsthat we looked at in continuous time,we're thinking about relative pricingof one asset relative to another or relative to a set of assets.So no-arbitrage pricing tells us about relationshipsthat exist among assets given pricesof a certain set of assets.If there are other assets that are not independent,their prices need to be uniquely determined.That's different from absolute pricing wherewe say what the price of a stock shouldbe based on reading its balance sheet,its earnings report, and so on, a bunch of external variables.Here we're looking at self-consistent relationshipsamong securities that exist in a market.And we don't have any view necessarily about howthat ties in to external observablesor values in the real world.So we have the law of one price.And, using this, we can ask whether a givenmodel of a marketplace is arbitrage free or not.Furthermore, we can impose this as a constraint.If we're thinking about building modelsor we're thinking about introducing new securitiesand designing new kinds of financial products,we want to make sure that it's arbitrage free.Certainly, if we're selling products,we don't want to be the ones getting arbitraged.We can take advantage of an arbitragewith other participants.That might be of interest, but, normally, wewould assume that everyone has the same insights,the same information, and the same access.And a sensible starting point and really a fairlyminimum requirement on any marketplaceis that it should be arbitrage free.But this does give us constraintson what might be present in the marketplace.So this is going to lead us to the fundamental theoremof asset pricing, at least in our simple, one-period model.

#### LA03_S01_v1-en

PROFESSOR: What are state prices?We have a model which has, say, three states of the world.And we began by describing thingsin terms of natural basis vectors.We introduced one element of our-- one dimensionof our vector space for each security we had.And what we'd like to do is do somethingin a corresponding way with respect to the payoff space.So we'd like to think about having one security or oneportfolio that's associated with each possible stateof the world.Now, to do that, we've talked about associatingstates of the world with different payoffs.So a natural thing that we could look foris a security or a portfolio thathas unit payoff in each state of the world.Remember, we began with basis vectorswhere a unit vector in our n-dimensional spacecorresponded to one unit of a bond, one unit of a stock,one unit of a given security.So these securities are known as Arrow-Debreu securities.We'll call them AD securities for short.And they're not necessarily tradable securities.They're portfolios of tradable assets within our original set.So we'll call them securities, but they're reallydifferent portfolios.And they have the property, if they exist,that they are portfolios that have unit payoff sothat A acting on x gives us either 1, 0, 0, 0, 1, 0, or soon, wherever we are.So, if we've got a marketplace wherethere are s such securities or portfolios,then the payoff matrix in terms of themwould be the identity matrix.The first AD security would have payoff one in the first state,the second one in the second, and so on.And the payoff matrix would be diagonal.So that would obviously be a very convenient stateof affairs.So, in terms of a general payoff matrix,the AD security could be replicatedif we have some portfolio such that, when A acts on it,we get a unit vector, but this unit vector, remember, isin the target space, not in our original space.So it's in the space of payoffs.So, if A acting on x has the form of a unit vectorwhere the payoffs are 0 in all of the statesexcept they're 1 in one of the states,those help us form a basis for the space of payoffs.Now, if A is invertible, then things are pretty nice.Then we know what they are.If A is invertible, then I can immediatelysolve for the AD securities by taking A inverse acting on unitvectors in the target space.The prices of AD securities are called state prices.So we think about these vectors or portfolios, hypothetically,that have unit payoff.Because they've got a positive payoff,they should have a positive price associated with them.And, if we collect all of those different prices, the priceof AD security 1, 2, 3, and so on into a vector with valuesthat we'll call psi 1, psi 2, up through psi s,those prices are called state prices.By our rules for no arbitrage, they have to be positive.Let's take a look at an example.Suppose we have a payoff matrix, our old friendA, this 4 by 3 matrix.And suppose I consider these vectors, x1 and x2.Well, I'm on my way.A acting on x1 is equal to 1, 0, 0.If you take a look at that, we have unit payoff.If I take this column plus twice this columnand I subtract this column, I'm leftwith unit payoff in the first stateand 0 in the other two states.And you should check that.Similarly, for the second state, Ican do it with this portfolio.If I have A acting on--excuse me, my pointer is lost.So A acting on the first portfolio gives this result.A acting on the second portfolio gives this result--0, 1, 0.So we can call x1 the first Arrow-Debreu security.It's really a portfolio in terms of our stocks and bondsand call options, but this portfoliohas this important property that it has unit payoff in one stateand zero payoff in the other states.So it's A acting on x is a basis vector in the space of payoffs.This gives us a basis vector with 1 in the second stateand 0 in the other states.So what do you think?Can you find a vector x3 that satisfies the propertythat, when the payoff matrix actson x3, which is a four-vector, it pays off 0, 0, 1?Let me give you a few choices to consider.So here's a question.What portfolio replicates the AD security for state 3?And here are four choices--a, b, c, and d.Take a look, and see which one of these possible portfolioscould serve as our third AD security, which hasunit payoff only in state 3.

#### LA03_S02_v1-en

PROFESSOR: So what did you find?You could either act with A on each of these vectorsand see what you get and see if you match the required payoff,0, 0, 1, or you could throw it on a computerand look at solving this system of linear equations.For example, in R, we can use the function qr.solve,which will help us solve non-square systemsof linear equations.Here's A. Here's our target function.And this finds a vector x3 such that A acting on x3is e3, 0, 0, 1.And here's the solution.And you notice this was one of the multiple-choice answersthat we had.But, if that's not the one you got,don't worry too quickly because it was a little bit of a trickquestion.There was more than one answer.Because there's a non-zero kernel in our matrix A,we could add any multiple of thisto any vector that does work as an AD securityand get another one.And you'll see that one of the other choicesI gave you also works as well because itdiffers by an element of the kernel of A.So suppose we want to find the price of an AD security.Well, first, we want to apply rules of no arbitrage.So let's set the bond price equal to 1.And then, in those terms, the restof the bond prices, S2, S3, S4, are independent variables.So now we have--we'd like to impose that there's no type II arbitrage.So we'd like the market price of our x tilde of our arbitrageportfolio to be 0.And that tells us that we have this relationshipamong the remaining prices that S4has to be equal to S2 minus S1.So we use no arbitrage to fix the price of asset 4, whichwas our second call option.So what do we do?We start with basis assets and our payoff matrix A.We're given a set of prices in the market.And maybe we can fix one of them.We're given a redundant security, xtilde, which is because our market is overcomplete.So then its price is given by the linear priceof the replicating portfolio.And, having fixed that, we can thendetermine the price of everything else,including now our third AD--our first AD security over here because now we know what S4 is.S4 is now fixed at S2 minus S1.And we can compute in terms of now two, notfour independent prices.We can compute the value, the market price,of this AD security as 1 minus S2 plus 2 S3.

#### LA03_S03_v1-en

PROFESSOR: What can we say about non-redundant assets?Well, suppose we've got a market with three states,and we have only one security.So it's a very simple payoff matrix in this case.It's just a single column.And let's give that column a name.Let's call it a1.And the price vector is just goingto be a number because there's only one security.And let's suppose that the market price is 2.And let's ask if we've got another payoff.Let's pick something, 1, 1, 2, which certainly is nota multiple of 1, 2, 3.Now, let's take a look at what constraints we haveand what we can say about prices.What can we say about the price of the payoffb, which is not in the marketplace?So, remember, b would represent if there were a new securityto be created.If you were to go out and create a new instrumentand you wanted to sell it in a marketplacewhere the only instrument that existedbefore was an instrument that had payoffs 1, 2, 3 and youwant to have an instrument that's payoff 1, 1, 2,you'd certainly like to make sure it avoids arbitrage.How could you do that?Well, we do it by comparison with the existing marketplace.So notice that, because a1 stochastically dominatesb, that because, in every state, each element isbigger or less than--excuse me, bigger or greater than the corresponding elementsover here, then we must have that S1has to be greater than a price thatwould be associated with Sb.So, if this were to be traded or if wewere to consider this combination of payoffs,the price associated with it must be less than S1.But we can also get a bound on the other side.Notice that, if I take one half of a1, then all of my valuesare less than those in b.And, therefore, Sb has to be greater than halfof the price of S1.So we can say that, in this case,Sb must be between 1 and 2.It can't be equal because there would be an arbitrage.But Sb is allowed to exist in a range avoiding arbitragesomewhere between 1 and 2.If the market had been complete, then wewould have had unique prices, but, in an incomplete market,we get price inequalities for whatmight be allowed if there were to benew securities with new payoffs thatdon't correspond to linear combinations of existingsecurities.Let's generalize things a little bit moreand look a little bit more systematicallyat how we get those results, apartfrom doing it by inspection.So we've got our vector a1, whichis 1, 2, 3, which is part of our payoff matrix.We have a price vector, and we have a target payoff vector.So let's construct the general linear combination, bminus lambda a, for arbitrary lambda.Well, what we'd like to do is consider the potential pointsof interest where the entries change sign.That will give us the points wherewe have stochastic dominance and constraints whenall of the remaining signs go positive or negative.So, if we do this, we can find out that, as we vary lambda,for lambda equal to 1, which was our first case,we find that's the turning point where one of the elementsgoes to 0 and the others go negative.At lambda equals 1/2, two of the elements go positive,and one goes to 0.And lambda equals 2/3 is not as interestingbecause, although we set one of them to 0,the other two securities in this portfolio have opposite sign.

#### LA03_S04_v1-en

PROFESSOR: So the reason that the state pricescan be valuable is because we can now characterizeall possible payoffs in terms not just of security prices,but in terms of the values of the payoffs, which we know needto have positive state prices.So the state prices need to be positivebecause the payoffs of the elementary AD securitiesare positive.And, in a complete market, all of the payoffscan be replicated, and they all have a unique price.So we have positive state prices if and onlyif there's no arbitrage.If the prices are 0 or negative, then there's arbitrage.We can take some of the AD securities as basis assets,take those portfolios as basis assets in our original space.If we drop the set of redundant securitiesand we choose as a basis the AD securities,then we'd have a very simple description of our securitiesmarket.The payoff matrix would just be the identity.But we know, in any event, that the payoff--that the price for any positive payoff, vector b,is given by the linear combination of the stateprices times the payoffs of those portfolios.So it's given by psi star b wherepsi is the vector of state pricesand b is the vector of payoffs.So, in terms of the original assets,let's see how we can rewrite this.If we write this in terms of the first column of A--let's let the first column of A be denoted a1--then the price of it is given by the state pricevector acting on its payoff.All right, so we take our first-- for example,in our original matrix A of 3, 2, 1,if we have a set of state prices,the state prices applied to the first column give a value S1,and that would be the market price of the security thatcorresponds to the payoff a1.Similarly, S2, the market price of a2,is related to the state prices by letting the state pricevector act on the second column of the payoff matrix and so on.Now, if we group these together, we notice,if we form a column vector of these, of S1, S2, S3,we notice that we could write this as a matrix equation.That is we could say that the row vector Sstar is equal to psi star acting on the payoff matrix.Because this is a row vector, it acts in turnon each of the column vectors in A.Finally, we can use the rule that the transpose of a productis the product of the transposes in the opposite order.So the transpose of a row vector is a column vector.This gives us S. And the transposeof psi transpose A of a row vector times a matrix is--the transpose is going to be A transpose times psi wherepsi is a column vector.So now we have a relationship between market prices and stateprices.The market prices are given in terms of the state pricesby multiplying times the transpose of the payoff matrix.

#### LA03_S05_v2-en

PROFESSOR: Our basic pricing relationshipbetween security prices and state pricesis that s is equal to A transpose psi, or A star psi.This is the adjoint.So A is a payoff matrix where we n securities,and market securities in the world.There are s states of the world that are independent.We can associate a market price with each of the n securities.We associate a state price, and theremay be a different number of them, one stateprice for each state of the world,1, 2, 3, 4, up through s.So the relationship that we expectis that the prices to be consistentneed to satisfy that s is equal to A star psi.And there's no arbitrage if and only if the state pricevector is strictly positive.So we need the state prices to be positivebecause each state price correspondsto some portfolio that has a payoff that is either positive,in fact, it specifically positive in one stateof the world and 0 in others.So the state prices must be greater than 0 in orderto avoid type 2 arbitrage.And they must obey this relationshipto be consistent with the security prices.Because the payoff matrix takes securities into payoffs,and therefore A star is what relateshow we relate security--excuse me-- state prices back to security prices.So we've seen this for complete markets.And in incomplete markets, there could be multiple solutions.There could be an infinite number of solutions for psi.So if there's at least one solution where psi is alwaysgreater than 0, then we're guaranteedthat there's no arbitrage.If all the solutions have psi less than or equal to 0,then there will be arbitrage in the marketplace.So it's helpful to diagram these relationshipsin terms of dual spaces.So I talked before about the left-hand side of the diagram.He said that we have one vector space of portfolios.And in our starting example, this was of dimension four.We had four securities.And we could construct portfoliosthat are linear combinations of quantities of securities.So each element of a vector in this spacerepresent how many of each kind of security we have.There's another space of identical dimensionof security prices.And, in this case, there's one priceassociated with each security.Now, we have a vector, excuse me,we have a matrix A, the payoff matrix, that maps portfolios,it acts on portfolios.It's a linear transformation, and it produces eigenvectorsof a different dimension, which I've drawn over herein this other vector space, that's the space of payoffsof some different dimension s.So A acting on x gives us a payoff b.If we want to know the price of a portfolio x,we act on it with the security pricevector s by taking a row vector of s times a column vector x.And now we see we can do exactly the same thingin terms of payoffs.If I've got a payoff matrix b, maybe I know the portfolio itcame from, maybe I don't.But if I've got a payoff matrix b,then I know what its price has to beby acting with state prices.So the state prices might take a row vector.I act on the payoffs b as a column vector.And that also gives me the price,and those prices need to match.In order for that to hold it has to be the A transpose, whichis the matrix which takes me from stateprices back to security prices hasto give us a relationship that s is equal to A star psi.And then we'll have a consistent set of pricing relationships.Why do we bother going through all this?Because we know what no arbitrage lookslike on the right side of the diagram.We don't know necessarily what itlooks like on the left side of the diagram.Because that's just however the marketplacehappened to be described, whatever the securitiesare, options, bonds, stocks, many different statesof the world.But the right-hand side is very clear.The right-hand side, there's one state for--there's one dimension for each state of the world.The state prices have to be positive.We have a natural association of what the basis vectors are,and therefore we can build up any payoffor linear combinations and immediately determineno arbitrage prices.Here's an example.Suppose we're given market with payoff matrixA and a particular price vector s.So is there arbitrage in this market?Well, A is an invertible, but thereis a pseudo-inversion, which is a standard constructionin linear algebra.And let me just show you how it works.That if we construct this quantity,AA transpose inverse times A, thissatisfies the interesting propertythat if I multiply by A transposeon the right-hand side as I do over here,I get the identity matrix.It's a 3-by-3 identity matrix.It's not a 4-by-4, which would be the normal invertible case.So it's not exactly invertible, but the pseudo-inversecan act on a particular subspace.And you can check that that's true here.In terms of the pseudo-inverse, now Ihave a chance of taking a look and finding a solutionfor the state price vector.If I take a look, if I act with the pseudo-inverse,this 3-by-4 matrix, and I act on the state prices, then I get this vector, which has positive numbers, whichis a good sign.And how do we check?Well, we can check that this satisfies the pricing equationby acting on the left with A transpose.And A transpose acting on the left, acting on psi,gives us our original pricing vector.So that's the sense in which M is a pseudo-inverse.Because if we multiply on the right by A star,it gives us this identity.And this helps us in this case solve for what the state pricevectors are.We find that the state price vectors are positive,and therefore there's no arbitrage.What other prices are allowed?Well, that was a particular value.Suppose I let the third security price vary, and I let it be x.So, in that case, we can use our pseudo-inverseto solve this problem, as well.We have psi is equal to n acting on s, the prices.And now we notice that it has this form.Now, it's going to depend on x, it'sa set of linear combinations.But now we need to impose the condition.Before, for a particular value of xthat I had on the previous slide, it just checked.And all the state prices were positive.But now the state prices are a function of x.We need to check, we need to enforcethat all of these components of this matrix--excuse me, of this vector, be positive.So let's do that.2x minus 1 has to be greater than 0.That implies it has to be bigger than a 1/2.Minus 4x plus 3 is 3 greater than 0.That tells us that x has to be less than 3/4.So we have that x is between a 1/2 and 3/4.And we noticed the third conditionis the same as the first condition.It doesn't give us anything new.So if x is anywhere between a 1/2 and 3/4,that's an allowed security price that will not allow arbitrage.So if x is equal to 0.7, we would get a state pricevector 0.4, 0.2, 0.4.All of those values are positive, and we're OK.We're in good shape.There's no arbitrage.Suppose we let another price vary.So we had one price fixed, the first price of the bond fixedso we could scale things.We had the fourth price fixed by no arbitrage,I have type two arbitrage.We let the third price vary, now let's let the final price vary.Now we've got two parameters to solve for, x and y.And we have a range of prices.And for each value of x and y we have a different possible stateprice vector, which will be givenby this linear combination of assets.And now we need to ask, what values of x and ykeep us from having arbitrage?That's in terms of state prices, and will automaticallytell us what are the allowed prices in the marketplace.

#### LA03_S06_v1-en

PROFESSOR: In an incomplete market,there can be multiple solutions psi.So, for example, consider an incomplete market,which has two securities, a bond and a stock.So there are three states, only two securities.Market is incomplete.What are we going to do?Well, suppose we're given the prices of the securities.And suppose they're $1 for the bond and $2 for the stock.The matrix A transpose that tells ushow to get from state prices to securityprices, the transposed matrix, is this 2 by 3 matrix, 1, 1, 1,3, 2, 1.We notice we can read off a solutionright away because the middle column here is 1, 2.That's what we're looking for for S.So, if A star, this transposed matrix,were to act on the three vector, 0, 1,0, that would solve our equation.So that's obviously a solution for the state price vector psi.But it's not good because it could allow arbitrage.Remember that every element in the state price vectorhas to be positive.None of its elements can be 0.If they were 0, that would allow arbitrage.But it's OK because there's one thingthat we haven't included yet, whichis that A star has a kernel.Because A is a 2 by 3 matrix, there is some vector--there's some three vector--that gets taken into 0 because we'remapping a three-dimensional spaceinto a two-dimensional space.And we can see what that vector is.It's just 1, minus 2, 1.That is, if you double the middle column,it's equal to the sum of the first and the third columns.So, if you act with A star on this vector, you get 0.That means that we can add to 0, 1, 0 any multiple--let's multiply by x--of that vector.Now, we want to choose x so that each component of psiis a positive number.So psi being strictly positive requires firstthat x be strictly positive becausethe first and third components are going to be equal to x.And the middle component is goingto be equal to 1 minus 2x.And that sets an upper bound on x,which says that x has to be between 0 and 1/2.And that tells us what the allowed state pricevectors are.There are an infinite number of thembecause x can be anywhere in this range.Does that always work?No.Suppose the state price-- suppose the market pricevector had been 1, 1.Then there's arbitrage.We saw that earlier.There's stochastic dominance.There's not going to be any solution for psi.And suppose, on the other hand, Sis equal to 1, 3, which is the first column.So then we might try to write down this equation.We could say that psi-- we try the same trick as before.Because 1, 3 is the first column of A transpose,we could say psi has to 1, 0, 0 plus some multipleof the kernel, plus some multiple of 1, minus 2, 0.But there isn't any value of x for which that's going to work.The first-- the second component that says we'regoing to have minus 2x, that tells us that xhas to be strictly negative.The third component is going to be equal to x.That says x has to be strictly positive.x cannot be both positive and negative at the same time.Therefore, there's no solution for any value of x.

#### LA03_S07_v1-en

PROFESSOR: So let's combine what we've seen.Suppose we're given a payoff matrixA. We're given market prices S. And we're given a target payoffb.What do we do?Well, we want to find all state price factors thatsatisfy our pricing equation.Are there any solutions?Is there a unique solution?Or are there multiple solutions?If there are no solutions to this equation,then this market structure permits arbitrage.If there's a unique solution, then it's a complete market.And, if there are multiple solutions,that means that it's an incomplete market.What we do is we then price the assetusing all of the solutions.That is the target payoff b.We act on it with psi star.If there's one solution for psi, then it's easy,and we have a redundant asset.Psi is greater than 0, and we computethe price of the redundant asset as psi star b.Otherwise, we find that there's a full range of allowed pricesthat are all consistent with no arbitrage, provided that theycorrespond to state price vectors thathave only positive values.For example, consider our incomplete market.So, if we have A is given by a stock and a bond,the prices are given by 1, 2, and we'reasked for a specific target payoff,say, 1 and 1/2, 1/2, 0, which is,after all, the payoff of one of our original securitiesfrom our first slide in this week's material,then what can we say?Well, we know that psi is given by 0, 1, 0plus some multiple of the kernel.And, to be consistent, A star psi equal to S,we know that we need to have x is between 0 and 1/2.So what's the price that we can associate with this calloption?Well, to price the call option, we computepsi star b for all allowed values of x.That tells us that we get, by acting with psi star band applying linearity, it's equal to 1/2 plus x times 1/2.And that means that we get 1/2 of 1 plus x.Substituting in for the allowed values of x,we find that the allowed values of this calloption in this incomplete market that is only a stock and a bondare between 1/2 and 3/4.So this is a new asset.It's not a redundant asset.There's no way to make it out of the existing securities.Nevertheless, arbitrage pricing setto bound based on the existing prices in the marketthat it can't violate under penalty of arbitrage.

#### LA04_S01_v1-en

PROFESSOR: So we've got two ways of computing prices.One of them is in terms of market prices.The other is in terms of state prices.And I'd like to combine them by going backto that diagram we drew earlier thatshows the algebraic notion of dual spacesand take advantage of a couple of results from linear algebra.So the idea is we want to relate the two.And, when it comes time in practice,you can use whichever one is convenient.The market prices are convenient in that we knowwhat traded securities are.And it's very easy to associate prices with securities.And those prices might be observable on the market.But what it doesn't tell us is necessarilywhat the market structure is and whatcould happen in different scenariosso that we make sure that everything is consistent.On the other hand, state prices are very easy.There are no-- there are no extra pieces moving around.Nothing else is hiding.And the reason for that, the difference between the two,is that we don't introduce extra states of the world thataren't observed where we might introduce redundant securities.So our initial assumption at the beginning,when we started talking about linear algebra,was that the states of the world were mutually exclusive,and they're non-overlapping.So that's really the reason why thingsare simpler in state space, but you can use whatever is easier.So I'd like to do some algebraic relationshipswith a few pictures.What we're going to come back to is the thingabout matrices where you can use whichever language ismore convenient.We often find that, for doing pricing,it's easier to compute in terms of observables in the marketprices.For understanding market structure, restrictions,and bounds, that's much more naturalin terms of state prices.And, if we have a dual picture, itmeans that we can freely move back and forth from oneto the other and get the advantages of both worlds.So let's see how that looks.So this duality picture means that we can do thingsin two different ways.And, although it's a little bit formal,we can get our pricing relationship very,very quickly by thinking about two different waysof computing the same thing.So, first of all, let's review what a dual space is.A dual space is a set of functions on a vector space.So let's begin with a vector space of portfolios.And I can act on it with security prices.And it's linear because the price of two portfoliosis the sum of the price of each of the portfolios.So the way I act specifically is I turn S into a row vector.I act on x.And that gives me a scalar, which is the price.But S acting on x1 plus x2 is S actingon x1 plus S acting on x2.Through our old friend linearity,I get the same price.Now, these are two different vector spaces, each of whichhas the same dimension because I'vegot one price per security.But, although they're both Rn, they are different spaces.And we saw they have different units.One of them is in dollars.The other is in shares.You can't add them.So, because we have two different Rn's, let'sgive them names.Let's call the lower one, our asset space, V. It's Rn.But the upper space, the price space,the set of market prices, we'll call V star for the dual space.And it's also Rn.So there are two different vector spacesof the same dimension.One of them acts on the other.And this is called a dual space because ithas the same dimension.Now, on the right-hand side of the diagram,we have an analogous situation.We have a set of payoffs.These are a state space, which is S-dimensional.Let's give that a name.We'll call it W. And it's S-dimensional.So, before, we could call that RS,but let's call it W now because there's another RS.There's another S dimensional vector space,and that's W star.It's a set of state prices, whichact on payoffs to give also values for portfoliosand, this time, portfolios that are defined notby their security composition, but by their payoffsin each state of the world.And the way we do that calculation is wetake a vector in the space W star.We turn it into a row vector by takingits adjoint or its transpose.And then we multiply it times the payoff vector b.And these two things have to be the same.So you can use whichever one you want,but our pricing relationship tells ushow to connect the two.So our pricing relationship, S equals A star psi,we can think of in the following way.We have our payoff matrix A, whichmaps V to W, which I've written up here.It takes portfolios into payoffs.We have A star, which goes in the other direction,it takes this dual space W star into V star.It's a transpose matrix.So the dimensions all work out.It takes an S-dimensional space into an n-dimensional space.And now we can compute our pricingfor a portfolio in terms of its payoffs in two different ways.And we'd better get the same answer.So let's see how that works in dual language.To compute the price of a portfolioon the left side of the diagram, I take S transpose times x.On the right side of the diagram,I would take psi star times b.But suppose b is the image of A. Suppose bis the payoff of a portfolio x.Then I would take psi star acting on A timesx, which I can write out here.So it must be the case that the row vectorS acting on x is the same thing as the row vector psi actingon the product A times x.Now, notice that psi star times A is justthe transpose of something.And remember the rule for matrices.The transpose of a product is a productof the transposes in the reverse order.And, also, the transpose of a transpose does nothing.So we can write this as A star psi transpose.If we apply that here, then we get this equation over here.But then we recognize that A star psiis exactly what we hoped to find in our pricing relationship.And, in fact, we have this quantity, A star psi,this quantity in parentheses.When we take its transpose and we act on it a vector x,we get the same thing as S, take its transpose, and act on x.Because x is arbitrary in these two cases,the only way this is going to holdis if we can identify S with A star psi.That's required for consistency.We don't yet know whether they're unique,but it is required.This says that we can price a portfolio either in termsof market prices or using the payoff matrixin terms of state prices.Now, there are some special relationshipsamong these operators between their imagesand their null spaces.And let me just give you an example.But here's the summary of the result.We can say that anything in the kernelof A star acting on anything of the image of A gives 0.That's this annihilator operator.You could think of it as being like orthogonality.Or we also have the additional relationshipthat anything in the image of A star acting on anythingin the kernel of A gives 0.So let's see how that works.Suppose we have an arbitrage portfolio.That is an arbitrage portfolio is a portfolio thathas zero payoff.A acting on x is equal to 0.It has zero payoff.It's what we call an arbitrage portfolio.So saying it's the kernel of A is just a fancy namefor saying that Ax equals 0.Now, suppose we act on it with a price vector,but that price vector is in the image of A star.Now, to be in the image of A star, thatmeans that we found some vector over here in W star,acted on it with A star, and got a security price.So that might not be all possible security prices,but it certainly is some of them.So to say that S is in the image of A starmeans that S is A star acting on some psi for some vector that'sthere.It means there's at least one.There could be more than one.So suppose we have these two conditions.And now let's let S act on x.What do we have?So we have an element of the imageof A star acting on an element of the kernel of A.So S star acting on x is going to be-- because it'sin the image, S star is A star psi is S star acting on x.Take the transposes.That's going to be psi star A acting on x.This matrix multiplication is associative.So let's regroup.Let's do a A times x first and then act on it with psi star.A times x is equal to 0 by this conditionbecause it's an arbitrage portfolio.And I get 0.So fancy notation that relates these different subspaces,but it's really just encapsulatingthe basic rules of arbitrage whenwe have redundant securities.

#### LA04_S02_v1-en

PROFESSOR: Here's a concrete example.Suppose that we've got A is an incomplete--represents the payoffs in an incomplete market.I have a stock and I have a bond.And the image of A is only two dimensional.So image of A is two dimensional because I have two securities.It's less than s, which is equal to 3.So the rank of the matrix A is equal to 2.And we know that.We know the largest it could be is the smallerthe number of its rows and columns.Because the two columns are independent,it's exactly equal to 2.So that image of A is a proper subspace of R3.It's only two dimensional.A star is the transpose, which we've seen before.We know it has a kernel, that is A star takes a threedimensional space into a two dimensional space.Its kernel is the vector 1 minus 2, 1.So suppose this-- this is a vector that lives in W star.It lives in our dual space.So if I come back here, it lives in this space over here.And now if I return, and I imagine that I take psiequals this vector, which is an elementof the kernel of A star.This isn't a valid state price vector,but it does live in the space W star.So this is just some vector.We noticed it does have a negative element here.So this psi is an element of the kernel of A star.And let's suppose it's going to act on the image of A.So let's let b be the payoff of some portfolio.So pick your favorite portfolio x,act on it with the payoff matrix A, get its payoff b.What is its state price?Well, if we act with a state price that'sin the kernel of A star acting on b,which is in the image of A, we can just do the computation.Psi star acting on b is the same thing as star acting on A timesx.We regroup, because it's associative.That's the same thing as psi star A acting on x, whichis A star psi acting on x.And that gives us 0.Because psi was in the kernel of A star, A star acting on psiis 0, therefore, this whole thing is 0.And that tells us that the price of this portfolio--or not the price, but if we act with psi star, which is nota valid state price vector.If we act with an element of the kernel of A starwith the image of A, we get 0.So that helps us narrow things down.So, let's bring it together.We've got two different ways we can approach pricing.And they're not just equivalent, they're called dual.It's related to the dual prices, and theyhave to give the same answers.And you can use whichever one is more convenient.State pricing says that we compute the price of our targetasset, the thing we might think about creatinga particular set of payoffs in different states of the worldby applying all of the allowed values of psi,all of the valid state price vectorswhich are consistent with our market structure.The price is uniquely determined if bis the payoff of a redundant asset,is we know that redundant assets should have pricesthat are uniquely determined.In equations, we would say that the price of our assetis given by--see if I can get the pointer back--there we go.It's given by psi acting on b.That is to say, the price we haveis psi star b where psi is consistent with the pricingrelationship, psi is in the dual space, and so all of its valuesare positive.So that's how we can do things in terms of state prices.We can also do replication pricing, whichis what we started out with.And we don't have any state prices involved at all.You need to identify if it's a redundant asset, and if it is,we associate the value of the payoff with the valueof the replicating portfolio.That's required to avoid arbitrage.Now, for non-redundant assets, wecan frame the allowed prices as a bound on the assetprices that are subject to boundsabove and below by taking a look at possible replicatingportfolios.In the dual side, we know what our view is about whatthe allowed state prices are.They have to be positive.It's not quite as easy to find the price boundsin our replicating pricing world,but we do it by looking at the outside values wherewe can replicate the portfolio.We can find a minimum bound on the priceby defining S min to be the largest price that we canobserve for any portfolio that is strictlyless for each of its components than the target payoff b.If that's the case, we know that this portfoliohas to be strictly less than--or that the price of this portfoliohas to be strictly greater than the price of this portfolio.And, similarly, we can look for a bound on the other side.So if we think back to our first example of stochastic dominancecomparing a stock and bond, we thinkabout having a degree of freedom that letsis very the portfolios so that we can move around and arrangeto where we can see the crossover points between wherewe would exceed a payoff, or go below our lower payoff in oneof our components.We can, with quite a bit more work,we can identify bounds for the prices.But either way in either picture,when we have non-redundant assets,their prices are not uniquely determined.But there are constraints to arbitrage.There are certain values that they're allowed to haveand some values that they can't have.

#### LA05_S01_v1-en

PROFESSOR: The fundamental theorem of asset pricingcharacterizes no arbitrage conditions in a marketplace.It says that there is no arbitrage in a market ifand only if there exists a state price vector whose componentsare strictly positive, and it's consistent with the marketprices, through our pricing relationship,that we can get the security prices by A transpose actingon the state price vector, all of whose componentsare positive.Now, it has an if and only if component.And one direction is easy.And that's the one we're going to do.The other direction is hard.It involves a theorem about separating hyperplanes.And I'll leave it to you to take a look at the literature.But, this one, we can use what we've done,and it's very easy to show.Let's see how it goes.We have type I and type II arbitrage,and we'd like to exclude them both.So, first, let's look at the absence of type I arbitrage.Suppose that I've got a portfolio with a payoff that'sgreater than 0.Remember what we mean here.We mean that it has to have no non-negative payoffs,and at least one of the components of bhas to be positive.So our statement of no type I arbitrageis that, if we have a positive payoff,if we have this condition, then the price of this portfoliomust be strictly positive.It can't be 0.It can't be negative.We can't get something for nothing.So how do we show this?Well, let's compute the price.S star x is the price.That's equal, via our pricing relationship,to psi star A, acting on the portfolio x.We can use associativity of our matrices.That's the same as psi star acting on A times x.But that Ax is the payoff of our portfolio b.And that psi star b, because psi has only positive components,and b has at least one positive componentand no negative components, this isgoing to be the sum of positive numbers or 0.And, therefore, it has to be greater than 0.Done, one line.Absence of type II arbitrage, suppose that wehave an arbitrage portfolio.That is, suppose I have a portfolio that's non-zero.So I do have securities in my portfolio.But they're combined in such a way that the payoff is 0.One way we do that is by having a securityheld long and other securities that replicate it held short.We saw that in the example of replicatingan option in terms of other securities in the portfolio.So, if I have a non-trivial portfolio that has a zeropayoff--that happens when we have a redundant assetin our marketplace-- then the absence of typeII arbitrage says, if you've got an arbitrage portfolio,then its price must be 0.In other words, the value of redundant assetsneeds to be uniquely determined by independent assetsin the marketplace.So that's what we require.How do we show it?Let's compute the price.S star x, the value of the arbitrage portfolio,is going to be given by psi star A acting on x,but A times x is 0.And, therefore, it's equal to 0.So that's shown one direction of the fundamental theoremof asset pricing and how we can be surethat we have consistent prices in the marketplace that don'tallow arbitrage, even when markets are incompleteor when there are redundant securities.

### 03-Recitation_7

#### LAR_S01_v1-en

PAUL F. MENDE: This week's materialcovers applications of linear algebra to asset pricing.And they're really very close correspondencesbetween a lot basic notions of linear algebraand those that are applied for the theory of asset pricing.So I'd like to do something a little bit different this week.What I'd like to do, is do a review of linear algebra,and along the way, we'll comment on the different terminologyand show how it maps to material that wascovered in the basic lectures.For people who need a refresher on linear algebra for this unitand for upcoming things on optimization,such as portfolio optimization, we have a lot of thingshere from the basics.But you won't learn all of linear algebra here;this is really just to review.There are a couple of references we've put out.I recommend, a couple of books I recommendand really anything you find online is probably great,it's very standard subject, but it isa prerequisite for the course.However, if you want to brush up,the book by Serge Lang, Introduction to Linear Algebra,is very clear.And the book by Sheldon Axler, Linear Algebra Done Right,does set itself an ambitious goal.You certainly don't need to read all of it,but for the more mathematically minded,you'll find it to be a very complete treatment.But in particular, covers some things like dual spacesthat we discuss in the main lecturesthat Lang doesn't cover.So it's good on both those counts.So we're going to cover this, but this subjectis a bit different.And within the framework of this course,it's going to be one unit.Remember that this is a topics course.These are methods that are used in different areas, notnecessarily as themselves.But because you'll be seeing this in other courses,in the Foundations of Finance, in Derivatives Pricing,you'll see these ideas come up.The idea of state prices, the idea of no arbitrage.And often, they'll be in very specific contexts.So what we've tried to do here, is give youan algebraic foundation that is usedfor more advanced treatments.This is really just an introduction to that,but it's so that you can think about what'sgoing on in a very general way.At the same time, the problem setsfor this week are very simple.They're not abstract at all.They deal with numbers, small matrices you can do themby hand, you can do them almost in your head,you can put them on a computer.So I don't think that we have a lot of detailed things,like solving the diffusion equationand Green's functions and binary value problems to worry about.What I think we'll do instead, is take a lookat some of the basics.And again, for the people who arefamiliar with linear algebra, you'llbe able to make this identification along the way,hopefully before I get there.So let's get started.

#### LAR_S02_v1-en

PROFESSOR: Here's a warm-up exercise.For each of these sets of equations,how many solutions are there?I don't care what they are.I just want you to find out how many there are.Now, this is a typical problem in linear algebra,and it has a close connection to what we looked at in lecturesthis week in asset pricing, where we'relooking at market structure.And we ask, are markets complete?How many different kinds of coveragecan we get to describe risks thatmight happen in different possible states of the world,to describe rewards and payoffs thatmight happen in different states of the world?We want to know, is it possible to cover everything?And if it is possible to cover everything,is our a solution unique?If it's not possible to cover everything, what's missing?What are the constraints?What can we do?If there are additional things that wecould do to complete a market, are those completions unique?And we invert solutions.We're given an answer.We go back to the original problem.These are all things that you've actuallyseen in other guises for a long time,solving equations as simple as this.But what I'm going to do is go through the basicsof linear algebra as a review.And I hope you've seen the lectures,but if you're coming here first for linear algebra review,you go back to the lectures, come back here again--either way you do it, I hope you makethe connection between the two.And certainly, feel free to skip parts, or speed it upto 1 and 1/2 or twice speed if it helps it go by faster.Vectors are elements in something called a vectorspace.And the key idea is not that they're columns of numbers.The key idea is that they're objectsthat can be added to get other objects of the same type.And of course, we've been dealingwith that throughout the entire course,not as columns of numbers, but we'vebeen looking at functions, where we add two functions,for example, and we get another function.If it obeys rules of addition and scalar multiplication,and it's closed under those operations,then we can think about this as a vector space.There are properties of vector addition.And this is not just for little arrows pointing in the plane.This is true for any mathematical objectsthat obey these properties.We can call it a vector space.It's commutative.V plus w is the same thing as w plus v. It's associative.You can do the addition in any order you'd like.It has an identity, in this case, an additive identitythat we call 0.And importantly, it has an additive inversethat we can have a negative, and we can go the other way.Now, one of the things that we saw in our exampleduring the lecture is that we can represent portfolio spaceas being a set of vectors.But do they form a vector space?One of the requirements is that there be, for example, a 0.Is there?Well, yeah.You could have an empty portfolio.You would add it to a portfolio, you would get nothing.What about v plus w and w plus v?Sure.If you've got 100 shares of Coca-Cola stockand 100 shares of Caterpillar, itdoesn't matter which way you add them.They add up either way.You can commute.What about the additive inverse?That's a bit tricky.How do we have the opposite of a portfolio?Well, the way we usually think about it is a simple answer.And this is approximation to reality,but definitely not the way real-world tradingexactly works.We can think about short positions in a securityas being like owning a negative quantity of that security.That says that if we have short positions,we think that a short portfolio is identifiedwith a long portfolio because the long portfolio arethe stocks you would need to buy to cover a short position.A short position, just as a reminder,is when you borrow stock and you sell it,but you have an obligation to replace the stock to the owner.So there's a natural fit.We can pick it out the additive inverse and the vectoras saying, what's the vector we need to add to get back to 0?In the case of a financial portfolio of securities,say that it is held short, we couldsay, what's the portfolio that we would need to covera set of short positions?That would be a minus of a minus v. Thatwould be v. We could say, what are the trades that weneed to do in order to liquidate a portfolio?That might be a signed portfolio with negative signsfor responding to required sales.And that would say that, if we have a portfolio,the additive inverse is the portfoliothat you would need to sell.You would need to take a negative relative positionin order to get to 0.Those all have correspondences.That's what we saw for portfolios in portfolio spaceduring the lecture this week.Now, the scalars form a field--and here, we use real numbers, not complex numbers.And why is that important?Well, first of all, there are properties that we have.The a times b, we can associate it either way,so we can multiply by a scalar--with two scalars first or the vector first.We have a distributive law for either multiplicationby scalars or multiplication--so a scalar times a sum of vectors or a sumof scalars times the vector.Either way, we have these simple laws.And there's a scalar identity, as well, which is the number 1.So that's fine.But where we run into an issue is that,if we're thinking about portfolio space--and there are lots of other vector spacesthat we use in finance.But if we think specifically of a portfolio space,and we think about our typical example of a set of stocks,stocks can only be held in integer quantities.And that doesn't form a field.There are lots of these buzzwords that are here.And we'll get to touch on some of them,but certainly not all of them.Let's look at some notions from linear algebra,like linear dependence, basis, dimension,different kinds of linear accommodation,and have a direct application of whatwe saw in the structure of financial markets.A linear combination of vectors isa sum of the vectors where we can multiply each vectorby an arbitrary scalar.We saw an example of that in building a portfolio.If you have a portfolio with 100 shares of stock aand 200 shares of stock b, that'sthe same as a single portfolio with components, say,100 and 200.Or it could be 100 times a portfolio with a single shareof stock plus 200 times the portfoliowith a single share of stock b.So we can multiply things by constants.We can add them together.And that's a linear combination.And that's an action that we can take on portfolios.Very natural.Now, a set of vectors is said to be linearly dependent if thereare a set of non-zero constants so that wecan write an equation like this wherewe can set this equal to 0.And of course, what that really meansis that we can solve for one of the vectorsin terms of the other vectors in the set.That's what we mean by a redundant security.We mean that its payoff could be reproduced by some combinationof other securities.Simple example in the introduction I think I gavewas a trivial example, not even with column vectorsin a high-dimensional space.If you have a $5 bill, a $10 bill, and a of $20 bills,you can trade them off for one another.You can replicate the payoff of one with the others.However, we do need to be careful about the divisibility.Assuming that we have constants, wecan show, though, that there are relationships.For example, we could say that 4 $5 bills minus& $20 bill is equal to 0.And that would show that those are--that's sufficient to show that those are linearly dependent.And it's a pretty obvious notion.This is the formal notion.And then, if we can't do that, wesay that the vectors are linearly independent.And this is really important.It means that they describe different kinds of things.An example in our portfolios wouldbe, in terms of our basic portfolio space,if we have two different stocks--they describe different things, that they describecompletely different payoffs--they are independent of each other.Linear dependence means that we can write one of the vectorsin terms of the others.And in the case of our payoff matrix,that means that we can write the payoff of one kind of securityin terms of another set of securities.And that means that we could build a portfolio thathas exactly the same payoff.And that means, in a certain sense,you don't really need the first one.Now, we might have it for lots of reasons, in the same waythat the existence of $1 bills doesn't mean that wedon't find $50 and $100 bills.Of course we do.They're there for lots of different reasons.And the same thing is true in financial markets.In fact, when it comes to derivative pricing,there's an entire, enormous market of securitiesthat arguably are all redundant.And yet there's an enormous demand for them,and enormous trading activity, and theyperform very important functions in the economy.When it comes just back to independence,we have a very simple question, though, which is not,how useful is it?It's just, can you do this?Can you write this equation?And if you can, great.Now, it says we really have one less degree of freedom.In this example, it says v1 can be expressedin terms of the others.Now, there is a technical point here to make,which is that we're dividing by a1,and we do need to make sure that actuallyleads to closure within our chosen field of scalars.And if they're integers, the answer is actually no.You can find a lot of things where this is not necessarilygoing to work for different financial securities.But it turns out that, in usual quantities that are done,this tends to be pretty small.And this is actually a good approximation,but you do have to check.Because either things are linearly independentor they're not.You can't be a little bit dependent.From a mathematical point of view, there's a bright line.From an applications point of view,it requires judgment of the modeler.And that's you.That's why this is a course in mathematical methodsthat are used.We're going through the mathematical rules.But how they get applied will depend.Because in most real-world financial settings,the assumptions the pure mathematicsare almost never satisfied, which means,technically, we can't use any of the results.And you'll need to use your judgmentto see when it might nevertheless be OK to do so.There's an infinite number of factorswe can multiply by all of these constants,but does that really mean that everything is infinite?No, it doesn't.If we start with a finite set of vectors,we can use them to generate a vectorspace just by taking all possible linear combinationsof them.Then it's pretty clear that, even though wecould multiply times an infinite number of scalarsand get an infinite number of vectors,everything is generated by a finite set.We say that set spans the vector space.And we call the vector-- we can saythat the vector space is the span of this set of vectors.So it's true, by construction, that it'sclosed under addition and scalar multiplication.Now if, in addition to spanning the vector space,the vectors are linearly independent,then we say they form a basis for V. The basis isn't unique,but it does mean it's the smallest number of vectorsthat we have to have in order to describe everythingin the vector space.And we call that number the dimension of the vector space.Given a basis, we have a way to describe every vectorin the vector space.It's a linear combination in terms of the basis vectors.And this expression is unique.And this leads us to our usual coordinate system.Because we think of our column vectorsas being coordinates with respect to a basis.If I have basis vectors u1, u2, u3,and I take all possible linear combinations,well I could write that-- so I have c1 times u1, c2 times u2,and so on for any set of c's.Our usual notation is we have these unitvectors, these unit basis vectors,1, 0, 0, 0, 0, 1, 0, 0, 0, and so on.And we see that if we apply this rule,we get our usual notation-- that weget a column vector of numbers.In the case of our classic payoff matrix,we're looking at this in terms of columns,we can think of the basis vectors as correspondingto the arrow to our securities.That is, they are the unit payoffsin state 1 of the world, state 2 of the world,state 3 of the world.And we can take linear combinations.If you want to end up with a vector that pays off 1, 2, 3,it's 1 times the vector 1, 0, 0 plus twicethe vector 0, 1, 0, plus 3 times the vector 0, 0, 1.So that gives us our usual notation.Subspace of a vector space is a vector spacethat's a subset of V. Now, that meansit has to be a vector space on its own.And the span of a subset of basic factors of Vdefines the subspace of V. If we takea set of linearly independent vectorsthat's smaller than the dimension of the space, thenwe--span is going to define a subspace.We can always define something smaller.You can think of a plane as a subspaceof three-dimensional space.You can take a group of independent assetsless than everything and talk about what they span.Because we're looking at everything generatedby a particular subset of basis vectors,it has to be a vector space.And we can take a look at the consequences.

#### LAR_S03_v1-en

PROFESSOR: Now, linear transformations are functions,sometimes called mappings, that go from one vector spaceto another.And they can be completely different dimensions.The key property is one we've been using since the beginning.It's linearity.And here it is.So we've been doing linear transformations all along,without calling them that.So if I have a mapping which says that T takes mefrom vector space V to vector space W,then that means that something of the form T acting on Vis a vector in the space W. Linearitymeans that when the operator acts on this sum,it's the sum of the operator actingon the individual elements.And when we take the transformation actingon scalar times our vector, we can bring the scalar outin front.It's a scalar times the operation acting on the vector.So this simple property of linearity,for example, that we've been using with expectationsis described by the actions on the vectors of the vectorspace.So if we know how it behaves on the basis vector,by using linearity we know how it behaves on anything.So consider a transformation acting on an arbitrary vector.And we can express it as a linear combination.So T is acting on V. V we could writein terms of the basis vectors.Applying linearity, we can write thisas the constants times T acting on each of the basis vectors.And if we know how T acts on each basis vector,then we know how it would act on any vector.And we just recombine the results.So in our payoff analogy, the payoff on a portfoliois the sum of the payoffs of the individual securities.And in fact, it doesn't matter how big your portfolio is.The only thing we need to know are the individual payoffs.And then we know how the payoff worksfor anything more general.And what this says is we really justadd up multiples of the columns thatcorrespond to the individual thingsthat we're interested in.So that brings us to matrix notation.If we combine these columns, we can form theminto something that looks like a matrix.So we construct the columns to be the outputof T acting on something.And I've written T as an abstract linear transformation.And M is the matrix, a concrete set of numbersthat we can write down.And that's important when we're thinkingabout bases and change of basis from one to another,and things more abstractly.That's not going to be very important for what we'redoing now, so we can closely identify the matrixwith the transformation itself.But they are two separate things.It requires a particular bases to write down a matrixwith respect to that basis.To change basis, your transformationis the same transformation, but it gets a different matrix.So the matrix M depends on the choice that we have.And then when M acts on a column vector of the original space,the result is going to be a linear combinationof the columns of M.And we've seen this.If we have a portfolio that consistedof the stock and a bond, and we multiplied it by the matrix A,what did we get?We just got the sum of the first two columns,which intuitively is what we'd expect.It's the sum of the payoffs of the security--individual securities.So this does for us the rules of matrix multiplicationthat might seem kind of weird when you first run into them.They correspond to a very natural wayof adding up payoffs, adding up securities, and adding upmoney.So in component notation, if we write M acting on--so I've got this complicated matrix M with elements mij.I act on a column vector.And the rules of matrix multiplicationtell me that I get a column--excuse me, that I get a column vector over here, whichis of different dimension.And we write-- in matrix notation,we can write this with summation convention.It would be sum over j of mij holdat the i-th component of the result, whichis, say, the second one here, could be i.We hold i fixed, and we sum over the second column,which is everything that we have here for the matching j's.So if we take i to be a particular number 1 through s,where s is the number of rows that we have,and we ask about the i-th one-- say, how do I get, for example,the second row over here--I get it by taking--by holding the I fixed.So that would be corresponding to this second row.And I take each element of the second row times each elementof this vector.You notice they have the same number,and that's what gives me this formula here.But really, the simple thing that's going onis when we do matrix multiplication,we're just taking linear combinations of the columns.These rules simplify if we're in the case of two dimensions.And in particular, if we have square matrices,we can think of this as transformations in the plane.We can look at what happens if we iterate transformationson the same space.More generally, we can define matrix multiplicationwhere I go from one vector space V to another space Wto yet another vector space.And we get that the action of successive lineartransformations is itself a linear transformation.The product of two matrices is itself a matrix.And we have these rules that are complicated to write down.But in principle, it's just telling usthat if we want to get from V to W to X,we could go straight from V to X by looking at this combinedmatrix.Now, the important among the properties of matrixmultiplication are that they're associative,they're distributive.But famously, they are not commutative.You can't change the order.And in particular, not only if you get a number,but if the vector spaces have different dimension,this doesn't even make any sense.In our example, we're really going to be looking typicallyat two vector spaces--one in the world of security markets, where we'vegot a set of securities that we identify wehave a basis vector for each traded security,and on the other hand we have state spacethat has to do with states of the world,possibly in the future, without regardto what finance people are doing and constructing securities.We're going from one to the other and then back.But if we wanted to do multiple hops across multiple spaces,this is the way in which we would do it.And there are two very important spacesthat we're going to use extensively.And these are subspaces of a linear transformation.They're called the image and the kernel.And so the image of a linear transformationis the set of everything that you canreach by acting on it with--by acting with t on all of the possible vectors in the vectorspace.So in our example, we said, what are all the possible payoffswe could generate with a given set of securities?Can I get everything?Do I get less than everything?Whatever it is, the span of the image that we havegenerates everything.So what we say is, specifically, the imageare all the vectors W that are T acting on somethingin our vector space.So this would be the payoff of all possible portfolios,because these V's are linear combinations of our basisassets.And this says that the image of a linear transformationare all the payoffs that can possibly be generated.So it could be the entire target space W.But often, it's going to be less.So this tells us what we can reach,what's reachable with a linear transformation,when it acts on everything in our original space.The kernel of a linear transformationis a subset not of the target space W,it's a subset of our original space V.And it's all the vectors that get mappedinto the zero vector.And sometimes, we say that it's annihilatedby the linear transformation T.So the kernel of a linear transformationis the set of all vectors that are taken into 0.This is going to be-- and this we've seen in lecture--essential to defining one kind of arbitrage.Because this would mean that the payoff on an--obviously, this is a special case.Zero always gets taken into zero.But what does this mean in a financial context?What's a concrete financial example?It's an arbitrage portfolio, wherewe have redundant securities.That is, if I can construct a set of securities--not just an empty portfolio, but actual securities,long and short positions-- and if ithad zero payoff, that's an example of something that'sin the kernel.It's a non-zero vector, it has zero payoff.So one more concept that's very importantis the rank of a linear transformation.And that's the dimension of the image.And that tells us how many linearly independent columnsare in the matrix.That's why we inspect our payoff matrices,see how many columns are there.we can know by inspection or by more sophisticated techniques,how many columns are there that are linearly independent.That tells us how many dimensions therehave to be in the target space.So the rank of a linear transformationis very important.And we've seen the rank of the payoff matrixis essential for telling us whether marketsare complete or incomplete, and in certain cases,about the number of redundant securitiesthey may have to be present.The fundamental theorem of linear transformationsis a rule about the dimensions of these important spaces.It says that the dimension of our original spaceis equal to the dimension of the image plus the dimensionof the kernel.So what that says is the dimension of the image,remember, is the number of independent securitiesthat we have that have payoffs that can'tbe replicated from each other.And the dimension of the kernel isgoing to be the number of redundant assets that we have--the number of assets that are left over thataren't giving us genuinely new payoff.The division between them is not unique,but this fundamental theorem is an important rule,and it holds no matter how we choose to divide things up.It's really a property of the relationship between these twospaces under the action of a particular lineartransformation.Of course, there are some special cases.So if the kernel's empty, if everythinggets taken into a new vector, then the rankof the transformation is equal to the dimension of the spaceV. And if V and W have the same dimension,and we say the matrix is of full rank,then the linear transformation is inevitable.It's a one-to-one mapping from space V to space W.Everything--we can reach every point in W by some vector in V.And from any point, we can alwaysfind the vector V that got us there.Now, it's easy to do operations with matrices on a computer.For two-by-two matrices, you can and shouldbe able to do them in your head.But for anything bigger than two by two,you probably should use a computer,because the rules for doing matrix multiplicationare very complicated, rules for doing thingslike determinants which apply if you have square matricesare even more complicated, and the rulesfor doing inversions of matrices are even more complicated,and the rules for solving for linear independenceof a bunch of sets if you have non-square matricesare even more complicated than that.So it's a good idea to try things out.You can do this in R, which we've been using,or you can pick a programming environment of your choice.But we want to distinguish operations of linear algebrafrom those that are commonly done in lots of computingenvironments, including R, where the typical thing isif you have two lists, two things that would looklike vectors, and if you multiply them together,or two matrices, what it does by defaultis it multiplies them pointwise.And that's not even an operation of linear algebra in general.So what we do is we need a different notation.But that's OK.And it's going to depend on the different languages.So in R, A times B, instead of the star operator,it's sandwiched between percent signs.Very easy and obvious to remember.Percent start percent, A times B,that's the notation for matrix multiplication of A times B.If you want the square, you can take, say, A times A.But what you don't do is A times B that's not a matrix product.That just takes A and B, If they're the same size, not evenif they're square, and multipliesthem element by element.And things-- there are operationswe can define, like exponentials of matricesif the matrices are square.But most of the functions by default don't do that.In this case in R, the exponential of the matrixis going to be the matrix of the exponentialof the individual matrix element.So in addition to that, you need to be awareof a whole bunch of limitations, because they're in computers.So it's easy to get nonsense coming out.And what you have to do this you haveto check your answers to make sure they're OK.Remember that we're dealing with real numbers computers.Can't do real numbers.They do discrete approximations.So there can be rounding issues.There could be issues of stability.A determinant that's close to 0 is not the same as onethat is 0.But for the computer, it might not be able to tell.And we might have two vectors that are either linearlydependent or they're not, they're parallelor they're not, but the computer might notbe able to tell to within machine precision.So you need to go back and forth between the computational tooland checking that things actually work and make sense.So here's an example of what we could do.Suppose we have a linear system of equations.So here's a system of equations like the one I wrote downat the beginning-- three equations, three unknowns.We can write this in matrix form.Using the rules of matrix multiplication,I can write this as M times v equal to b, where I define vto be the vector x, y, z--those are three coordinates.I define b to be a constant.This would be like our payoff vector is B.So here it's 3, 6, 9.And I have a bunch of coefficients in frontthat are all the coefficients in these equations.And by organizing them in this way--1, 2, 3, show up here as 1, 2, 3, 4, 5,6 get multiplied times x, y, z to give us this expression,we can encapsulate this set of equations.In this matrix notation.How do we solve it?Well, M times v equals b, we'd liketo write v as b divided by M. We can't quite do that.We can't just divide by a matrix.But we can do the next best thing if M is invertible.We'd like to have something that we couldwrite as v is M inverse b.Can we do it?So we can define a matrix in R as saying a matrix,here's the list of numbers.We tell it that we want there to be three rows.And it will organize things like this--1, 2, 3, 4, 5, 6, 7, 8, 9.The command to invert a matrix in Ris called solve, because it thinkswe want to solve this system of linear equations.And if we say solve, we get a problem.Here is an error message--computationally singular reciprocal condition10 to the minus 18, which sounds awfully close to 0.And the problem is that's the number we get--something of that order-- if we look at the determinant.The determinant is actually really close to 0.And the reason for it should be pretty obvious nowif we take a look at it.The determinant is 0, that would arise if the rows or columnswere linearly dependent.Notice that the middle column is the average of the firstand the third column.So this column plus this column add upto twice the middle column.That means the determinant is 0.That means that an inverse doesn't exist.Suppose I tweak it.And suppose I change this number from a 9 to a 10.Now, actually, we're golden.So now we have something that is invertible.All three columns are independent.And we can invert it.So what we'd like to do is find the v suchthat when we act with M on the left, we get this vector.If we do that in R, I've got M defined here,I have b defined here.The determinant is minus 3.That's safely away from 0.And if I define M inverse to be the inverse matrix,I get a bunch of numbers.And you might suspect that these couldbe done as fractions, not as decimals,and you would be right.And then we can take M inverse multiplied times b,and we get this vector here, whichlooks like minus 1, 2, 1.776 times 10 to the minus 15.Hmm.Looks to me kind of like minus 1, 2, 0.And if we check, we find out, actually,that that's also the equation.You can see that here, because minus 1, 2, 0,it says take twice the second columnand subtract the first column.So 4 minus 1 is 3.10 minus 4 is 6.And 16 minus 7 gives us 9.So we're good.

#### LAR_S10_v2-en

PROFESSOR: So let's look systematicallyat systems of linear equations and seehow we can classify them.And what you'll see is that this matches closelywith the kind of classification welooked at in the structure of financial markets.Are they complete?Or are they incomplete?What's the rank of the payoff matrix?Are there unique solutions?Are there redundant securities?So in general, there are different kindsof systems of linear equations.And we have cases where we have either homogeneousor inhomogeneous equations.So in the first case, we have an inhomogeneous equationof the form that we looked at whenwe tried to solve a matrix times a vector equalsa fixed constant, b.And the question to solve is, can we find a solution v suchthat when acted on by M, we get the particular target--actually, the payoff vector-- b.Now, there's special case when b is equal to 0.We have what's called a homogeneous equation,because every term in it has a v. 0 is0 times v. And in this case, we're asking,is v in the kernel?And the reason that that's importantis that if we have a solution to the second equation,and acting on b is equal to 0, thenwe can add any multiple of that to the solutionin the first equation, and get another equation.So in general, we've got s equations wit n unknowns,and we want to know when we have a solution.And roughly what we expect to findis that it depends on whether we havethe same number of equations as unknowns,whether we have more unknowns, or whether we have fewer.So what we'd roughly expect it that if s and n are equal,if we have as many equations as unknowns,that there should be a unique solution.And if we've got more equations than we do variables,then we're not going to find any solutions at all.Or generally, that system would be overdeterminedand overconstrained.And if we have fewer equations than variables,we'd expect there to be infinitely many solutions.So that intuition is correct, but it's notenough to count the variables.We need to look at the rank.We need to ask about the number of independent equations,and the number of independent rows and columnsin our linear transformation.So the exact situation depends on the dimensionof the image of the kernel.And remember, those are related through the Fundamental Theoremof Linear Transformations.So let's go through some cases.First of all, suppose that s is equal to n.So we have the same number of equations as unknowns.The matrix M is square.And then there are two subcases.We saw that the matrix might be invertible.Or even if it's square, it might not be invertible.Invertible means that all the rows and columnsare linearly independent.In a securities market, it means that thereare as many securities as there are states with payoffsin the world, and that none of the securitiesis redundant, that none can be written in terms of the others.In that case, we have a unique way to replicate the payoff.Not only can we find a solution, that solution is uniqueand we get it by inverting the matrix.So it's invertible, easy, multiplying left and right hereby an inverse, we get a solution.Now, the determinant of M is 0, if the matrix is notinvertible, if there is a linear dependence among the rowsor columns, then we don't have a unique solution.But what we do have is a nonzero kernel.So there's going to be some nontrivial vector that'staken in to 0 by the action of the matrix.Now, if we look at that in terms of the Fundamental Theoremof Linear Transformations, we cansee that this tells us that the dimension of the image of Mhas to be the rank, and that's going to be n--the dimension of our security space or our original space--minus the dimension of the kernel.And that's going to be smaller, because our assumption isthat this number is bigger than 0.So subtracting a number bigger than 0 leadsto a number smaller than n.And that's going to be equal to s.So we end up with the case where in effect, n, the rank,is going to be less than s.So what that means is that we've got some vectors b for whichthere won't be a solution.There's some vectors that we can reach.There's certain cases where we can solve the equation.But we can't solve it for every possible vector,only for a subset of the vectors.And the size of the subset dependson the size of the kernel of M. The bigger the kernel of M is,the smaller the image of M is.So let's look at how to do this in R.And I'll let you run these commands.These are just simple things that youcan run in the command line.It's mostly about the case where we have a nonsingularmatrix that we just looked at.So here's a system of linear equations.These are three equations, three unknowns.The matrix is nonsingular.The function solve(M) inverts the matrix.If we say solve(M,b), it gives us the unique solution.And it's set up in R. I've constructed a matrix.I've written down a vector, b.I asked to solve for v. And here I get my answerin decimal form, or in happier notation,we can just say v is minus 1/3, 2/3, 0.And you can check that that satisfies the equations above.What we also found, though, of course,is it's a unique solution.So we know that there are no others,because of our properties of M.Now, what about the case where we have a square matrixbut it's singular?So this is the other system we looked at earlier.So in this case, I have the nine down here.Rows and columns are linearly dependent.And there's a technique for solving these equations,as well, numerically.So we can use this function qr to get a particular solution,if it exists.So what we do is, I construct a new matrix.This is M1, in this case.b is going to be the same vector that we had before,and we'd like to solve it.So if we try to solve using our previous method,we get an error message.And it tells us, guess what?Matrix is probably singular, determinant's probably 0.But if we use qr.solve, then we get a warning messagethat the matrix is singular, but we neverthelesscan get a solution.So the solution that we have, the particular solutionthat we have, depends on how we do it.Because remember, if we have a particular solution,if there's a b, it does hit the particular b in question,it's not uniquely determined, because we couldadd any element of the kernel.So you can check the kernel of z is this factor.As I said, the central column is the sumof the first and third columns.So that's what z tells us.And v, here's my particular choice, 0, 0, 1/3.You can check that that satisfies the equationthat we need.When I look in R, it found a different solution.So this one is not as pretty as mine is,but it's equally valid.How do we know that?Two different ways.Number one, we can act on it with Mand verify that it satisfies the equation.Or, number two, we can take the difference between the resultsand find out if they differ by an element of the kernel.Now, suppose that we've got more equations than unknowns.Then in general, there aren't going to be any solutions,or there won't be solutions for at least some values of b.But again, we need to be careful about not just countingvariables, we need n equations, we needto ask if they're independent.After all, if I've got two more equations than unknowns,but those equations are the same equationor they're multiples of the same equation, that doesn't reallycount.So we get at that through looking at the rank.So what's going on in this case iswe've got a smaller space going into a bigger one.So we can't hit everything.If we start with a three dimensional spaceand we map it into a four dimensional space,the most we can hope to hit is a three dimensional subspace.There's always going to be something left over.If we look at this in terms of our Fundamental Theoremof Linear Transformations and we write this out,we can see that the dimension of the imagehas to be less than the entire size of the space.But intuitively, it's because we're taking a small spaceand putting it into a bigger one.So there's no general solution.That means that there's at least a lot--an infinite number of factors that we can't solve for.But we might happen to find a specific one, dependingon the particular b that we have.If it's within the image, then we can find a solution.So here's an example in R. Let's take a lookat four equations and two unknowns.So in this case, qr.solve will give us a particular solution,if it exists.But we need to check, because it will sometimes outputthings that aren't solutions.So we need to check by substitution.And in this case, there is a solutionfor this particular set of coefficients,this b on the right hand side, there is a solution.And you can check that it's 3, minus 2.But we do need to check that, because it's possiblethat we could get something different.And I have an example of that over here,where we have a good answer.And then a case where if I change this 5 into a 6, whichI've done over here numerically, Iget R also gives me an answer.And if you substituted it and you find guess what,it doesn't solve the equation.So there's a specific algorithm in qr.solve which does generatean output, even when it shouldn't.So it's on you to check and make sure that it actually works.Finally, let's take a look at case 3.When there are more unknowns than equations,than there are multiple solutions.This time, we've got a big space going into a smaller one.So think about our first example.We've got four securities going into a three dimensional space.Maybe I've got 10 going into a three dimensional space.So if the space is genuinely larger,we have a really big space going into a smaller one,then some vectors have to get mapped to 0.If we again look at our dimension formulafrom the Fundamental Theorem of Linear Transformations, whatwe can see is that the dimension of the kernelhas to be bigger than 0.Now, if the dimension of the kernel is bigger than 0,that means that any solutions that we do find are not unique.It means there's an infinite number of them.So what it means is if we can find a set of basis factorsfor the kernel, say it's one dimensional,say it's three dimensional, we canadd any linear combination of basis vectors in the kernelto any particular solution and get another solution.So it's a particular kind of infinity.We have an infinite number of solutionsbecause we can add a finite dimensional vectorspace to it, which is equal to the dimension of the kernel.So if the kernel is one dimensional,we have an infinite number of solutions,but we have a one parameter family for that solutions.If the kernel is two dimensional,we have a two parameter family of solutions.So there are two independent parameters, each of whichcould take an infinity of values,but it's not just anything goes.Here's an example in R. Let's takea look at the transpose of the previous matrix, why not?In this case, we've got two equations and four unknowns.Before, we had four equations and two unknowns.So here's the system of linear equations we'd like to solve.The qr.solve function does give us a particular solutionthat we can work with.But now we also need to solve the kernel.Now if we do that and we solve for the kernel numerically,again, there's not a unique way to write it down.There are all kinds of different choicesyou can make for basis factors.And when we do it by hand, we tend to take easy things.These are the ones that I found.And I like them, because they've got integer entriesand they've got a bunch of zeros.That makes it easy to check, and they look nice.However, if you do it in R, you can get something like this.Which, it turns out, there's a zero entry.It's equally valid, but it looks a little bit messier.However, they span the same space.And given any particular solution,such as this one, whether we find itby I, which is easier to do for this set of equations,or if we find it numerically by applying qr.solve,once we have that particular solution,we have a two parameter family general solution.We can add some constant times this basis factorplus the other constants this basis factor.Or, if you prefer to use these two vectors as a basis,we get the same thing.This kernel function is not built into R.There's an example of it I can show you.We can take a look with the definition of kernelby taking a look at adapting the eigenvalue function.This turns out to give us a nice view of the kernel, because wetransfer this into a problem where we can thinkof the kernel being related to the eigenvectorsof a different linear transformation.So the basis might be inconvenient,but if they're not 2 by 2 matrices or 2 by 4 or 4by 2 matrices, where you can look at it,squint a little bit, and guess what the kernel is,you may need to resort to numerical methodsor to other algorithms, and that's completely finein larger case.It's really except for small cases,you wouldn't want to do that.But conceptually, the idea is exactly the same.So what we've done is we've classified different kinds,different categories of systems of linear equations,and their solutions.And we've seen that these correspondto the different cases that we want that,when we examined questions of market completeness--is s bigger or smaller than n?What's the rank the payoff matrix?When we looked at whether there are solutions--what's the image of the payoff matrix?What's the kernel of the payoff matrix?Are there redundant securities?These are all encompassed by the same questionsthat we asked whenever we want to solve any simple systemof linear equations.

### 04-Problem_Set_7

## 11-Week_8-Optimization

### 01-Overview

### 02-Lecture_8

#### Opt01_S01_v1-en

PROFESSOR: In optimization, critical pointsare often critical.We have a function that may be a scalarfunction of multiple variables.We'd like to find its largest value in oneof the necessary conditions.It may be that the partial derivatives with respectto the variables vanish.We also need to check possible boundary terms.So let's take a look at critical points or continuous functions,multiple variables, and see how we can classify them,so we can keep that in mind as welook at financial applications.For a function of a single variable,critical points are places where the first derivative vanishes.Consider the Taylor expansion for a continuous function.I have f of x expanding around a point x0,and I have a linear term times the first derivativeplus a quadratic times the second derivativeevaluated at a point and so on for higher term.Now, if the first derivative varnishes,then I have the special result. If I move the f of x0to the other side, I have that the amountby which f differs from the value at point f0is a parabola.It looks like a quadratic term in the vicinity of x0when x minus x0 is small and the higher orderterms x minus x0 cubed, to the fourth,and so on are small compared to the term that we keep.Now, we need to check that the second derivative, in fact,is not vanishing.For the generic case, it will be.If it vanishes, then we go to the next higher order term.This is typical unless there's either a very accidental reasonwhy it vanishes where there's a particular symmetry.Now, in higher dimensions this parabola,which might be concave or convex dependingon the sign of f double prime, isdescribed by a quadratic form.It's described by the matrix of second partial derivatives.So for a function of several variables,Taylor's theorem tells us that for a scalar functionin the neighborhood of a vector point, a fixed point x0,that we can do an expansion.f of x is being the gradient of ftimes the difference between x and x0 as a vector quantity.That's a leading order term plus a second-order termplus cubic terms and so on.And the second-order term is of particular interest.It's a vector, this difference vector x minus x0transpose times Q times the same vector on the right-hand sidewith a 1/2 in front.And this Q defines a quadratic form.This is just a matrix of second partial derivatives.You can write it out in terms of components if you'd like.And f is the gradient function, and thisvarnishes at a critical point.So when the gradient of f vanishes,which means that all of the first derivativesvanish, not just one of them or two of them--when they all vanish and when x minus x0 is small in magnitude,then we can approximate the deviation of the functionfrom a particular point by this quadratic behavior.So this quadratic behavior, as in the single-variable case,is somewhat universal.It's worth studying because every function, unless Qvanishes for some particular reason,is going to have this form when we're sufficientlyclose in the neighborhood.So there are more possibilities than two,just the two signs of f double primein the single-variable case, and we can take a lookat how they're classified.The eigenvalues determine the type of critical point we have.If the eigenvalues of Q are all positive,the function is convex up and then the critical pointis a minimum.If the eigenvalues of Q are all negative,the function is concave and the critical point is the maximum.If Q has both positive and negative values,then it's called a saddle point.There are some maximum in one direction.It's a minimum in some other direction.And if any of the eigenvalues are 0,they define flat directions where the function is neitherincreasing or decreasing.Now, the reason we talk about the eigenvaluesis because the eigenvectors determine,really, the axes of orientation, and the eigenvaluestell us how things vary along those directions.Because Q is a symmetric matrix--remember, the order of partial derivatives doesn't matter--the eigenvectors are going to be orthogonal.So the general cases we might getwith all kinds of mixed partials reallyare set of cases if we think of diagonalizingand having orthogonal indices--or excuse me, and having orthogonal axes, thenthe eigenvalues whether they're positive or negativealong different directions tell uswhether in that particular directionalong that particular axis the shape of the curveis like a parabola, it's convex up, convex down,or if it's a flat direction.We can take a look at a few examples.So let's look at a few examples of functions of two variables.So I can plot them on the screen in projected three dimensions.Let's consider a function f.It's a function of x and y.So for example, suppose I have this function. f of xyis x times e to the minus x squared plus y squared.And I think of z, the z-coordinate,as being the height of this plot,and this is one way, a prospective plot.And I've given you code in R so that you can run this and getthis pretty picture yourself.But where do we see critical points?Well, the critical points that we seeare local maximum here, a local minimum here.And in fact, if this is what we've got,these are global max and global min as well.They're places where the first derivatives vanish.We can also visualize this in terms of a contour plot, wherewe see-- in a contour plot, we seelines of constant value of f drawn together.We notice-- now, of course, contour linesnever cross because we can't have two different valuesat the same place.But we can see over here, there'sa height scale on the right-hand side.So white is high.Black is low.But otherwise, you see an interesting symmetryon the left and right parts of the graph.So here's a function that typifiesthe kind of classic example where we have a minimum value.This is just instead of a parabola, it's circular.It's a paraboloid.x squared plus y squared, so the minimum value is obviouslythe origin where its value is 0 and everywhere else it'sgreater.Here's a 3D plot.We noticed that with this particular description,the function is rotationally symmetric.If I'd put in different coefficients for x and y,then the axes would have-- the circleswould have been ellipses.And if it had been those axes were then rotated alongsome other direction, the quadratic formmight have a cross term as well, a term in xy.But geometrically, it's the same idea of what's going on.There's a single minimum.There's some contours around it.This is an example of the function,which has a saddle point.Here, I have f of x is x squared minus 4y squared.So you notice that not only is the sign of the x termand the y term different, but the coefficientis as well so that the speed of change or the rate of curvaturecan be different in the two different directions.So if I move along the x direction, I'm increasing.If I move along the y direction for the origin, I'm decreasing.Here's a contour plot of the same thing.Now here's an interesting case where we have a flat direction,and we also have a mistake in the equation.So that should just be f of x equals--f of x and y equals y squared.So you notice that because there's no y dependence,the function has a symmetry.I can translate in y.I can take any value.And that means that as I move in the y direction,not only is the direction flat, but every cross section,the x dependence at any given point y in that valley,is exactly the same.So this is an example where we have a flat direction,and it's due to asymmetry in the problem.And in this case, one of the eigenvaluesof our quadratic form Q, our matrix of second derivatives,is going to be 0.This is a case where, like the other one,I have a flat direction along the y equal 0.But unlike the other one, it's not symmetric.It's not translationally symmetric.And you can see that as I move along the y-axisfor different values of y, the cross section,the cross-sectional curvature, as I move in the x directionchanges.So in one perpendicular direction, I'm completely flat.But in the other direction, thereare changes that are seen once I move in the perpendiculardirection.And here's a picture of the same thing shown as a contour plot.

#### Opt02_S01_v1-en

PROFESSOR: In the presence of constraints,it's not enough to just find critical points.Constraints are everywhere in the real worldand certainly in finance and economics.We have finite resources that we need to allocate.We have a finite budget.We have a finite risk limit that we shouldn't exceed.So we're often asked to solve problemswhere we're looking for the best solution or a maximum valueof some scalar function subject to a constraint.And those constraints can take different forms.They might be equalities.They might be inequalities.They might involve one or multiple variables.So let's start at the beginning with the Lagrange multipliermethod for solving equality constraintsin multidimensional optimization problems.Here's a picture to help visualize things.This is a contour map of the neighborhoodof Mount Washington showing its hiking trails.Mount Washington is the tallest point in New England.And, if I asked you to leave MIT and to find the tallest pointand you had a functional description of this,you could certainly find lots of local extrema,but the global maximum would be at 6,288 feetright here at the top of Mount Washington.But you notice there are lots of hiking trails around the topof Mount Washington.And there's even an auto road here,and there's a railroad that goes down the backside.But, if you were looking for a tranquil way,you might, say, be over here at the Appalachian Mountain ClubLake of the Clouds Hut.And you'd like to hike over here to Tuckerman Ravine, whichdescends rather steeply.And you'd like to do it without goingthrough the summit at all.Well, a question you certainly could askis, along a trail of my choice, saythis one, what's the highest point that I would reach alongthe trail?So the trail represents your constraint.You're not free to go anywhere in latitude and longitudeon this map.That's your constraint.But we can ask, as you go along the trail, at every point,you're definitely at some elevation above sea level.And we could think of that as being a functionh of x, y where x and y give your latitudeand longitude for example.And we could ask a very reasonable question.If there are no cliffs here, eventhough it descends steeply, and if you don'tfall into a crevasse, we could ask,what was the highest point along that trail?One of the things that we can see immediatelyis, whatever it is, wherever the highest pointis along this path, it has nothingto do with the global maximum.It doesn't go anywhere near the summit of Mount Washington.OK, so it's not enough to just take a functionand find its extrema because the answerthat we're looking for may not be anywhere nearby.The answer to doing this is also--let's think about this a little bit geometrically.Imagine that we're ascending.Say we're climbing through Tuckerman Ravine.And we're going to go along here.What does it mean?As long as we're ascending, we are crossing contour lines.Contour lines, remember, are level setswhere the altitude is constant, where our scalar functionh is constant.What it means to reach an extremum along the pathor to reach a maximum along the pathis that you're no longer crossing contour lines.That is your direction of travel,the tangent along the path that you're taking,is parallel to the contour lines themselves.The point at which you reach a maximumis when the direction of your trailis along the direction of a contour line, at leastinstantaneously.In either direction going forward or backward,you would be going down at a critical point.So the geometrical condition we haveis that the direction of the pathshould be tangent to the level sets.And that we can state as a condition on the gradientsof the two functions, one describing the constraintalong the path and the other describingthe shape of the level sets of the function hwithout the constraints.And, when we overlay the two, we saythey need to be in the same direction.And that's what the Lagrange multipliermethod is going to give us.So here is the Lagrange multiplier method.What we're going to do is take our original unconstrainedfunction, h of x, y, and we're goingto construct a new function called the Lagrange function,which is going to have one extra variable, whichis a variable called lambda.And this extra variable lambda is knownas the Lagrange multiplier.And the way I construct the functionis I take my original function, h of x, y,and I subtract lambda--it's linear lambda in this new variable--times, in parentheses, I have my constraint.So imagine that the constraint is given by some equationin x and y, saying what they need to satisfy.x and y is equal to some constant.So all I've done is I've taken my original functionminus lambda times the constraint itself.So the strategy here, in practical terms,is to take a problem in two parts,maximize the function subject to a constraint,and turn it into a simpler problem in more variables.So the problem in three variables,with x, y, and lambda, is going to have no constraints.So the idea is that we're going to take all threepartial derivatives now, set all three of them equal to 0.That will impose the condition that the vectors--that the direction of my constraintis along the direction of the level sets.And it's easy to solve.So let's take a look at a couple of examples,first in algebraic functions, and then we'llsee how this applies in finance, most notably, to the caseof portfolio optimization.The general method is this.If we have multiple constraints, we introduce one constantcalled the Lagrange multiplier per constraint.We define the Lagrange function, whichis linear in the constraints.It's got extra variables, one per Lagrange multiplier,but it has a simpler solution.We take the derivatives with respectto each of the original variables.And, of course, that gives us the original partialderivatives we would have had plus something that'slinear in lambda or the other Lagrange multipliers.And, when we take the derivative with respectto the Lagrange multipliers, the equationswe get when we set those derivatives to 0are just the constraint equations themselves.So that's it.Then we find the critical points,and we can substitute them in and makesure they solve the problem.We can check second derivatives to make sure that, in fact, wehave a maximum and not a minimum or a point of inflection.And, usually, not always, but in many problems,it doesn't even matter what the Lagrange function is.What we care is the location of the extremal value, notthe value itself.So that's worth keeping in mind because it can simplify things.So, for example, if we want to picka different form of the Lagrange functionthat's easier to solve, but wherewe know it has the same critical points, that's OK.We can do that.And, in fact, when it comes to the constraint,we have a lot of freedom as to how we could change itbecause, at the critical points, the constraint function isgoing to vanish.So let's take a look at a couple of examples.So here's a chance for you to do your own concept check.And you can pause the video at this point.And then we'll solve it together.But here's the example.Let's let h of x, y be the function x plus y.And let's let the constraint be that the solutions,the maximum, minimum, or extrema that we're looking for,have to lie along a circle of radius r.r here is just a radius.It's not the risk-free rate.So we construct our Lagrange function,L of x, y, and lambda, to be our function h, x plus y,minus lambda times the constraint.So, if you'd like, pause the video.See if you can solve it.Find the critical points.And then come back, and we'll take a look at this together.OK, so let's compute some derivatives together.What we find is we take the first partial of Lwith respect to x.We get 1 minus 2 lambda.Notice it's we have lambda here.We're always going to have something linear in lambdabecause this is left over, and the partial derivativesact on the constraint.So that tells us that x is 1 over 2 lambda.I take the partial with respect to y.My function is symmetric in x and y.So, no surprise, I get that y is 1 over 2 lambda.And now, because x and y are both equal to 1 over 2 lambda,I can eliminate lambda.And I see that x is equal to y.So I'm almost done.x is equal to y, but they also haveto lie along the constraint, whichmeans that the sum of their squareshas to be equal to r squared.So, if I substitute x equals y into this constraint equation--and notice the constraint equationI get just by differentiating with respect to lambda.There's no lambda in the original function h.And there's a linear in lambda before the constraint.So differentiating with respect to lambda justgives me back my constraint.It's exactly what I would have had before,but, whereas, without the Lagrange multiplier method,you might have tried to solve for y in terms of x--you could have written y as beingplus or minus the square root of r squared minus x squared,substituted it back into h, and then triedto solve for that extremum.You'd have had a more complicated function and fewervariables.Here we're going to keep everythingwhere all the variables start on equal footing.We substitute into the constraint.We find there are two solutions.x and y are each equal to plus or minus rover square root of 2.Either they're both plus signs, or they're both minus signs.And it's easy to check that either,at 45 degrees in the first quadrantor in the third quadrant, we havetwo points on the circle, which representthe maximum and the minimum values of x plus y.And, if we substitute in the values,these are the values, square root of 2 times ror minus square root of 2r, OK?So that one you might have guessed justfrom symmetry of the problem, but this is the method.It's really very easy, very straightforward.Let's do another example.Here, again, pause the video.Take a look at doing this.And then, after you've checked your own conceptsand your own math, come back and compare.A couple of things to note, our function in this caseis a general quadratic form with a cross term.So it may not be obvious immediately where the extremaor whether they're maxima or minima or saddle points.And we're going to look at this quadratic form,instead of linear on our previous example,and we're going to have it lie along the unit circle.So, subject to the constraint that points lie along the unitcircle, we want to ask where are the maxima and minimaof the function h of x, y.We construct a Lagrangian by takingthe quadratic form minus lambda times the constraint.Now, one thing to consider as you'redoing this, a couple of things that don't matter, one of themis the sign of lambda.If you change lambda to minus lambda,if you change, in fact, the sign of the constraint to 1minus x squared minus y squared, you'llget exactly the same result. And you should check that.If you carry through the signs consistently,you'll find that, when you eliminate lambda,everything goes through exactly the same.But it's also true that there are different waysto write the constraint, and any of them would work.So, for example, if I want x squaredplus y squared to equal 1, I couldtake x squared plus y squared to the fourth power equal to 1.Or I could take x squared plus y squared minus 1to the 12th power.Anything that imposes the constraint is going to work.The idea is the coefficient of lambda,when we have found our constrained solution,the coefficient of lambda will vanish.It vanishes only-- it will vanish on the solution.There might be other roots to the equation that might be offsomewhere in the complex plane.We're not going to worry about this,but it is the case that, if it's a solution,then the coefficient of lambda will vanish.So this is another easy algebraic equation.We take derivatives.We'll have some simple linear equations to solve.Why don't you go ahead and try?Pause the video here.Come back, and we'll take a look together.Last chance.OK, let's take a look.So we do partials.So let's look at our partials of L. We have16x plus 12y minus 2 lambda.Notice that everything now, comparedto the previous example, is linear in x and y.That last term is always linear in lambda.I take the partial with respect to y.And I have terms also in x and y--12x plus 34y minus 2 lambda y equals 0.And I have the constraint, which isjust x squared plus y squared has to be equal to 1.So this has to be satisfied here.So we've got these equations.We can solve them for x and y and eliminate lambda.We can eliminate lambda immediatelyby taking the difference of these equations,solve for x relative to y, and then getthe exact values for x and y in the unit circleby solving this equation.And what we find our two solutions, x and y,are in the direction 1, 2--and I've normalized this to be on the unit circle--and in the direction minus 2, 1.And, interestingly, those are, in normalized form,the eigenvectors of the quadratic form that'sdefined by the matrix, which we could havewritten as Q is 8, 6, 6, 17.So, if you compute the eigenvalues and eigenvectorsfor this, you'll find 12 and 5 for the eigenvaluesand eigenvectors 1, 2 and minus 2, 5.And, if we normalize the eigenvectorsto be of unit length, we get exactly the results shown here.

#### Opt03_S01_v1-en

PROFESSOR: When we optimize a portfolio of assets,what we'd like to do is think about findingan optimal trade-off of risk and return.What do we have as a constraint?Well, typically, we have a budget constraint.We've got some amount of capital,and we can assign weights to different risky assets,let's say.Let's call those weights w sub i for the weight, the fractionof capital invested in asset i.And, depending on what choices I make,I'll earn a different return and have different levels of risk.So, if we think of w as being a control variable that we'refree to choose, but it's subject to a constraint,a budget constraint, where the sum of the weightsneed to equal 1, we can ask the question about how do wemaximize return, how do we minimize risk,provided that we've got appropriate measuresfor both of them.And then we can do this using the Lagrange multiplier method.So we might think of the risk as beingrelated to the variance of the portfolio.And the variance of the portfoliofor a weighted set of returns, as we've seen before,is a quadratic form.And here I've written it in vector notation.It's w transpose times the covariance matrix, whichis the covariance matrix where the elements Cij arethe covariance between the returns on asset i and asset j,times w again.So it's quadratic in the w's, butwith lots of off-diagonal terms, potentially,where the assets have correlations among themselves.And the expected returns are just the weighted averageof the vector of expected returnson the individual assets.So C and mu correspond to the covariance and expected returnson the individual assets.Sigma squared p and mu p, the p stands for portfolio.Those are based on a linear combination.And w is the set of linear weighting factorsthat we get to choose.I will take mu to be excess returns in excessof the risk-free rate so that we don't have a little minus r subf's to subtract off everywhere.At least for the people who have taken finance courses,you know that we always need to look at thingsrelative to the risk-free rate.So this would be a problem that soundsgreat for constraint optimization for the Lagrangemultiplier method.What do we know about these different components?Well, one thing that we know is that the covariance matrix canbe expanded out in terms of a quadratic sum,in terms of diagonal terms that involveonly the variance of the individual assetsand that involve cross terms.Notice that, in this expression, every time there'sa w that appears, it's always multiplied by a sigma.So I have w1 sigma 1 quantity squared.And here I might have w1 sigma 1 w2 sigma 2.Those always appear together.Rho ij is the correlation matrix.So the covariance matrix is symmetric.And it's symmetric because the variance and covariancebetween asset i and asset j is the same as between j and i.So it's obviously symmetric.It's positive definite.And it's positive-definite.We know that it's positive because the variance isobtained by taking the expectationof a positive quantity.So it must be positive.And that means that, no matter what w's we put in there,we're always going to get a positive quantity.So this is a positive-definite matrix.And that means that all of its eigenvalues are positive.Now, we know that it can't be-- it has to be non-negative.How do we know it's strictly positive?Well, for the covariance matrix to have a zero eigenvalue,that would mean that it's a singular matrixand that it's not invertible.And one reason that that could happenis that we either have risk-free assets, whichhave no correlation to anything else,or that we have linearly dependent data sets.Whenever there's a matrix where multiple rows or columns arelinearly dependent, the matrix is less than full rank.It's not invertible.And it has zero eigenvalues.So we're going to specifically exclude those cases.So we're going to assume that all of the assetsare linearly independent.And that means that our matrix isgoing to be positive-definite.It's going to be symmetric.And it's going to be invertible.That also means that we could useit to define a quadratic form on the vector space of weights wif we wanted to think more broadly.And we can use that to come up with kindof a geometric picture of risk that we won't needfor our portfolio optimization, but, in this language,we can think of looking at comparingtwo different portfolios that are described by weight factorsw and w prime and say their inner product in this spaceis related to the w transpose times C times w prime.This is the inner product here.And this vanishes.We would say these two portfoliosare orthogonal if they are uncorrelated.So that's just a convenient thingthat you could keep in mind for other applications,but not required for portfolio variance.And in a very simple, concrete case, we could get some data,and we can visualize what we mean by an optimal portfoliojust by crunching some numbers without doingthis kind of algebra at all.Here's an example.Suppose I look at historical data,and I take time series returns for a couple of assets,in this case, the S&P 500 index, whichI've denoted by ticker symbol SPX,and the gold ETF, the Exchange-Traded Fund whosevalue is based on the deposits of gold.And I wanted to know, what would be an optimal portfolioto hold consisting of these two assets?So what I can do is I can look at the timeseries of historical returns.And, as a function of the weight vectors,I can compute what the portfolio returns were.So I can say suppose I did a portfolio thatwas 50-50, that was 90-10, that was 10-90, that was 40-60.So, for each possible relative weighting of the twowhere the weights have to add up to 1,I can compute what the time series of returns was.Now, there's really only one numberthat matters, relative weight of the two,because they satisfy a budget constraint.The two numbers have to add up to 1.So I can think of this as being a functionof a single variable, the relative weight,say, of gold versus equities in this portfolio.And I do want to be careful in thinking about this averagingthat, since I'm constructing my views based on past timeseries, if I talk about, say, a 50-50 portfolio, if I'm justgoing to take a 50-50 average of the two time series of returns,that would mean that's not a buy-and-hold portfolio.It implies that, in every time period,say every month, that I'm rebalancing the portfolio backto 50-50 so that that is indeed the portfolio return.So, subject to those provisos, you can do the calculation.And, if you do it, you get, for each value from, say,0-100 to 100-0, if we're weighting between the two,we could compute what the time series of returns is.And then we could plot some objective function.Perhaps, it's the Sharpe ratio, which is the expected return,or the expected excess return above the risk-free rate,divided by the standard deviation of the returns.That's a scalar quantity that gets largerwhen there are higher returns or when the risk is lower.There are other functions we could consider instead,but here I've plotted an example of Sharperatio versus the fraction of gold that's in my portfolio.And, just looking at this picture,we can see that the Sharpe ratio gets better and better as Iincrease gold up to a certain point, and then it goes down.So this is fairly typical of what we might see.And, obviously, the goal of optimizationwould be to find this point.This would be the optimal Sharpe ratio.It's a particular choice of objective functionand not uniquely determined.But, for that choice of objective function,this would be the maximum value.Now, for a different choice of function,the maximum might be somewhere else.If I looked at a different data setover a different period of time, the valuesmight move because maybe the return samplesI have are not representative.Maybe the return processes are not stationary.And there are a couple of other thingsthat we know could happen based on whatwe know about functions, even of a single variable.There might be multiple extrema.Could there be more than one maximum?Could the maximum be at the endpoints?Could it be either at 0 or 1?Maybe the function is monotonicallyincreasing or decreasing.And another possibility that's important financiallyis, could there be extrema that are outsideof the obvious budget area?I looked between 0% and 100%.But if the weight--if we continued this curve, supposeit was increasing from the beginning and up to here,and then it continued, and it peaked somewhere out here,say at a value of 130% in gold and minus 30 in equities,let's say.That would correspond to a maximum which isn't achievableif the w's need to be positive or bounded between 0 and 1,but it would correspond to somethingwe could conceivably do in a levered portfoliowhere we borrow money to be able to invest more money than weinitially have in our account and wherewe take short positions that would be representedby negative weights.So here, in the picture I've drawn,we have an obvious solution that lies--it satisfies the budget constraint,and it lies in a range where w is between 0 and 1without imposing any additional rules on bounds.So it's an interior extremum point.So that's just a visualization.Next, we'd like to take a look at applyingthis systematically for portfolios that mayhave many more than two assets.

#### Opt04_S01_v1-en

PROFESSOR: Here's our first portfolio problem.Let's find a minimum-variance portfolio.So let's set up our Lagrange function as follows.Let's take a look at a Lagrange functionthat depends on a vector of weights.And the function that I'd like to minimizewould be the variance.And the variance, as we've seen, is given by wtranspose time the covariance matrix times w.I'm throwing a 1/2 in front just to make it a little bit easierwhen I take derivatives of a quadratic functionbecause I care more about the location of the extremathan I do about the value of the Lagrange function.So, if this is minimized, one half of itis also minimized as well.Over here, I have my constraint.And, by the way, l is completely arbitrary.So, if I divide it by 1/2 or multiply it by 3,it's not going to change anything either.The definition of this is arbitrary,but, once we pick a definition for l, we need to leave it.So here I've written in vector form the constraintthat these weights need to add up to 1.And I've done this with a particular construction, whichis a little unfortunate in my opinion,but it's in the literature in various places.So I'm going to stick to this so you'llrecognize it if you see it.We're going to use the Greek letter iota,which looks like an i missing its dot,to represent a vector of 1's.So it's just 1, 1, 1, 1, 1 for the number of assetsI have, whether it's 2 or 30 or 500, OK?So iota represents a vector of 1's.And, of course, if I take its transpose,it becomes a row vector.And the row vector of 1's times a column vector of w1, w2, w3just gives me the sum of the weights.So the sum of the weights is given by iota transpose w.And that needs to be equal to 1.So I've written the constraint in this form times the Lagrangemultiplier.Remember, we expect the Lagrange multiplier methodin any number of dimensions to enforce the constraint.The equation of the partial with respect to lis equal to 0 is going to tell us the constraint needsto be satisfied.So l is my Lagrange multiplier.Iota is a constant.It's just a vector of 1's.And C is the covariance matrix, whichwe're assuming to be given.So this is an interesting idea.We want to solve the minimum-variance portfolio.And why do we need a constraint?Well, if we didn't have the constraint,the minimum variance would be don't invest.If you keep all your money under your mattress,there's no risk at all.You'd definitely have minimum variance.Now, you might ask, why would youwant to find the minimum-variance portfolio?It sounds useful, but this is all about risk and nothingabout return.So, if there were no return on these assets,it's not at all clear why you wouldwant to have a minimum-variance portfolio.Why are you investing if there's no benefitfor taking this risk?If you are forced to invest and you'reforced to have your weight vector fully deployedin risky assets, then this will bethe minimum-variance portfolio.But this isn't just a mathematical thing.People do this, and there are fundsthat trade based on this idea of minimum variance.Why do they do it?Well, one idea is that we're leaving out the return.So we could say, well, people obviouslyexpect to earn a return.What assumption implicitly about returnswould lead to this case?One of them would be, if you thoughtthe average return on assets was 0,then maybe you shouldn't be investing at all.Another case would be where you thought that youcouldn't tell anything.You thought that they're positive on average,but you don't have any skill in predicting them.That would at least be coherent.And, finally, you might say, well,I do have an estimate for the expected returns,but I'm going to make the same estimate for all the returns.And, in that case, this comes out just as a special case.But let's just take it as given and look at itas a mathematical exercise for a moment.So we have a constraint.We need to be fully invested.The sum of the w's needs to be equal to 1.Subject to that constraint, givena set of variances and covariances,how do we find the portfolio that has minimum variance?Remember, this is in a very high-dimensional vector space.So w could be 500 components if we're in the S&P 500.It could have thousands of componentsif we're in the US markets.It could have tens of thousands of componentsif we're in global markets.So, in this very, very high-dimensional space,we're looking for this.So, for any given vector, we plug it in,and we get a number for the variance.And we have this single number that we need to extremize.We want to find the minimum valueover all of the possible vectors in this verylarge-dimensional space.Let's go.So what we'd like to do is differentiate with respectto each of the variables, each of the w sub i's.So, for each component, we take a partial derivative,and we set it equal to 0, plus we have one partial derivativethat we set equal to 0 through the Lagrange multiplier.And, if you'd like, you can write this out in componentsand do it as well.Now, as we vary the weights, rememberthat we have a quadratic form in the weights w.So, as I vary the weights with respectto a particular w sub i, I'm goingto have a whole bunch of terms, dependingon all the cross terms and the diagonal terms itself.So, if I vary with respect to, say, w1,I'm going to have C1,1, but I'm also going to have C1,2 timesw2 and C1,3 times w3 and all possible combinations.So I can write this as a sum over all values jin the portfolio times the matrix element Cij wj minus l.And I'm going to write this in matrix notation.Even though, iota, they're all 1's, I'mgoing to write it as iota sub i.And the reason is that then I can write this--I can recognize this as being a vector equation.So this right-hand side is the sameas the component of the equation thatsays that C acting on the vector wis equal to the vector iota times l.So how do I solve that?Let's just multiply in the left and right sides by C inverse.And we get this solution here.w is C inverse times iota times some constant l.In fact, right now, we know almost all we need to know.We know that the weights are proportional to the inversecovariance matrix times the vector of 1's.So, to fix the proportionality constant,well, we can do it the fancy way.We can take i transpose and multiply it on the left,a row vector times w.That gives us l time iota transpose C inverse iota.And set that equal to 1.And solve for it.So l is going to be 1 over iota transpose C inverse iota.These things, these expressions, we'll see a few more of them.They look complicated, but, keep in mind,they're really just scalars.They're just numbers.So they don't have any variables in them.It's row vector times a square matrix times a column vector,so a symmetric matrix also.So these are just numbers.So we've got a solution so that the wfor the minimum-variance portfoliois going to be C inverse iota divided by this constant.And now we can see what this constant does.We really just divided by the sum of the weights.And that means that the weights add up to 1.And you can see that because, if youact on this expression on the left by an iota transpose,the numerator and denominator become the same.And we get that it's equal to 1.What does that mean in financial terms?Well, consider a special case where the covariance matrixis diagonal.So suppose that all the assets are independent of each other,but they each have their own variance.So the covariance matrix in that casehas the variances down the diagonal,sigma 1 squared, sigma 2 squared, sigma 3 squared,and so on.And, in this case, C inverse times iotatells us that all of the weights in the minimum-varianceportfolio are going to be proportional to 1over the variance.So, special case, Cij diagonal, and weget that wi is proportional to 1 over sigma i squared.What that says is something actuallythat's kind of reasonable.That is that the riskier an asset is,the larger its sigma squared is, the less weight Ishould have in the portfolio.So we might have typically thought, in capital terms,of an equal-weighted portfolio as beingequal capital associated with each of the assets.But, if the assets have different levels of riskinessand especially if we're not considering return,then we might want to think about thingsfrom a risk perspective.And, instead of allocating equal capital,we might want to allocate equal risk.That is the risk is a measure of how much we might gain or lose.So putting equal amounts of capital on a very riskyand a very low-risk asset are quite different activities.Under this solution for the global minimum-varianceportfolio, under the special case where the assets areuncorrelated, qualitatively, what this solution is tellingus is adjust your exposures to equalizethe risk exposure, rather than the capital exposure,in the different assets.Let's take a look at one numerical example.So here's a numerical example of the minimum-variance solution.I've taken from CRSP, which is a researchdatabase of historical equity returns, a set of about700 stocks over a period of many years.I've estimated the covariance matrix from historical data.And I've put it in R to compute the quantitiesthat we wrote down before.In R, the function solve is to invert a matrixbecause it's thinking of solving systems of linear equations.And matrix operations are sandwichedbetween percent signs.So percent star percent means do matrix multiplication.And a t of a vector means take its transpose.So this is just, in R speak, implementing whatwe had before in our data set.And what we find is we get a vector.We got a 690-component vector whose components sum to 1that tells us where the minimum-variance solution is.Notice something interesting.I've ordered them from smallest to biggest.690, there's no natural ordering amongst stocks,but I can order them according to the weightsin this solution.And what I find is some of them are negative, and some of themare positive.So the minimum-variance solution is a long-short portfolio.The weights add up to 1, but that's a net weight, notthe gross weight.Some of the weights over here are negative numbersbecause I didn't constrain them.I didn't need to--I didn't say that they had to be positive values.So, if you were interested in implementingthis in this case--and this is not atypical-- you wouldhave to hold short positions.What about an upper bound?Well, I didn't hit anything equal to or greater than 1.The largest value I have looks like it's about 3 and 1/2%in any one asset.I'm not evenly balanced.I have about 300 stocks short, about 400 stocks long.But it does satisfy my constraints.It is the minimum-variance portfoliofor this particular covariance matrix that we have.And the solution requires, in this case,that the w's, which were only constrained by the budget,involve both positive and negative values.

#### Opt05_S01_v1-en

PROFESSOR: OK, now, let's include return.After all, that's what most investors are interested in.We'd like to take some risk in order to earn some return.So how much return can we get?How little risk?And is there any limit to what's feasible?What's the best that we could do if wewere willing to look at different classesof trade-offs?So what we're going to do is we'regoing to find a solution that will tell usall possible portfolios that we couldget with different combinations of risk and return.Now, from the foundations of financeand from maybe common sense, thereare a couple of things that we allought to be able to agree on.And that is that, if we're rational investors,anyone taking a given level of riskshould prefer more return to less return.And, for a given level of return,investors should prefer to have less risk rather than morerisk.But what we don't have any universal solution tois trade-offs where we need to takeextra risk to get extra return.So let's see what we can solve simply in terms of the thingsthat we know are required.So let's generalize our Lagrange function that we did fromour minimum-variance case to include--in addition to our variance that we want to minimize,our budget that we want to constrain,let's also have a constraint on the return.So let's set the portfolio to have a certain requiredlevel of return.So think of mu p as being a constant that we fix.I'd like my portfolio to have 6% annualized returnor 10% annualized return.So the question we're going to askis, for a given level of return that we'redemanding, what is the portfolio thathas the least amount of risk?That's something that we should all agree,for this constrained problem, would be a good thing.Of all the portfolios that have the given return,we should all want to hold the one thathas the least amount of risk.Now, this isn't the unique formulation of the problem,but this is the one that's got the easiest mathematics.So, in the structure of the problem,we've added one extra term to our previous example.Because we have two constraints, wehave to Lagrange multipliers, now called l and m.The structure still is quadratic in the variance.It's linear in w and the constraints.And the solution is going to look very similar.There's just a little bit more algebra to eliminatetwo Lagrange multipliers instead of one.We vary the weights, as we did before,by taking the partial derivatives with respectto each of the components or eachof the weights in our portfolio.So the partial of my Lagrange functionwith respect to weight wi is goingto be the sum over j of Cij wj.This is just the i-th component of the matrix productsigma times the vector w minus Lagrange multiplier ltimes the i-th component of the vector of 1's minusm times the i-th component of the vectorof expected excess returns.We solve for the weights in exactly the same way.We have one term that's linear in w,two that are w independent.We move those to the right-hand side.We multiply both sides of the equation by C inversebecause we know that C inverse--that C is invertible.And we have our solution that hereis w in terms of C inverse times,instead of just one thing, two different things.Now, we'd be done, but we still have these unknown Lagrangemultipliers.So that's a little annoying.We don't quite-- we're not quite done yet.We need to solve for the Lagrange multipliers,eliminate them, and then see what we can find in terms of w.And then, finally, we will substitute back inand see what the variance of the portfoliois that we can get for the minimum-variance portfolioas a function now of our selected constrained return, musub p.So we eliminate the Lagrange multipliers,as we did before, by solving the constraints.So the sum of the weights is equal to 1.If I take i transpose and I multiply it times the equationabove--hold on one second.We've got a small problem with our notation.The omegas here should be C's.I will update this in the handouts later on.I was changing my own notation.So we'll use C for covariance.These should be C's.And we're just solving for the constraints.So the point is I have l here and here.I have m here and here.And we want to solve for l and m.These things in parentheses that we have here,these are just constants.So they look like complicated matrix expressions,but they're just numbers.So I can write this as a little matrix problem whereI can say that I've got some linear combination of l and mtimes a matrix with those coefficients I've highlightedis equal to some constants 1 and mu p.And then, to solve for l and m, I'mjust going to invert the problem.So, to be clear, I construct a matrix M that's a 2by 2 matrix of this form, a, b, b,c, where a and b are these things now with C's properlyand not omegas.And I can solve that by taking an inverse, whichis easy to do.The inverse of this symmetric matrix, of a 2 by 2 matrix,is easy to take.And then we can eliminate the Lagrange multipliersand obtain, finally, the varianceas a function of the return.So, when we do that, there are two things we've achieved.One of them is we have an expression for our w's.And the other is now we have a relationship between sigma,or sigma squared, but between sigma and mu subp between risk and return.So the result is that we get the minimum-variance portfoliofor a given level of return.And this is actually a hyperbola in space.So we can write this out in terms of sigma squaredand some bunch of constants.These are the things that were in that matrix Mthat I wrote down before.But it's sigma squared depends on mu p squared minus somethingtimes mu p plus a constant.When I plot this in terms of mu and sigma,I get a hyperbola that's known as the efficient frontier.And, asymptotically, we can check that this becomes linear,that these become proportional, because, as mu p goesto infinity, it dominates the last two terms.And I'm left with sigma p squaredis proportional to mu p.In pictures, we get a hyperbola.And it's conventional to draw things this way,for historical reasons, where we drawthe standard deviation on the x-axis,and we draw the return on the y-axis.So the lines that I've shown in this example,these are numerical examples from the previous data set,but taken over two different time periods.So the red and the blue lines just correspondto different input data sets.What we see in both cases is this shape, this hyperbola.And the idea is that every point along the hyperbolais a solution to our equation for a given level of return.So, if I were looking for a returnat this level in these units, I would move across.And I would say that anything to the left of this pointis not feasible.Anything to the right is, but it's not desirable.So all of the points over here areportfolios that have the same return, but higher risk.Of all the portfolios of this level of return, as I move,I can go lower and lower and lower, but then this is it.I can't get lower than this.And, similarly, pick a different level of return,and all of these are higher until I get across here.And that's the minimum-variance portfoliofor a given level of return.Now, if we think about this in the other direction,if we think about transposing it,if we say, for a given level of risk,what portfolio would I want, well, I'dwant the portfolio with the highest level of return.I'm also on the interior region of this curve.So I would say, these portfolios of this level of risk,I would want the highest return.And that would be up here.Now, you notice that these curves, being hyperbolas,do turn around.And these are not functions, strictly speaking,because there are two values on the curve for valuesof a given level of risk.There are two levels of return.But the negative ones, the lower part,is financially uninteresting.We don't consider it a solution to the problem.For a given level of risk, we knowthat everyone is going to pick the upper value ratherthan the lower one.So, typically, we're going to discard everything down herefor the lower portion.And the part that matters is this interior regioninside the curve.Now, the problem we've solved is a single-period optimizationproblem.We've assumed that everything is stationary.We've assumed that our covariance matrix, which we'veestimated from historical returns, is both accurateand unchanging over time.If those things aren't true, then the results change.So, over a 10-year period, you might not be surprisedthat, in a different 10-year period,the realized covariance is going to be different.And, perhaps, the past decade of realized covariancemight not be the best predictor for the next 10 yearsof realized covariance, but it is a common starting pointto do.But, clearly, for our optimization problem,we've taken as one of the inputs a view asto what the future covariance matrix should be.If we change that input, we're going to change the output.The efficient frontier is going to move.Similarly, for our estimates of expected return,if we change them, if they're historical estimatesand we either need to update them because of changing marketconditions or, simply, we believe market conditions arethe same, but we've taken a different data setto estimate them, if the inputs change,the outputs will change.One of the challenges for applications in the real worldis that these changes typically are not negligible.They're often very, very big.And, furthermore, the results canbe extremely sensitive to very small changesin some of the inputs.So it does raise questions about the stability of the result,as well as relying on important and difficultstatistical challenges like how to best estimatethe parameters.Algebraically, though, we do have a clear notionthat's worth keeping in mind, despitethe practical difficulties.There is a feasible set.And there is-- even if we can't accurately find it,there is something that's the best portfolio, thathas the best return for a given risk.And, furthermore, we can map out where it is and divide the riskreturn space into those portfolios that are achievableand those that aren't.Remember that we started from a very high-dimensional vectorspace of possible portfolios where we've gotone component for every asset.And we're plotting all of those high-dimensional portfolioson a single two-dimensional plot.That picture isn't easily invertible,at least not in your head.That is two neighboring points, two points thatappear to be close on this plot, might be very, very differentportfolios.We don't know that.So we might ask, how do we move toward the efficient frontier?Are we close even if we're not exactly on it?Those would be good things to know.One thing that is interesting, though,the immediate consequence of our solution,is that everything that's strictlyon the portfolio-- on the efficient frontierhas a very simple algebraic description.We wrote down that, before we eliminated our Lagrangemultipliers, that w was C inverse actingon a linear combination of two vectors,the iota vector of 1's and the vector of excess returns.And what that means is that these, C inverse on iotaand C inverse acting on mu, are two very special portfolios.It says that every portfolio on the efficient frontier,every portfolio that has an optimal trade-off of riskand return, is a linear combinationof two special portfolios called characteristic portfolios thatare given with weights that are given by the Lagrangemultipliers.And there's financial interpretationof those two portfolios.C inverse acting on iota, as we've seen,is the global minimum-variance portfolio.It's the portfolio we would get if we minimized riskwithout regard to return.The second portfolio, the one with respect to mu,is the portfolio of the maximum Sharpe ratio.And, by taking linear combinations of those two,we sweep out that entire curve.

#### Opt06_S01_v1-en

PROFESSOR: The results we've looked atcan be generalized in two ways.One of them is by including more linear constraints of the kindwe had, and that's easy.We add more Lagrange multipliers.So we might have a rule that in additionto a return constraint and a budget constraint,we might want to limit certain risk exposures.We might want to limit the portfoliodata, which is its sensitivity to the overall market.We might want to target a particular industry exposureor foreign country exposure, or wemight want to neutralize them.If we're allowing a long-short portfolio,we might say that our net exposure to a given countryshould be equal to 0.So in all those cases, we just had one more Lagrangemultiplier, and we solve the same thing.It's just the algebra gets a little bit more complex.Another kind of constraint that'simportant in investment managementand many practical problems are inequality constraints,and the Lagrange multiplayer method will not handle these.In this case, we need to proceed with numerical solutionsand a technique called quadratic programming.The idea of inequality constraintis we might want, for example as I hinted before, we might havea mandate where we're not allowed to short positionsand we need all our w's to be equal to 0.The Lagrange multiplier method has no guaranteethat the solutions will end up with positive values of w.They could be anywhere in the vector spaceand not in half the vector space or a quadrant of the vectorspace where all the w's are positive.And we might have a constraint on an upper bound.We might not be allowed to use leverage,which would say that the individual weights allneed to be less than 1.We might have more binding or tighter constraints,where a typical investment manager isn't allowedto put all of his or her eggs in one basketor even a lot of them.There might be a rule that says, the weight investedin a particular asset or asset class can't exceed, say, 5%or 10% or 1%.So there might be some limit that's well inside the 0 and 1range, and it could be applied at the levelof an individual weight or it couldbe applied to a sum portfolio, which would correspondto some linear combination of weights being constrainedwith some upper or lower bound.So when we have this kind of thing,the Lagrange multiplier method might give usa method where the constraints are satisfied,these inequalities.But it's not guaranteed to do so.And in general, we need to use this technique calledquadratic programming.The quadratic here comes from the factthat our objective function is quadratic,and our constraints being linear means that we can alwaysfind solutions.And we're not going to derive this.We'll have some references for it,and you can take a look if you'reinterested in the algorithms.But you'll find packages for doing this numerically,and we'll take a look at some numerical examples as well.Qualitatively, the important thingis that we're always going to be by adding extra constraints.The more constraints we have, the smallerour efficient frontier becomes, the smallerour feasible set of portfolios becomes.The constraints in the best case are non-binding,and then we have no change.But the constraints can only make things worse.They can only remove, if they are binding,portfolios that otherwise would have been feasibleand have them not be feasible.So we would expect the feasible spaceto shrink when we solve for the inequality constraints,and we'd expect the constrained optimization problem to give ussomething that's smaller and that is not necessarilythe solution to the original constraint maximization.Now, there are lots of other investment constraintswe could have--position size, leverage size, factor exposure,different balances for long-short neutrality.We could be long-short in weights.We could be equal beta, long and short.We could have other factor exposures.There are many other techniques.There's a broad variety of them thatcan be handled in quadratic programming.There's a package in R called quadprogand a function called solve.QP you can take a look at,and you can take a look at our code examples as well.What we find is typically something like this.This is just an example of an asset allocation problem.Suppose I start with eight assets,and I've got their means and their covariances.I have their mu vector, expected excess returns,and I have their covariance matrix c.And here are the individual assetswith their individual risk and return.I haven't plotted what the correlations are among them,but these are down here.And if I compute from that mu and sigma whatthe unconstrained efficient frontier is,I find this hyperbola that's shown here on the black line.So everything that's feasible is on that interiorof the black line.When we include a long-only constraintand a no-levergage constraint-- so we'llhave a budget constraint, and we'llwant to maximize our return or minimize the risk for a givenlevel of return.And in addition, if we impose that the weights haveto be strictly between--they have to be greater than or equal to 0 and less thanor equal to 1, they can't be negative,they can't be greater than 1, they can't be short,they can't be leverage positions,then we find the blue line as being the set of solutions.And this is the efficient frontier,and the feasible portfolios are the interior region.So these are the-- everything inside hereis a feasible portfolio, and the points that are optimalare the points that are on the blue line.Everything above and to the left on this graph is not reachable.We cannot get returns that have lower risk for the same levelof return than the ones in our solution to our optimalequation.We cannot get returns that have--portfolios that have higher return for given risk or thathave lower risk for a given return.That excludes the region above and to the leftof the blue curve.But we can see what we've lost in applying the constraintsand limiting the weights to be strictly between 0 and 1,that we've lost the area that's the differencebetween the black curve and the blue curve.Those are portfolios that we mighthave had that aren't here.So it's always an interesting idea when to ask,are constraints binding?And if the constraints are binding,what does it cost to have those constraints?What would happen if we loosen the constraints?The optimal solution would move.Where would it move to?Are we close?Are we giving up a lot by imposingthese constraints or not?So we do have these things that are set for constraints.We typically think about solving and findingan optimal portfolio, but there area couple of things that we might also keep in mind.One of them is that if you're goingto optimize your portfolio, you'rehighly dependent on the inputs.You might want to know how sensitive your results areto those inputs.That is, if you were to change them a little bit,if you had estimation errors in your returnsor in your covariance matrix, would youmove just a little bit all along the way?Would you move along the efficient frontier?Or would you end up somewhere else completely?Conversely, even if you're not an optimizer,you've just got some equal weighted portfolio,or you're following an index--you've got some country index--it's of interest even if you haven't optimizedto ask where your portfolio would lie along this riskand return plot.Is it close to the efficient frontier?And for example, that's an even--an equal-weighted portfolio with even allocations of capitalto all of the assets.That's an easy thing to explain to investors.If you find that it's reasonably close to the frontier anyways,then you're not sensitive to any of these estimation problems.That would be good to know.On the other hand, if you're far away,now you can use this picture to make a compelling case for whya careful analysis and constraint optimizationsolution for an asset allocation or a general portfoliooptimization problem gives benefit for the investorin terms of increasing the expected return,decreasing the expected risk, or both.

### 03-Recitation_8

#### Rec08_S01_v1-en

PROFESSOR: Take a look at portfolio optimizationon the computer.We'll take a look at some data.We'll run some calculations of the efficient frontier.And then, we'll compare the different versionsof constrained optimizations that we've talked about,one of them where we use the exact closed form result wherewe have equality constraints and the other usingtechniques of quadratic programmingwhen inequality constraints are present.So the exact results that are obtained by the Lagrangianmultiplier method work well if we'vegot a fixed number of equality constraints.But a budget constraint might have some risk constraints.For example, we might want to have a market-neutral portfoliowhere some of the market betas as measured, say, by kappasand betas and to 0.We might want to set an industry exposure to a particular level.But typically, what we're doing is eitherwe're targeting an objective like a budget,or we're targeting a constraint to manage risk or exposuressuch as a long-short portfolio or with an industry constraint.And those work terrifically well because we canhave any number of constraints.There's a couple of caveats for the closed form.Number one, we want to have more assetsor more degrees of freedom than we do constraints.And second, the constraints generallyneed to be independent of each other.There can be degenerate cases.And finally, the constraints needto be consistent with each other.It's possible to write down constraints that cannotsimultaneously be satisfied.But usually, it's a fairly straightforward problem.Now, when we do that for equality constraints,there's nothing that bounds the rangeof the weights in the solution.They could be anything.The w's that we get for a portfolio couldbe any real number, and that meansthey don't lie between 0 and 1 where we typicallythink of the weight of capital allocation within a portfolio.Now, we can generalize.Certainly for negative weights, wecan think of those short positions.They're effectively the case where a short position as wesell some securities short and werequire bringing back that number of securitiesto get to 0.And it functions to a pretty good approximationas treating it like a negative number.What about w bigger than 1?That's a levered position.We borrow money.Usually, we'll assume for financial assumptions weborrow at the risk-free rate.And we can buy more than the amount of capitalthat we initially have present.So that's OK.But even then, there are practical real-worldlimitations.We could get to a w of 1 and 1/2, a w of 2, a w of 10if we're highly leveraged.We can't get to a w of 50 million.No one's going to give you that much credit or me.So we do want to know if things lie within a reasonable amount.And in fact, this is true in generalof constrained problems.We always want to know for a solutionto a constrained optimization problem,are the constraints binding?After all, it could be that we finda solution that is not pinned at one edge or the other.In the case of equality constraints,we force them to bind.But in the case of inequality constraints,we might be at a maximum or you mightbe somewhere in the interior regionwhere those constraints don't actuallycome into play for the particular values,the parameters, that we have to work with.

#### Rec08_S02_v1-en

PROFESSOR: So in practice, we almost alwayshave to deal with inequality constraintsto keep allocations that are just unreasonable.Typically, for Long-only managers,we say that weights should be between zero and one,but they really have to be much less than one.Any responsible manager is not going to be undiversified,put all of his or her eggs in one basket.So we'll often see things where the weights may be constrainedto be, say, between zero and 5%, zero and 10%,depending on the liquidity the assets.Could be zero and 1%.And the zero lower bound would be for a Long-only managerwhere they're not permitted to short securities.So these are cases that quadratic programming handlesperfectly.So we can add in addition to equality constraints,we can add any number of inequality constraints.And those inequality constraints canbe framed either at the level of individual weights,individual components within the weight vector,or linear combinations of them which is usefulif we want to say, for example, that our weight, our exposureto a particular industry in the economy, our exposureto a particular country in an international portfolioneeds to be bounded by a certain amount.And then we take a linear competition of certain assetsand say that that bound lies only in that case.So these are all things that we cando using quadratic programming.So let's set up a few things on the computer,and this R Notebook is going to be available to download alongwith the data file that you can use for rerunningthese simulations.And then what I'd encourage you to do is go get your own data,build your own covariance matrix,make your own estimations of risk and return, and run this.Or take a look at your own personal portfolioor your retirement portfolio and run this and seeis your investment portfolio efficient.So what are the things we need to do computationally?Well, the nice thing about this R Notebookis it contains both code and text.So when you download it and you run it,you can turn it into a nice pretty PDF HTMLfile you can take a look at, but we'regoing to look at it in code view here.And what I'm going to do is I'm going to start,you can set this up anyway.And I hope these colors show up on the video.But this background color here in gray is a block of code.And the code are commands in R.And the lines that begin with the pound sign,these are comments.The libraries are loaded once, so these librariessuch as quadprog for quadratic programming,they need to be downloaded from CRAN from the R archive.You can do that with the install.packages command.And you'd need to put the name in quotesfor installed.packages.Library loads the package.It's not the packages command, don't ask me why.It doesn't use quotes.But the install.packages you do once thenit's on your computer.And you can see which packages are installed in your computerby looking at the Packages tab over on the rightand see which ones are here and which ones are loadedat a given point in time.And you can load them, and then they'll be available to use.Here are a few others.I'm not sure if we use all of these today for this,but none of them is bad to have.You have a reshape command for changing and arranging data.The tidyverse command is useful as is actually tidyquant,and I think we've seen it already in the course,for a bunch of data handling commands thatgive logical structure to data thathave different kinds of relationships.ggplot is a package that does prettier and more sophisticatedplots than the base R package.And in the code, I think I've gotsome done both ways, the base R command and the ggplot.If you take a look in your RStudio,I think in the Help file, you willfind that there is a set of cheat sheets,and you will find a bunch of things, including--I'm not sure if ggplot is on here.It may be, but there are a bunch of things herethat are very useful and you can find more.Yes, there is a ggplot one right there.So you can take a look at that and download that,see some of the commands, look at examples.So we're going to get all this stuff and run this code walk,and we'll be ready to go.One of the things that we have is this data file,and this data file is taken from an example givenin book by Richard Micheaux calledefficient asset management which I encourageyou to take a look at.We've got here just some data that hetook from historical data.And as I said, you can get your own.So these are a bunch of country indices.And we have the correlation in each country with each otherover on the left-hand side.Then we have a couple of other assets.And then we have for each asset, its expected meanand its expected standard deviation.Now, the true estimation of thoseis very, very tricky business.Here, these are taken by doing estimates from historyand assuming that the future is goingto be like the past, which is always a problematic way to go.But it doesn't matter.The assumption is you provide the inputs,the algorithms tell you what to do next.So we've got a clear separation of responsibility.Your job is to make estimates for the future--co-variances, correlations, and expected returns.So we've run that.And what we'd like to do then is construct some of the objectsthat we saw.So here what we're going to do is we're going to pull out,first, the appropriate columns to make a correlationmatrix to have a vector of standard deviations.Mu is going to be the vector of expected excess returnsand iota is going to be the vector of ones.There are eight because, in this example, we have eight assets.The covariance matrix here is constructedas the correlation matrix with the diagonal matrix of sigmasof the volatility is on the left and on the right,and that generates exactly what we expectfor the covariance matrix the element CIJ, our sigmai sigma j times rho_ij.And then, the thing that we really need in all our formulasis the inverse covariance matrix.And in R, that's given by the solve commandbecause it's also used for solvingsystems of simultaneous linear equations.We have a few constants that came out of our algebrafor looking at solving the Lagrange multiplierproblem, which we call a, b, and c, maybe lower case.But in any event, we have these as matrix operations in R.Matrix operations are formed by having a percent sign,so % star % is matrix multiplication.The t operator is a transpose.So here we have iota transpose times c inverse times iota.And we're converting this to as.numericto take it away because the classes of objects and the datatyping that are implicit sometimesdon't work well in some of the subsequent operations.So it doesn't hurt to force things to the formthat you want them to.They may not be elegant, it may not be necessary,but this works for me.And I'm pretty sure I've tested this,it will work for you, too.But, by all means, feel free to do better.So I'm going to run this whole block, and what I want to dois I want to look at a couple of things.What I've done is we've defined parameters--the correlation, the covariance matrix, the means,the standard deviations, those arethings we're going to need for our optimization problem.Those are our inputs.But let's take a look at them firstfrom a business perspective.So what do we see in the data?Well, if we look at the data, hereis a correlation plot of each country and assetwith every other one.So a correlation matrix is symmetric,so we only need to see half of it.In this form-- and this is using a package in R called coreplot,this correlation plot shows for each pair,for example, Canada with Germany, a dot herewhose size is the magnitude of the correlationand whose color is given on this scale on the right-hand side.So dark blue is a correlation of one,and we see that along the diagonalbecause a correlation of anything with itself,by definition, is one.And for the other values, we see different magnitudes.And notice that are all positive,and this is fairly typical.It's hard to find assets that are negativelycorrelated with each other.And when you can, you should pay close attention to thembecause they let you lower risk and, in general,let you take bigger positions for the same level of riskand earn more return.It depends on the balance of risk and return.In any event, our method is agnostic about that.You could put in any valid covariance matrix.One thing to be aware of when you'regetting numerical estimates, if you'retempted to approximate things from historical serieswhere the time series for the data might be different,maybe we have more data available for one market thanfor another, we need to make sure it'svery easy to get pairwise estimates for the correlationsby looking between any pair of what their longestcommon period is.And that's a typical way that we might do it.And R has a bunch of features for howto deal with missing data and doing a covariance matrix.You can look at Help pages for that.However, there's an important overall propertythat could get lost if we do things pairwise,and that's the covariance matrix must be positive definite.The positive definiteness follows--or at least positive semidefinite.The positive definiteness followsbecause it comes from the expectation of a square.It has to be positive definite.It really has to-- it can't be positive semidefinite,it shouldn't have singularities or zeros,those would be a sign that we included some redundant assets.You might think here the US bonds thatare included would be uncorrelated with everything,but of course, interest rates are not completely fixed.There is risk in US bonds.There's interest rate risk, even if there's not default risk.So the correlation is not zero with other risky assets.But we can't have something that's strictlyconstant in the conference matrix,we wouldn't be allowed to invert it.So that's our data in terms of how things are correlated.What about the risk and return of these different assets?Let's take look at that.So here's a plot where we have conventional terms.We have risk on the x-axis.We have excess return along the y-axis.And each of the assets that we're investing in,the market for each country, is plotted on this risk returndiagram.So we see in the lower left, we'vegot very low risk, very low return assets,currencies and government bonds.And during this particular time period where this is estimated,we have a bunch of very high risk, high return assets movingas we move toward the upper right.And we see, generally, the behaviorthat we would expect, that to get higher returns,you need to take higher amounts of risk.The one interesting thing in this numerical exampleis that France and Japan are so close in their valuesthat, actually, they're difficult to resolveat the screen and the data labels have taken over.So you should look at the numbers.And in fact, the fact that they'reso close, to a certain degree, fakes outthe optimizer a little bit.So it's not a good state of affairs,and it leads to some numerical instabilitiesthat we want to be aware of.

#### Rec08_S03_v1-en

PROFESSOR: Now that we have our data, let's optimize.So let's start with the minimum variance portfolio.That was the simplest optimization we had.There's only one constraint, the budget constraint.So we have a covariance matrix, we have our expected returnswhich we're going to ignore because they don't enterinto the problem, and what we'd liketo do is solve for the minimum variance portfolio.So if we do that, remember that we had a very simple solution,that the minimum variance portfolio isproportional to c inverse iota.So we're going to run this chunk of code here.And what this does is here's c inverse times iota, and thenremember that we have it normalizedso that the weights sum to 1.One way we could do it was by looking at the--dividing by transpose iota inverse covariance iota,but I like to think of this sometimes in a little bitmore practical terms.These are weights.They need sum to 1.So let's sum them and normalize themso that they sum to 1 by dividingby the sum of the raw weights.So we know that these are proportional firstto the inverse covariance matrix times iota.As we said in the special cases like a diagonal covariancematrix, it says the exposure is goingto be inversely proportional to the variance, which makes senseat least qualitatively that the riskier an asset is,the less exposure we're going to have.And this is typical of the way that wethink about risk and portfolio construction,that the amount of capital we haveisn't actually the first thing we think about.We often think about how much risk exposurewe have because that's going to bethe basis for getting return.And we're often, in financial institutions, not necessarilyconstrained by our budget because we can borrow.We can use the balance sheet of an organization perhaps.We still need to be accountable for our capital usage.But when it comes to looking at potential investments,we want to make sure that we get a high return per unit of risk,not just a high return per unit of capital, which would notdistinguish between the return on two investmentsa very different risk.Now, the other interesting portfoliowe might as well plot while we're here,which is the portfolio of maximum Sharpe ratio, whichis c inverse times mu.And what we saw in solving the problem wherewe had both a budget constraint and an expected returnconstraint was that any portfolioin the efficient frontier could be writtenas a linear combination of two portfolios,sometimes called characteristic portfolios.One of them was the global minimum variance portfolio,and it's associated with this particular vectoriota, a vector of 1's that corresponds to the budgetconstraint.The other one is associated with the vectorof expected excess returns, and that'sc inverse mu or it's a portfolio proportional to c inverse mu.So by taking linear combinations of those two portfolios,we can reach everything on the efficient frontier.So we solve for them.What do we get?We get a bunch of numbers, and here are the numbers.So we've got a column vector, and we can look upwhich assets are which.But it's pretty clear that these numbers are unconstrained.Some of the numbers here are negative.They correspond to short positions.Some of them are big.They correspond to long positions.Take a look at the bottom two columns that we have here.These were the ones of France and Japan,and this says the optimal thing to dois to go short one of them 60%, a huge position,and go long the other one 1.7 and similar kinds of numbersfor both of these.So these are very, very big numbers.They're not the kinds of things a typically prudent assetallocator would do, even though here they're optimal.This looks like extremely large positions,very large short positions, very highly levered long positions.We can also look at a bar plot.Taking a look just at rank order is oftena helpful overview for a portfoliojust to see where things stand.And if we look for this portfolio,you see, say, for the mu portfolio.You can do the same thing for the iota portfolio.We see that the weights to go from negative to positiveand that most of the weights in the middleactually are not going to have as big an influence as twogigantic weights on the top and the bottom.

#### Rec08_S04_v1-en

PROFESSOR: So the portfolios thatshow up when we're using only equality constraintshave these issues where the weights are unboundedand they could be anywhere.They might happen to be at small, reasonable-lookingvalues.But there's no guarantee of that,and it's interesting to see what happens when weimpose inequality constraints.For one thing, we often have to.Those are just the rules of the game--the financial constraints, the investment mandatedoesn't permit us to use the discretionto do something that mathematicallyappears to be optimal.But it also raises an interesting perspective,which is if these constraints do become binding,how much are we giving up?What is the cost of our distance from true optimality if we wereto remove those constraints?After all, if we really had confidenceand we really knew where we were,we might advocate for lifting the constraintsif we could show that the benefit was greatand, in fact, that we had a better risk-adjusted return,possibly even lower risk, by relaxing the constraints.We're thinking about this not only,how do I get an answer if I've got tighter constraints,but what does it mean?How does it compare?What am I giving up?How can I look at a perspective on this and thinkingabout the set of all possible investmentportfolios one might have?And of course, we're talking very concretelyabout portfolio optimization, but this appliesto many, many other kinds--the lessons apply to many, many other kindsof constraint optimization.So let's take a look at what happens.And what we want to do is let's startby imposing the most typical kind of constraint,which is the "no short, no leverage" rule.That is, the weights have to be strictly boundedbetween 0 and 1.So we might want them to be smaller.You can take the code and rerun that.Let's just apply that fairly loose constraint.But we already expect that it'll be binding in this casebecause we saw that minimum variance portfolio already,which is going to have highly-leveraged leveragedpositions and short positions.So the way we do this is using the techniqueof quadratic programming, and you can read about itin the Help files.The function in R is called "solve.QP" from this library.And let me show you the code, and you'llwant to read the code in conjunctionwith the documentation.But let's take a look.So the inputs to this sample program that we haveare going to include a covariance matrix.They're going to include a vector of expected returns.And they're going to include a couple of thingswe want to pay attention to.I mean, that's what we need coming in.We want to know how many points we're going to compute.But we want to pay attention to the minimum and maximum valuesof mu because if we're not allowing our portfolios to beleveraged, then the highest possible return we could get,our mu sub p, is going to be the biggest return among our assetsbecause the highest return we could get without leverageis putting all our eggs in one basket.We find the portfolio that's got the highest return,and there's only one way to get it,which is putting hundreds of our assets there.Similarly at the other end, minimum variance portfolio,it's going to be--depending on the covariance, we may find somethingat this special point on here.So we always want to look at identifying special pointswhether they're symmetries or whether they're endpoints.But let's just prepare our data and take a lookat what's going to happen.So we're going to require the quadratic programming.We put that inside the function in caseyou didn't load it beforehand.It doesn't really matter that much.We're going to define Nu, the size of our universe,to be the number of points we have.We know in this example it's going to be 8.We define a Iota to be a vector of 1s of equal length.And we define Zero, just for conveniencebelow, to be a vector of the same length just filled 0s.Now, I'm going to define a constraint,a little fudge parameter called epsilon.And the idea is that we want to avoid rounding errors.And because we're going to take a look starting at the lowestpossible return and incrementing our way all the way upto the highest return in the portfolio,if we're off by a little bit, we mightend up with an unfeasible constraint,or infeasible constraint.That is, if we're off by a little bit in our roundingand we ask for a portfolio that has a return just evena tiny amount more than the largest expectedreturn in our input set, there won't be a solution.So what we'll do is we'll just nudge the endpointsdown a little bit.And you can set this parameter to be anything you'd like.This level seems to work OK.Now, the documentation is dense.They've packed a lot into one thing,and I'll let you look at the code in the construction.But this is what goes into it.There are a whole bunch of constraintsthat are simultaneously going into the program,and they're all formulated in terms of specifying, puttingthe-- coding the data into a matrix and into a vector.So what are the constraints?Let's just talk about them.And as I said, you can read the documentation,and you can look at this particular setupwhere it's implemented in one case.Then, you can do your own.We've got a budget constraint, so the weightshave to sum to 1.We have a return constraint because what we're going to dois we're going to solve the problem,find the minimum variance for a given level of mu,and then we're going to look at varying mu all the way upto our maximum value of mu.We have a lower bound on our individual weights,and we have an upper bound on the individual weights.And those are just for individual components.Now, it's possible to add additional rules as well,such as constraints on linear combinations for the weightsthat I mentioned in our introduction.So this thing, the A matrix here as defined--cbind in R is a function that binds columns.It takes columns and creates a bigger object.So this is just the conventions required for the program.This is not a particularly interestingmathematical object.So it has one column with the Iotas,the second column with the mus, and these other thingsthat are here.And as I said, you can check that.Now, the next thing we want to doare we want to set up the endpoints.And here, we're defining mu_min and mu_max,and these are just ways of taking a look, at making surethat we nudge the endpoints a little bitby an amount that's proportional to the range that's here.So these are just some reasonable values.You could set them in different ways.Then, we're going to set up for three thingsthat we want to have.We're going to have the sigma_p willbe the standard deviation of the optimal portfolioof a particular value of mu sub p.We're going to walk through a range of mu sub p's.So in this line we generate that.This is using the sequence command in R.It just generate a list of numbers.It generates an array.And you can find similar things in Python and other languages,or you can build it yourself because we'regoing to use that in the for loop in just a moment.And then, w is going to be where we'regoing to put the weights because, remember,we usually are looking for the location of the extrema.But we also can find the value of the extrema.So when it comes to the efficient return frontier,it's a little bit of an exception.We usually are looking at a dimensional plot.We're not thinking of the 8- or 500-dimensional spacethat we started with, but we can capture everything.So these variables are defined sigma and was placeholders where we're going to put the results.So what do we do?We're going to run through a for loop,and we're going to go through for each of the pointsthat we have here.These are increments, so we'll count our way up in steps mu.This b vector is defined in the documentation.It's going to involve a 1 for one of the constraints.And here, with changes in each pass through for loop,it's going to be the mu sub p that we're solving for.Remember, that's how we did analyticallyour original problem.We fixed the mu sub p.Then, we minimized the variance subject to the constraintthat the portfolio return be equal to that given mu sub p.And then, our results are a function of mu sub p.Here, what we're going to do is just computefor a bunch of discrete mu sub p'sand then capture all the data.Here is the line.This is the work horse that does the actual calculations.So this is solve.QP.It takes these inputs, the covariance matrix,and a bunch of constant parametersthat we have that have all been defined.And what are the outputs?So we put them into an object called opt,and there are two things that we want.One of them is opt, the value part of it,which is picking this off.We use the notation "opt$value" because opt is a complex objectand it has different pieces.The amount that we have for the opt valueis the value at the location of the maximumof the original function, which is 1/2 w transposed cw.We're interested in sigma, so we multiply by 2and take the square root.That gives us our standard deviationin the appropriate units.And we want the weights, and that'swhat's called "solution."And we're going to put them into this array w, into this matrix.And then finally, we're going to report everything,and we're going to put it into this variable calledmvef for mean variance efficient frontier.And we set up a data frame where webring these objects together.We've got the portfolio returns, the associated mu sub p'sfor which we solve the problem, and the weights.So let's see what the results look like.

#### Rec08_S05_v1-en

PROFESSOR: We'll apply it to our global asset allocationproblem.And let's pick 100 points, let's say,and we're going to run this chunk of code right here.And we're going to do 100 points on the efficient frontier.We're going to run our function.It's the mvef as a function of the covariance,the historical expected returns, and our number of points.We'll put this in an object we'll call big MVEF for lackof imagination.You can plot the results either using the base R plotcommander.Here, I've done it using ggplot to getsomething that's a little bit more nicely formatted.And there are a couple other thingsthat are nice about ggplot.One of them is it really respectsthe structure of the data when we've got more complex,related data.And at the practical level, it lets us layer and add thingsto build more complex plots if wewant to put several graphs on the same page,where the base R command doesn't do that as elegantly.So our first command here is we'redefining this object because we're going to use it again,mvef.plot.The ".plots" is just a naming convention,and what we're doing is we're telling it,plot these xy things and put some labels out there.So what do we get?We get something that looks qualitativelylike the hyperbolas we saw.There's a curve.But it's obviously not a hyperbola because it bends.Instead of going asymptotically straight,it has a non-conic curve.It's got a kink in there, and it ends.It stops at a point, which is the highestreturn in our data set.And similarly, it stops down here at the bottom.But there it is.We've solved.So these points here represent the portfoliossubject to the constraints that havethe maximum level of return for a given the level of risk.Or the exact problem that we solved,they've got the minimum risk for a given level of return.Everything in the graph that is below and to the rightis feasible but not optimal.Everything that is above and to the leftwould require violating one of the constraints.Now, how do we compare this to the unconstrained problem?Well, let's take a look at that.So let's look at running this chunk of code.Remember that we defined A, B, C to be the numbers that wedid in lecture for looking at the exact problemwithout inequality constraints, so we can do it.And remember that we solved explicitlyfor a function of-- sigma p was a quadratic function of mu subp.So let's solve for this here, and let'splot the results together.And that gives us the blue line.And in addition, I plotted the red dotsare the original assets in our data set.So what we can see is that blue line is indeed a hyperbola.We've cut it off at the same upper level of mu sub p,so it's commensurate so it doesn't run off the page.We see that there's a region between the blueand the black lines.That's what we give up by imposing our constraints.The things between the blue and the black linesare risk-return combinations thatare not allowed with our inequality constraints, thatwould be allowed, that would not violate a budget constraint,but they do violate one of the inequality constraints.So that's the cost of not taking short positions.That's the cost of not using leverage.This is the area between the two curvesis how much more return we could have gotten per unit of riskor how much risk reduction we could have gotten, particularlywith the short positions, that generatea synthetic negative correlation, how much less riskwe could have taken for a given level of return.So the blue line is computed analytically,and that's our Lagrange multiplier method.The black line or the black set of dots connected by a curvethrough them is the numerical result of quadratic programmingthat we've done by running this algorithmand running it through the computer.

#### Rec08_S06_v1-en

PROFESSOR: So this is our traditional risk returnplot where we have risk on the x-axis, excess returnon the y-axis, and we can see what's efficient.We can plot any portfolio on this graph,see how far it is from the efficient frontier.But one thing that we don't have insight intois how to reverse the mapping.After all, the portfolios here arein an eight-dimensional space.What do those portfolios look like?What are the portfolios on the efficient frontier?The red dots are basis vectors.Those are basic vectors, the direction of oneof the assets projected down to this two-dimensional space.Can we see what's going on as we movealong the efficient frontier?Sure we can.We've already solved that.That was one of the outputs of the optimizer.So let's take a look at running the next chunk of code,which is down here.And what we're going to do is let's run this and take a lookat a plot.And what we're doing here is we're looking at a stacked barplot because remember that the weights go between 0 and 1.So when we have short weights, a stacked bar plotis a terrible idea.But when the weights have to be between 0 and 1,it's a terrific idea because they add up to 1,and we have a good idea as to what the portfolio balance is.So what we're looking at is that as we move alongthe efficient frontier from our lowest returnup to the highest return, we're asking what the portfoliocomposition looks like.What we see on the left-hand side of the pictureis that we start with US bonds.If you want to have really low risk,you don't have any choice.There's just no room in the portfolio.For anything risky, it's going to dominate.As we start increasing, we get more and more--we go from the bonds.Pretty quickly, we go to euros, so weget a little bit more return.And that gradually decreases as thoseget crowded out as we move our wayalong the efficient frontier.What's growing?Well, take a look at US assets on the bottom.They're growing.So look at this again in vertical slices.As we move from left to right, we see that the US is growing.We see that Japan and France and all the countriesare growing in different slices in different wedges.So as we move up the efficient frontier,we're having more risky assets, fewer riskless assets.And the reason we see some common things and these lookssomewhat proportional is precisely because of the naturethat we saw that when we're--that this is driven by certain linear combinations thatwork for balancing what the risk and return are,the kind of thing we saw in the unconstrained case.But then we hit a turning point.So as we keep moving up and as the return level gets higher,we finally need return that we justcan't get except by being completely in the risky assets.So when we get up about 80% of the way across this graph,what we see is there's no more room even for euros,and we see that the riskiest assets are dominating.In this case, it's France and Japanbecause those are the two that have the highest return.So when we're at the far right-hand side of the graph,we're dominated by return.We have to invest in the riskiest assets.Otherwise, there's no way to satisfy the constraint--or excuse me, not necessarily the riskiestin the highest return assets.In this case, we have two of thembecause they're very, very closely connectedin terms of their risk and return for where they sit.So the portfolio is including both of theminstead of taking opposite positionsas it did when the weights were completely unconstrained here.Because the weights have to be positive,it's looking for a little bit of correlation offset.But there we go.So this is interpolating between the lowest return, lowest riskside and the highest return side of the efficient frontier.

#### Rec08_S07_v1-en

PROFESSOR: Can we find the efficient frontier in practice?The optimizations would be absolutely optimalif we knew the exact value of the inputsand we knew that the returns were generatedin exactly the way these models predict,but neither of those things is true.Let's take the inputs first of all.Even if we knew the exact data-generating process,the parameters we need to estimatefrom historical data using statistical techniques,or we need other forecasting techniquesto predict what the future excess returns will be.Given that they're drawn from some distribution,getting the parameters and fittingthose from the limited and noisy data we have can be tricky.We also have the issue that the data-generating process,if there is such a thing, is not stable over infinite periodsof time.Here, we've got attention.We'd like to use longer and longer historical periods.If we can to get better statistics.But the longer we go, the less likelyit is that a given covariance matrix reallyheld that would be a good basis for forecasting the future.So in practice, it's quite challengingto get good estimates for what the inputs are evenunder the assumption that there'sa fixed data-generating process that we know what it isand that the time series are stationary.And probably none of those things is true.But let's take a look.We can at least see how big the estimation side isby making the assumption that everything is held fixedand that we know how the noise is generated.Let's do it via Monte Carlo.We've already seen how these techniques canbe used to get visualizations of the evolutionof random processes.We've seen how Monte Carlo techniquescan be used to approximate the prices of options.And now let's use it to simulate a whole bunchof different scenarios.So this kind of scenario analysisis quite a typical application of Monte Carlo techniquesas well.What are we going to do?Well, here's the idea.Let's assume that the data that we have,the code that we've been working with,the covariance matrix, the expected returns--let's suppose that those are actually the truth.That's the way the world really works.But let's forget that we know where they came from.Let's pretend we don't know what their actual values are.Let's suppose that what we have to look at is historical data.We're going to simulate it.But what we're looking at is realizationsof data that are drawn from a probability distributionwith a particular covariance and with a particular setof expected returns.And we're going to do that a whole bunch of different times.So here's the setup.There's a true data-generating process.We're going to generate a whole bunchof decade-long simulations.Each one is going to be a possible outcome that we couldhave had, data that we could be lookingat by which we need to estimate what the true values are.And we don't get the true values.There's no answer in the back of the book here.What we need to do is we're charged with making investmentdecisions.So what we're going to do is each time weget a chunk of simulated historical data,we're going to act on it.We're going to try to infer the most likely values for whatthe covariance matrix and the expected excess returns are.We will find where we think the efficient frontier should be,and that will be a set of portfolios.But then each of those portfolios,we're going to plot on the risk and return graph,not against where we thought it's risk and return would be,but where they actually are based on the true values.So this is all under some almost perfect--this is like the best case we could possibly have.There is a stable data-generating process.Everything is stationary.We know what the model is.We just don't know the parameters.So this is all-- any uncertaintieswe see, any imprecision we see all comes from the parameterestimation side.None of it comes from this other more challenging problemslike our markets changing with time.Can we use historical estimates from the past?Are they good predictors of the future?Do we need something else?This is our baseline.So let's see how well we can do that.So what we're going to do is write a functionto do mean variance.We'll call mvmc for "mean variance Monte Carlo."And let's take a look at what it consists of.So here's our code, our mean variance Monte Carlo,and I've defined a function which has a similar functioncall.It takes a covariance matrix.It takes a vector of expected returns and a bunch of points.So let's run this to define the function.And what we're going to do is generate a simulated covariancematrix.Now, the data that we started withwas based on the simulation's monthly returns.It could be anything.There's a standard technique for generatingcorrelated random variables that are normally distributed,which we're going to use here.And that's to use this Cholesky decomposition, which basicallytakes the square root of the covariance matrix,and we'll sandwich it and reconstruct something.So you can take a look.This is a standard technique that you can look upfor generating jointly normal correlated random variables,and what we're going to do is we'regoing to generate a bunch of simulated time serieswith those parameters.So what happens is we're using thisfor generating normal random numbers.The parameters are going to be the mu inputs that we haveand the covariance matrix that we have.So this tells us that we're going to generate thingsfrom a random distribution whose parameters are the onesthat we're setting to be exactly the ones that we started with.But of course, because it's a random sample,we're going to get different actual values.Then, for each set of simulated historical data,we're going to run our computation of wherethe efficient frontier is.So what we'll do is we'll do a loop.And for each one, we're going to run an efficient frontier.We'll do that a whole bunch of times,and then we'll plot them and see how it looks.So the rest of this is pretty much the samethat we saw before, and we're goingto output this into something we'll call mvmc.It's going to have sigma p on the efficient frontieras a function of mu sub p, the grid of pointsthat we work with, and we'll put the weights as well for what'son the efficient frontier.So let's see how it looks, shall we?Let's do 100 simulations.You can run the code and do more.And what we're going to do is generate a bunch of points.So we'll have this for loop over simulations.So within this for loop, we're going to run our mean varianceMonte Carlo.Because it's going to overwrite the variables each time, let'spull out the ones we want.So sigma_sim will be our--in this case, for step n in our for loop.This will be the n-th set of sigma variableson our efficient frontier plot.Remember that we're having pairs of mus and sigmas,and the ensemble of them for giving inis going to sweep out the curve.And here are the corresponding mus,the points that we held fixed as we build upour efficient frontier.And that's it.So we're going to run this loop, and then we'regoing to plot it.So let's take a look and see what we get.Oh, boy.So the blue line is our unconstrained efficientfrontier.The black line that's the envelopecurve of all these red dots, that'sthe true efficient frontier under the constraintswith the inequality constraints we've been talking about.So the blue line and the black lineare exactly the ones that we saw above.What are the red dots?Well, each line of red dots that you seeis the output of one of our 100 simulations.Using our best historical estimates and our besttechniques of optimizing based on a givenset of inputs that we had, this is where we think--these are things that we thought were on the efficient frontierplotted against where they really truly are.So we don't plot their locations based on whatwe thought the values were.This is based on where they actually were.And of course, in the real world, we couldn't do that.So this is absolutely a best case.We would just find out when the investment returns came inand we found that a particular portfolio landed far awayfrom the efficient frontier.And you can see that these red points are not allclustered really close to the efficient frontier.It might be what you would expect.Some of them are very, very far away.Of course, a lot of them are close, and we could get lucky.But if we were to end up with a point far away,we might say, well, what happened?How did that happen?I thought we were doing something that was optimal.And in this case, we did.We did everything right, and we stillended up with the red points.So it's a challenging thing to see how to do it in practice.There are many things that are going on.What you might think of as being the simplest one,doing statistical estimation evenin a case where we know exactly how everything works,leads to portfolios being all over the place.So we do need to deal with that.We do need to deal with the possibility the marketstructures are changing over time.We do need to think about alternative ways of using datafor forecasting future risk and return,and we need to think about the optimization we have.Not only in a pure world, does itgive us something that is truly the best?But is it something that actuallyis going to be robust and useful when we apply itin the financial markets or in other decision-making settings?Try it out on your own with this notebook.Run it, tweak the parameters, go get your own datasets, and have some fun.

### 04-Problem_Set_8

## 12-Week_9-Optimal_Decision_Making_and_Optimal_Strategies

### 01-Overview

### 02-Lecture_9

#### Opt10_S01_v1-en

PROFESSOR: So let's take a look at another kind of optimizationthrough what's called the calculus of variations, thatis actually behind ideas like dynamic programming,even though it doesn't always get credited that way.And it's a global view and often getsdiscretized in things like Bellman's principleof optimality for dynamic programming.So here's the idea.The idea is suppose that we've got some function that'sgoing to represent a kind of policy, somethingthat we decide over time.For concreteness, the examples that we'regoing to be looking at are going to involve trading policy.So imagine that you're a trader.Your job is to trade a large block of shares.So you've got 100,000 or a million shares of stock,and you need to trade them over a given period of time.So the amount you trade at a given point in timeor the amount perhaps, that you have an inventory in a givenamount of time might be a quantity q,which is some function of time.And the idea is how should you vary qas a function of time in an optimal way.What are the considerations?Well, if you dump all your shares at once,you're going to get a worse price.Because people will know you're there.There's not enough liquidity in the market.If you go really slowly on the other hand,you'll incur a lot of risk.So if there are different trade offs,we can capture those in a function thatinvolves penalties for the different things thatmight go wrong, and ask about solvingfor a policy as a function of time.This is very different from solving for a single scalarvariable at a point.What we're doing is we're asking about somethingthat we're varying with respect to a function, a functionof time.And we want to solve for a function.So how do you differentiate with respect to a function?This is a classical problem, and I'dlike to show you a simple example in justa couple of pictures.And as I said, we're not going to be using this directly.But you will see the flavor of thisin some of the applied problems if we look at,for solutions to the problem of optimal trading.So the first thing is to considerthat we have a function, q of t, whichis what we're going to control and what we want to solve for.And we're going to let the Lagrangian now, bea function of q and of its first time derivative,which I'll call q dot.So q dot represents dq/dt.OK, and we're going to construct a function called the action,but that's just the name.It's a S. And we're going to integratethis function across time.And we're going to consider S as a function of functions.So S is a function of different q's.If you pick a different trajectory, q of t,stuff it into L, along with a time derivative,q dot, you'll get a different number.So what we want to ask is, given a particular functional formof L. And given an arbitrary function of q, I can compute S.And I want to know what function q,gives me the minimum value of S.So here's how we're going to do it.First, we're going to characterize our deviations.How do we average over all possible functions?Well, here's one way we could do it.Let's start with the particular qand look at it as a one parameter family of deviations.So let's let the alpha just be a parameter scalarthat we can vary.And we'll say that when alpha is 0,we have our starting function.And we're going to vary it in proportionto some other unknown function, x of t.So x of t is arbitrary, but what we'd likeis at the endpoints of the integration, whent is equal to 0 or big T, at the initial or the terminal point,that this deviation part, alpha xt should vanish.So for arbitrary alpha, we're changing qin the direction of the function x.But we're leaving the endpoints fixed.Now you could say, well, you just move the problemfrom an unknown q into an unknown x.And that's true, but what we're going to seeis it's not going to depend on which x we pick.So let's just substitute this informally.Let's see what we get for our results.And then we'll apply to a couple of simple examples.So I'm going to substitute, this expression,this alpha-dependent expression for q into my integral for S.And I'm going to say that an optimal solution wouldbe when the derivative of S with respect to alpha varnishes.That is, at least over this particular directionfor varying q, I'm varying q in the directionof a particular deviation x of t--It's a time-dependent function.I don't know what it is.But certainly, if this is going to be stationary,if it's going to be a critical point, then as I very alpha,this should be equal to 0.So I'm going to take dS d alpha.And I'm going to apply the ordinary chain rule.That's going to be partial of L with respectto q times partial of q with respect to alpha, plus it alsodepends q dot, partial of L with respect to q dot,times partial of q dot with respect to alpha.And the whole thing is integrated dt.And in more general cases, L might be more complex.And sometimes it's given an explicit time dependence.We're just going to look at this simple form.It's just a function of q and q dot.And we're q and q dot as being independent for the moment.Now, let's substitute.We know that the partial of u with respect to alpha.Here's q.So I take the partial with respect to alpha.It's just x of t.So this first line, I have partial L with respectto q times dq d alpha, is just partialof L with respect to q times x.And in the second term, the partial of qdot with respect to alpha, well, q dot is dq/dt.So the partial is just going to be dx/dt.It's going to be the derivative of x with respect to time,times this part is unchanged that's in front.Now let's do an integration by parts.Let's take the second term, integrate by parts,and move the t derivative over to the left-hand side.So instead of t acting on x, I'm goingto get d by dt acting on the first term.As usual, when I do integration by parts, I have a minus sign.And I have a boundary term I needto consider as well, which has this form-- partial of Lwith respect q dot times x, evaluatedat the end point the integral, t equals big T to t equals 0.Now the boundary term for my integration by partsvanishes, because x vanishes when tis that either the end points.That's the condition I add here.And now this term the remains hasthe quantity in square brackets, all multiplied times x of t.Integrated dt is equal to 0, and in this equation,has to hold for any function, x of tthat you might choose to consider.Well, the only way that can be true for any x of tis if the quantity of square brackets vanishes.And that gives us what are calledEuler-Lagrange equations.So the Euler Lagrange equations satisfy the conditionthat the action is stationary when q is suchthat it satisfies this equation-- partial of Lwith respect to q minus the derivative with respectto time, the total derivative with respectto time with the partial of L with respectto q dot needs to vanish.And this is well known to people who'vestudied classical mechanics.For example, this gives a different wayof formulating Newton's second law, F equals Ma,force is equal to mass times acceleration.Here's how we do it.We take a look at constructing Lagrange here.We think of q as representing the position of a particle,q dot is representing its velocity.And q double dot, the second derivative with respectto time, as representing the acceleration.Here is our functional form for L. It looks like the energy.We'll that V be the potential energy.But notice, this term looks like kinetic energy--1/2 m q dot squared, minus some function of qthat's independent of q dot.If this were the energy, there would be a plus sign here.And it has a minus sign.In any event, if you're not familiar with thisin classical mechanics, just take itas a particular functional example.Let's apply the rules.Partial of L with respect to q dot is going to be just--this is the only term with the q dot in it.It's going to be m times q dot.Partial of L with respect to q it'sgoing to give me minus derivative of Vwith respect to q.And that tells us, when I substitute itinto this equation, that m q dot, which is mass timesacceleration, is minus the prime of q,which in classical mechanics, is equal to the force.Specifically, if we take a problem where V of qis quadratic in q, this represents a harmonicoscillator.We have that the force is minus kq.It represents restoring force.If q gets large and positive, the forceis in the negative direction.And I'm going to get this very concrete differential equationand q double dot minus kq.And the solutions to this are sines and cosines,which you can check, satisfy the equation, with the frequencygiven by square root of k/m where k and m areprimary for the problem.K showed up in the potential, V. M showed upin our original Lagrange function here, as m.So that's an example as to how wecan get a differential equation out of this general principle.But what it tells us is not just thisis how a harmonic oscillator behaves.It tells us that of all possible things that a harmonicoscillator could do, not the ones that actually does,all the things that could do, the correct solution--the one the Newton tells us is the right solution--also happens to be the one that minimizesthis interesting integral here.So it turns out that while Newton's equationsare pretty good, that we can generalize this principleto many, many more problems than the specific differentialequations that Newton came up with.Here's another example.This is from the paper from Almgren and Chrissthat we'll look at more, which isabout optimal ways of dividing a trading solution.Their key idea is to take a look at penalizing both tradingfast, because of the high market impact thatwould be incurred if you try to tradea large block of shares too quickly, and inventory risk--that is if you hang on to your shares for too long,there's market risk that they might change in value.Now in their solution, they end upwith something which is discrete.They do a multi-period problem.But if we were to take the continuous time limit,we could replace their discrete sumby the integral that would have this general form, whichlooks an awful lot like the harmonic oscillators solutionwe just saw that looks like Newton's equations.So they have a term in delta q, which representsthe change in the quantity.It represents the speed of trading.And they have a term that ends on q squared, which dependson the quantity that's left.So we see we have an action term in this interval.We have something that depends on q dot squared,something that depends on q squared,just as we did in our example from Newtonian mechanics.So it's very similar, except that the harmonic oscillatorwould have the wrong sign.This would be a repulsive force.So it wouldn't be a very sensible for a harmonicoscillator.But the mathematics goes through almost the same way.The difference is that the solutions insteadof being sines and cosines, are exponential with a plusor minus sign.And when we impose boundary conditions,we find a particular linear combination of themthat involves a plus sign an a minus sign in this form thatinvolves hyperbolic functions.But it's basically a linear combinationof the two solutions.So in this picture, we have a problemthat was formulated initially as a recursive problem, verydiscretely, about what happens over small periods of time.But we have a trade-off between the desireto minimize risk and improve speed at a short distance,with a global problem where we need an optimal global solutionthat might not necessarily be an iterated setof myopic, short-term solutions.And the calculus of variations tells us how to do that.It says solve the entire trajectory all at once.And these are examples of what those solutions look like.

#### Opt11_S01_v1-en

PROFESSOR: Dynamic programming isthe name given to a set of techniquesthat help us recursively formulate an optimal solutionto a multi-period problem.When we looked at our initial portfolio optimization problem,for example, we looked at it as a single period problem.But often we have multiple problems.And it may be the case that the solutionto the multiple problem is not justa sequence of short-term solutionsto one period problems.So the idea is that's due to Bellmanand draws on a lot of classical mathematicsthat's much earlier, is to think about a sequence of decisions.And we'd like to minimize some overall objective functionby the time we've completed our assigned task, whichcould be on a finite horizon.As it often is, it might be an indefinite task that goes on.And then we need to minimize the long range running average.The observation that's key for dynamic programmingis that we can set up problems recursivelyso that in each time period, the decision thatneeds to be made, based on the informationset and the state variables where we currently areand the problem to be solved over the remainingperiod of time has the same structural form in each timeperiod.So that as we evolve forward in time,we get to solve the same problem again and again and again.And a typical solution to that isobtained by starting at the end wherewe have to complete our task and working our way backwards,taking advantage of this common structure in each time period.We might think of this applying this is to problem say,in portfolio re-balancing.We might have a particular periodwhere we set up an optimal portfolio,say for the next month or the next quarter.At the end of the quarter, we find outthat our portfolio is no longer optimal.Either our forecasts have changed for future expectedreturns and variances.Or simply, the market prices have moved.And our weight allocations aren't wherethey were initially.So should we re-balance while there arecosts associated with doing so?And should we have known better?Maybe if we knew that the costs were going to move,we could have taken that into account ahead of timeand managed our positions a bit better sothat we don't incur repeated transaction costs where we'reconstantly catching up if some of thatmight have been foreseeable.So what we'd like to do is have a balancebetween these short term decisions, wherewe could re-optimize step by step in a global perspective.What we really want to solve is the optimal long term problem.We're particularly interested in the casewith a solution to the global problemmight differ from taking a short term perspective.So here's a simple example.Suppose I have a grid and I want to start at one pointand finish at another.I want to start at the green point.I want to finish the red point.And let's assume that I'm allowed to move along the gridand I would like to find the path of minimum length.And in fact, it might not be unique.So let's see if we could find the number of minimum lengthpaths that are available on this graph.And we'd like to do it with a recursive setup.It's typical of the way in which we'llset up our dynamic programming problems.Now let's assume that because we wantto get from S to F, that we probably don't wantpaths to retrace our steps.So let's assume just to simplify that, we'regoing to require our paths either to go up or dothe right, that there's not going to beany backtracking involved.And you can show of course, it's not hardin this case see that that should be true.So how do we set this up/ Well, first of all,we'd like to think of a one-step relationship that at any givennode on this graph, given by coordinates i and j,the number of paths to reach that node say a point here--let's see if we can get our pointer--our point here let's say, is equal to the number of pathsthat enter from below plus the number thatenter from the left.So there are two ways that we could get to a given point.So however many ways that we're here, these pathscould all move into the node over here.And I can get to this point by coming from the leftor by coming up from below.So that's characterized here as a number of pathsinto a given point, is the numberthat come from below plus the number that come from the left.Next we have a boundary condition.So on the edges of the graph, definedby my starting and ending points,there's only one way to get there.That is by not allowing backtracking.So if on the left edge, I just came up from below-- notallowed to come from above from anywhere else,and similarly on the left-hand sideand on the top of the graph.So these provide boundary conditions.So here's the procedure that we have to solve.First, let's label each boundary node with a 1.Because there's only one way to get there.So each of these points has only one pathfrom the start to get there.Because they're on the boundaries.I can only go up, or I can move to the right.I'm not allowed to go down.I'm not allowed to go to the left.So these have only one point to get.There then for each interior node,as I move into the interior, I assignto each node the sum of the values that come from the pointto the left and from the point below.And as I fill in the graph in this way,I can find what the total number of pathsis that lead to my terminal point.And in this case, it's equal to 15.Here's another example.Suppose that we want to go from the top of this graphdown to the bottom.And we can take a path.At each point, we can move either to the left or the rightas we move down.Each node is associated with a number.And like a typical game of this type,let's assume that we collect a score that'sassociated with the number of points on each node.So let's assume that we have a path that as we traverseit and go down, we are entitled to collectthe sum of the points along the different nodesthat we encounter.So here's your chance.Why don't you pause the video right here,and see if you can find what's the optimal number that you canfind going from top to bottom.What's the largest sum that you can find in parts whereyou add up the values that you encounteras you move from top to bottom?

#### Opt11_S02_v1-en

PROFESSOR: Well, one way we could doit is with a greedy algorithm.A greedy algorithm is one where we do what's optimally local.We take a look at the next time stepand we pick the best value.So for example, I would start at 9.My choices are to go either to 2 or to 3.3 is bigger.So I'm going to take 3.My next choice, given that I'm at 3,is I can either get 8 or 10.I'm going to take 10.From 10, my choices are 1 or 5.And I'm going to take 5.And, here, my final choice is between 11 or 12.And I'll take 12.And my sum is equal to 39.So did you get something higher or lower?If you got something equal or lower,take a moment to see if you could do even better.Pause the video and see what you can find.There is a better solution.Let's try this.Let's take a look now and build in our grapha set of interior values where we'll start from the top.Let's at each point on the top--from the top going down--let's add each node that we mightbe able to encounter the sum of the valuesthat we would reach if we got to that node.So you can see that if we're at this point over here,we would have had 9 plus 3 in the original graph.If we were to have made this choice,we would have ended up with 11.So by proceeding in this way, where we take each nodeand we add all the values above that would have led to reachingthis node for getting here the best choice,we can build a tree with a set of nodesthat represent the best choices we couldhave gotten as we go down here.And then when we reach the terminal values,we pick the ones that's the best.And here's one that says 42.To find out how to get 42, we reclimb the tree.We say, well, the way we got to 42 was coming from this placehere where we added 11 to get there and then from this pointhere where we would have added pointsto get there taking this 11 and all the way back up.And what you'll notice is not onlyis 42, special number as being the ultimate answer--it's bigger than 39.But, also, you'll notice that whathappened is we did some things thatwere suboptimal locally but still were optimal globally.That is, when we came to this point here at 3,we chose to go for 8 in this solution,whereas before we went for 10, which wouldhave been the greedy solution.Once we were over here in 10, we no longerhad access to some better solutions.So this is typical.We often might take things that are short-term optimal thatlead us to no longer having accessto states that might be much more profitable in the future.So we'd like to have a systematic wayto avoid that happening and to make surethat we end up with a globally optimal solution.But there are a number of aspectsthat are common to dynamical programming problems.And these also show up in modern machine learning methodsas well.First, we have state variables that tell us how things behaveand where we are given a particular set of evolutionin a particular place.Usually, at a given point in timeor a given point in our process, wehave a number of actions we can take,a number of control variables that we have under our control,such as the number of shares that we might choose to trade.There are stochastic factors that are involved.We're typically looking at Markov processes thatare evolving in time so that because they're Markov,we only need to know the current statevariables not how we got here.But that doesn't mean we're safe from being trapped or havingdifferent actions cut out from us.We need to be able to reach things in the future.The effects of the actions in the environmentmight be fully known.Typically, they are in dynamical programming problems.That is, we know how the environment works.We have a complete model for the environment.Many realistic cases, and certainly in financial markets,that's not necessarily true.And methods like reinforcement learningare able to generalize and deal with caseswhere we may have only incomplete informationor a probabilistic understanding of what happens in the future.And we have boundary conditions.And, typically, these are terminal conditionsthat we have, and they permit us to work backwards.We often have rewards that are associatedwith the optimal value.We'd like to maximize our rewards.We would like to minimize our costs.So there may be penalty functionsfor taking suboptimal actions.And there may be discounting.That is, in the same way that we discount present valuein accounting and in finance, we mightdiscount the value of a future rewardrelative to an immediate reward.We might say that a reward that takes place far in the futureis less valuable, not equally valuable,to a reward in the next time period.That's a trade-off between long-term and short-term costs.It might say that if we need to defer gratificationto get a reward sometime in the far future,it should be a bigger reward.But those are problems that we couldchoose to include or not include in our specificationof the problem.And what we're looking for is an optimal policy.That is, we're looking for a set of rules that tell usin any situation we might find in the futurewith any given set of state variablesat a given point in time what is the bestaction we should take at that time to move us forward.And those actions do two things.One of them is they might get us immediate rewards.But they also position our state variables suchthat we have access to future rewards as well.The general kind of problem that we're trying to solvecould be formulated like this.And I'll leave out the notation and some of the jargon.Let's imagine that we start in a particular state.Let's call it state 0.So we've got something in our environment.We then take an action.And that action earns a reward, which we can keep.And we find ourselves in a different state.That is, we may have had some impact on our environment.When we looked at examples beforeof say algorithmic trading, we assumedthat the markets were the same after we participatedin them as when we came.But that's often not the case and certainly notfor significant financial transactionsand for significant financial intermediaries.So let's assume that our action did change the world.And now we have to deal with the world that's been changed.And that's part of the problem that we need to solve.We then take a new action.It earns a new reward.And it puts us in another state.And these are going to be iterated forward.And we want to solve for the best policy.And the complications that we may haveare that the evolution might be stochastic.That is, maybe we don't exactly knowwhat state we'll end up with.Maybe the best we have is a probability distributiontelling us what state we would end up in next.Maybe the rewards are stochastic.Maybe we don't know what the returnis we receive on an investment.But we only understand-- we're only given it's probabilitydistribution.Maybe the environment itself is unknown,and maybe the optimal policy to deal with that environmentis unknown as well.Maybe at certain points in time we should flip a coinand randomize our own decisions.So all of these are things that wemight consider as being within the scope of solvingfor finding an optimal policy.And let's take a look at some applicationswhere we can start very concrete and then look at expanding outand think about different places where they might be applied.Needless to say, this is a very big topic.And we're just going to introduce it, showwhat some of the thought processesare, what some of the characteristicsare that show up in typical problems,and see where they might be helpful, reformulating themfor solving different kinds of financial problems.

#### Opt12_S01_v1-en

PROFESSOR: Let's look at two approachesto the question of optimal trading, wherewe'd like to minimize execution costs in a tradingsetting, where we need to deal with randomness, and possiblymarket impact.First solution, the dynamic programming solution,is described by Bertsimas and Lo.So here is the question.We have fixed quantity of shares-- let's call it big Q--that we need to buy in a particular period of timeor a horizon, t.And the optimal trading policy isto find the best sequence of trades that satisfiesthe boundary conditions.So what we'd like to do is we need the set of trades.Let qt be the trade quantity at each period.And I have t periods.So the sum of q sub t from one to big Tneeds to add up to the total number of shares.And what we'd like to do is minimize the costwhen we bought, and this is the market value.So you notice the qt is going to vary in each time period.And we have control over the q's, but we do nothave control over the prices.Those are in the market, and thosemay be subject to random fluctuations,and they may be subject to feedback effectsfrom our trading.But here the objective is to minimize this function subjectto this constraint.So in each trade period, we'll model the price processas being arithmetic Brownian motion,so rather than log normal motion.And that's so that we can solve the problem analytically.But also, these typical trading problems, the overall timehorizons are fairly short.They might be a matter of days.And this is not a terrible model for price movements.So here's our model for the price movement.This is price, not return.The price in period t is the previous priceplus our random increment, that's going to be 0 mean,and a term that depends on the amount that we traded.So this is a market impact term.We're going to assume it's proportional to the size.So theta is a coefficient.And this says that if we make a trade if we're buying,and we buy a large quantity, the pricegoes up by a large amount.Now you might think that that's good.Your trades became more valuable.But what's happened is the price went hereafter you executed your trade and makes your future tradeseven more expensive.So we're going to hold theta fixed.And we're going to assume that this is a linear function.And we'll see that's actually pretty conservative.In the real world, transaction coststend to be for large quantities, a faster varying function,possibly quadratic as a function of q.But for purposes of this model, this is nice.It's easy to describe.And it's easy to solve.So epsilon is going to be a 0 mean process.And we want to think about which of the variables we controland which are the ones we have to observe in the environment.So p is the price.And we unfortunately cannot determine the prices.We have to take the prices we get.So we can observe them, and they'regoing to have a random component.The other state variable is the number of sharesthat we have remaining.And we'll designate that by W. W isgoing to be the total quantity at time t,minus the number of shares that have been done previously.So this decrements the number of shares.W is the inventory.It's the number of shares that we have remaining.So at a given point in time at a point t,we have two things that describe the state.What's the current price?How many shares do we have left to trade?And this is a Markov decision process.It's in the family decision problems,where the future decisions dependonly on what the current state variables are,not on the history for how we got there.Q is a control variable.We get to pick.At least we get some control over something.And what we get to do is choose a sequenceof q's to find the optimal sequenceto minimize our overall result for the overall transactioncosts.So our goal is to find a sequenceof cues that minimize the cost.And this is a policy.So the optimal policy is the one that minimizesthe total expected cost.The dynamic programming principlesays let's frame our decisions as a recursive set of problems,so that the optimal decision and the optimal sequenceat each step is also optimal for all the remaining shares.So if we can have a set of sub-problems, each of whichis of the same structure, then when we solve one,we can solve them all and recurse our way backfrom a definite point, usually the terminal point,back to the beginning, and find the optimal solution.So the optimal policy satisfies this.Now we are going to solve it from the end.But we need to frame each decision with respectto uncertainty that occurs in the future.So in one step what we would say is that our value function isgoing to be given the prices available through t minus 1,and given the number of shares wehave available that we need to move W sub t.Having completed all the trades through q of t minus 1,we want to minimize over all possible tradesin the next period, the expected value of our final cost.And that's going to be equal to the trade in the next period,qt, whatever it is, times the price in the next period,plus whatever is left over after we do our next trade.And that's going to be whatever is left over having notdone this at time t plus 1 for the next period,involving a new price.The new starting price will be p sub t.And The new starting quantity is W of t plus 1.But these quantities are unknown at this point,because we haven't picked a q yet.And that's why these are all inside the expectation value.And the expectation value is taken at time t.So I have a recursive problem, where I don't know what V is.But I have the same unknown function on the leftand on the right.It's in the expected value on the right,because these are future values.Over here, these are taken at present values,which are taken to be known.I know what the last observed price is.I know what the inventory remaining is.And I'm going to minimize with respect to my control variable,the average over all possible outcomes for what the pricethe expected future price might be,so that I can minimize the expected total cost of trading.So we can't solve this, because it'sgot a V on the left and a V on the right.But what we can do is we can set it up recursively and workour way backwards from a known point back to the beginning.So the easy place to start is at the end.And the reason it's easy at the endis in our very last trading period, we have no choice.Whatever we've got left, we have to sell.That's the importance of the terminal condition.And we've seen that in many other settingsfor boundary value problems that we've done.If you know the terminal conditions,it helps fix many other aspects of the problem.So if you get your last period and you'vegot some shares left over you haven't traded yet,you've got to trade them.So that is not a random variable.In the final period left, we needto trade the number of shares remaining.So therefore, the terminal condition at time tis that this expectation where we'regoing to minimize the final priceand there's not going to be anything left over,because there won't be any additional quantity,is going to be the expectation over qt times the final price.And that's something that we can write downthis way in terms of our price process.So this piece is from our equationfor how the price evolves.And there's no more V because we're in the final period.There is nothing left over.Everything has been liquidated at this point.So let's take expectations of this.That's pretty easy.Where is our random variable?Well, there's a random variable here in terms of epsilon.Everything else is actually known.We know the previous price.And we know we know what q sub t is whenwe're in that final period.So we're going to get the expectationis going to be qt times the previous price plus theta timesq sub t.We don't minimize with respect to qt,because we don't have any choice.It's fixed.We have to dump all the shares we have left.So in the final period we can re express thisas a function of W, because Wt and qt are the same thing.And we've got this expression, that our valuefor the final period is going to beW sub t times the price plus theta times Wt.And this is a quadratic function of Wt.And it's a linear function in the price.So no more expectations, no minimizations.This is an explicit formula for Vin terms of the state variables, p and W.That's what we mean by describing the state in termsof a value function.What about one period previously?In the next to last period, we can take this resultand substitute it into our recursion.So our recursion-- we're going to put this resultfrom the previous slide, which isa definite, non-stochastic form of known form.We're going to put that function in,and here it is in closed form.And now we're going to think about this,where we haven't yet realized the next to last trade.So we'd like to solve for what is qt minus 1in order to minimize the expected cost.Well, the expected cost of our total trading programis going to be the cost in the next to last periodplus whatever the cost is in the final period that's dumpingwhatever shares are there.The reason we have expectations now,compared to the previous case, iswe haven't done yet, our next to last trade.We have some choice.That is we're going to pick q some t minus 1.That's going to affect the final period.So whatever is left over, we have to pick.But this is in the next to last period.It's the last discretionary choice that we have to make.So that's OK.Let's just expand things out.And inside the expectation, we nowcan write this out in terms of our known variableswith this expression.And then, what are we going to do with this expression?Well, we're going to compute the expectation.We're going to minimize the result for all possible valuesof q or control variable.And then we're going to re express thingsin terms of the state variables as theywere known at time t minus 1.And then we're going to do this again and againand again until we get back to the beginning.

#### Opt12_S02_v1-en

PROFESSOR: In order to express thingsin terms of known quantities, we used recursion relationsfor the price and for the inventory remaining, whichare pretty simple.So if I've got a Wt and a future pointI don't know that necessarily.But I can express it certainly, in terms of Wt minus 1and qt minus 1, which is the thing that Iwanted to vary and choose.And similarly for the price, I canexpress the relationship between p of t minus 1 and t minus 2in this way, using the recursion relation for the priceevolution.So if we substitute that into the resultsfrom the previous slide, you get a whole bunch of algebra to do.But when we combine the terms--so what we're going to do is we'regoing to substitute that in.We're going to compute the expectation.Computing the expectation, we're alwaysgoing to track where the random variables appear,the only randomness that's going to appearin the epsilons, which appear in the price coefficientsSo we're going to look everywherewhere there's a price it appears with an uncertainty for whatthe future price variation is.That's going to contribute non-triviallyto the expectation.Once we've computed the expectation,there's no more randomness.But there is dependence on the control variable,in this case, q of t minus 1.We minimize that.And here, we can see that we're going to minimize this.And this has a quadratic form plus some constant that'sleftover.So the minimization term is goingto involve minimizing a quadratic form.The reason it's quadratic does comefrom our choice of a linear cost impact functionat the beginning.So for more complicated functions,the algebra in the derivatives get a little bit morecomplicated.But the general idea is what we see here.So we want to minimize that quadratic functionand find our decision variable.When we do that, the constant doesn't matter.And what we find is our decision variable for our nextto last period, is that what we should dois we should trade half the remaining shares.So that's the solution.That's an output.That's not a guess.So we've got that this should be half the remaining shares thatminimizes the function that we saw on the previous slide.We take this result, and we plug it in to evaluate the function,assuming that we've made that optimal choice.And we get a new expression for the value functionin terms of state variables that are known at time t minus 1.We know what the previous observed price was.We know what the inventory was.And now by substituting in our optimal solution for q hat,we can express things this way.And this is the value that we'll havea time t minus 1 under the assumptionthat we're going to follow an optimal policyfor the remaining two time periods.So this is the desired closed form expression.It depends only on the two things I've written here--the price and on the inventory, which we know.Well, let's keep going.So there's going to be more algebra.But it's going to be the same ideauntil we get to the beginning.We use one more step.We do a substitution for our inventory.We write out our expectation.We do the expectation by identifying each occurrenceof the random variable.We regroup terms so that we can group things in termsof W times something with p.So we group the W's together.We group the p's together.We minimize by varying the q's for the next time period.We find that this also gives us a quadratic function.The solution to this quadratic functionis going to be that the optimal trade at time t minus 2,two periods before the terminal value,is going to be 1/3 of the remaining inventory.We keep going.We substituted it in.We get our new value function at this point.Again, it's a function of p.It's a function of W that are known.And as a term that's linear in p,terms that are linear and quadratic and W,it's just the coefficients that change.So as Bellman set out and as we hoped we would find,the structure of the problem is the same in each period.In each time period, we have to do the same thing--compute an expectation, minimize,and substitute variables.And in each time period, we have a formulathat's got the same structural form as the one before.So we know how to solve it each time.It's just the details that changea little bit in each period.So we keep going.And we find that at each time step,we have the same solution.We get a quadratic in every period.And each time, we got some fractionof the remaining shares that's going to decrease linearlywith the number of time steps that are remaining.We take that value.We substitute it in.And for our arbitrary k, we find that we get this result.It's something that's quadratic in W. It's linear and p.The only thing that's changing is this k dependent coefficientas we go.We keep going all the way back to the beginningto where k is the t minus 1.And we're back in the initial period.And for the initial period, we solve that.We find that q hat in first periodis W1, which is our whole inventory divided by t.In that's just Q/T. So what our solution has told us--and here's our optimal value that we have here,again is the same structural reform that we had before,something that's linear in p.It's quadratic in W1.And therefore we found the first tradesize is 1/T for the total.The second trade size is 1/(T-1) of the remainder.So the optimal solution that we foundis we should divide up our trade quantity into equal slices.And you might have guessed that as a starting point.Why don't we start equal?But here, we've shown that there'sa balancing between the uncertaintythat we have in the time periods and the marketimpact that we have.So the market impact that we have--remember, if we trade too fast, we'regoing to incur a high market impact thatthen is going to affect the subsequent trades.And we're looking for the balance between them.In this particular case, with this special choiceof market impact function, we've gonethrough these steps are the same steps you would do.If you'd like, you can try it out,going through with a more complex market impact function.For example, a quadratic market impactfunction instead of a linear.The expected cost at the initial time--therefore, we can go, and now we can substitute back in.Because we know what the expected quantitiesare going to be.We know what the quantities tradedare going to be in each period.We don't know what the prices will be.But we do know what the market impact is.So if we substitute that in, we findthat we're going to get the expected value of Q/Ttimes the sum of the prices.This comes out because our trade quantities are actuallyconstant.And then we can move the expectation insideand look at the sum of the expected prices.If we do that, we're going to get sum over little tfrom 1 to big T.We can do this sum explicitly.It's just T(T+1)/2 .And we got our final result, whichis that the term involves what we would havehad if there were no frictions.If theta were equal to 0, we would have justhad the total quantity times the initial priceplus an expected part that's due to the transaction costs.And this piece is quadratic in Q, in the total quantity,not in the quantity done individual period.So it's proportional to theta, whichis our market cost parameter.And its quadratic in the number of shares.So under this solution, the minimum cost solutionis to trade equal slices to divide up our trade.If it's over 10 days, we do 1/10 per day.But we find that the market impact,relative to a frictionless trade,relative to the mark to market value of a portfoliois going to be quadratic in the number of shares.Market to market is a standard wayof accounting for the value of an investment, wherewe look at what the quantity is that we hold in an account.And we multiply times the market price.And that means the value on a market to market basisassumes that it could be liquidated with no impactcosts.And that's not a fair assumption for almostany non-trivial investment.So this tells us there's a significant deviationbetween the actual expected liquidation costand/or acquisition cost in this case, where we're buying--this it's q squared.This would be the same if we're market to market or selling.But the expected acquisition costis going to be a function that's quadratic in Q.And that's going to differ from what the market to market costwould be, which would simply be the first term this expression.So we can compute with the expected transaction costs are.It does depend on the number of time periods.So if we were to spread this out over more time periods,t, the longer we spread it out, the lower wecan make the transaction costs but even the limitwhere we do it over an infinite number of time periods,the total transaction cost is going to be finite.And it is going to be proportional to Q squared.If we compare with say, trading everythingin the initial period, we can seethat we would have incurred a higher transaction costs.So if we doped all our shares in period one,we would have ended up with a cost that would have alsobeen proportional to Q squared, but without the factor of 1/2.So by this particular case, by slicing our tradesand spreading them out over time, we can lower the costs.And we can lower them as much as by a factor of 2, but not morethan that.So in both cases, we have market impact.But by optimally executing our, tradeswe can cut the transaction costs in half.So to summarize what we've seen for the Bertsimas and Losolution for optimal trading, the cost of optimal executionis half the cost of immediate execution.The cost is quadratic in the total trade quantity.If the quantity is small, then Q squared might be small.But the impact is permanent.So the idea is that each trade we doleaves its mark on the subsequent trades.And that's why these quantities build upand why it's important to work from the endback to the beginning.There are a lot of things that we left out of this analysis.So this model is quite specialized.And you can generalize it to more realistic cases.It doesn't account for things like a temporary marketimpact that might go away.That's often the case in markets where we're looking dynamicallyover multiple time scales.It doesn't penalize the opportunity costs of delay.After all, if we're buying the shares,maybe we're not just buying them for liquidity reasons.Perhaps we're buying shares because we have a signal.We know we have good forecast for the future price.We think that the value is going to go up.And the longer we wait, yeah, we might get a lower cost.But we might lose out of the expected gain in the returns.So perhaps we should include that in our tradeoff as well, the opportunity cost of waiting.We're not penalizing for risk, for volatilityin the final value.And we're not really asking aboutwhether this particular trader or investor hasdifferent preferences, different risk tolerances thatmight favor faster or slower execution.But it is an example of using dynamic programmingto get a recursive structure for the problem,finding an optimal policy so that we know before we evenbegin what our actions will be in the future,subject to all of the conditions that we might find alongthe way.

#### Opt13_S01_v1-en

PROFESSOR: Techniques for finding optimal policies canbe broadly applied for finding optimal strategiesin a wide variety of settings.The space of optimal trading strategieslooks at how we might devise trading in a worldwhere there's some uncertainty about the environment, wherethere may be adversaries on the other side who are tryingto thwart our optimal methods, and wherewe may try to define an optimal policysubject to a number of things that areunknown about the environment.So what we'd like to do is come up with an optimal policy.But these models are also helpful for exploringhow marketplaces work and how there'san interplay between, possibly, different kinds of agents,different kinds of actors who might havedifferent sets of preferences, different information sets,and so on.So we can use strategic models to takea look at market structure to lookat even features of developing models for marketmicrostructure.Where does liquidity come?From where do bid offer spreads come from?How do prices actually come to incorporate information?When it comes to practical strategies for a traderor portfolio manager, the starting pointis to think of what your objective is.What is it you would like to optimize?Do you want to minimize your costs?Maybe if you're a trader acting as an agent for a client,that should be your objective.If you're trading on your own account,you might have a concern where youwould like to minimize your costs,but you also don't want to give up opportunity costs if you'retrading for a reason, and you might have a trading signalthat decay, for some reason.Do you want to minimize your risk?Do you want to maximize your utility?What are the constraints that you're subject to?So we need to think about what it is we want to extremize,and then we want to define policy variables we haveunder our control, state variablesthat we need to monitor that would affect our decision,and we need models for how the state variables would evolvein time on their own, absent our participation, justin the general environment and how they respond to the controldecisions that we make.So one common way to approach thisis to look at minimizing the cost for a given level of risksubject to, perhaps, the expected utility function thatreflects what our risk preferences are sothat it could be a general class thatmight be different for different peoplewith different preferences.So let's consider this case, wherewe want to buy or sell a block of shares for little quantity qand at time t.Let's divide the total trade horizon into n sub-periods.Let's allow it to be invisible, possibly without the tgoing to 0.But let's think of this as being finite because we typicallyare trading in finite periods.Trades are discrete.The time periods don't need to be discrete.But let's imagine that we're at least re-evaluatingthe possibility of trading at regular intervals delta t.We can always choose not to trade.Trade quantity in a given period could be 0.But the available trading times we'll denote by t sub k,which are going to be at k delta t in clock time,where k will go from 0 up through n.Let's let q sub k be the amount that we hold at time k.And we'll have boundary conditionsthat-- let's say that we're selling a block of sharesthis time.And in this case, we're going to start with initial value big Q.And we're going to decrement until weget to a terminal value in our final period at-- of 0.So the amount that we trade in a given period of timeis going to be delta qk.It's just going to be the change in shares between oneperiod and the next.And that's where we get to decide.So part of our strategy, part of our policy,part of our optimal solution and programis going to be to determine sequence deltak so that the shares add up to the total number qthat we sell over this period of time.So a strategy, a solution, to this optimization problemis find an algorithm that assigns values delta qk basedon, at each time stop, the information that's availableup to that point in time.So what we need to do is devise a set of rulesyou could hand off to someone.You don't know what the future prices are.You do have a model for what their stochastic evolutionmight be.But that way, someone could take your set of instructions.At any point in time, they could say, aha,I've got this many shares left.Here's the price that I observe.What should I do?In the example of Bertsimas and Lo,we saw that, actually, the optimal programdidn't depend on the prices.It didn't-- it was the same thing no matter what.It was just due to equal trading.So that was a very stylized example.More generally, it could depend on thingsthat evolve that are not yet known at the beginning,and that's what we want to do when we devise a strategy.So what price process might we use for trading?We're going to look at a specific example.It was developed by Almgren and Chris optimal trading policies.So let's take a look at their assumptions.And I encourage you to take a look at their original paper.So for the drift rate, the--during the price period, we're goingto think about this as a short-term tradingexample, where the drift rate is goingto be taken to 0 as an initial approximation.So we're not going to include the opportunity costs.Those could be added later.That might be a reasonable example.It might not.But we're going to do this to simplify the mathematics.So one immediate specialization we're makingis to have no draft, just randomness.And this is an obvious generalizationthat you can make and redo the derivation to take a look at.We're going to let the price process diffuse sothat there will be randomness.And we're going to allow there to be market impact sothat our trading affects the final price.So really, if we're setting up typical elementsof an optimization problem, we liketo get the realistic details.But the minimum ingredients that we needare two things that we want to minimize,which are at odds with each other.That's the basic feature we have.So in this case, we're not minimizing the opportunitycost.We're leaving out that one leg.But we do have two other legs that will give usa non-trivial problem.One of them is that we want to minimize risk.The other is we want to minimize cost.And those two are going to conflict with each other.So we're going to assume that there is a speed of tradingthat we could define.Let's think of a variable delta q over delta t.And we're going to assume that our market impact is a functionof the trading speed.The more we trade in a given time period,the higher the market impact.We're also going to allow for a two-part market impact model.We're going to think of there being permanent,as well as temporary, market impact.A permanent impact affects all future trades.And a temporary impact affects the pricethat you get in that period.You might think of it as being due to order book structure,due to the fact that you need to cross the bid offer spreadand go deeper in the order book than the initial price.But it won't affect the next trading periodbecause liquidity might be replenished.So there are two possible things.Obviously, you can specialize, where you setone or the other of these to 0.But let's include a two-part model market impact.So the market impact shows up in the pricing evolutionwith a model that looks like this.Let's assume that the price in one periodis given by the price in another period plus two components.One of them is a random movement.So zk is going to be a random variable.Sigma is going to be the volatility associatedwith the change in delta square root of delta t--so what we'd expect for sigma square root of delta t--to be the size of the shock that we would getduring a time period delta t.And that's the diffusive part.And we're going to assume that we have a permanent marketimpact that's some function g.And our assumption is it only depends on the rate of trading.It doesn't necessarily depend on the number of sharesthat we have in inventory because that's notknown by the market.The amount that we push into the market in a given time periodwill be seen by the market.Those are the shares that we expose.And those might realistically be modeledas affecting future periods.And the impact that we have is goingto be some function that depends on the rate at which we'retrading times the size of the time periodif we have the same rate over a longer time interval.We're going to have a larger market impact.And we'll also include that theremight be a temporary market impact that just affectsthe price during a particular period that affectsour execution costs for one set of trades,but not for the subsequent time periods.So we have g represents a function of arbitrary form.We'll pick some examples so we can solve this later on.But g represents permanent market impact.h represents temporary market impactthat we might have for the short term.So we like to look at the total trading cost.And obviously, we'd like to minimizewhat we lose relative to a frictionless set of trading.So in the case where we're selling,we'd like to maximize the cost.And we can think of what's sometimescalled the implementation shortfall as beingthe difference between a frictionless tradeand the real-world frictions where we're alwaysgoing to lose something.So what do we have?Well, we've got our frictionless price is quantitytimes the initial price.That's what we'd have if there were no impact at all.We could implement everything all at once.And we're going to have subtractedfrom that what the actual impact isof the price changes over the trades that we actually do.So if we break this into parts, wehave one piece that comes from the diffusivity termsfrom all of our trades and we haveanother part that comes from the permanent market impact term.And we're summing this over all periods,with delta q being the quantity that wedo in each period times the impact time in each periodand the piece that's left over that is non-transientthat affects only the parts that are done within each period.So this part here, this final termthat's the temporary increase is multiplied by delta q.It's only the change that we have.This part here depends on q, the decreasing balancefor the number of shares, even though this term here dependsonly on the trading velocity.But we've taken something that-- wherewe have initial variables big Q and P0,initially known price and quantity.We have unknowns, which are the q's and delta q's.And we need to determine-- find the optimal policy.And we've substituted p tilde k, whichis the price we receive in each period.And we've expressed it in terms of these other variables, someof which are unknown, including this random variable, z subk, others of which are functions of the yet to be determinedpolicy.So this is g of delta q and h of delta q.So this is the expression that we'd like to optimize.So implementation shortfall we can think aboutas something that we measure after we'redone with our program--that if we're selling a bunch of shares,our effective final price is less than p0--and we hope to receive.So the final price could actually be lessor could be greater due to the randomness of the diffusion.We're not taking that into account here.So let's assume that all the trades are executed.So it's not always the case in marketsthat, when you send in a quantity--when you observe a price, you send in the quantitythat you want.Depending on whether you do market orders or limit orders,you're necessarily going to get the quantityyou want at the price you thought you were going to get.But let's assume that all the trades are filled regardlessof the price movement.Let's not consider unfulfilled orders.And let's note that before we start trading,the realized effective price is a random variable.So we're going to need to take expectations,and we want to optimize the expectations.So we're going to optimize either the expected costor the variance or both or maybe some linear combination.So what do we have?Well, let's look at what the expected cost and variance are.The expected cost-- I take the expectation of the previousresult. I have the expectation of my random variablein the z's.It's going to drop out because itwas arithmetic Brownian motion and 0 mean,and we didn't have a drift term.So the expected cost that we have has these two terms, whichare written in terms of my functionh and j in terms of the permanent and temporary marketimpact.And the algebraic structure is a little bit different.We're going to massage those so they have a common form.This has a qk because this depends on the total amount,and this depends on the incremental amount.And then if we compute the variance,the variance does depend on the diffusive term.This expected cost term is independent of sigmabecause the fluctuations were equally likely to help us outas to hurt us.But the variance absolutely depends on sigma.That will only hurt us.So this depends on sigma squared.And it's a positive quantity.It depends on the sum of the q squareds.To look at a concrete example, let's make some assumptionsfor the market impact functions.If we take the permanent impact functiong to be of linear form--so it's something proportional to the trading speed.Let's call it gamma times v, where v is the trading speeddelta q over delta t.We'll find that the final permanent change dependson the total amount that we have, q.And what's going on is that when we have this kind of marketimpact function, the early tradesare going to push down the price on the later trades.So it's permanent.The more we trade early, the more it hurts us later on.If we trade more slowly at the beginning,there's less impact on the later trades,but there will be greater variance.So we're going to need to find an optimal balancebetween those two features.So there's a bunch of algebra wherethe contribution from the expected shortfall thatcomes from the permanent impact function--and with this identity above me, we can simplify some of that.I can rewrite this sum of the delta q'sby writing it this way.I can expand it out, expand out this square,regroup some of the terms, and I can pull outan overall factor of the-- from-- this isthe sum of squared differences.I can get the total value of q, quantitysquared, by completing the square minus another term herethat just depends on the differencesand shows up here in the second term,where I have q times the differences.And then I can re-express this termin terms of q, which is a constant and something whichis quadratic in the trading velocity.What about h?Well, let's let that be linear as well.And the choice chosen by Almgren and Chrisis one we can stick with.Let's let there be something that depends on-- maybeon the absolute value.So we'll let it depend on the sign.We're going to-- not going to assume that we everget helped out by trades.So there's never any positive benefit to trading.If you're a market maker and you are providing liquidityto the markets, then you can make money on your trades.We're going to assume that that's not the case here.So remember that h is going to be multiplied times the tradethat we do in a given size.So that's why the constant term--we want to make sure it's going to have the appropriate sign.So it's-- we are going to lose money regardless of whetherwe're buying or selling.That's why we have the sign function there.And the other term is linear.And it's going to multiply a delta q.So we have that down here, when wesubstitute in that linear expression in the top.This is just an assumption.Eta and c1 are constant coefficients.And when we substitute that general form,we're going to get something in expression,which is the contribution to the expected cost--is something that depends on the absolute valueof the number of shares that we tradeand something that's quadratic.So if we combine those terms from the h and the g,from the temporary and the permanent,we find that our expected cost isgoing to have term that's going to be constantplus a term that's linear with an absolute valueplus a term that's quadratic.If all the terms have the same sign,then we can drop the absolute value.That's assuming, as in the little grid examplewe had, that we're not changing directions--that if we want to sell shares, our strategy is not to buy someback and then resell them.That might be possible.You could imagine a scenario with asymmetric market impactwhere, if you go in the opposite direction,you fake out the market, induce a price change that'sin your favor, and then you turn around on the other side.We're going to assume that the markets don't respond that wayand you are not trying to manipulate them in such a way.So we'll remove the absolute value.And then we'll have a term which is--which now simplifies.If all of the delta q's have the same value,then we can sum them up.We get big Q. So we have a constant term in front.We've got some parameter here whose signis going to depend on the chosen parameters in the problem.And we've got something which is quadratic in delta q.

#### Opt13_S02_v1-en

PROFESSOR: So we take a look at the minimum cost solution.And we find in this case, that wedo get a solution for dividing thingsinto equal cost for the moment.But hang on, we'll generalize this in a bit.So for that very special set where all we want to dois to minimize the expected cost,we do have a solution where the trade we with each sizeis 1 Nth of the total fraction.So this is a linear trajectory that minimizes the squares thatwe had, that sum of delta Q's.And we can substitute it in.We get an expression for what the expected cost isunder this program that minimizes the total cost.The variance of this though, can be very big.So given our program for equal size,we get a very large variance.And again, this variance is goingto persist even in the limit where N goes to infinityand we have a large number of trading periods.As N goes to infinity, we've got a finite cost,which now is linear in Q. And we have a variance,which is quadratic in Q. Excuse me,the expected cost is determined it's linear and quadratic in Q, and a finite variance, even as we spread our trades outinfinitely far.Suppose we wanted a minimum variance strategy.Well, we'd dump all our shares at once.We'd incur an immediate cost.And here, our variances 0.Our market impact is going to be very big. .And our associated cost is very large.Suppose we like an optimal strategythat balances those two.Suppose we'd like to include some compensationand multi-function so that a risk-averse trader is not justgoing to be indifferent to the trading speed.So let's make it so that it's advantageous to notdelay an infinitely long amount of time.Let's assume that it's not good to allow fluctuations,even if they're equally likely to be positive or negative.And what we'd like to do is we'd like to have a lower cost,but we don't want to let the variance be arbitrarily large.So one way we could do that is wecould introduce utility function of this form.It could be the expected cost plus some function,some constant lambda, times the variance.So we get two special cases--the minimum impact response to letting lambda equals 0.We want the lowest cost.We don't care about the variance.Or we have the minimum variance by lettinglambda go to infinity, and we don'tcare about what the cost is.So for intermediate values of lambda,we're going to have a one-parameter familyof optimal trading strategies.And those are going to form an efficient trading frontier.We can solve this in closed form in, the case, linear functions,for g and h.Let's take a look at the form that those have.Our function, U, our utility functionthat we're going to extremize, isgoing to have the form of some constant times delta Q squaredplus some other constant involvingthe constants of the problem, and proportional to lambdatimes Q squared.So we're going to take a minimum with respect to Qand set it equal to 0.And we have this set of difference equationsthat comes about from the fact that we'vegot these delta Q's here in addition to the q's over here.So this is of the form of a second difference equation.This is a discrete equation, but it'sa discrete analog to something that looks like a second orderdifferential equation.So we've got this general form.We'd like to find a functional formthat solves this recursive equationand that satisfies these boundary conditions.Well, I'll tell you what it is, and you can substitute it in.You can solve for this by taking a look at guessesof particular forms or by lookingat the similar kind of cases that we havefor differential equations.But you can check the solution here,which is a linear combination of positive and negativeexponentials satisfies this second order differenceequation.And it satisfies the boundary conditions.So when t goes to 0, this is 0.When t goes to big T, this satisfies the conditionthat we have our property boundary condition.So because we're selling, when i is equal to 0,we've got N minus i is equal to Nand delta t is equal to big T, the numerator and denominatorare equal and we get Q.And we get to our terminal value,i increases linearly here.But it's not a linear function.It's inside this parabolic sine.But when we do approach not continuously,but we approach gradually, the terminal value,where the final trading value at the end, quantitythat we have left at the final valueis going to be 0, where i is equal to N and thenthe numerator is equal to 0.I've redefined the parameters because wehad this eta hat that from one of our trading functionsand lambda, which is our preference parameter.And I've wrapped those all up into a single new parametercalled kappa.It's defined by this equation.So kappa is defined through this equation,but you can see it's just a constant here.And qualitatively, we can ask whatthis trajectory looks like.So is it a set of linear slices?Do we just end up dividing our trades equally?The answer is no.We end up with something that looks a little bit differently.The trajectories are defined for each period in each lambda.And depending on whether we have positive or negative riskaversion, in this case, depending on the valuesthat we have for lambda, if we have positive risk aversion,then we'll find this lower curve,something that looks like this.That cinch function tells us thatinstead of a risk-neutral idea, wherewe would have equal trading strategies,we want to start out big and then gradually decreaseour trade size.So it turns out that there's a particular shape to this curve.It does satisfy this endpoint.So we end up with 0 at this point in time.And the speed of trading depends on the amount of risk aversionthat's in the value of lambda.So for a given set of parameters and a givenset of risk preferences, we solve an optimization problem.It gives us how we should trade over time in orderto balance the market impact that lowersor that it increases our cost of trading.And the balance is not against the risk, the uncertaintyof doing things for a longer period of timeif we were to stretch things out to tryto minimize our market impact.Finally, because this is a one-parameter family of curves,we can take a look at this.Almgren and Chriss plotted this is an efficient frontierfor trading.But we can say as a function of our parameter lambda,where do we want to be?The naive strategy at B, the equal slicing strategy,has the lowest total cost.But the efficient frontier is this one-parameter familyof strategies where there's an optimal strategyfor each value of lambda that you might choose to consider.

